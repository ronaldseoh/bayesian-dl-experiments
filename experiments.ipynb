{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23968,
     "status": "ok",
     "timestamp": 1572888905019,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "i3PGAUFJVFHI",
    "outputId": "52d5f23c-29be-47db-a142-d9a9e056f1b1"
   },
   "outputs": [],
   "source": [
    "# Google Colab-only setup. No need to run this cell in other environments.\n",
    "use_colab = False\n",
    "\n",
    "if use_colab:\n",
    "    # Mount my Google Drive root folder\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # cd to bayesian-dl-experiments directory\n",
    "    %cd 'drive/My Drive/Colab Notebooks/bayesian-dl-experiments'\n",
    "    !ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bka_bK83VFHh"
   },
   "source": [
    "## Experiment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pHbfpytEVFHu"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# IPython reloading magic\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Random seeds\n",
    "# Based on https://pytorch.org/docs/stable/notes/randomness.html\n",
    "torch.manual_seed(682)\n",
    "np.random.seed(682)\n",
    "\n",
    "# torch.device / CUDA Setup\n",
    "use_cuda = True\n",
    "\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    torch_device = torch.device('cuda')\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    # Note: https://discuss.pytorch.org/t/what-does-torch-backends-cudnn-benchmark-do/5936\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "else:\n",
    "    torch_device = torch.device('cpu')\n",
    "\n",
    "# Dataset to use\n",
    "dataset_name = 'yacht'\n",
    "\n",
    "# Training set size\n",
    "dataset_train_size = 0.8\n",
    "\n",
    "# L2 regularization strength\n",
    "reg_strength = 0.01\n",
    "\n",
    "# Epochs\n",
    "n_epochs = 10\n",
    "\n",
    "# Number of different data splits to try\n",
    "n_splits = 2\n",
    "\n",
    "# Data batch sizes\n",
    "n_training_batch = 10\n",
    "\n",
    "# Number of test predictions (for each data point)\n",
    "n_predictions = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sZwe_f-yVFIf"
   },
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eEfdrHcOVFIj"
   },
   "source": [
    "### Get the data as a torch Dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29318,
     "status": "ok",
     "timestamp": 1572888910387,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "5u5qU-9JVFIr",
    "outputId": "53f78ffd-3926-4103-d351-872d40b045d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./datasets_files/yacht/yacht_hydrodynamics.data\n",
      "dataset size = torch.Size([308, 7])\n",
      "training set size = 246\n",
      "testing set size = 62\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "from ronald_bdl import datasets\n",
    "\n",
    "if dataset_name == 'MNIST':\n",
    "    dataset = datasets.MNIST(root_dir='./datasets_files', transform=None, download=True)\n",
    "else:\n",
    "    dataset = datasets.UCIDatasets(dataset_name, root_dir='./datasets_files', transform=None, download=True)\n",
    "\n",
    "train_size = int(dataset_train_size * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "    \n",
    "# Print the size of the dataset\n",
    "print(\"dataset size = \" + str(dataset.data.shape))\n",
    "print(\"training set size = \" + str(train_size))\n",
    "print(\"testing set size = \" + str(test_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LaasFWpqVFJ1"
   },
   "source": [
    "## Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 36104,
     "status": "ok",
     "timestamp": 1572888917189,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "gAqkGtg7VFJ9",
    "outputId": "21d0a1ad-457c-485d-c11b-d95dac89a385"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCNetMCDropout(\n",
      "  (input): Linear(in_features=6, out_features=100, bias=True)\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (1): Linear(in_features=100, out_features=100, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=100, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from ronald_bdl import models\n",
    "\n",
    "network = models.FCNetMCDropout(\n",
    "    input_dim=len(dataset.features), \n",
    "    output_dim=len(dataset.targets),\n",
    "    hidden_dim=100,\n",
    "    n_hidden=2,\n",
    "    dropout_rate=0.01,\n",
    ")\n",
    "\n",
    "# Send the whole model to the selected torch.device\n",
    "network.to(torch_device)\n",
    "\n",
    "# Print the network structure\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1PpzPMI8VFKE"
   },
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DuTnXABzVFKI"
   },
   "source": [
    "### Setup optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p19qFgSAVFKS"
   },
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "\n",
    "# Model to train mode\n",
    "network.train()\n",
    "\n",
    "# Mean Squared Error for loss function to minimize\n",
    "objective = nn.MSELoss()\n",
    "\n",
    "# Adam optimizer\n",
    "# https://pytorch.org/docs/stable/optim.html?highlight=adam#torch.optim.Adam\n",
    "# NOTE: Need to set L2 regularization from here\n",
    "optimizer = optim.Adam(\n",
    "    network.parameters(),\n",
    "    lr=0.01, \n",
    "    weight_decay=reg_strength # L2 regularization\n",
    ")\n",
    "\n",
    "rmse_non_mc, rmse_mc, test_lls_mc = [], [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jc7Td1h1VFKb"
   },
   "source": [
    "### Train/test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 38058,
     "status": "ok",
     "timestamp": 1572888919158,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "m4kavCiTVFKf",
    "outputId": "f0642c31-f41f-4cc3-cf7f-22a496b86861",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running split 0, epoch 0\n",
      "Running split 0, epoch 1\n",
      "Running split 0, epoch 2\n",
      "Running split 0, epoch 3\n",
      "Running split 0, epoch 4\n",
      "Running split 0, epoch 5\n",
      "Running split 0, epoch 6\n",
      "Running split 0, epoch 7\n",
      "Running split 0, epoch 8\n",
      "Running split 0, epoch 9\n",
      "\n",
      "Running split 0 test:\n",
      "Mean = tensor([[ 93.8531],\n",
      "        [ 89.6675],\n",
      "        [ 67.5957],\n",
      "        [ 62.2736],\n",
      "        [ 40.5143],\n",
      "        [ 45.0080],\n",
      "        [ 81.6247],\n",
      "        [ 82.1640],\n",
      "        [102.0260],\n",
      "        [ 61.2794],\n",
      "        [ 70.5819],\n",
      "        [100.4111],\n",
      "        [ 63.1331],\n",
      "        [ 70.6257],\n",
      "        [115.0932],\n",
      "        [126.1112],\n",
      "        [ 78.4996],\n",
      "        [ 97.8473],\n",
      "        [ 90.9057],\n",
      "        [ 58.2732],\n",
      "        [ 93.8544],\n",
      "        [ 59.0250],\n",
      "        [ 36.0878],\n",
      "        [ 72.8479],\n",
      "        [107.6530],\n",
      "        [100.9108],\n",
      "        [109.9260],\n",
      "        [ 72.1726],\n",
      "        [ 64.3754],\n",
      "        [ 72.3660],\n",
      "        [ 86.0217],\n",
      "        [ 65.4583],\n",
      "        [ 75.4726],\n",
      "        [ 81.6691],\n",
      "        [ 50.7310],\n",
      "        [ 75.2734],\n",
      "        [ 50.0252],\n",
      "        [100.0667],\n",
      "        [ 55.5979],\n",
      "        [ 85.4006],\n",
      "        [ 73.7417],\n",
      "        [ 90.4057],\n",
      "        [ 73.6228],\n",
      "        [ 97.0552],\n",
      "        [ 43.6001],\n",
      "        [106.6072],\n",
      "        [ 80.5173],\n",
      "        [ 36.1234],\n",
      "        [ 71.3889],\n",
      "        [111.0373],\n",
      "        [ 67.4200],\n",
      "        [105.0455],\n",
      "        [ 90.7150],\n",
      "        [105.1062],\n",
      "        [101.7463],\n",
      "        [ 90.1846],\n",
      "        [131.5695],\n",
      "        [ 89.4590],\n",
      "        [ 51.3064],\n",
      "        [ 86.9755],\n",
      "        [ 91.5264],\n",
      "        [ 92.6675]])\n",
      "Variance = tensor([[12166.7549],\n",
      "        [13823.3721],\n",
      "        [14742.7979],\n",
      "        [16091.0938],\n",
      "        [10436.8955],\n",
      "        [10713.6582],\n",
      "        [19676.2598],\n",
      "        [12876.0781],\n",
      "        [25090.6523],\n",
      "        [20626.7500],\n",
      "        [13680.5635],\n",
      "        [12411.0566],\n",
      "        [20770.2227],\n",
      "        [10316.1006],\n",
      "        [25915.2539],\n",
      "        [17683.5781],\n",
      "        [12895.6445],\n",
      "        [26468.4121],\n",
      "        [13393.0410],\n",
      "        [21018.3730],\n",
      "        [19630.0391],\n",
      "        [15485.1904],\n",
      "        [13263.5723],\n",
      "        [21067.7793],\n",
      "        [25637.8887],\n",
      "        [12691.4941],\n",
      "        [12435.2852],\n",
      "        [10454.7803],\n",
      "        [13423.6650],\n",
      "        [21315.6367],\n",
      "        [12495.2783],\n",
      "        [14264.4414],\n",
      "        [15297.7939],\n",
      "        [19457.1895],\n",
      "        [13781.6104],\n",
      "        [20597.3633],\n",
      "        [10431.8486],\n",
      "        [27498.1504],\n",
      "        [16223.1006],\n",
      "        [13413.0615],\n",
      "        [12863.9219],\n",
      "        [28396.7305],\n",
      "        [21006.1426],\n",
      "        [12378.0391],\n",
      "        [15499.6650],\n",
      "        [18479.6055],\n",
      "        [13705.2207],\n",
      "        [13372.0596],\n",
      "        [18716.2031],\n",
      "        [25243.1211],\n",
      "        [12850.9990],\n",
      "        [12428.3457],\n",
      "        [24614.2734],\n",
      "        [12760.0801],\n",
      "        [15564.7285],\n",
      "        [19558.1699],\n",
      "        [17716.3125],\n",
      "        [ 9852.0518],\n",
      "        [20498.6152],\n",
      "        [14526.3848],\n",
      "        [13274.7031],\n",
      "        [20868.6934]])\n",
      "rmse_mc = tensor(74.5744)\n",
      "rmse_non_mc = tensor(168.4649)\n",
      "test_ll_mc = tensor(-6.2105)\n",
      "\n",
      "Running split 1, epoch 0\n",
      "Running split 1, epoch 1\n",
      "Running split 1, epoch 2\n",
      "Running split 1, epoch 3\n",
      "Running split 1, epoch 4\n",
      "Running split 1, epoch 5\n",
      "Running split 1, epoch 6\n",
      "Running split 1, epoch 7\n",
      "Running split 1, epoch 8\n",
      "Running split 1, epoch 9\n",
      "\n",
      "Running split 1 test:\n",
      "Mean = tensor([[  0.2257],\n",
      "        [ 85.7293],\n",
      "        [-21.2667],\n",
      "        [ 89.7661],\n",
      "        [  5.4617],\n",
      "        [ 37.3083],\n",
      "        [ 10.6652],\n",
      "        [ 38.9386],\n",
      "        [ 32.3252],\n",
      "        [-12.5209],\n",
      "        [ 12.8580],\n",
      "        [ 29.7223],\n",
      "        [ 36.8695],\n",
      "        [ 52.3284],\n",
      "        [ 21.9263],\n",
      "        [ 46.2489],\n",
      "        [ 90.6717],\n",
      "        [ 15.3276],\n",
      "        [ 31.1882],\n",
      "        [ 75.9630],\n",
      "        [ 38.2448],\n",
      "        [ 53.2823],\n",
      "        [ 20.6714],\n",
      "        [ 19.3099],\n",
      "        [ 59.0280],\n",
      "        [ -6.7943],\n",
      "        [ 31.6166],\n",
      "        [ 25.6514],\n",
      "        [ 28.3780],\n",
      "        [ 14.1715],\n",
      "        [ 40.9411],\n",
      "        [ 40.1965],\n",
      "        [  9.9966],\n",
      "        [  4.8539],\n",
      "        [ 35.2616],\n",
      "        [ 41.7282],\n",
      "        [  7.3230],\n",
      "        [ 76.2854],\n",
      "        [ 21.0355],\n",
      "        [  5.0891],\n",
      "        [  6.3374],\n",
      "        [ 83.0161],\n",
      "        [  2.2230],\n",
      "        [ 93.7548],\n",
      "        [ 40.6765],\n",
      "        [ -8.3380],\n",
      "        [ 14.2048],\n",
      "        [ 31.6921],\n",
      "        [ 20.0966],\n",
      "        [ 41.9346],\n",
      "        [ 22.8479],\n",
      "        [-13.3288],\n",
      "        [ 53.1846],\n",
      "        [ 14.1032],\n",
      "        [ -6.4062],\n",
      "        [ 66.4816],\n",
      "        [ 27.9492],\n",
      "        [  1.0949],\n",
      "        [ 41.7620],\n",
      "        [ 14.8837],\n",
      "        [ 60.1378],\n",
      "        [ -9.9161]])\n",
      "Variance = tensor([[ 3041.7375],\n",
      "        [ 8185.6226],\n",
      "        [ 6914.2178],\n",
      "        [ 8837.9912],\n",
      "        [ 3375.0063],\n",
      "        [ 3348.0845],\n",
      "        [ 3166.4470],\n",
      "        [ 2978.3716],\n",
      "        [ 2989.0449],\n",
      "        [ 6888.6431],\n",
      "        [ 3922.2825],\n",
      "        [ 9597.7666],\n",
      "        [ 3490.7302],\n",
      "        [ 3952.9272],\n",
      "        [ 3360.5586],\n",
      "        [ 9636.0732],\n",
      "        [ 7758.2275],\n",
      "        [ 3333.4414],\n",
      "        [ 4026.5410],\n",
      "        [ 6212.8662],\n",
      "        [ 3846.1814],\n",
      "        [ 5982.1353],\n",
      "        [ 3571.0022],\n",
      "        [ 3284.1326],\n",
      "        [ 8270.0967],\n",
      "        [ 6938.5620],\n",
      "        [ 4031.2998],\n",
      "        [ 7926.9365],\n",
      "        [ 3315.5442],\n",
      "        [ 6482.6040],\n",
      "        [ 8359.1455],\n",
      "        [ 3864.4768],\n",
      "        [ 6942.8643],\n",
      "        [ 3260.7375],\n",
      "        [ 2955.0994],\n",
      "        [ 9851.1357],\n",
      "        [ 3668.6462],\n",
      "        [ 7721.6445],\n",
      "        [ 3053.0068],\n",
      "        [ 3868.3044],\n",
      "        [ 3243.9329],\n",
      "        [ 6180.5132],\n",
      "        [ 6330.2295],\n",
      "        [ 8648.7490],\n",
      "        [ 3523.3684],\n",
      "        [ 6467.4390],\n",
      "        [ 6475.5786],\n",
      "        [ 4955.5347],\n",
      "        [ 3443.1692],\n",
      "        [ 3257.5442],\n",
      "        [10005.6699],\n",
      "        [ 6734.3247],\n",
      "        [ 3612.8831],\n",
      "        [ 3796.4739],\n",
      "        [ 6511.0591],\n",
      "        [ 6279.0083],\n",
      "        [ 3578.7102],\n",
      "        [ 6885.2412],\n",
      "        [ 9390.3799],\n",
      "        [ 4050.0916],\n",
      "        [ 9220.6865],\n",
      "        [ 3161.7207]])\n",
      "rmse_mc = tensor(29.5239)\n",
      "rmse_non_mc = tensor(73.0014)\n",
      "test_ll_mc = tensor(-5.1281)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in range(n_splits):\n",
    "\n",
    "    # Prepare new train-test split\n",
    "    train, test = random_split(dataset, lengths=[train_size, test_size])\n",
    "    train_loader = DataLoader(train, batch_size=n_training_batch)\n",
    "    \n",
    "    # Training\n",
    "    for epoch in range(n_epochs): # loop over the dataset multiple times\n",
    "\n",
    "        print(\"Running split \" + str(s) + \", epoch \" + str(epoch))\n",
    "\n",
    "        for i, data in enumerate(train_loader):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, targets = data\n",
    "\n",
    "            # Store the batch to torch_device's memory\n",
    "            inputs = inputs.to(torch_device)\n",
    "            targets = targets.to(torch_device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = network(inputs)\n",
    "\n",
    "            loss = objective(outputs, targets)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            \n",
    "    # Testing\n",
    "\n",
    "    # Model to eval mode\n",
    "    network.eval()\n",
    "\n",
    "    # Get the test data\n",
    "    inputs, targets = test.dataset[test.indices]\n",
    "\n",
    "    # Store the batch to torch_device's memory\n",
    "    inputs = inputs.to(torch_device)\n",
    "    targets = targets.to(torch_device)\n",
    "\n",
    "    predictions, mean, var, metrics = network.mc_predict(inputs, n_predictions,\n",
    "                                                         y_test=targets, reg_strength=reg_strength)\n",
    "\n",
    "    print()\n",
    "    print(\"Running split \" + str(s) + \" test:\")\n",
    "    print(\"Mean = \" + str(mean))\n",
    "    print(\"Variance = \" + str(var))\n",
    "\n",
    "    # Print and store additional metrics\n",
    "    if len(metrics) > 0:\n",
    "        for key, value in metrics.items():\n",
    "            print(str(key) + \" = \" + str(value))\n",
    "\n",
    "            if key == 'rmse_mc': rmse_mc.append(value)\n",
    "            elif key == 'rmse_non_mc': rmse_non_mc.append(value)\n",
    "            elif key == 'test_ll_mc': test_lls_mc.append(value)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PB4HFH9MVFK3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-MC RMSE 7.631426 +- 2.625468 (stddev) +- 1.856486 (std error), median 7.631426 25p 6.318692 75p 8.944160 \n",
      "\n",
      "MC RMSE 7.684747 +- 2.574000 (stddev) +- 1.820093 (std error), median 7.684747 25p 6.397747 75p 8.971747 \n",
      "\n",
      "MC Test Log-likelihood -3.552364 +- 0.194530 (stddev) +- 0.137554 (std error), median -3.552364 25p -3.649629 75p -3.455099 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Copied from DropoutUncertaintyExps repo\n",
    "print('non-MC RMSE %f +- %f (stddev) +- %f (std error), median %f 25p %f 75p %f \\n' % (\n",
    "        np.mean(rmse_non_mc), np.std(rmse_non_mc), np.std(rmse_non_mc)/np.sqrt(n_splits),\n",
    "        np.percentile(rmse_non_mc, 50), np.percentile(rmse_non_mc, 25), np.percentile(rmse_non_mc, 75)))\n",
    "\n",
    "print('MC RMSE %f +- %f (stddev) +- %f (std error), median %f 25p %f 75p %f \\n' % (\n",
    "        np.mean(rmse_mc), np.std(rmse_mc), np.std(rmse_mc)/np.sqrt(n_splits),\n",
    "        np.percentile(rmse_mc, 50), np.percentile(rmse_mc, 25), np.percentile(rmse_mc, 75)))\n",
    "\n",
    "print('MC Test Log-likelihood %f +- %f (stddev) +- %f (std error), median %f 25p %f 75p %f \\n' % (\n",
    "        np.mean(test_lls_mc), np.std(test_lls_mc), np.std(test_lls_mc)/np.sqrt(n_splits), \n",
    "        np.percentile(test_lls_mc, 50), np.percentile(test_lls_mc, 25), np.percentile(test_lls_mc, 75)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "experiments.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
