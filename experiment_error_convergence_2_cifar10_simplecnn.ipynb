{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bka_bK83VFHh"
   },
   "source": [
    "## Experiment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8D5NSPs_cJZe"
   },
   "source": [
    "### Random seed / PyTorch / CUDA related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5979,
     "status": "ok",
     "timestamp": 1575227654566,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "pHbfpytEVFHu",
    "outputId": "fc6e59f5-fe07-4f25-b85a-0c465d4a7fb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Requirement already satisfied: pyro-ppl in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
      "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (1.3.1)\n",
      "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (4.40.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (3.1.0)\n",
      "Requirement already satisfied: graphviz>=0.8 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (1.17.4)\n",
      "Requirement already satisfied: pyro-api>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (0.1.1)\n",
      "/content/drive/My Drive/Colab Notebooks/bayesian-dl-experiments\n",
      "datasets_files\n",
      "experiment_comparison_toy.ipynb\n",
      "experiment_error_convergence_1_uci_fcnet.ipynb\n",
      "experiment_error_convergence_2_cifar10_simplecnn.ipynb\n",
      "experiment_number_of_test_predictions_1_uci_fcnet.ipynb\n",
      "experiment_number_of_test_predictions_2_cifar10_simplecnn.ipynb\n",
      "LICENSE\n",
      "README.md\n",
      "ronald_bdl\n",
      "test_results\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "\n",
    "# Use Google Colab\n",
    "use_colab = True\n",
    "\n",
    "# Is this notebook running on Colab?\n",
    "# If so, then google.colab package (github.com/googlecolab/colabtools)\n",
    "# should be available in this environment\n",
    "\n",
    "# Previous version used importlib, but we could do the same thing with\n",
    "# just attempting to import google.colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    colab_available = True\n",
    "except:\n",
    "    colab_available = False\n",
    "\n",
    "if use_colab and colab_available:\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # If there's a package I need to install separately, do it here\n",
    "    !pip install pyro-ppl\n",
    "\n",
    "    # cd to the appropriate working directory under my Google Drive\n",
    "    %cd 'drive/My Drive/Colab Notebooks/bayesian-dl-experiments'\n",
    "    \n",
    "    # List the directory contents\n",
    "    !ls\n",
    "\n",
    "# IPython reloading magic\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Random seeds\n",
    "# Based on https://pytorch.org/docs/stable/notes/randomness.html\n",
    "random_seed = 682"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tqlpuws9Y-8U"
   },
   "source": [
    "### Third party libraries (NumPy, PyTorch, Pyro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6455,
     "status": "ok",
     "timestamp": 1575227655051,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "2zNVvKmZY-8X",
    "outputId": "e36d839c-aea0-4560-d542-9290e420c9fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.6.8 (default, Oct  7 2019, 12:59:55) \n",
      "[GCC 8.3.0]\n",
      "NumPy Version: 1.17.4\n",
      "PyTorch Version: 1.3.1\n",
      "Pyro Version: 1.0.0\n"
     ]
    }
   ],
   "source": [
    "# Third party libraries import\n",
    "import numpy as np\n",
    "import torch\n",
    "import pyro\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Print version information\n",
    "print(\"Python Version: \" + sys.version)\n",
    "print(\"NumPy Version: \" + np.__version__)\n",
    "print(\"PyTorch Version: \" + torch.__version__)\n",
    "print(\"Pyro Version: \" + pyro.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6992,
     "status": "ok",
     "timestamp": 1575227655599,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "uyRIfCC5Y-8g",
    "outputId": "8f130afa-cd6e-4ee3-bc0a-dbd6af2c8070"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Version: 10.1.243\n",
      "cuDNN Version: 7603\n",
      "CUDA Device Name: Tesla K80\n",
      "CUDA Capabilities: (3, 7)\n"
     ]
    }
   ],
   "source": [
    "# More imports...\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import random_split, DataLoader, RandomSampler\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from pyro.infer import SVI, Trace_ELBO, HMC, MCMC\n",
    "\n",
    "# Import model and dataset classes from ronald_bdl\n",
    "from ronald_bdl import models, datasets\n",
    "\n",
    "# pyplot setting\n",
    "%matplotlib inline\n",
    "\n",
    "# torch.device / CUDA Setup\n",
    "use_cuda = True\n",
    "\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    torch_device = torch.device('cuda')\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    # Disable 'benchmark' mode\n",
    "    # Note: https://discuss.pytorch.org/t/what-does-torch-backends-cudnn-benchmark-do/5936\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    use_pin_memory = True # Faster Host to GPU copies with page-locked memory\n",
    "\n",
    "    # CUDA libraries version information\n",
    "    print(\"CUDA Version: \" + str(torch.version.cuda))\n",
    "    print(\"cuDNN Version: \" + str(torch.backends.cudnn.version()))\n",
    "    print(\"CUDA Device Name: \" + str(torch.cuda.get_device_name()))\n",
    "    print(\"CUDA Capabilities: \"+ str(torch.cuda.get_device_capability()))\n",
    "else:\n",
    "    torch_device = torch.device('cpu')\n",
    "    use_pin_memory = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XIFRoH3AcJZn"
   },
   "source": [
    "### Variable settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DGRg2u0Q_I3n"
   },
   "source": [
    "#### Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f2gc_i7T_HVw"
   },
   "outputs": [],
   "source": [
    "# CIFAR10 data transformation setting\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Set the proportion of the original dataset to be available as a whole\n",
    "subset_proportions = [0.05]\n",
    "\n",
    "# Proportion of the dataset to be used for training\n",
    "dataset_train_size = 0.8\n",
    "\n",
    "# Number of dataset splits\n",
    "n_splits = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fzxIZiUcA8D8"
   },
   "source": [
    "#### NN settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g_pzGq1_cJZp"
   },
   "outputs": [],
   "source": [
    "# Dropout\n",
    "dropout_rates = [0.1, 0.3, 0.5]\n",
    "\n",
    "# Regularization strengths\n",
    "reg_strengths = [0.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DuTnXABzVFKI"
   },
   "source": [
    "\n",
    "### Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 830,
     "status": "ok",
     "timestamp": 1575227752260,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "p19qFgSAVFKS",
    "outputId": "3895eaea-67d8-4780-91f5-8d4be308a397"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201912011915\n"
     ]
    }
   ],
   "source": [
    "# Epochs\n",
    "n_epochs = [10, 100, 500]\n",
    "\n",
    "# Optimizer learning rate\n",
    "optimizer_learning_rate = 0.001 # PyTorch default value is 0.001\n",
    "\n",
    "# Optimizer momenutm\n",
    "optimizer_momentum = 0.9\n",
    "\n",
    "# Training data batch sizes\n",
    "n_training_batch = 64\n",
    "\n",
    "# Number of test predictions (for each data point)\n",
    "n_prediction = 500\n",
    "\n",
    "# Cross Entropy to minimize\n",
    "objective = nn.CrossEntropyLoss()\n",
    "\n",
    "# Test start time\n",
    "test_start_time = datetime.datetime.today().strftime('%Y%m%d%H%M')\n",
    "\n",
    "print(test_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1PpzPMI8VFKE"
   },
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11504639,
     "status": "error",
     "timestamp": 1575239261379,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "m4kavCiTVFKf",
    "outputId": "02b9b726-8f0d-47e0-d92e-d86d31bd2dd1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subset 0.050000, dropout_rate 0.100000, reg_strength 0.050000\n",
      "n_epoch 10\n",
      "\n",
      "Files already downloaded and verified\n",
      "subset size = (2500, 32, 32, 3)\n",
      "training set size = 2000\n",
      "test set size = 500\n",
      "\n",
      "Training with split 0\n",
      "epoch 0 loss = 2.287264\n",
      "epoch 1 loss = 2.169008\n",
      "epoch 2 loss = 2.065376\n",
      "epoch 3 loss = 2.059536\n",
      "epoch 4 loss = 2.064392\n",
      "epoch 5 loss = 2.060936\n",
      "epoch 6 loss = 1.993528\n",
      "epoch 7 loss = 1.945353\n",
      "epoch 8 loss = 1.789426\n",
      "epoch 9 loss = 1.954190\n",
      "final loss = 1.954190\n",
      "accuracy_mc = tensor(0.2669, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2799, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.9391, device='cuda:0')\n",
      "training time = 6.145179748535156 seconds\n",
      "testing time = 3.3558475971221924 seconds\n",
      "\n",
      "Training with split 1\n",
      "epoch 0 loss = 2.218683\n",
      "epoch 1 loss = 2.057780\n",
      "epoch 2 loss = 1.961197\n",
      "epoch 3 loss = 2.064317\n",
      "epoch 4 loss = 1.935919\n",
      "epoch 5 loss = 1.862661\n",
      "epoch 6 loss = 1.843862\n",
      "epoch 7 loss = 1.835509\n",
      "epoch 8 loss = 1.835636\n",
      "epoch 9 loss = 1.818727\n",
      "final loss = 1.818727\n",
      "accuracy_mc = tensor(0.2779, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2889, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.8240, device='cuda:0')\n",
      "training time = 6.149224519729614 seconds\n",
      "testing time = 3.2855260372161865 seconds\n",
      "\n",
      "Training with split 2\n",
      "epoch 0 loss = 2.171865\n",
      "epoch 1 loss = 2.032576\n",
      "epoch 2 loss = 1.976232\n",
      "epoch 3 loss = 1.951283\n",
      "epoch 4 loss = 1.915828\n",
      "epoch 5 loss = 1.991851\n",
      "epoch 6 loss = 1.905324\n",
      "epoch 7 loss = 1.956152\n",
      "epoch 8 loss = 1.923304\n",
      "epoch 9 loss = 1.854198\n",
      "final loss = 1.854198\n",
      "accuracy_mc = tensor(0.2695, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2701, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.9949, device='cuda:0')\n",
      "training time = 6.208892345428467 seconds\n",
      "testing time = 3.179459810256958 seconds\n",
      "\n",
      "Training with split 3\n",
      "epoch 0 loss = 2.222513\n",
      "epoch 1 loss = 2.058137\n",
      "epoch 2 loss = 1.963916\n",
      "epoch 3 loss = 2.003280\n",
      "epoch 4 loss = 1.960456\n",
      "epoch 5 loss = 1.777712\n",
      "epoch 6 loss = 1.886051\n",
      "epoch 7 loss = 1.870540\n",
      "epoch 8 loss = 1.762552\n",
      "epoch 9 loss = 1.834425\n",
      "final loss = 1.834425\n",
      "accuracy_mc = tensor(0.2832, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2808, device='cuda:0')\n",
      "test_ll_mc = tensor(-2.0228, device='cuda:0')\n",
      "training time = 6.289247989654541 seconds\n",
      "testing time = 3.235114336013794 seconds\n",
      "\n",
      "Training with split 4\n",
      "epoch 0 loss = 2.095388\n",
      "epoch 1 loss = 2.114188\n",
      "epoch 2 loss = 1.956360\n",
      "epoch 3 loss = 1.890110\n",
      "epoch 4 loss = 1.909372\n",
      "epoch 5 loss = 1.893992\n",
      "epoch 6 loss = 1.794811\n",
      "epoch 7 loss = 1.819513\n",
      "epoch 8 loss = 1.752186\n",
      "epoch 9 loss = 1.821314\n",
      "final loss = 1.821314\n",
      "accuracy_mc = tensor(0.3535, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.3517, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.9026, device='cuda:0')\n",
      "training time = 6.130201101303101 seconds\n",
      "testing time = 3.1609303951263428 seconds\n",
      "\n",
      "Training with split 5\n",
      "epoch 0 loss = 2.264089\n",
      "epoch 1 loss = 2.224543\n",
      "epoch 2 loss = 2.165225\n",
      "epoch 3 loss = 2.143568\n",
      "epoch 4 loss = 2.084915\n",
      "epoch 5 loss = 2.155885\n",
      "epoch 6 loss = 1.904337\n",
      "epoch 7 loss = 2.048876\n",
      "epoch 8 loss = 2.004627\n",
      "epoch 9 loss = 2.023072\n",
      "final loss = 2.023072\n",
      "accuracy_mc = tensor(0.3417, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.3570, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.9267, device='cuda:0')\n",
      "training time = 6.1702940464019775 seconds\n",
      "testing time = 3.20271635055542 seconds\n",
      "\n",
      "Training with split 6\n",
      "epoch 0 loss = 2.214921\n",
      "epoch 1 loss = 2.190548\n",
      "epoch 2 loss = 2.291926\n",
      "epoch 3 loss = 2.217463\n",
      "epoch 4 loss = 2.272284\n",
      "epoch 5 loss = 2.256649\n",
      "epoch 6 loss = 2.101862\n",
      "epoch 7 loss = 2.029491\n",
      "epoch 8 loss = 2.119029\n",
      "epoch 9 loss = 2.035464\n",
      "final loss = 2.035464\n",
      "accuracy_mc = tensor(0.2798, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2758, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.8749, device='cuda:0')\n",
      "training time = 6.122800350189209 seconds\n",
      "testing time = 3.182973861694336 seconds\n",
      "\n",
      "Training with split 7\n",
      "epoch 0 loss = 2.193600\n",
      "epoch 1 loss = 2.113150\n",
      "epoch 2 loss = 1.945522\n",
      "epoch 3 loss = 2.031307\n",
      "epoch 4 loss = 2.050291\n",
      "epoch 5 loss = 1.963434\n",
      "epoch 6 loss = 1.923381\n",
      "epoch 7 loss = 2.025070\n",
      "epoch 8 loss = 1.835774\n",
      "epoch 9 loss = 1.993467\n",
      "final loss = 1.993467\n",
      "accuracy_mc = tensor(0.3266, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.3076, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.8895, device='cuda:0')\n",
      "training time = 6.18681788444519 seconds\n",
      "testing time = 3.1853041648864746 seconds\n",
      "\n",
      "Training with split 8\n",
      "epoch 0 loss = 2.246423\n",
      "epoch 1 loss = 2.190703\n",
      "epoch 2 loss = 2.224169\n",
      "epoch 3 loss = 1.972028\n",
      "epoch 4 loss = 1.899778\n",
      "epoch 5 loss = 1.893902\n",
      "epoch 6 loss = 1.855610\n",
      "epoch 7 loss = 1.910776\n",
      "epoch 8 loss = 1.914080\n",
      "epoch 9 loss = 1.840044\n",
      "final loss = 1.840044\n",
      "accuracy_mc = tensor(0.3136, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.3295, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.9989, device='cuda:0')\n",
      "training time = 6.0981457233428955 seconds\n",
      "testing time = 3.29506516456604 seconds\n",
      "\n",
      "Training with split 9\n",
      "epoch 0 loss = 2.298957\n",
      "epoch 1 loss = 2.062334\n",
      "epoch 2 loss = 2.014978\n",
      "epoch 3 loss = 1.934358\n",
      "epoch 4 loss = 1.942879\n",
      "epoch 5 loss = 1.989051\n",
      "epoch 6 loss = 1.898356\n",
      "epoch 7 loss = 1.896403\n",
      "epoch 8 loss = 1.898992\n",
      "epoch 9 loss = 1.793830\n",
      "final loss = 1.793830\n",
      "accuracy_mc = tensor(0.3540, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.3570, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.8442, device='cuda:0')\n",
      "training time = 6.2422943115234375 seconds\n",
      "testing time = 3.175300121307373 seconds\n",
      "\n",
      "subset 0.050000, dropout_rate 0.100000, reg_strength 0.050000\n",
      "n_epoch 100\n",
      "\n",
      "Files already downloaded and verified\n",
      "subset size = (2500, 32, 32, 3)\n",
      "training set size = 2000\n",
      "test set size = 500\n",
      "\n",
      "Training with split 0\n",
      "epoch 0 loss = 2.287264\n",
      "epoch 1 loss = 2.169008\n",
      "epoch 2 loss = 2.065376\n",
      "epoch 3 loss = 2.059536\n",
      "epoch 4 loss = 2.064392\n",
      "epoch 5 loss = 2.060936\n",
      "epoch 6 loss = 1.993528\n",
      "epoch 7 loss = 1.945353\n",
      "epoch 8 loss = 1.789426\n",
      "epoch 9 loss = 1.954190\n",
      "epoch 10 loss = 1.930843\n",
      "epoch 11 loss = 1.752575\n",
      "epoch 12 loss = 1.807545\n",
      "epoch 13 loss = 1.811882\n",
      "epoch 14 loss = 1.821418\n",
      "epoch 15 loss = 1.644708\n",
      "epoch 16 loss = 1.817723\n",
      "epoch 17 loss = 1.921880\n",
      "epoch 18 loss = 1.610551\n",
      "epoch 19 loss = 1.880772\n",
      "epoch 20 loss = 1.781973\n",
      "epoch 21 loss = 1.795143\n",
      "epoch 22 loss = 1.668130\n",
      "epoch 23 loss = 1.693227\n",
      "epoch 24 loss = 1.573176\n",
      "epoch 25 loss = 1.690201\n",
      "epoch 26 loss = 1.563359\n",
      "epoch 27 loss = 1.696444\n",
      "epoch 28 loss = 1.636100\n",
      "epoch 29 loss = 1.752537\n",
      "epoch 30 loss = 1.666635\n",
      "epoch 31 loss = 1.582765\n",
      "epoch 32 loss = 1.630029\n",
      "epoch 33 loss = 1.683898\n",
      "epoch 34 loss = 1.527934\n",
      "epoch 35 loss = 1.691844\n",
      "epoch 36 loss = 1.690298\n",
      "epoch 37 loss = 1.421870\n",
      "epoch 38 loss = 1.621978\n",
      "epoch 39 loss = 1.524459\n",
      "epoch 40 loss = 1.418278\n",
      "epoch 41 loss = 1.476486\n",
      "epoch 42 loss = 1.677721\n",
      "epoch 43 loss = 1.565547\n",
      "epoch 44 loss = 1.502619\n",
      "epoch 45 loss = 1.582294\n",
      "epoch 46 loss = 1.563985\n",
      "epoch 47 loss = 1.311425\n",
      "epoch 48 loss = 1.536651\n",
      "epoch 49 loss = 1.451827\n",
      "epoch 50 loss = 1.567356\n",
      "epoch 51 loss = 1.442138\n",
      "epoch 52 loss = 1.490723\n",
      "epoch 53 loss = 1.513491\n",
      "epoch 54 loss = 1.435766\n",
      "epoch 55 loss = 1.365576\n",
      "epoch 56 loss = 1.590530\n",
      "epoch 57 loss = 1.465492\n",
      "epoch 58 loss = 1.474452\n",
      "epoch 59 loss = 1.399219\n",
      "epoch 60 loss = 1.423291\n",
      "epoch 61 loss = 1.336793\n",
      "epoch 62 loss = 1.664128\n",
      "epoch 63 loss = 1.409643\n",
      "epoch 64 loss = 1.289296\n",
      "epoch 65 loss = 1.290467\n",
      "epoch 66 loss = 1.466760\n",
      "epoch 67 loss = 1.481539\n",
      "epoch 68 loss = 1.505183\n",
      "epoch 69 loss = 1.457718\n",
      "epoch 70 loss = 1.587351\n",
      "epoch 71 loss = 1.715492\n",
      "epoch 72 loss = 1.363548\n",
      "epoch 73 loss = 1.336152\n",
      "epoch 74 loss = 1.379774\n",
      "epoch 75 loss = 1.533822\n",
      "epoch 76 loss = 1.317574\n",
      "epoch 77 loss = 1.412674\n",
      "epoch 78 loss = 1.522626\n",
      "epoch 79 loss = 1.370260\n",
      "epoch 80 loss = 1.297417\n",
      "epoch 81 loss = 1.518190\n",
      "epoch 82 loss = 1.213132\n",
      "epoch 83 loss = 1.338683\n",
      "epoch 84 loss = 1.469978\n",
      "epoch 85 loss = 1.276591\n",
      "epoch 86 loss = 1.228788\n",
      "epoch 87 loss = 1.467560\n",
      "epoch 88 loss = 1.448918\n",
      "epoch 89 loss = 1.280705\n",
      "epoch 90 loss = 1.327704\n",
      "epoch 91 loss = 1.282759\n",
      "epoch 92 loss = 1.270894\n",
      "epoch 93 loss = 1.476522\n",
      "epoch 94 loss = 1.318606\n",
      "epoch 95 loss = 1.281642\n",
      "epoch 96 loss = 1.361493\n",
      "epoch 97 loss = 1.321288\n",
      "epoch 98 loss = 1.286946\n",
      "epoch 99 loss = 1.408356\n",
      "final loss = 1.408356\n",
      "accuracy_mc = tensor(0.2919, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.3005, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.8024, device='cuda:0')\n",
      "training time = 61.573015451431274 seconds\n",
      "testing time = 3.2409017086029053 seconds\n",
      "\n",
      "Training with split 1\n",
      "epoch 0 loss = 2.130896\n",
      "epoch 1 loss = 2.093492\n",
      "epoch 2 loss = 1.965788\n",
      "epoch 3 loss = 1.932885\n",
      "epoch 4 loss = 1.912340\n",
      "epoch 5 loss = 1.853069\n",
      "epoch 6 loss = 1.834909\n",
      "epoch 7 loss = 1.758218\n",
      "epoch 8 loss = 1.989158\n",
      "epoch 9 loss = 1.824100\n",
      "epoch 10 loss = 1.760533\n",
      "epoch 11 loss = 1.797139\n",
      "epoch 12 loss = 1.901103\n",
      "epoch 13 loss = 1.719895\n",
      "epoch 14 loss = 1.662729\n",
      "epoch 15 loss = 1.797239\n",
      "epoch 16 loss = 1.524953\n",
      "epoch 17 loss = 1.735188\n",
      "epoch 18 loss = 1.780995\n",
      "epoch 19 loss = 1.629427\n",
      "epoch 20 loss = 1.602817\n",
      "epoch 21 loss = 1.774418\n",
      "epoch 22 loss = 1.793520\n",
      "epoch 23 loss = 1.735260\n",
      "epoch 24 loss = 1.607822\n",
      "epoch 25 loss = 1.747636\n",
      "epoch 26 loss = 1.744789\n",
      "epoch 27 loss = 1.758271\n",
      "epoch 28 loss = 1.735667\n",
      "epoch 29 loss = 1.621902\n",
      "epoch 30 loss = 1.526267\n",
      "epoch 31 loss = 1.592313\n",
      "epoch 32 loss = 1.429823\n",
      "epoch 33 loss = 1.607334\n",
      "epoch 34 loss = 1.422027\n",
      "epoch 35 loss = 1.555107\n",
      "epoch 36 loss = 1.627103\n",
      "epoch 37 loss = 1.625527\n",
      "epoch 38 loss = 1.569508\n",
      "epoch 39 loss = 1.501792\n",
      "epoch 40 loss = 1.600377\n",
      "epoch 41 loss = 1.488763\n",
      "epoch 42 loss = 1.464236\n",
      "epoch 43 loss = 1.649150\n",
      "epoch 44 loss = 1.658839\n",
      "epoch 45 loss = 1.659284\n",
      "epoch 46 loss = 1.547860\n",
      "epoch 47 loss = 1.687082\n",
      "epoch 48 loss = 1.401337\n",
      "epoch 49 loss = 1.489837\n",
      "epoch 50 loss = 1.622383\n",
      "epoch 51 loss = 1.404773\n",
      "epoch 52 loss = 1.432139\n",
      "epoch 53 loss = 1.625620\n",
      "epoch 54 loss = 1.462459\n",
      "epoch 55 loss = 1.405679\n",
      "epoch 56 loss = 1.522301\n",
      "epoch 57 loss = 1.433490\n",
      "epoch 58 loss = 1.666177\n",
      "epoch 59 loss = 1.430823\n",
      "epoch 60 loss = 1.550855\n",
      "epoch 61 loss = 1.404094\n",
      "epoch 62 loss = 1.528408\n",
      "epoch 63 loss = 1.467433\n",
      "epoch 64 loss = 1.461486\n",
      "epoch 65 loss = 1.582272\n",
      "epoch 66 loss = 1.556402\n",
      "epoch 67 loss = 1.548732\n",
      "epoch 68 loss = 1.379580\n",
      "epoch 69 loss = 1.481644\n",
      "epoch 70 loss = 1.629934\n",
      "epoch 71 loss = 1.445977\n",
      "epoch 72 loss = 1.490543\n",
      "epoch 73 loss = 1.483257\n",
      "epoch 74 loss = 1.312558\n",
      "epoch 75 loss = 1.379258\n",
      "epoch 76 loss = 1.629619\n",
      "epoch 77 loss = 1.544953\n",
      "epoch 78 loss = 1.582097\n",
      "epoch 79 loss = 1.334785\n",
      "epoch 80 loss = 1.445743\n",
      "epoch 81 loss = 1.474627\n",
      "epoch 82 loss = 1.548492\n",
      "epoch 83 loss = 1.446103\n",
      "epoch 84 loss = 1.484432\n",
      "epoch 85 loss = 1.737743\n",
      "epoch 86 loss = 1.385277\n",
      "epoch 87 loss = 1.648832\n",
      "epoch 88 loss = 1.473685\n",
      "epoch 89 loss = 1.395033\n",
      "epoch 90 loss = 1.515894\n",
      "epoch 91 loss = 1.712435\n",
      "epoch 92 loss = 1.364335\n",
      "epoch 93 loss = 1.453998\n",
      "epoch 94 loss = 1.438715\n",
      "epoch 95 loss = 1.439799\n",
      "epoch 96 loss = 1.599393\n",
      "epoch 97 loss = 1.432758\n",
      "epoch 98 loss = 1.348172\n",
      "epoch 99 loss = 1.604457\n",
      "final loss = 1.604457\n",
      "accuracy_mc = tensor(0.3830, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.3911, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.7236, device='cuda:0')\n",
      "training time = 61.35890007019043 seconds\n",
      "testing time = 3.184049367904663 seconds\n",
      "\n",
      "Training with split 2\n",
      "epoch 0 loss = 2.179335\n",
      "epoch 1 loss = 2.013197\n",
      "epoch 2 loss = 2.044296\n",
      "epoch 3 loss = 1.962875\n",
      "epoch 4 loss = 1.927752\n",
      "epoch 5 loss = 1.941213\n",
      "epoch 6 loss = 1.842333\n",
      "epoch 7 loss = 1.871482\n",
      "epoch 8 loss = 1.818111\n",
      "epoch 9 loss = 1.882670\n",
      "epoch 10 loss = 1.849234\n",
      "epoch 11 loss = 1.803402\n",
      "epoch 12 loss = 1.824494\n",
      "epoch 13 loss = 1.782408\n",
      "epoch 14 loss = 1.864113\n",
      "epoch 15 loss = 1.738767\n",
      "epoch 16 loss = 1.730618\n",
      "epoch 17 loss = 1.736569\n",
      "epoch 18 loss = 1.960732\n",
      "epoch 19 loss = 1.824038\n",
      "epoch 20 loss = 1.709100\n",
      "epoch 21 loss = 1.637282\n",
      "epoch 22 loss = 1.808627\n",
      "epoch 23 loss = 1.783070\n",
      "epoch 24 loss = 1.773745\n",
      "epoch 25 loss = 1.655253\n",
      "epoch 26 loss = 1.665423\n",
      "epoch 27 loss = 1.636518\n",
      "epoch 28 loss = 1.770041\n",
      "epoch 29 loss = 1.577982\n",
      "epoch 30 loss = 1.856040\n",
      "epoch 31 loss = 1.602460\n",
      "epoch 32 loss = 1.649730\n",
      "epoch 33 loss = 1.756684\n",
      "epoch 34 loss = 1.600553\n",
      "epoch 35 loss = 1.807146\n",
      "epoch 36 loss = 1.918254\n",
      "epoch 37 loss = 1.778403\n",
      "epoch 38 loss = 1.838336\n",
      "epoch 39 loss = 1.760392\n",
      "epoch 40 loss = 1.563294\n",
      "epoch 41 loss = 1.703150\n",
      "epoch 42 loss = 1.554862\n",
      "epoch 43 loss = 1.603076\n",
      "epoch 44 loss = 1.775755\n",
      "epoch 45 loss = 1.666065\n",
      "epoch 46 loss = 1.638114\n",
      "epoch 47 loss = 1.671595\n",
      "epoch 48 loss = 1.633861\n",
      "epoch 49 loss = 1.621607\n",
      "epoch 50 loss = 1.572272\n",
      "epoch 51 loss = 1.621905\n",
      "epoch 52 loss = 1.696672\n",
      "epoch 53 loss = 1.680134\n",
      "epoch 54 loss = 1.515530\n",
      "epoch 55 loss = 1.527290\n",
      "epoch 56 loss = 1.443428\n",
      "epoch 57 loss = 1.572681\n",
      "epoch 58 loss = 1.487495\n",
      "epoch 59 loss = 1.443272\n",
      "epoch 60 loss = 1.579073\n",
      "epoch 61 loss = 1.720815\n",
      "epoch 62 loss = 1.558274\n",
      "epoch 63 loss = 1.636762\n",
      "epoch 64 loss = 1.595153\n",
      "epoch 65 loss = 1.614066\n",
      "epoch 66 loss = 1.611490\n",
      "epoch 67 loss = 1.738021\n",
      "epoch 68 loss = 1.512247\n",
      "epoch 69 loss = 1.555841\n",
      "epoch 70 loss = 1.477278\n",
      "epoch 71 loss = 1.678009\n",
      "epoch 72 loss = 1.391721\n",
      "epoch 73 loss = 1.455865\n",
      "epoch 74 loss = 1.560767\n",
      "epoch 75 loss = 1.561510\n",
      "epoch 76 loss = 1.526817\n",
      "epoch 77 loss = 1.480886\n",
      "epoch 78 loss = 1.421288\n",
      "epoch 79 loss = 1.457537\n",
      "epoch 80 loss = 1.507367\n",
      "epoch 81 loss = 1.500210\n",
      "epoch 82 loss = 1.416970\n",
      "epoch 83 loss = 1.448471\n",
      "epoch 84 loss = 1.465049\n",
      "epoch 85 loss = 1.520349\n",
      "epoch 86 loss = 1.604044\n",
      "epoch 87 loss = 1.428006\n",
      "epoch 88 loss = 1.424742\n",
      "epoch 89 loss = 1.413640\n",
      "epoch 90 loss = 1.381231\n",
      "epoch 91 loss = 1.440295\n",
      "epoch 92 loss = 1.459800\n",
      "epoch 93 loss = 1.459070\n",
      "epoch 94 loss = 1.442015\n",
      "epoch 95 loss = 1.619305\n",
      "epoch 96 loss = 1.393121\n",
      "epoch 97 loss = 1.503169\n",
      "epoch 98 loss = 1.247255\n",
      "epoch 99 loss = 1.287051\n",
      "final loss = 1.287051\n",
      "accuracy_mc = tensor(0.2992, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.3023, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.7262, device='cuda:0')\n",
      "training time = 61.58479595184326 seconds\n",
      "testing time = 3.3183517456054688 seconds\n",
      "\n",
      "Training with split 3\n",
      "epoch 0 loss = 2.147730\n",
      "epoch 1 loss = 2.039446\n",
      "epoch 2 loss = 2.010424\n",
      "epoch 3 loss = 1.938412\n",
      "epoch 4 loss = 1.936285\n",
      "epoch 5 loss = 1.832843\n",
      "epoch 6 loss = 1.843340\n",
      "epoch 7 loss = 1.855661\n",
      "epoch 8 loss = 1.823789\n",
      "epoch 9 loss = 1.770921\n",
      "epoch 10 loss = 1.848956\n",
      "epoch 11 loss = 1.788673\n",
      "epoch 12 loss = 1.932401\n",
      "epoch 13 loss = 1.826272\n",
      "epoch 14 loss = 1.761863\n",
      "epoch 15 loss = 1.755510\n",
      "epoch 16 loss = 1.771632\n",
      "epoch 17 loss = 1.608049\n",
      "epoch 18 loss = 1.664033\n",
      "epoch 19 loss = 1.777696\n",
      "epoch 20 loss = 1.630578\n",
      "epoch 21 loss = 1.728762\n",
      "epoch 22 loss = 1.732855\n",
      "epoch 23 loss = 1.710569\n",
      "epoch 24 loss = 1.568758\n",
      "epoch 25 loss = 1.638625\n",
      "epoch 26 loss = 1.561232\n",
      "epoch 27 loss = 1.737895\n",
      "epoch 28 loss = 1.669835\n",
      "epoch 29 loss = 1.626140\n",
      "epoch 30 loss = 1.596569\n",
      "epoch 31 loss = 1.709750\n",
      "epoch 32 loss = 1.575918\n",
      "epoch 33 loss = 1.757745\n",
      "epoch 34 loss = 1.602239\n",
      "epoch 35 loss = 1.550123\n",
      "epoch 36 loss = 1.475386\n",
      "epoch 37 loss = 1.729284\n",
      "epoch 38 loss = 1.586751\n",
      "epoch 39 loss = 1.575334\n",
      "epoch 40 loss = 1.571487\n",
      "epoch 41 loss = 1.619762\n",
      "epoch 42 loss = 1.560700\n",
      "epoch 43 loss = 1.714716\n",
      "epoch 44 loss = 1.684873\n",
      "epoch 45 loss = 1.536790\n",
      "epoch 46 loss = 1.476136\n",
      "epoch 47 loss = 1.615222\n",
      "epoch 48 loss = 1.501327\n",
      "epoch 49 loss = 1.520905\n",
      "epoch 50 loss = 1.719297\n",
      "epoch 51 loss = 1.591749\n",
      "epoch 52 loss = 1.721992\n",
      "epoch 53 loss = 1.572599\n",
      "epoch 54 loss = 1.478750\n",
      "epoch 55 loss = 1.539488\n",
      "epoch 56 loss = 1.470432\n",
      "epoch 57 loss = 1.484873\n",
      "epoch 58 loss = 1.661384\n",
      "epoch 59 loss = 1.472076\n",
      "epoch 60 loss = 1.479214\n",
      "epoch 61 loss = 1.516917\n",
      "epoch 62 loss = 1.679601\n",
      "epoch 63 loss = 1.528019\n",
      "epoch 64 loss = 1.509061\n",
      "epoch 65 loss = 1.607738\n",
      "epoch 66 loss = 1.664540\n",
      "epoch 67 loss = 1.644569\n",
      "epoch 68 loss = 1.772822\n",
      "epoch 69 loss = 1.474405\n",
      "epoch 70 loss = 1.519316\n",
      "epoch 71 loss = 1.596365\n",
      "epoch 72 loss = 1.610506\n",
      "epoch 73 loss = 1.617036\n",
      "epoch 74 loss = 1.394283\n",
      "epoch 75 loss = 1.484906\n",
      "epoch 76 loss = 1.564595\n",
      "epoch 77 loss = 1.543413\n",
      "epoch 78 loss = 1.675893\n",
      "epoch 79 loss = 1.777229\n",
      "epoch 80 loss = 1.566893\n",
      "epoch 81 loss = 1.449101\n",
      "epoch 82 loss = 1.555043\n",
      "epoch 83 loss = 1.478710\n",
      "epoch 84 loss = 1.440387\n",
      "epoch 85 loss = 1.436323\n",
      "epoch 86 loss = 1.508713\n",
      "epoch 87 loss = 1.484897\n",
      "epoch 88 loss = 1.542167\n",
      "epoch 89 loss = 1.523956\n",
      "epoch 90 loss = 1.609800\n",
      "epoch 91 loss = 1.610476\n",
      "epoch 92 loss = 1.440518\n",
      "epoch 93 loss = 1.659147\n",
      "epoch 94 loss = 1.600488\n",
      "epoch 95 loss = 1.428061\n",
      "epoch 96 loss = 1.504400\n",
      "epoch 97 loss = 1.579298\n",
      "epoch 98 loss = 1.676878\n",
      "epoch 99 loss = 1.601563\n",
      "final loss = 1.601563\n",
      "accuracy_mc = tensor(0.3100, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.3054, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.8271, device='cuda:0')\n",
      "training time = 61.538386821746826 seconds\n",
      "testing time = 3.236621141433716 seconds\n",
      "\n",
      "Training with split 4\n",
      "epoch 0 loss = 2.140104\n",
      "epoch 1 loss = 1.948069\n",
      "epoch 2 loss = 1.907338\n",
      "epoch 3 loss = 1.882177\n",
      "epoch 4 loss = 1.804967\n",
      "epoch 5 loss = 1.937431\n",
      "epoch 6 loss = 1.758542\n",
      "epoch 7 loss = 1.869229\n",
      "epoch 8 loss = 1.812585\n",
      "epoch 9 loss = 1.777286\n",
      "epoch 10 loss = 1.950664\n",
      "epoch 11 loss = 1.819413\n",
      "epoch 12 loss = 1.656163\n",
      "epoch 13 loss = 1.687551\n",
      "epoch 14 loss = 1.820062\n",
      "epoch 15 loss = 1.877297\n",
      "epoch 16 loss = 1.705474\n",
      "epoch 17 loss = 1.688105\n",
      "epoch 18 loss = 1.731925\n",
      "epoch 19 loss = 1.657612\n",
      "epoch 20 loss = 1.718724\n",
      "epoch 21 loss = 1.536108\n",
      "epoch 22 loss = 1.757848\n",
      "epoch 23 loss = 1.638546\n",
      "epoch 24 loss = 1.668074\n",
      "epoch 25 loss = 1.629974\n",
      "epoch 26 loss = 1.754019\n",
      "epoch 27 loss = 1.592390\n",
      "epoch 28 loss = 1.737479\n",
      "epoch 29 loss = 1.730716\n",
      "epoch 30 loss = 1.583389\n",
      "epoch 31 loss = 1.740783\n",
      "epoch 32 loss = 1.674060\n",
      "epoch 33 loss = 1.522009\n",
      "epoch 34 loss = 1.589549\n",
      "epoch 35 loss = 1.659713\n",
      "epoch 36 loss = 1.594014\n",
      "epoch 37 loss = 1.613593\n",
      "epoch 38 loss = 1.479985\n",
      "epoch 39 loss = 1.598558\n",
      "epoch 40 loss = 1.594613\n",
      "epoch 41 loss = 1.435343\n",
      "epoch 42 loss = 1.560089\n",
      "epoch 43 loss = 1.490085\n",
      "epoch 44 loss = 1.565875\n",
      "epoch 45 loss = 1.547487\n",
      "epoch 46 loss = 1.656278\n",
      "epoch 47 loss = 1.560898\n",
      "epoch 48 loss = 1.684804\n",
      "epoch 49 loss = 1.601435\n",
      "epoch 50 loss = 1.447671\n",
      "epoch 51 loss = 1.591876\n",
      "epoch 52 loss = 1.487290\n",
      "epoch 53 loss = 1.437914\n",
      "epoch 54 loss = 1.405599\n",
      "epoch 55 loss = 1.452753\n",
      "epoch 56 loss = 1.571905\n",
      "epoch 57 loss = 1.649207\n",
      "epoch 58 loss = 1.516167\n",
      "epoch 59 loss = 1.645924\n",
      "epoch 60 loss = 1.518189\n",
      "epoch 61 loss = 1.694462\n",
      "epoch 62 loss = 1.615861\n",
      "epoch 63 loss = 1.347259\n",
      "epoch 64 loss = 1.520848\n",
      "epoch 65 loss = 1.526065\n",
      "epoch 66 loss = 1.346876\n",
      "epoch 67 loss = 1.572089\n",
      "epoch 68 loss = 1.523385\n",
      "epoch 69 loss = 1.606555\n",
      "epoch 70 loss = 1.492365\n",
      "epoch 71 loss = 1.520263\n",
      "epoch 72 loss = 1.517059\n",
      "epoch 73 loss = 1.524476\n",
      "epoch 74 loss = 1.400205\n",
      "epoch 75 loss = 1.537382\n",
      "epoch 76 loss = 1.434518\n",
      "epoch 77 loss = 1.659192\n",
      "epoch 78 loss = 1.407175\n",
      "epoch 79 loss = 1.374463\n",
      "epoch 80 loss = 1.390451\n",
      "epoch 81 loss = 1.467799\n",
      "epoch 82 loss = 1.550866\n",
      "epoch 83 loss = 1.635352\n",
      "epoch 84 loss = 1.719776\n",
      "epoch 85 loss = 1.702294\n",
      "epoch 86 loss = 1.475539\n",
      "epoch 87 loss = 1.322750\n",
      "epoch 88 loss = 1.411240\n",
      "epoch 89 loss = 1.370041\n",
      "epoch 90 loss = 1.390198\n",
      "epoch 91 loss = 1.318083\n",
      "epoch 92 loss = 1.351600\n",
      "epoch 93 loss = 1.626399\n",
      "epoch 94 loss = 1.548679\n",
      "epoch 95 loss = 1.759249\n",
      "epoch 96 loss = 1.358994\n",
      "epoch 97 loss = 1.579638\n",
      "epoch 98 loss = 1.499540\n",
      "epoch 99 loss = 1.498935\n",
      "final loss = 1.498935\n",
      "accuracy_mc = tensor(0.4204, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.4266, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.6221, device='cuda:0')\n",
      "training time = 61.59467530250549 seconds\n",
      "testing time = 3.2820184230804443 seconds\n",
      "\n",
      "Training with split 5\n",
      "epoch 0 loss = 2.305924\n",
      "epoch 1 loss = 2.280113\n",
      "epoch 2 loss = 2.185028\n",
      "epoch 3 loss = 2.232463\n",
      "epoch 4 loss = 2.136455\n",
      "epoch 5 loss = 2.078263\n",
      "epoch 6 loss = 2.182584\n",
      "epoch 7 loss = 1.993451\n",
      "epoch 8 loss = 2.091719\n",
      "epoch 9 loss = 2.179915\n",
      "epoch 10 loss = 2.152759\n",
      "epoch 11 loss = 2.028420\n",
      "epoch 12 loss = 2.160921\n",
      "epoch 13 loss = 2.117785\n",
      "epoch 14 loss = 1.956302\n",
      "epoch 15 loss = 1.982470\n",
      "epoch 16 loss = 2.061361\n",
      "epoch 17 loss = 2.070748\n",
      "epoch 18 loss = 2.145405\n",
      "epoch 19 loss = 2.126333\n",
      "epoch 20 loss = 2.041637\n",
      "epoch 21 loss = 2.155177\n",
      "epoch 22 loss = 2.010829\n",
      "epoch 23 loss = 1.977752\n",
      "epoch 24 loss = 2.024835\n",
      "epoch 25 loss = 1.955459\n",
      "epoch 26 loss = 1.960694\n",
      "epoch 27 loss = 1.926175\n",
      "epoch 28 loss = 1.859138\n",
      "epoch 29 loss = 1.965057\n",
      "epoch 30 loss = 2.046022\n",
      "epoch 31 loss = 1.969943\n",
      "epoch 32 loss = 1.812418\n",
      "epoch 33 loss = 1.919419\n",
      "epoch 34 loss = 1.951252\n",
      "epoch 35 loss = 1.702638\n",
      "epoch 36 loss = 2.018859\n",
      "epoch 37 loss = 1.811218\n",
      "epoch 38 loss = 2.059131\n",
      "epoch 39 loss = 2.085022\n",
      "epoch 40 loss = 1.802636\n",
      "epoch 41 loss = 2.120071\n",
      "epoch 42 loss = 1.778703\n",
      "epoch 43 loss = 1.755210\n",
      "epoch 44 loss = 1.744025\n",
      "epoch 45 loss = 1.880902\n",
      "epoch 46 loss = 1.993770\n",
      "epoch 47 loss = 1.864166\n",
      "epoch 48 loss = 1.828069\n",
      "epoch 49 loss = 1.962265\n",
      "epoch 50 loss = 1.768750\n",
      "epoch 51 loss = 1.938524\n",
      "epoch 52 loss = 1.608170\n",
      "epoch 53 loss = 1.904890\n",
      "epoch 54 loss = 1.946639\n",
      "epoch 55 loss = 1.935368\n",
      "epoch 56 loss = 1.755206\n",
      "epoch 57 loss = 1.837367\n",
      "epoch 58 loss = 1.781370\n",
      "epoch 59 loss = 1.543118\n",
      "epoch 60 loss = 1.801135\n",
      "epoch 61 loss = 1.926612\n",
      "epoch 62 loss = 1.894798\n",
      "epoch 63 loss = 1.810099\n",
      "epoch 64 loss = 1.951941\n",
      "epoch 65 loss = 1.769216\n",
      "epoch 66 loss = 1.930869\n",
      "epoch 67 loss = 1.690959\n",
      "epoch 68 loss = 1.755859\n",
      "epoch 69 loss = 1.888788\n",
      "epoch 70 loss = 1.818375\n",
      "epoch 71 loss = 1.763490\n",
      "epoch 72 loss = 1.847804\n",
      "epoch 73 loss = 1.976102\n",
      "epoch 74 loss = 1.930612\n",
      "epoch 75 loss = 1.676961\n",
      "epoch 76 loss = 1.838906\n",
      "epoch 77 loss = 1.722641\n",
      "epoch 78 loss = 1.710225\n",
      "epoch 79 loss = 1.885939\n",
      "epoch 80 loss = 1.815603\n",
      "epoch 81 loss = 1.746017\n",
      "epoch 82 loss = 1.790545\n",
      "epoch 83 loss = 1.519849\n",
      "epoch 84 loss = 1.746791\n",
      "epoch 85 loss = 1.746646\n",
      "epoch 86 loss = 1.862890\n",
      "epoch 87 loss = 1.769864\n",
      "epoch 88 loss = 1.842781\n",
      "epoch 89 loss = 1.644127\n",
      "epoch 90 loss = 1.913128\n",
      "epoch 91 loss = 1.768794\n",
      "epoch 92 loss = 1.721749\n",
      "epoch 93 loss = 1.668993\n",
      "epoch 94 loss = 1.804733\n",
      "epoch 95 loss = 1.767282\n",
      "epoch 96 loss = 1.742305\n",
      "epoch 97 loss = 1.816773\n",
      "epoch 98 loss = 1.896196\n",
      "epoch 99 loss = 1.654174\n",
      "final loss = 1.654174\n",
      "accuracy_mc = tensor(0.3705, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.3637, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.7974, device='cuda:0')\n",
      "training time = 61.42811179161072 seconds\n",
      "testing time = 3.2700624465942383 seconds\n",
      "\n",
      "Training with split 6\n",
      "epoch 0 loss = 2.231004\n",
      "epoch 1 loss = 2.327673\n",
      "epoch 2 loss = 2.285709\n",
      "epoch 3 loss = 2.257146\n",
      "epoch 4 loss = 2.243789\n",
      "epoch 5 loss = 2.218160\n",
      "epoch 6 loss = 2.175036\n",
      "epoch 7 loss = 2.225033\n",
      "epoch 8 loss = 2.128220\n",
      "epoch 9 loss = 2.275976\n",
      "epoch 10 loss = 2.140842\n",
      "epoch 11 loss = 2.172980\n",
      "epoch 12 loss = 2.059437\n",
      "epoch 13 loss = 2.359231\n",
      "epoch 14 loss = 2.328247\n",
      "epoch 15 loss = 2.244248\n",
      "epoch 16 loss = 2.032464\n",
      "epoch 17 loss = 2.158072\n",
      "epoch 18 loss = 2.124760\n",
      "epoch 19 loss = 2.242890\n",
      "epoch 20 loss = 2.255353\n",
      "epoch 21 loss = 2.245409\n",
      "epoch 22 loss = 2.319658\n",
      "epoch 23 loss = 2.102957\n",
      "epoch 24 loss = 2.052422\n",
      "epoch 25 loss = 2.066427\n",
      "epoch 26 loss = 2.143034\n",
      "epoch 27 loss = 1.970699\n",
      "epoch 28 loss = 1.985632\n",
      "epoch 29 loss = 2.125595\n",
      "epoch 30 loss = 2.145504\n",
      "epoch 31 loss = 1.960738\n",
      "epoch 32 loss = 2.053299\n",
      "epoch 33 loss = 1.992425\n",
      "epoch 34 loss = 2.064977\n",
      "epoch 35 loss = 2.170779\n",
      "epoch 36 loss = 1.927016\n",
      "epoch 37 loss = 2.063527\n",
      "epoch 38 loss = 1.931635\n",
      "epoch 39 loss = 2.048556\n",
      "epoch 40 loss = 2.064939\n",
      "epoch 41 loss = 1.894119\n",
      "epoch 42 loss = 1.952805\n",
      "epoch 43 loss = 1.791797\n",
      "epoch 44 loss = 1.963057\n",
      "epoch 45 loss = 1.864380\n",
      "epoch 46 loss = 1.924196\n",
      "epoch 47 loss = 1.702356\n",
      "epoch 48 loss = 1.698629\n",
      "epoch 49 loss = 1.965200\n",
      "epoch 50 loss = 1.858479\n",
      "epoch 51 loss = 2.058616\n",
      "epoch 52 loss = 1.940770\n",
      "epoch 53 loss = 1.824465\n",
      "epoch 54 loss = 1.752476\n",
      "epoch 55 loss = 1.729392\n",
      "epoch 56 loss = 1.723472\n",
      "epoch 57 loss = 1.803739\n",
      "epoch 58 loss = 1.725569\n",
      "epoch 59 loss = 1.710984\n",
      "epoch 60 loss = 1.874972\n",
      "epoch 61 loss = 1.742519\n",
      "epoch 62 loss = 1.782223\n",
      "epoch 63 loss = 1.792635\n",
      "epoch 64 loss = 1.700290\n",
      "epoch 65 loss = 1.821710\n",
      "epoch 66 loss = 1.816764\n",
      "epoch 67 loss = 1.828560\n",
      "epoch 68 loss = 1.654508\n",
      "epoch 69 loss = 1.713801\n",
      "epoch 70 loss = 1.720593\n",
      "epoch 71 loss = 1.687045\n",
      "epoch 72 loss = 1.548273\n",
      "epoch 73 loss = 1.568955\n",
      "epoch 74 loss = 1.620075\n",
      "epoch 75 loss = 1.821337\n",
      "epoch 76 loss = 1.731927\n",
      "epoch 77 loss = 1.714400\n",
      "epoch 78 loss = 1.762081\n",
      "epoch 79 loss = 1.605778\n",
      "epoch 80 loss = 1.462437\n",
      "epoch 81 loss = 1.516824\n",
      "epoch 82 loss = 1.806641\n",
      "epoch 83 loss = 1.688117\n",
      "epoch 84 loss = 1.632025\n",
      "epoch 85 loss = 1.635633\n",
      "epoch 86 loss = 1.558934\n",
      "epoch 87 loss = 1.495181\n",
      "epoch 88 loss = 1.548127\n",
      "epoch 89 loss = 1.534821\n",
      "epoch 90 loss = 1.546971\n",
      "epoch 91 loss = 1.501110\n",
      "epoch 92 loss = 1.637316\n",
      "epoch 93 loss = 1.523654\n",
      "epoch 94 loss = 1.507178\n",
      "epoch 95 loss = 1.467935\n",
      "epoch 96 loss = 1.544083\n",
      "epoch 97 loss = 1.544305\n",
      "epoch 98 loss = 1.772681\n",
      "epoch 99 loss = 1.463068\n",
      "final loss = 1.463068\n",
      "accuracy_mc = tensor(0.4464, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.4461, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.5666, device='cuda:0')\n",
      "training time = 61.163301944732666 seconds\n",
      "testing time = 3.278912305831909 seconds\n",
      "\n",
      "Training with split 7\n",
      "epoch 0 loss = 2.199651\n",
      "epoch 1 loss = 2.050058\n",
      "epoch 2 loss = 1.916502\n",
      "epoch 3 loss = 2.080034\n",
      "epoch 4 loss = 1.977314\n",
      "epoch 5 loss = 1.938117\n",
      "epoch 6 loss = 1.919095\n",
      "epoch 7 loss = 1.827753\n",
      "epoch 8 loss = 1.856962\n",
      "epoch 9 loss = 1.915359\n",
      "epoch 10 loss = 1.853301\n",
      "epoch 11 loss = 1.911817\n",
      "epoch 12 loss = 1.814601\n",
      "epoch 13 loss = 1.965986\n",
      "epoch 14 loss = 1.896323\n",
      "epoch 15 loss = 1.866806\n",
      "epoch 16 loss = 1.879494\n",
      "epoch 17 loss = 1.868827\n",
      "epoch 18 loss = 1.949024\n",
      "epoch 19 loss = 1.863053\n",
      "epoch 20 loss = 1.769293\n",
      "epoch 21 loss = 1.817456\n",
      "epoch 22 loss = 1.857596\n",
      "epoch 23 loss = 1.877677\n",
      "epoch 24 loss = 1.917237\n",
      "epoch 25 loss = 1.942104\n",
      "epoch 26 loss = 1.924379\n",
      "epoch 27 loss = 1.777570\n",
      "epoch 28 loss = 1.785217\n",
      "epoch 29 loss = 2.003401\n",
      "epoch 30 loss = 1.836575\n",
      "epoch 31 loss = 1.852380\n",
      "epoch 32 loss = 1.842306\n",
      "epoch 33 loss = 1.888979\n",
      "epoch 34 loss = 1.745756\n",
      "epoch 35 loss = 1.828845\n",
      "epoch 36 loss = 1.679110\n",
      "epoch 37 loss = 1.883863\n",
      "epoch 38 loss = 1.828372\n",
      "epoch 39 loss = 1.715629\n",
      "epoch 40 loss = 1.689289\n",
      "epoch 41 loss = 1.753465\n",
      "epoch 42 loss = 1.690354\n",
      "epoch 43 loss = 1.721612\n",
      "epoch 44 loss = 1.812136\n",
      "epoch 45 loss = 1.754988\n",
      "epoch 46 loss = 1.615039\n",
      "epoch 47 loss = 1.736713\n",
      "epoch 48 loss = 1.779065\n",
      "epoch 49 loss = 1.665434\n",
      "epoch 50 loss = 1.686581\n",
      "epoch 51 loss = 1.684117\n",
      "epoch 52 loss = 1.720449\n",
      "epoch 53 loss = 1.638297\n",
      "epoch 54 loss = 1.732889\n",
      "epoch 55 loss = 1.679342\n",
      "epoch 56 loss = 1.665889\n",
      "epoch 57 loss = 1.705927\n",
      "epoch 58 loss = 1.792342\n",
      "epoch 59 loss = 1.641229\n",
      "epoch 60 loss = 1.776623\n",
      "epoch 61 loss = 1.734343\n",
      "epoch 62 loss = 1.867918\n",
      "epoch 63 loss = 1.588377\n",
      "epoch 64 loss = 1.696206\n",
      "epoch 65 loss = 1.719639\n",
      "epoch 66 loss = 1.589896\n",
      "epoch 67 loss = 1.663503\n",
      "epoch 68 loss = 1.644088\n",
      "epoch 69 loss = 1.742554\n",
      "epoch 70 loss = 1.657407\n",
      "epoch 71 loss = 1.587706\n",
      "epoch 72 loss = 1.619815\n",
      "epoch 73 loss = 1.581841\n",
      "epoch 74 loss = 1.677361\n",
      "epoch 75 loss = 1.581248\n",
      "epoch 76 loss = 1.552632\n",
      "epoch 77 loss = 1.725911\n",
      "epoch 78 loss = 1.731423\n",
      "epoch 79 loss = 1.609809\n",
      "epoch 80 loss = 1.583213\n",
      "epoch 81 loss = 1.585876\n",
      "epoch 82 loss = 1.468332\n",
      "epoch 83 loss = 1.652689\n",
      "epoch 84 loss = 1.483246\n",
      "epoch 85 loss = 1.481767\n",
      "epoch 86 loss = 1.494196\n",
      "epoch 87 loss = 1.617242\n",
      "epoch 88 loss = 1.500478\n",
      "epoch 89 loss = 1.464271\n",
      "epoch 90 loss = 1.518682\n",
      "epoch 91 loss = 1.593372\n",
      "epoch 92 loss = 1.506396\n",
      "epoch 93 loss = 1.459105\n",
      "epoch 94 loss = 1.715882\n",
      "epoch 95 loss = 1.570556\n",
      "epoch 96 loss = 1.513121\n",
      "epoch 97 loss = 1.604070\n",
      "epoch 98 loss = 1.632349\n",
      "epoch 99 loss = 1.613881\n",
      "final loss = 1.613881\n",
      "accuracy_mc = tensor(0.3549, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.3515, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.7598, device='cuda:0')\n",
      "training time = 61.19864058494568 seconds\n",
      "testing time = 3.233574628829956 seconds\n",
      "\n",
      "Training with split 8\n",
      "epoch 0 loss = 2.156435\n",
      "epoch 1 loss = 2.035257\n",
      "epoch 2 loss = 1.951195\n",
      "epoch 3 loss = 2.042183\n",
      "epoch 4 loss = 1.985817\n",
      "epoch 5 loss = 1.987535\n",
      "epoch 6 loss = 2.014871\n",
      "epoch 7 loss = 1.901518\n",
      "epoch 8 loss = 1.831014\n",
      "epoch 9 loss = 1.927196\n",
      "epoch 10 loss = 1.869398\n",
      "epoch 11 loss = 1.948769\n",
      "epoch 12 loss = 1.908249\n",
      "epoch 13 loss = 1.839604\n",
      "epoch 14 loss = 1.848042\n",
      "epoch 15 loss = 1.813527\n",
      "epoch 16 loss = 1.891103\n",
      "epoch 17 loss = 1.863754\n",
      "epoch 18 loss = 1.802437\n",
      "epoch 19 loss = 1.847380\n",
      "epoch 20 loss = 1.768745\n",
      "epoch 21 loss = 1.800719\n",
      "epoch 22 loss = 1.831305\n",
      "epoch 23 loss = 1.848879\n",
      "epoch 24 loss = 1.883163\n",
      "epoch 25 loss = 1.944191\n",
      "epoch 26 loss = 1.748369\n",
      "epoch 27 loss = 1.793842\n",
      "epoch 28 loss = 1.723207\n",
      "epoch 29 loss = 1.773700\n",
      "epoch 30 loss = 1.807787\n",
      "epoch 31 loss = 1.826966\n",
      "epoch 32 loss = 1.824879\n",
      "epoch 33 loss = 1.831918\n",
      "epoch 34 loss = 1.726305\n",
      "epoch 35 loss = 1.674646\n",
      "epoch 36 loss = 1.834651\n",
      "epoch 37 loss = 1.698126\n",
      "epoch 38 loss = 1.656141\n",
      "epoch 39 loss = 1.690111\n",
      "epoch 40 loss = 1.680713\n",
      "epoch 41 loss = 1.817937\n",
      "epoch 42 loss = 1.690342\n",
      "epoch 43 loss = 1.832953\n",
      "epoch 44 loss = 1.829021\n",
      "epoch 45 loss = 1.745078\n",
      "epoch 46 loss = 1.729449\n",
      "epoch 47 loss = 1.673678\n",
      "epoch 48 loss = 1.723348\n",
      "epoch 49 loss = 1.734112\n",
      "epoch 50 loss = 1.734589\n",
      "epoch 51 loss = 1.742388\n",
      "epoch 52 loss = 1.623659\n",
      "epoch 53 loss = 1.671459\n",
      "epoch 54 loss = 1.745619\n",
      "epoch 55 loss = 1.597203\n",
      "epoch 56 loss = 1.730811\n",
      "epoch 57 loss = 1.690620\n",
      "epoch 58 loss = 1.671908\n",
      "epoch 59 loss = 1.841351\n",
      "epoch 60 loss = 1.844239\n",
      "epoch 61 loss = 1.821128\n",
      "epoch 62 loss = 1.690147\n",
      "epoch 63 loss = 1.699788\n",
      "epoch 64 loss = 1.767647\n",
      "epoch 65 loss = 1.667475\n",
      "epoch 66 loss = 1.788997\n",
      "epoch 67 loss = 1.595047\n",
      "epoch 68 loss = 1.627281\n",
      "epoch 69 loss = 1.637949\n",
      "epoch 70 loss = 1.624938\n",
      "epoch 71 loss = 1.761951\n",
      "epoch 72 loss = 1.599204\n",
      "epoch 73 loss = 1.796373\n",
      "epoch 74 loss = 1.616880\n",
      "epoch 75 loss = 1.759950\n",
      "epoch 76 loss = 1.637749\n",
      "epoch 77 loss = 1.553756\n",
      "epoch 78 loss = 1.751140\n",
      "epoch 79 loss = 1.630237\n",
      "epoch 80 loss = 1.694335\n",
      "epoch 81 loss = 1.655660\n",
      "epoch 82 loss = 1.455729\n",
      "epoch 83 loss = 1.737044\n",
      "epoch 84 loss = 1.752177\n",
      "epoch 85 loss = 1.607363\n",
      "epoch 86 loss = 1.630812\n",
      "epoch 87 loss = 1.567967\n",
      "epoch 88 loss = 1.482320\n",
      "epoch 89 loss = 1.593415\n",
      "epoch 90 loss = 1.683730\n",
      "epoch 91 loss = 1.676393\n",
      "epoch 92 loss = 1.723830\n",
      "epoch 93 loss = 1.562071\n",
      "epoch 94 loss = 1.669575\n",
      "epoch 95 loss = 1.816058\n",
      "epoch 96 loss = 1.787407\n",
      "epoch 97 loss = 1.781445\n",
      "epoch 98 loss = 1.563392\n",
      "epoch 99 loss = 1.628526\n",
      "final loss = 1.628526\n",
      "accuracy_mc = tensor(0.3390, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.3306, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.8124, device='cuda:0')\n",
      "training time = 61.53773641586304 seconds\n",
      "testing time = 3.1665313243865967 seconds\n",
      "\n",
      "Training with split 9\n",
      "epoch 0 loss = 2.261740\n",
      "epoch 1 loss = 2.152536\n",
      "epoch 2 loss = 1.938846\n",
      "epoch 3 loss = 2.004356\n",
      "epoch 4 loss = 2.107070\n",
      "epoch 5 loss = 1.886497\n",
      "epoch 6 loss = 1.959255\n",
      "epoch 7 loss = 1.912728\n",
      "epoch 8 loss = 1.864190\n",
      "epoch 9 loss = 1.885939\n",
      "epoch 10 loss = 1.810038\n",
      "epoch 11 loss = 1.905398\n",
      "epoch 12 loss = 1.652015\n",
      "epoch 13 loss = 1.762361\n",
      "epoch 14 loss = 1.795376\n",
      "epoch 15 loss = 1.745043\n",
      "epoch 16 loss = 1.668064\n",
      "epoch 17 loss = 1.759197\n",
      "epoch 18 loss = 1.763259\n",
      "epoch 19 loss = 1.678294\n",
      "epoch 20 loss = 1.642258\n",
      "epoch 21 loss = 1.805294\n",
      "epoch 22 loss = 1.668189\n",
      "epoch 23 loss = 1.700468\n",
      "epoch 24 loss = 1.867942\n",
      "epoch 25 loss = 1.686063\n",
      "epoch 26 loss = 1.755761\n",
      "epoch 27 loss = 1.618652\n",
      "epoch 28 loss = 1.687969\n",
      "epoch 29 loss = 1.843952\n",
      "epoch 30 loss = 1.522612\n",
      "epoch 31 loss = 1.783765\n",
      "epoch 32 loss = 1.794671\n",
      "epoch 33 loss = 1.602450\n",
      "epoch 34 loss = 1.746149\n",
      "epoch 35 loss = 1.613982\n",
      "epoch 36 loss = 1.512005\n",
      "epoch 37 loss = 1.726496\n",
      "epoch 38 loss = 1.686233\n",
      "epoch 39 loss = 1.646562\n",
      "epoch 40 loss = 1.548198\n",
      "epoch 41 loss = 1.420230\n",
      "epoch 42 loss = 1.627860\n",
      "epoch 43 loss = 1.687562\n",
      "epoch 44 loss = 1.694464\n",
      "epoch 45 loss = 1.542514\n",
      "epoch 46 loss = 1.667318\n",
      "epoch 47 loss = 1.557822\n",
      "epoch 48 loss = 1.568161\n",
      "epoch 49 loss = 1.474615\n",
      "epoch 50 loss = 1.591495\n",
      "epoch 51 loss = 1.489780\n",
      "epoch 52 loss = 1.641538\n",
      "epoch 53 loss = 1.554134\n",
      "epoch 54 loss = 1.440884\n",
      "epoch 55 loss = 1.566430\n",
      "epoch 56 loss = 1.470200\n",
      "epoch 57 loss = 1.494920\n",
      "epoch 58 loss = 1.444907\n",
      "epoch 59 loss = 1.457386\n",
      "epoch 60 loss = 1.427625\n",
      "epoch 61 loss = 1.485071\n",
      "epoch 62 loss = 1.665685\n",
      "epoch 63 loss = 1.569602\n",
      "epoch 64 loss = 1.560227\n",
      "epoch 65 loss = 1.407499\n",
      "epoch 66 loss = 1.380224\n",
      "epoch 67 loss = 1.558867\n",
      "epoch 68 loss = 1.504813\n",
      "epoch 69 loss = 1.495127\n",
      "epoch 70 loss = 1.407769\n",
      "epoch 71 loss = 1.743484\n",
      "epoch 72 loss = 1.448383\n",
      "epoch 73 loss = 1.547938\n",
      "epoch 74 loss = 1.472988\n",
      "epoch 75 loss = 1.422010\n",
      "epoch 76 loss = 1.494834\n",
      "epoch 77 loss = 1.346754\n",
      "epoch 78 loss = 1.575903\n",
      "epoch 79 loss = 1.500702\n",
      "epoch 80 loss = 1.344128\n",
      "epoch 81 loss = 1.596036\n",
      "epoch 82 loss = 1.370053\n",
      "epoch 83 loss = 1.485966\n",
      "epoch 84 loss = 1.486279\n",
      "epoch 85 loss = 1.257514\n",
      "epoch 86 loss = 1.521379\n",
      "epoch 87 loss = 1.413162\n",
      "epoch 88 loss = 1.386571\n",
      "epoch 89 loss = 1.251190\n",
      "epoch 90 loss = 1.330054\n",
      "epoch 91 loss = 1.545927\n",
      "epoch 92 loss = 1.326567\n",
      "epoch 93 loss = 1.244977\n",
      "epoch 94 loss = 1.577310\n",
      "epoch 95 loss = 1.474982\n",
      "epoch 96 loss = 1.346728\n",
      "epoch 97 loss = 1.411028\n",
      "epoch 98 loss = 1.329888\n",
      "epoch 99 loss = 1.425065\n",
      "final loss = 1.425065\n",
      "accuracy_mc = tensor(0.4376, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.4438, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.5810, device='cuda:0')\n",
      "training time = 61.102288007736206 seconds\n",
      "testing time = 3.301429033279419 seconds\n",
      "\n",
      "subset 0.050000, dropout_rate 0.100000, reg_strength 0.050000\n",
      "n_epoch 500\n",
      "\n",
      "Files already downloaded and verified\n",
      "subset size = (2500, 32, 32, 3)\n",
      "training set size = 2000\n",
      "test set size = 500\n",
      "\n",
      "Training with split 0\n",
      "epoch 0 loss = 2.287264\n",
      "epoch 1 loss = 2.169008\n",
      "epoch 2 loss = 2.065376\n",
      "epoch 3 loss = 2.059536\n",
      "epoch 4 loss = 2.064392\n",
      "epoch 5 loss = 2.060936\n",
      "epoch 6 loss = 1.993528\n",
      "epoch 7 loss = 1.945353\n",
      "epoch 8 loss = 1.789426\n",
      "epoch 9 loss = 1.954190\n",
      "epoch 10 loss = 1.930843\n",
      "epoch 11 loss = 1.752575\n",
      "epoch 12 loss = 1.807545\n",
      "epoch 13 loss = 1.811882\n",
      "epoch 14 loss = 1.821418\n",
      "epoch 15 loss = 1.644708\n",
      "epoch 16 loss = 1.817723\n",
      "epoch 17 loss = 1.921880\n",
      "epoch 18 loss = 1.610551\n",
      "epoch 19 loss = 1.880772\n",
      "epoch 20 loss = 1.781973\n",
      "epoch 21 loss = 1.795143\n",
      "epoch 22 loss = 1.668130\n",
      "epoch 23 loss = 1.693227\n",
      "epoch 24 loss = 1.573176\n",
      "epoch 25 loss = 1.690201\n",
      "epoch 26 loss = 1.563359\n",
      "epoch 27 loss = 1.696444\n",
      "epoch 28 loss = 1.636100\n",
      "epoch 29 loss = 1.752537\n",
      "epoch 30 loss = 1.666635\n",
      "epoch 31 loss = 1.582765\n",
      "epoch 32 loss = 1.630029\n",
      "epoch 33 loss = 1.683898\n",
      "epoch 34 loss = 1.527934\n",
      "epoch 35 loss = 1.691844\n",
      "epoch 36 loss = 1.690298\n",
      "epoch 37 loss = 1.421870\n",
      "epoch 38 loss = 1.621978\n",
      "epoch 39 loss = 1.524459\n",
      "epoch 40 loss = 1.418278\n",
      "epoch 41 loss = 1.476486\n",
      "epoch 42 loss = 1.677721\n",
      "epoch 43 loss = 1.565547\n",
      "epoch 44 loss = 1.502619\n",
      "epoch 45 loss = 1.582294\n",
      "epoch 46 loss = 1.563985\n",
      "epoch 47 loss = 1.311425\n",
      "epoch 48 loss = 1.536651\n",
      "epoch 49 loss = 1.451827\n",
      "epoch 50 loss = 1.567356\n",
      "epoch 51 loss = 1.442138\n",
      "epoch 52 loss = 1.490723\n",
      "epoch 53 loss = 1.513491\n",
      "epoch 54 loss = 1.435766\n",
      "epoch 55 loss = 1.365576\n",
      "epoch 56 loss = 1.590530\n",
      "epoch 57 loss = 1.465492\n",
      "epoch 58 loss = 1.474452\n",
      "epoch 59 loss = 1.399219\n",
      "epoch 60 loss = 1.423291\n",
      "epoch 61 loss = 1.336793\n",
      "epoch 62 loss = 1.664128\n",
      "epoch 63 loss = 1.409643\n",
      "epoch 64 loss = 1.289296\n",
      "epoch 65 loss = 1.290467\n",
      "epoch 66 loss = 1.466760\n",
      "epoch 67 loss = 1.481539\n",
      "epoch 68 loss = 1.505183\n",
      "epoch 69 loss = 1.457718\n",
      "epoch 70 loss = 1.587351\n",
      "epoch 71 loss = 1.715492\n",
      "epoch 72 loss = 1.363548\n",
      "epoch 73 loss = 1.336152\n",
      "epoch 74 loss = 1.379774\n",
      "epoch 75 loss = 1.533822\n",
      "epoch 76 loss = 1.317574\n",
      "epoch 77 loss = 1.412674\n",
      "epoch 78 loss = 1.522626\n",
      "epoch 79 loss = 1.370260\n",
      "epoch 80 loss = 1.297417\n",
      "epoch 81 loss = 1.518190\n",
      "epoch 82 loss = 1.213132\n",
      "epoch 83 loss = 1.338683\n",
      "epoch 84 loss = 1.469978\n",
      "epoch 85 loss = 1.276591\n",
      "epoch 86 loss = 1.228788\n",
      "epoch 87 loss = 1.467560\n",
      "epoch 88 loss = 1.448918\n",
      "epoch 89 loss = 1.280705\n",
      "epoch 90 loss = 1.327704\n",
      "epoch 91 loss = 1.282759\n",
      "epoch 92 loss = 1.270894\n",
      "epoch 93 loss = 1.476522\n",
      "epoch 94 loss = 1.318606\n",
      "epoch 95 loss = 1.281642\n",
      "epoch 96 loss = 1.361493\n",
      "epoch 97 loss = 1.321288\n",
      "epoch 98 loss = 1.286946\n",
      "epoch 99 loss = 1.408356\n",
      "epoch 100 loss = 1.424100\n",
      "epoch 101 loss = 1.461887\n",
      "epoch 102 loss = 1.323950\n",
      "epoch 103 loss = 1.250125\n",
      "epoch 104 loss = 1.303000\n",
      "epoch 105 loss = 1.365145\n",
      "epoch 106 loss = 1.227272\n",
      "epoch 107 loss = 1.211318\n",
      "epoch 108 loss = 1.182855\n",
      "epoch 109 loss = 1.196047\n",
      "epoch 110 loss = 1.172113\n",
      "epoch 111 loss = 1.232756\n",
      "epoch 112 loss = 1.442360\n",
      "epoch 113 loss = 1.305869\n",
      "epoch 114 loss = 1.504576\n",
      "epoch 115 loss = 1.380484\n",
      "epoch 116 loss = 1.210796\n",
      "epoch 117 loss = 1.397201\n",
      "epoch 118 loss = 1.289733\n",
      "epoch 119 loss = 1.445153\n",
      "epoch 120 loss = 1.239665\n",
      "epoch 121 loss = 1.158123\n",
      "epoch 122 loss = 1.191338\n",
      "epoch 123 loss = 1.314563\n",
      "epoch 124 loss = 1.311823\n",
      "epoch 125 loss = 1.257463\n",
      "epoch 126 loss = 1.520839\n",
      "epoch 127 loss = 1.246431\n",
      "epoch 128 loss = 1.443052\n",
      "epoch 129 loss = 1.307505\n",
      "epoch 130 loss = 1.157036\n",
      "epoch 131 loss = 1.416684\n",
      "epoch 132 loss = 1.144472\n",
      "epoch 133 loss = 1.223025\n",
      "epoch 134 loss = 1.188960\n",
      "epoch 135 loss = 1.236778\n",
      "epoch 136 loss = 1.182004\n",
      "epoch 137 loss = 1.242015\n",
      "epoch 138 loss = 1.360482\n",
      "epoch 139 loss = 1.155531\n",
      "epoch 140 loss = 1.205077\n",
      "epoch 141 loss = 1.129610\n",
      "epoch 142 loss = 1.074558\n",
      "epoch 143 loss = 1.241824\n",
      "epoch 144 loss = 1.273910\n",
      "epoch 145 loss = 1.132372\n",
      "epoch 146 loss = 1.162158\n",
      "epoch 147 loss = 0.997546\n",
      "epoch 148 loss = 1.180428\n",
      "epoch 149 loss = 1.053569\n",
      "epoch 150 loss = 1.054851\n",
      "epoch 151 loss = 1.129787\n",
      "epoch 152 loss = 1.286297\n",
      "epoch 153 loss = 1.244910\n",
      "epoch 154 loss = 1.192770\n",
      "epoch 155 loss = 1.255131\n",
      "epoch 156 loss = 1.070117\n",
      "epoch 157 loss = 1.254073\n",
      "epoch 158 loss = 1.129514\n",
      "epoch 159 loss = 1.214602\n",
      "epoch 160 loss = 1.265556\n",
      "epoch 161 loss = 1.224086\n",
      "epoch 162 loss = 1.168835\n",
      "epoch 163 loss = 1.320904\n",
      "epoch 164 loss = 1.306051\n",
      "epoch 165 loss = 1.131640\n",
      "epoch 166 loss = 1.270347\n",
      "epoch 167 loss = 1.202570\n",
      "epoch 168 loss = 1.260844\n",
      "epoch 169 loss = 1.174239\n",
      "epoch 170 loss = 1.161500\n",
      "epoch 171 loss = 1.013656\n",
      "epoch 172 loss = 1.130489\n",
      "epoch 173 loss = 1.331593\n",
      "epoch 174 loss = 1.264307\n",
      "epoch 175 loss = 1.183203\n",
      "epoch 176 loss = 1.071035\n",
      "epoch 177 loss = 1.111662\n",
      "epoch 178 loss = 1.295136\n",
      "epoch 179 loss = 1.030796\n",
      "epoch 180 loss = 1.240162\n",
      "epoch 181 loss = 1.098617\n",
      "epoch 182 loss = 1.276281\n",
      "epoch 183 loss = 1.126526\n",
      "epoch 184 loss = 1.153504\n",
      "epoch 185 loss = 1.071348\n",
      "epoch 186 loss = 1.103523\n",
      "epoch 187 loss = 1.376359\n",
      "epoch 188 loss = 1.261745\n",
      "epoch 189 loss = 1.154572\n",
      "epoch 190 loss = 1.192280\n",
      "epoch 191 loss = 1.210219\n",
      "epoch 192 loss = 1.099873\n",
      "epoch 193 loss = 1.134796\n",
      "epoch 194 loss = 1.070044\n",
      "epoch 195 loss = 1.063698\n",
      "epoch 196 loss = 1.042643\n",
      "epoch 197 loss = 1.151823\n",
      "epoch 198 loss = 0.974109\n",
      "epoch 199 loss = 1.101640\n",
      "epoch 200 loss = 1.190025\n",
      "epoch 201 loss = 1.000812\n",
      "epoch 202 loss = 1.055984\n",
      "epoch 203 loss = 1.029536\n",
      "epoch 204 loss = 1.014731\n",
      "epoch 205 loss = 1.397517\n",
      "epoch 206 loss = 0.951119\n",
      "epoch 207 loss = 1.177984\n",
      "epoch 208 loss = 1.086936\n",
      "epoch 209 loss = 1.220590\n",
      "epoch 210 loss = 1.147061\n",
      "epoch 211 loss = 1.446988\n",
      "epoch 212 loss = 1.442052\n",
      "epoch 213 loss = 1.057036\n",
      "epoch 214 loss = 1.049695\n",
      "epoch 215 loss = 0.975870\n",
      "epoch 216 loss = 1.057054\n",
      "epoch 217 loss = 1.140277\n",
      "epoch 218 loss = 1.128860\n",
      "epoch 219 loss = 1.147145\n",
      "epoch 220 loss = 1.291968\n",
      "epoch 221 loss = 1.221384\n",
      "epoch 222 loss = 1.145839\n",
      "epoch 223 loss = 1.299611\n",
      "epoch 224 loss = 1.179400\n",
      "epoch 225 loss = 1.076576\n",
      "epoch 226 loss = 1.060058\n",
      "epoch 227 loss = 1.241821\n",
      "epoch 228 loss = 1.358593\n",
      "epoch 229 loss = 1.186133\n",
      "epoch 230 loss = 1.307723\n",
      "epoch 231 loss = 1.074534\n",
      "epoch 232 loss = 1.056183\n",
      "epoch 233 loss = 0.934825\n",
      "epoch 234 loss = 1.209458\n",
      "epoch 235 loss = 1.194490\n",
      "epoch 236 loss = 1.085512\n",
      "epoch 237 loss = 1.049976\n",
      "epoch 238 loss = 1.111263\n",
      "epoch 239 loss = 1.171060\n",
      "epoch 240 loss = 1.270446\n",
      "epoch 241 loss = 1.042350\n",
      "epoch 242 loss = 1.128983\n",
      "epoch 243 loss = 1.110811\n",
      "epoch 244 loss = 1.150725\n",
      "epoch 245 loss = 1.079845\n",
      "epoch 246 loss = 1.085055\n",
      "epoch 247 loss = 1.146806\n",
      "epoch 248 loss = 1.051979\n",
      "epoch 249 loss = 1.050988\n",
      "epoch 250 loss = 0.991389\n",
      "epoch 251 loss = 0.961006\n",
      "epoch 252 loss = 1.032206\n",
      "epoch 253 loss = 1.046891\n",
      "epoch 254 loss = 1.162547\n",
      "epoch 255 loss = 1.144816\n",
      "epoch 256 loss = 1.092676\n",
      "epoch 257 loss = 1.316833\n",
      "epoch 258 loss = 1.176445\n",
      "epoch 259 loss = 1.138782\n",
      "epoch 260 loss = 1.064602\n",
      "epoch 261 loss = 1.023945\n",
      "epoch 262 loss = 1.051494\n",
      "epoch 263 loss = 1.060592\n",
      "epoch 264 loss = 1.080132\n",
      "epoch 265 loss = 1.099211\n",
      "epoch 266 loss = 1.093156\n",
      "epoch 267 loss = 1.035946\n",
      "epoch 268 loss = 1.011117\n",
      "epoch 269 loss = 1.149376\n",
      "epoch 270 loss = 1.227380\n",
      "epoch 271 loss = 1.097578\n",
      "epoch 272 loss = 1.300458\n",
      "epoch 273 loss = 1.002260\n",
      "epoch 274 loss = 1.230256\n",
      "epoch 275 loss = 0.933013\n",
      "epoch 276 loss = 1.183984\n",
      "epoch 277 loss = 1.321701\n",
      "epoch 278 loss = 1.220343\n",
      "epoch 279 loss = 1.262578\n",
      "epoch 280 loss = 1.045327\n",
      "epoch 281 loss = 1.080672\n",
      "epoch 282 loss = 0.910511\n",
      "epoch 283 loss = 0.953740\n",
      "epoch 284 loss = 1.005456\n",
      "epoch 285 loss = 1.177521\n",
      "epoch 286 loss = 1.369502\n",
      "epoch 287 loss = 1.038832\n",
      "epoch 288 loss = 1.183803\n",
      "epoch 289 loss = 1.352127\n",
      "epoch 290 loss = 1.135478\n",
      "epoch 291 loss = 1.056841\n",
      "epoch 292 loss = 1.109498\n",
      "epoch 293 loss = 1.138249\n",
      "epoch 294 loss = 0.974651\n",
      "epoch 295 loss = 1.255213\n",
      "epoch 296 loss = 1.072811\n",
      "epoch 297 loss = 1.153196\n",
      "epoch 298 loss = 1.062507\n",
      "epoch 299 loss = 1.014596\n",
      "epoch 300 loss = 1.089126\n",
      "epoch 301 loss = 0.925491\n",
      "epoch 302 loss = 1.211477\n",
      "epoch 303 loss = 0.871504\n",
      "epoch 304 loss = 0.974295\n",
      "epoch 305 loss = 1.050612\n",
      "epoch 306 loss = 1.028340\n",
      "epoch 307 loss = 0.981611\n",
      "epoch 308 loss = 0.988530\n",
      "epoch 309 loss = 0.926760\n",
      "epoch 310 loss = 0.931734\n",
      "epoch 311 loss = 0.995747\n",
      "epoch 312 loss = 1.235694\n",
      "epoch 313 loss = 0.983331\n",
      "epoch 314 loss = 1.144894\n",
      "epoch 315 loss = 1.064162\n",
      "epoch 316 loss = 1.178576\n",
      "epoch 317 loss = 1.307338\n",
      "epoch 318 loss = 0.947921\n",
      "epoch 319 loss = 0.970598\n",
      "epoch 320 loss = 1.097712\n",
      "epoch 321 loss = 1.095623\n",
      "epoch 322 loss = 1.076560\n",
      "epoch 323 loss = 1.037550\n",
      "epoch 324 loss = 0.918065\n",
      "epoch 325 loss = 1.027387\n",
      "epoch 326 loss = 1.042641\n",
      "epoch 327 loss = 0.960687\n",
      "epoch 328 loss = 1.309273\n",
      "epoch 329 loss = 1.213361\n",
      "epoch 330 loss = 1.081459\n",
      "epoch 331 loss = 1.001008\n",
      "epoch 332 loss = 1.114561\n",
      "epoch 333 loss = 0.908321\n",
      "epoch 334 loss = 1.057421\n",
      "epoch 335 loss = 0.913927\n",
      "epoch 336 loss = 1.076905\n",
      "epoch 337 loss = 1.083079\n",
      "epoch 338 loss = 0.984796\n",
      "epoch 339 loss = 1.048462\n",
      "epoch 340 loss = 0.961031\n",
      "epoch 341 loss = 0.967247\n",
      "epoch 342 loss = 1.225721\n",
      "epoch 343 loss = 0.984399\n",
      "epoch 344 loss = 1.165981\n",
      "epoch 345 loss = 1.051296\n",
      "epoch 346 loss = 1.047421\n",
      "epoch 347 loss = 1.294316\n",
      "epoch 348 loss = 0.899587\n",
      "epoch 349 loss = 1.243543\n",
      "epoch 350 loss = 0.980952\n",
      "epoch 351 loss = 1.138282\n",
      "epoch 352 loss = 1.015774\n",
      "epoch 353 loss = 1.032156\n",
      "epoch 354 loss = 1.060430\n",
      "epoch 355 loss = 0.989887\n",
      "epoch 356 loss = 1.245922\n",
      "epoch 357 loss = 1.053392\n",
      "epoch 358 loss = 0.932669\n",
      "epoch 359 loss = 1.020042\n",
      "epoch 360 loss = 1.169665\n",
      "epoch 361 loss = 1.062129\n",
      "epoch 362 loss = 1.265091\n",
      "epoch 363 loss = 0.983224\n",
      "epoch 364 loss = 0.957357\n",
      "epoch 365 loss = 0.945655\n",
      "epoch 366 loss = 0.980659\n",
      "epoch 367 loss = 1.070409\n",
      "epoch 368 loss = 1.059908\n",
      "epoch 369 loss = 0.933626\n",
      "epoch 370 loss = 0.953173\n",
      "epoch 371 loss = 0.978599\n",
      "epoch 372 loss = 1.046454\n",
      "epoch 373 loss = 1.282980\n",
      "epoch 374 loss = 1.002216\n",
      "epoch 375 loss = 1.038706\n",
      "epoch 376 loss = 1.152283\n",
      "epoch 377 loss = 1.045950\n",
      "epoch 378 loss = 0.930436\n",
      "epoch 379 loss = 0.956094\n",
      "epoch 380 loss = 1.100983\n",
      "epoch 381 loss = 1.044145\n",
      "epoch 382 loss = 0.945985\n",
      "epoch 383 loss = 0.995680\n",
      "epoch 384 loss = 0.871410\n",
      "epoch 385 loss = 0.970899\n",
      "epoch 386 loss = 1.007621\n",
      "epoch 387 loss = 1.012652\n",
      "epoch 388 loss = 1.115011\n",
      "epoch 389 loss = 1.054017\n",
      "epoch 390 loss = 0.966069\n",
      "epoch 391 loss = 1.178812\n",
      "epoch 392 loss = 1.089177\n",
      "epoch 393 loss = 1.096807\n",
      "epoch 394 loss = 1.025795\n",
      "epoch 395 loss = 0.898936\n",
      "epoch 396 loss = 1.079731\n",
      "epoch 397 loss = 1.174827\n",
      "epoch 398 loss = 0.924369\n",
      "epoch 399 loss = 1.087219\n",
      "epoch 400 loss = 1.057103\n",
      "epoch 401 loss = 1.203006\n",
      "epoch 402 loss = 1.069699\n",
      "epoch 403 loss = 0.985379\n",
      "epoch 404 loss = 0.797895\n",
      "epoch 405 loss = 0.992289\n",
      "epoch 406 loss = 1.031395\n",
      "epoch 407 loss = 1.014958\n",
      "epoch 408 loss = 1.019622\n",
      "epoch 409 loss = 1.076190\n",
      "epoch 410 loss = 0.973810\n",
      "epoch 411 loss = 1.022082\n",
      "epoch 412 loss = 0.815063\n",
      "epoch 413 loss = 1.035402\n",
      "epoch 414 loss = 1.045527\n",
      "epoch 415 loss = 1.010736\n",
      "epoch 416 loss = 1.056122\n",
      "epoch 417 loss = 0.917562\n",
      "epoch 418 loss = 1.136887\n",
      "epoch 419 loss = 1.346712\n",
      "epoch 420 loss = 1.032222\n",
      "epoch 421 loss = 0.950913\n",
      "epoch 422 loss = 1.057697\n",
      "epoch 423 loss = 0.957367\n",
      "epoch 424 loss = 1.115433\n",
      "epoch 425 loss = 1.002577\n",
      "epoch 426 loss = 0.957172\n",
      "epoch 427 loss = 0.763333\n",
      "epoch 428 loss = 0.851520\n",
      "epoch 429 loss = 0.901118\n",
      "epoch 430 loss = 1.089834\n",
      "epoch 431 loss = 0.951023\n",
      "epoch 432 loss = 1.101211\n",
      "epoch 433 loss = 0.995250\n",
      "epoch 434 loss = 0.893921\n",
      "epoch 435 loss = 1.189727\n",
      "epoch 436 loss = 1.041922\n",
      "epoch 437 loss = 0.832128\n",
      "epoch 438 loss = 1.001911\n",
      "epoch 439 loss = 1.090816\n",
      "epoch 440 loss = 1.185603\n",
      "epoch 441 loss = 1.063587\n",
      "epoch 442 loss = 1.181665\n",
      "epoch 443 loss = 1.086644\n",
      "epoch 444 loss = 1.128167\n",
      "epoch 445 loss = 0.946812\n",
      "epoch 446 loss = 0.889034\n",
      "epoch 447 loss = 0.976699\n",
      "epoch 448 loss = 0.946261\n",
      "epoch 449 loss = 0.984898\n",
      "epoch 450 loss = 1.046725\n",
      "epoch 451 loss = 0.936667\n",
      "epoch 452 loss = 1.084339\n",
      "epoch 453 loss = 0.986634\n",
      "epoch 454 loss = 1.175173\n",
      "epoch 455 loss = 0.908472\n",
      "epoch 456 loss = 1.060447\n",
      "epoch 457 loss = 0.969667\n",
      "epoch 458 loss = 1.121537\n",
      "epoch 459 loss = 0.991497\n",
      "epoch 460 loss = 1.151077\n",
      "epoch 461 loss = 0.872486\n",
      "epoch 462 loss = 1.014309\n",
      "epoch 463 loss = 0.966405\n",
      "epoch 464 loss = 0.974993\n",
      "epoch 465 loss = 0.800496\n",
      "epoch 466 loss = 0.970865\n",
      "epoch 467 loss = 1.011804\n",
      "epoch 468 loss = 0.836043\n",
      "epoch 469 loss = 0.984602\n",
      "epoch 470 loss = 1.087046\n",
      "epoch 471 loss = 1.131737\n",
      "epoch 472 loss = 1.111240\n",
      "epoch 473 loss = 0.947911\n",
      "epoch 474 loss = 0.912618\n",
      "epoch 475 loss = 0.956835\n",
      "epoch 476 loss = 1.053342\n",
      "epoch 477 loss = 0.828567\n",
      "epoch 478 loss = 0.968012\n",
      "epoch 479 loss = 1.039760\n",
      "epoch 480 loss = 0.993592\n",
      "epoch 481 loss = 0.969014\n",
      "epoch 482 loss = 0.868944\n",
      "epoch 483 loss = 1.033674\n",
      "epoch 484 loss = 0.923984\n",
      "epoch 485 loss = 0.912452\n",
      "epoch 486 loss = 1.144081\n",
      "epoch 487 loss = 0.794826\n",
      "epoch 488 loss = 1.034092\n",
      "epoch 489 loss = 1.172019\n",
      "epoch 490 loss = 1.003013\n",
      "epoch 491 loss = 1.185965\n",
      "epoch 492 loss = 0.845933\n",
      "epoch 493 loss = 0.930805\n",
      "epoch 494 loss = 0.859778\n",
      "epoch 495 loss = 1.063396\n",
      "epoch 496 loss = 1.276650\n",
      "epoch 497 loss = 1.301948\n",
      "epoch 498 loss = 0.942106\n",
      "epoch 499 loss = 1.206491\n",
      "final loss = 1.206491\n",
      "accuracy_mc = tensor(0.3538, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.3499, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.7474, device='cuda:0')\n",
      "training time = 305.2403836250305 seconds\n",
      "testing time = 3.1616275310516357 seconds\n",
      "\n",
      "Training with split 1\n",
      "epoch 0 loss = 2.248862\n",
      "epoch 1 loss = 2.060227\n",
      "epoch 2 loss = 2.132067\n",
      "epoch 3 loss = 2.025126\n",
      "epoch 4 loss = 2.099831\n",
      "epoch 5 loss = 2.076684\n",
      "epoch 6 loss = 1.952089\n",
      "epoch 7 loss = 1.849588\n",
      "epoch 8 loss = 2.066349\n",
      "epoch 9 loss = 1.960961\n",
      "epoch 10 loss = 1.942169\n",
      "epoch 11 loss = 1.940133\n",
      "epoch 12 loss = 2.043006\n",
      "epoch 13 loss = 1.912650\n",
      "epoch 14 loss = 1.899297\n",
      "epoch 15 loss = 1.807915\n",
      "epoch 16 loss = 1.836384\n",
      "epoch 17 loss = 1.830833\n",
      "epoch 18 loss = 1.898465\n",
      "epoch 19 loss = 1.867165\n",
      "epoch 20 loss = 1.904360\n",
      "epoch 21 loss = 1.812403\n",
      "epoch 22 loss = 1.568954\n",
      "epoch 23 loss = 1.707426\n",
      "epoch 24 loss = 1.971605\n",
      "epoch 25 loss = 1.791046\n",
      "epoch 26 loss = 1.736867\n",
      "epoch 27 loss = 1.707179\n",
      "epoch 28 loss = 1.643365\n",
      "epoch 29 loss = 1.825242\n",
      "epoch 30 loss = 1.766251\n",
      "epoch 31 loss = 1.693858\n",
      "epoch 32 loss = 1.675524\n",
      "epoch 33 loss = 1.703889\n",
      "epoch 34 loss = 1.630701\n",
      "epoch 35 loss = 1.532500\n",
      "epoch 36 loss = 1.815006\n",
      "epoch 37 loss = 1.779681\n",
      "epoch 38 loss = 1.686846\n",
      "epoch 39 loss = 1.606516\n",
      "epoch 40 loss = 1.551935\n",
      "epoch 41 loss = 1.607182\n",
      "epoch 42 loss = 1.576854\n",
      "epoch 43 loss = 1.697100\n",
      "epoch 44 loss = 1.716248\n",
      "epoch 45 loss = 1.593060\n",
      "epoch 46 loss = 1.796579\n",
      "epoch 47 loss = 1.636819\n",
      "epoch 48 loss = 1.628410\n",
      "epoch 49 loss = 1.570009\n",
      "epoch 50 loss = 1.602518\n",
      "epoch 51 loss = 1.654939\n",
      "epoch 52 loss = 1.526567\n",
      "epoch 53 loss = 1.532637\n",
      "epoch 54 loss = 1.563621\n",
      "epoch 55 loss = 1.400781\n",
      "epoch 56 loss = 1.607244\n",
      "epoch 57 loss = 1.491155\n",
      "epoch 58 loss = 1.591189\n",
      "epoch 59 loss = 1.401193\n",
      "epoch 60 loss = 1.365135\n",
      "epoch 61 loss = 1.590301\n",
      "epoch 62 loss = 1.476356\n",
      "epoch 63 loss = 1.429096\n",
      "epoch 64 loss = 1.526597\n",
      "epoch 65 loss = 1.478062\n",
      "epoch 66 loss = 1.507800\n",
      "epoch 67 loss = 1.695156\n",
      "epoch 68 loss = 1.484716\n",
      "epoch 69 loss = 1.453379\n",
      "epoch 70 loss = 1.488465\n",
      "epoch 71 loss = 1.463856\n",
      "epoch 72 loss = 1.394157\n",
      "epoch 73 loss = 1.577694\n",
      "epoch 74 loss = 1.419111\n",
      "epoch 75 loss = 1.573183\n",
      "epoch 76 loss = 1.441613\n",
      "epoch 77 loss = 1.527929\n",
      "epoch 78 loss = 1.462168\n",
      "epoch 79 loss = 1.544226\n",
      "epoch 80 loss = 1.477933\n",
      "epoch 81 loss = 1.288197\n",
      "epoch 82 loss = 1.597382\n",
      "epoch 83 loss = 1.361666\n",
      "epoch 84 loss = 1.438681\n",
      "epoch 85 loss = 1.652211\n",
      "epoch 86 loss = 1.389817\n",
      "epoch 87 loss = 1.351993\n",
      "epoch 88 loss = 1.371824\n",
      "epoch 89 loss = 1.443317\n",
      "epoch 90 loss = 1.413083\n",
      "epoch 91 loss = 1.342384\n",
      "epoch 92 loss = 1.657420\n",
      "epoch 93 loss = 1.492354\n",
      "epoch 94 loss = 1.371458\n",
      "epoch 95 loss = 1.385636\n",
      "epoch 96 loss = 1.481774\n",
      "epoch 97 loss = 1.371051\n",
      "epoch 98 loss = 1.387169\n",
      "epoch 99 loss = 1.636872\n",
      "epoch 100 loss = 1.327896\n",
      "epoch 101 loss = 1.419431\n",
      "epoch 102 loss = 1.456456\n",
      "epoch 103 loss = 1.582435\n",
      "epoch 104 loss = 1.261732\n",
      "epoch 105 loss = 1.380646\n",
      "epoch 106 loss = 1.505082\n",
      "epoch 107 loss = 1.556264\n",
      "epoch 108 loss = 1.408994\n",
      "epoch 109 loss = 1.679688\n",
      "epoch 110 loss = 1.562778\n",
      "epoch 111 loss = 1.250341\n",
      "epoch 112 loss = 1.366621\n",
      "epoch 113 loss = 1.302984\n",
      "epoch 114 loss = 1.376026\n",
      "epoch 115 loss = 1.394995\n",
      "epoch 116 loss = 1.442063\n",
      "epoch 117 loss = 1.410923\n",
      "epoch 118 loss = 1.371622\n",
      "epoch 119 loss = 1.366350\n",
      "epoch 120 loss = 1.388851\n",
      "epoch 121 loss = 1.280033\n",
      "epoch 122 loss = 1.240798\n",
      "epoch 123 loss = 1.566136\n",
      "epoch 124 loss = 1.644750\n",
      "epoch 125 loss = 1.428668\n",
      "epoch 126 loss = 1.310209\n",
      "epoch 127 loss = 1.389278\n",
      "epoch 128 loss = 1.388445\n",
      "epoch 129 loss = 1.566767\n",
      "epoch 130 loss = 1.645274\n",
      "epoch 131 loss = 1.311506\n",
      "epoch 132 loss = 1.419648\n",
      "epoch 133 loss = 1.272717\n",
      "epoch 134 loss = 1.473480\n",
      "epoch 135 loss = 1.185719\n",
      "epoch 136 loss = 1.410979\n",
      "epoch 137 loss = 1.343442\n",
      "epoch 138 loss = 1.412761\n",
      "epoch 139 loss = 1.439020\n",
      "epoch 140 loss = 1.371255\n",
      "epoch 141 loss = 1.307180\n",
      "epoch 142 loss = 1.406943\n",
      "epoch 143 loss = 1.380799\n",
      "epoch 144 loss = 1.376142\n",
      "epoch 145 loss = 1.403142\n",
      "epoch 146 loss = 1.386981\n",
      "epoch 147 loss = 1.667866\n",
      "epoch 148 loss = 1.537471\n",
      "epoch 149 loss = 1.226273\n",
      "epoch 150 loss = 1.447470\n",
      "epoch 151 loss = 1.485077\n",
      "epoch 152 loss = 1.340718\n",
      "epoch 153 loss = 1.380989\n",
      "epoch 154 loss = 1.474714\n",
      "epoch 155 loss = 1.295759\n",
      "epoch 156 loss = 1.377765\n",
      "epoch 157 loss = 1.504681\n",
      "epoch 158 loss = 1.311489\n",
      "epoch 159 loss = 1.397727\n",
      "epoch 160 loss = 1.340556\n",
      "epoch 161 loss = 1.495446\n",
      "epoch 162 loss = 1.386356\n",
      "epoch 163 loss = 1.420287\n",
      "epoch 164 loss = 1.419674\n",
      "epoch 165 loss = 1.370426\n",
      "epoch 166 loss = 1.303850\n",
      "epoch 167 loss = 1.339695\n",
      "epoch 168 loss = 1.479397\n",
      "epoch 169 loss = 1.371748\n",
      "epoch 170 loss = 1.296032\n",
      "epoch 171 loss = 1.681249\n",
      "epoch 172 loss = 1.431375\n",
      "epoch 173 loss = 1.315992\n",
      "epoch 174 loss = 1.193788\n",
      "epoch 175 loss = 1.305176\n",
      "epoch 176 loss = 1.469911\n",
      "epoch 177 loss = 1.331453\n",
      "epoch 178 loss = 1.282685\n",
      "epoch 179 loss = 1.312760\n",
      "epoch 180 loss = 1.400235\n",
      "epoch 181 loss = 1.487829\n",
      "epoch 182 loss = 1.294296\n",
      "epoch 183 loss = 1.504426\n",
      "epoch 184 loss = 1.228354\n",
      "epoch 185 loss = 1.197100\n",
      "epoch 186 loss = 1.232962\n",
      "epoch 187 loss = 1.323655\n",
      "epoch 188 loss = 1.367116\n",
      "epoch 189 loss = 1.249267\n",
      "epoch 190 loss = 1.249256\n",
      "epoch 191 loss = 1.428458\n",
      "epoch 192 loss = 1.343874\n",
      "epoch 193 loss = 1.354252\n",
      "epoch 194 loss = 1.126354\n",
      "epoch 195 loss = 1.212808\n",
      "epoch 196 loss = 1.145854\n",
      "epoch 197 loss = 1.262716\n",
      "epoch 198 loss = 1.489659\n",
      "epoch 199 loss = 1.450672\n",
      "epoch 200 loss = 1.503065\n",
      "epoch 201 loss = 1.324620\n",
      "epoch 202 loss = 1.250321\n",
      "epoch 203 loss = 1.436694\n",
      "epoch 204 loss = 1.454411\n",
      "epoch 205 loss = 1.446871\n",
      "epoch 206 loss = 1.460192\n",
      "epoch 207 loss = 1.408278\n",
      "epoch 208 loss = 1.674690\n",
      "epoch 209 loss = 1.384417\n",
      "epoch 210 loss = 1.267095\n",
      "epoch 211 loss = 1.281330\n",
      "epoch 212 loss = 1.473493\n",
      "epoch 213 loss = 1.338275\n",
      "epoch 214 loss = 1.279648\n",
      "epoch 215 loss = 1.578988\n",
      "epoch 216 loss = 1.210537\n",
      "epoch 217 loss = 1.472673\n",
      "epoch 218 loss = 1.423990\n",
      "epoch 219 loss = 1.167683\n",
      "epoch 220 loss = 1.414768\n",
      "epoch 221 loss = 1.281507\n",
      "epoch 222 loss = 1.323608\n",
      "epoch 223 loss = 1.357389\n",
      "epoch 224 loss = 1.403268\n",
      "epoch 225 loss = 1.305233\n",
      "epoch 226 loss = 1.189119\n",
      "epoch 227 loss = 1.521458\n",
      "epoch 228 loss = 1.304887\n",
      "epoch 229 loss = 1.235736\n",
      "epoch 230 loss = 1.417425\n",
      "epoch 231 loss = 1.227551\n",
      "epoch 232 loss = 1.356231\n",
      "epoch 233 loss = 1.161525\n",
      "epoch 234 loss = 1.378269\n",
      "epoch 235 loss = 1.170782\n",
      "epoch 236 loss = 1.249056\n",
      "epoch 237 loss = 1.197093\n",
      "epoch 238 loss = 1.356187\n",
      "epoch 239 loss = 1.441163\n",
      "epoch 240 loss = 1.324038\n",
      "epoch 241 loss = 1.322626\n",
      "epoch 242 loss = 1.193979\n",
      "epoch 243 loss = 1.250151\n",
      "epoch 244 loss = 1.271018\n",
      "epoch 245 loss = 1.436615\n",
      "epoch 246 loss = 1.277122\n",
      "epoch 247 loss = 1.506153\n",
      "epoch 248 loss = 1.202635\n",
      "epoch 249 loss = 1.236373\n",
      "epoch 250 loss = 1.271405\n",
      "epoch 251 loss = 1.394652\n",
      "epoch 252 loss = 1.125934\n",
      "epoch 253 loss = 1.545767\n",
      "epoch 254 loss = 1.298391\n",
      "epoch 255 loss = 1.341860\n",
      "epoch 256 loss = 1.292752\n",
      "epoch 257 loss = 1.239210\n",
      "epoch 258 loss = 1.212958\n",
      "epoch 259 loss = 1.178223\n",
      "epoch 260 loss = 1.219729\n",
      "epoch 261 loss = 1.488998\n",
      "epoch 262 loss = 1.493056\n",
      "epoch 263 loss = 1.363526\n",
      "epoch 264 loss = 1.550169\n",
      "epoch 265 loss = 1.150144\n",
      "epoch 266 loss = 1.216691\n",
      "epoch 267 loss = 1.284850\n",
      "epoch 268 loss = 1.235192\n",
      "epoch 269 loss = 1.359799\n",
      "epoch 270 loss = 1.281710\n",
      "epoch 271 loss = 1.269054\n",
      "epoch 272 loss = 1.236360\n",
      "epoch 273 loss = 1.150317\n",
      "epoch 274 loss = 1.256176\n",
      "epoch 275 loss = 1.316636\n",
      "epoch 276 loss = 1.235376\n",
      "epoch 277 loss = 1.301553\n",
      "epoch 278 loss = 1.297033\n",
      "epoch 279 loss = 1.195245\n",
      "epoch 280 loss = 1.419557\n",
      "epoch 281 loss = 1.193563\n",
      "epoch 282 loss = 1.410569\n",
      "epoch 283 loss = 1.327801\n",
      "epoch 284 loss = 1.570737\n",
      "epoch 285 loss = 1.365495\n",
      "epoch 286 loss = 1.182683\n",
      "epoch 287 loss = 1.318988\n",
      "epoch 288 loss = 1.224020\n",
      "epoch 289 loss = 1.380047\n",
      "epoch 290 loss = 1.154063\n",
      "epoch 291 loss = 1.526759\n",
      "epoch 292 loss = 1.424334\n",
      "epoch 293 loss = 1.218134\n",
      "epoch 294 loss = 1.405147\n",
      "epoch 295 loss = 1.154481\n",
      "epoch 296 loss = 1.130425\n",
      "epoch 297 loss = 1.524742\n",
      "epoch 298 loss = 1.410520\n",
      "epoch 299 loss = 1.199610\n",
      "epoch 300 loss = 1.132500\n",
      "epoch 301 loss = 1.275909\n",
      "epoch 302 loss = 1.420577\n",
      "epoch 303 loss = 1.377049\n",
      "epoch 304 loss = 1.204333\n",
      "epoch 305 loss = 1.213691\n",
      "epoch 306 loss = 1.421892\n",
      "epoch 307 loss = 1.396137\n",
      "epoch 308 loss = 1.212103\n",
      "epoch 309 loss = 1.421922\n",
      "epoch 310 loss = 1.341192\n",
      "epoch 311 loss = 1.219551\n",
      "epoch 312 loss = 1.246371\n",
      "epoch 313 loss = 1.276301\n",
      "epoch 314 loss = 1.124724\n",
      "epoch 315 loss = 1.237015\n",
      "epoch 316 loss = 1.379984\n",
      "epoch 317 loss = 1.328510\n",
      "epoch 318 loss = 1.272750\n",
      "epoch 319 loss = 1.228131\n",
      "epoch 320 loss = 1.481514\n",
      "epoch 321 loss = 1.276608\n",
      "epoch 322 loss = 1.416929\n",
      "epoch 323 loss = 1.263283\n",
      "epoch 324 loss = 1.299397\n",
      "epoch 325 loss = 1.232278\n",
      "epoch 326 loss = 1.265858\n",
      "epoch 327 loss = 1.262832\n",
      "epoch 328 loss = 1.435230\n",
      "epoch 329 loss = 1.391044\n",
      "epoch 330 loss = 1.250393\n",
      "epoch 331 loss = 1.310538\n",
      "epoch 332 loss = 1.409165\n",
      "epoch 333 loss = 1.231583\n",
      "epoch 334 loss = 1.479755\n",
      "epoch 335 loss = 1.253953\n",
      "epoch 336 loss = 1.443863\n",
      "epoch 337 loss = 1.216941\n",
      "epoch 338 loss = 1.399266\n",
      "epoch 339 loss = 1.352355\n",
      "epoch 340 loss = 1.349982\n",
      "epoch 341 loss = 1.264698\n",
      "epoch 342 loss = 1.347281\n",
      "epoch 343 loss = 1.219800\n",
      "epoch 344 loss = 1.153018\n",
      "epoch 345 loss = 1.308249\n",
      "epoch 346 loss = 1.238452\n",
      "epoch 347 loss = 1.247473\n",
      "epoch 348 loss = 1.598661\n",
      "epoch 349 loss = 1.224725\n",
      "epoch 350 loss = 1.444604\n",
      "epoch 351 loss = 1.347147\n",
      "epoch 352 loss = 1.462646\n",
      "epoch 353 loss = 1.184180\n",
      "epoch 354 loss = 1.454296\n",
      "epoch 355 loss = 1.280113\n",
      "epoch 356 loss = 1.255805\n",
      "epoch 357 loss = 1.263831\n",
      "epoch 358 loss = 1.356671\n",
      "epoch 359 loss = 1.242143\n",
      "epoch 360 loss = 1.178841\n",
      "epoch 361 loss = 1.308519\n",
      "epoch 362 loss = 1.218629\n",
      "epoch 363 loss = 1.432073\n",
      "epoch 364 loss = 1.248447\n",
      "epoch 365 loss = 1.438553\n",
      "epoch 366 loss = 1.304590\n",
      "epoch 367 loss = 1.375879\n",
      "epoch 368 loss = 1.384163\n",
      "epoch 369 loss = 1.342026\n",
      "epoch 370 loss = 1.461635\n",
      "epoch 371 loss = 1.147328\n",
      "epoch 372 loss = 1.367582\n",
      "epoch 373 loss = 1.310343\n",
      "epoch 374 loss = 1.445853\n",
      "epoch 375 loss = 1.393449\n",
      "epoch 376 loss = 1.200180\n",
      "epoch 377 loss = 1.169330\n",
      "epoch 378 loss = 1.210443\n",
      "epoch 379 loss = 1.161962\n",
      "epoch 380 loss = 1.179583\n",
      "epoch 381 loss = 1.188454\n",
      "epoch 382 loss = 1.213138\n",
      "epoch 383 loss = 1.441394\n",
      "epoch 384 loss = 1.359914\n",
      "epoch 385 loss = 1.252041\n",
      "epoch 386 loss = 1.633823\n",
      "epoch 387 loss = 1.236315\n",
      "epoch 388 loss = 1.407687\n",
      "epoch 389 loss = 1.388469\n",
      "epoch 390 loss = 1.254516\n",
      "epoch 391 loss = 1.357942\n",
      "epoch 392 loss = 1.238545\n",
      "epoch 393 loss = 1.199836\n",
      "epoch 394 loss = 1.319444\n",
      "epoch 395 loss = 1.395851\n",
      "epoch 396 loss = 1.427232\n",
      "epoch 397 loss = 1.580863\n",
      "epoch 398 loss = 1.323774\n",
      "epoch 399 loss = 1.222798\n",
      "epoch 400 loss = 1.302418\n",
      "epoch 401 loss = 1.421818\n",
      "epoch 402 loss = 1.203041\n",
      "epoch 403 loss = 1.200194\n",
      "epoch 404 loss = 1.338113\n",
      "epoch 405 loss = 1.245997\n",
      "epoch 406 loss = 1.336192\n",
      "epoch 407 loss = 1.167865\n",
      "epoch 408 loss = 1.340145\n",
      "epoch 409 loss = 1.288990\n",
      "epoch 410 loss = 1.261886\n",
      "epoch 411 loss = 1.327234\n",
      "epoch 412 loss = 1.497975\n",
      "epoch 413 loss = 1.288404\n",
      "epoch 414 loss = 1.339328\n",
      "epoch 415 loss = 1.239415\n",
      "epoch 416 loss = 1.166228\n",
      "epoch 417 loss = 1.418089\n",
      "epoch 418 loss = 1.314861\n",
      "epoch 419 loss = 1.326658\n",
      "epoch 420 loss = 1.417184\n",
      "epoch 421 loss = 1.290508\n",
      "epoch 422 loss = 1.395611\n",
      "epoch 423 loss = 1.236182\n",
      "epoch 424 loss = 1.303427\n",
      "epoch 425 loss = 1.161009\n",
      "epoch 426 loss = 1.256190\n",
      "epoch 427 loss = 1.090724\n",
      "epoch 428 loss = 1.273558\n",
      "epoch 429 loss = 1.282156\n",
      "epoch 430 loss = 1.297282\n",
      "epoch 431 loss = 1.403588\n",
      "epoch 432 loss = 1.302034\n",
      "epoch 433 loss = 1.506433\n",
      "epoch 434 loss = 1.122169\n",
      "epoch 435 loss = 1.184497\n",
      "epoch 436 loss = 1.086772\n",
      "epoch 437 loss = 1.254499\n",
      "epoch 438 loss = 1.402717\n",
      "epoch 439 loss = 1.056414\n",
      "epoch 440 loss = 1.589410\n",
      "epoch 441 loss = 1.242123\n",
      "epoch 442 loss = 1.242757\n",
      "epoch 443 loss = 1.172423\n",
      "epoch 444 loss = 1.250962\n",
      "epoch 445 loss = 1.549590\n",
      "epoch 446 loss = 1.214793\n",
      "epoch 447 loss = 1.351746\n",
      "epoch 448 loss = 1.454793\n",
      "epoch 449 loss = 1.266162\n",
      "epoch 450 loss = 1.452684\n",
      "epoch 451 loss = 1.518236\n",
      "epoch 452 loss = 1.203792\n",
      "epoch 453 loss = 1.486084\n",
      "epoch 454 loss = 1.281590\n",
      "epoch 455 loss = 1.257000\n",
      "epoch 456 loss = 1.171177\n",
      "epoch 457 loss = 1.080440\n",
      "epoch 458 loss = 1.308966\n",
      "epoch 459 loss = 1.162597\n",
      "epoch 460 loss = 1.205234\n",
      "epoch 461 loss = 1.214323\n",
      "epoch 462 loss = 1.257913\n",
      "epoch 463 loss = 1.404572\n",
      "epoch 464 loss = 1.109481\n",
      "epoch 465 loss = 1.277181\n",
      "epoch 466 loss = 1.192477\n",
      "epoch 467 loss = 1.358272\n",
      "epoch 468 loss = 1.186100\n",
      "epoch 469 loss = 1.350667\n",
      "epoch 470 loss = 1.034940\n",
      "epoch 471 loss = 1.189359\n",
      "epoch 472 loss = 1.393979\n",
      "epoch 473 loss = 1.393272\n",
      "epoch 474 loss = 1.104311\n",
      "epoch 475 loss = 1.148911\n",
      "epoch 476 loss = 1.104372\n",
      "epoch 477 loss = 1.236109\n",
      "epoch 478 loss = 1.233443\n",
      "epoch 479 loss = 1.292378\n",
      "epoch 480 loss = 1.154546\n",
      "epoch 481 loss = 1.333853\n",
      "epoch 482 loss = 1.382005\n",
      "epoch 483 loss = 1.468916\n",
      "epoch 484 loss = 1.346614\n",
      "epoch 485 loss = 1.248964\n",
      "epoch 486 loss = 1.233532\n",
      "epoch 487 loss = 1.317842\n",
      "epoch 488 loss = 1.148174\n",
      "epoch 489 loss = 1.299393\n",
      "epoch 490 loss = 1.226040\n",
      "epoch 491 loss = 1.103212\n",
      "epoch 492 loss = 1.233012\n",
      "epoch 493 loss = 1.312725\n",
      "epoch 494 loss = 1.319862\n",
      "epoch 495 loss = 1.141767\n",
      "epoch 496 loss = 1.249475\n",
      "epoch 497 loss = 1.297802\n",
      "epoch 498 loss = 1.443926\n",
      "epoch 499 loss = 1.153099\n",
      "final loss = 1.153099\n",
      "accuracy_mc = tensor(0.4046, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.4171, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.6258, device='cuda:0')\n",
      "training time = 305.7869074344635 seconds\n",
      "testing time = 3.1490752696990967 seconds\n",
      "\n",
      "Training with split 2\n",
      "epoch 0 loss = 2.237489\n",
      "epoch 1 loss = 2.137951\n",
      "epoch 2 loss = 1.981264\n",
      "epoch 3 loss = 2.051647\n",
      "epoch 4 loss = 1.957989\n",
      "epoch 5 loss = 2.052073\n",
      "epoch 6 loss = 1.968619\n",
      "epoch 7 loss = 2.048528\n",
      "epoch 8 loss = 2.012068\n",
      "epoch 9 loss = 1.924836\n",
      "epoch 10 loss = 1.975196\n",
      "epoch 11 loss = 1.987819\n",
      "epoch 12 loss = 1.932160\n",
      "epoch 13 loss = 1.891551\n",
      "epoch 14 loss = 1.942634\n",
      "epoch 15 loss = 1.906704\n",
      "epoch 16 loss = 1.883208\n",
      "epoch 17 loss = 1.950761\n",
      "epoch 18 loss = 1.826333\n",
      "epoch 19 loss = 1.776561\n",
      "epoch 20 loss = 1.776167\n",
      "epoch 21 loss = 1.724940\n",
      "epoch 22 loss = 1.926398\n",
      "epoch 23 loss = 1.572496\n",
      "epoch 24 loss = 1.806382\n",
      "epoch 25 loss = 1.679328\n",
      "epoch 26 loss = 1.592379\n",
      "epoch 27 loss = 1.594293\n",
      "epoch 28 loss = 1.742480\n",
      "epoch 29 loss = 1.658176\n",
      "epoch 30 loss = 1.689634\n",
      "epoch 31 loss = 1.561086\n",
      "epoch 32 loss = 1.590428\n",
      "epoch 33 loss = 1.704465\n",
      "epoch 34 loss = 1.684622\n",
      "epoch 35 loss = 1.648444\n",
      "epoch 36 loss = 1.593711\n",
      "epoch 37 loss = 1.660042\n",
      "epoch 38 loss = 1.637277\n",
      "epoch 39 loss = 1.526671\n",
      "epoch 40 loss = 1.556298\n",
      "epoch 41 loss = 1.532632\n",
      "epoch 42 loss = 1.554450\n",
      "epoch 43 loss = 1.543355\n",
      "epoch 44 loss = 1.453213\n",
      "epoch 45 loss = 1.491992\n",
      "epoch 46 loss = 1.466727\n",
      "epoch 47 loss = 1.555771\n",
      "epoch 48 loss = 1.408181\n",
      "epoch 49 loss = 1.474297\n",
      "epoch 50 loss = 1.377004\n",
      "epoch 51 loss = 1.485350\n",
      "epoch 52 loss = 1.477187\n",
      "epoch 53 loss = 1.405772\n",
      "epoch 54 loss = 1.378169\n",
      "epoch 55 loss = 1.584306\n",
      "epoch 56 loss = 1.386600\n",
      "epoch 57 loss = 1.627226\n",
      "epoch 58 loss = 1.420168\n",
      "epoch 59 loss = 1.518764\n",
      "epoch 60 loss = 1.520978\n",
      "epoch 61 loss = 1.373830\n",
      "epoch 62 loss = 1.484033\n",
      "epoch 63 loss = 1.728262\n",
      "epoch 64 loss = 1.449657\n",
      "epoch 65 loss = 1.545513\n",
      "epoch 66 loss = 1.383831\n",
      "epoch 67 loss = 1.426537\n",
      "epoch 68 loss = 1.284122\n",
      "epoch 69 loss = 1.368845\n",
      "epoch 70 loss = 1.360486\n",
      "epoch 71 loss = 1.465899\n",
      "epoch 72 loss = 1.449030\n",
      "epoch 73 loss = 1.390113\n",
      "epoch 74 loss = 1.536683\n",
      "epoch 75 loss = 1.349430\n",
      "epoch 76 loss = 1.555544\n",
      "epoch 77 loss = 1.449356\n",
      "epoch 78 loss = 1.456865\n",
      "epoch 79 loss = 1.266357\n",
      "epoch 80 loss = 1.300954\n",
      "epoch 81 loss = 1.481922\n",
      "epoch 82 loss = 1.423767\n",
      "epoch 83 loss = 1.415523\n",
      "epoch 84 loss = 1.405378\n",
      "epoch 85 loss = 1.366894\n",
      "epoch 86 loss = 1.446312\n",
      "epoch 87 loss = 1.299959\n",
      "epoch 88 loss = 1.568445\n",
      "epoch 89 loss = 1.399194\n",
      "epoch 90 loss = 1.213228\n",
      "epoch 91 loss = 1.415219\n",
      "epoch 92 loss = 1.206973\n",
      "epoch 93 loss = 1.300633\n",
      "epoch 94 loss = 1.322105\n",
      "epoch 95 loss = 1.273895\n",
      "epoch 96 loss = 1.469617\n",
      "epoch 97 loss = 1.411672\n",
      "epoch 98 loss = 1.227017\n",
      "epoch 99 loss = 1.427969\n",
      "epoch 100 loss = 1.313537\n",
      "epoch 101 loss = 1.303116\n",
      "epoch 102 loss = 1.314207\n",
      "epoch 103 loss = 1.255127\n",
      "epoch 104 loss = 1.319128\n",
      "epoch 105 loss = 1.372900\n",
      "epoch 106 loss = 1.458639\n",
      "epoch 107 loss = 1.360717\n",
      "epoch 108 loss = 1.533326\n",
      "epoch 109 loss = 1.339405\n",
      "epoch 110 loss = 1.366567\n",
      "epoch 111 loss = 1.310302\n",
      "epoch 112 loss = 1.131436\n",
      "epoch 113 loss = 1.295843\n",
      "epoch 114 loss = 1.199811\n",
      "epoch 115 loss = 1.551381\n",
      "epoch 116 loss = 1.247829\n",
      "epoch 117 loss = 1.378367\n",
      "epoch 118 loss = 1.092717\n",
      "epoch 119 loss = 1.301362\n",
      "epoch 120 loss = 1.245362\n",
      "epoch 121 loss = 1.345142\n",
      "epoch 122 loss = 1.374213\n",
      "epoch 123 loss = 1.456067\n",
      "epoch 124 loss = 1.193692\n",
      "epoch 125 loss = 1.208325\n",
      "epoch 126 loss = 1.261248\n",
      "epoch 127 loss = 1.398048\n",
      "epoch 128 loss = 1.295513\n",
      "epoch 129 loss = 1.255054\n",
      "epoch 130 loss = 1.199594\n",
      "epoch 131 loss = 1.446441\n",
      "epoch 132 loss = 1.256322\n",
      "epoch 133 loss = 1.197832\n",
      "epoch 134 loss = 1.288821\n",
      "epoch 135 loss = 1.332116\n",
      "epoch 136 loss = 1.392003\n",
      "epoch 137 loss = 1.283740\n",
      "epoch 138 loss = 1.191603\n",
      "epoch 139 loss = 1.147271\n",
      "epoch 140 loss = 1.198812\n",
      "epoch 141 loss = 1.329609\n",
      "epoch 142 loss = 1.151273\n",
      "epoch 143 loss = 1.405176\n",
      "epoch 144 loss = 1.524638\n",
      "epoch 145 loss = 1.237579\n",
      "epoch 146 loss = 1.290146\n",
      "epoch 147 loss = 1.331858\n",
      "epoch 148 loss = 1.207011\n",
      "epoch 149 loss = 1.127760\n",
      "epoch 150 loss = 1.386120\n",
      "epoch 151 loss = 1.134293\n",
      "epoch 152 loss = 1.158411\n",
      "epoch 153 loss = 1.204439\n",
      "epoch 154 loss = 1.264303\n",
      "epoch 155 loss = 1.303418\n",
      "epoch 156 loss = 1.181728\n",
      "epoch 157 loss = 1.404672\n",
      "epoch 158 loss = 1.291751\n",
      "epoch 159 loss = 1.116395\n",
      "epoch 160 loss = 1.231475\n",
      "epoch 161 loss = 1.190017\n",
      "epoch 162 loss = 1.263127\n",
      "epoch 163 loss = 1.266815\n",
      "epoch 164 loss = 1.315549\n",
      "epoch 165 loss = 1.163227\n",
      "epoch 166 loss = 1.482243\n",
      "epoch 167 loss = 1.164968\n",
      "epoch 168 loss = 1.158107\n",
      "epoch 169 loss = 1.234234\n",
      "epoch 170 loss = 1.214597\n",
      "epoch 171 loss = 1.220795\n",
      "epoch 172 loss = 1.243444\n",
      "epoch 173 loss = 1.244787\n",
      "epoch 174 loss = 1.258139\n",
      "epoch 175 loss = 1.264846\n",
      "epoch 176 loss = 1.225454\n",
      "epoch 177 loss = 1.187723\n",
      "epoch 178 loss = 1.170667\n",
      "epoch 179 loss = 1.101138\n",
      "epoch 180 loss = 1.123519\n",
      "epoch 181 loss = 1.192432\n",
      "epoch 182 loss = 1.191026\n",
      "epoch 183 loss = 1.217541\n",
      "epoch 184 loss = 1.090146\n",
      "epoch 185 loss = 1.321639\n",
      "epoch 186 loss = 1.215830\n",
      "epoch 187 loss = 1.293977\n",
      "epoch 188 loss = 1.309380\n",
      "epoch 189 loss = 1.154495\n",
      "epoch 190 loss = 1.135122\n",
      "epoch 191 loss = 1.278834\n",
      "epoch 192 loss = 1.222243\n",
      "epoch 193 loss = 1.450811\n",
      "epoch 194 loss = 1.153896\n",
      "epoch 195 loss = 1.314099\n",
      "epoch 196 loss = 1.152967\n",
      "epoch 197 loss = 1.257365\n",
      "epoch 198 loss = 1.161906\n",
      "epoch 199 loss = 1.138074\n",
      "epoch 200 loss = 1.159602\n",
      "epoch 201 loss = 1.153041\n",
      "epoch 202 loss = 1.262673\n",
      "epoch 203 loss = 1.229309\n",
      "epoch 204 loss = 1.168566\n",
      "epoch 205 loss = 1.330926\n",
      "epoch 206 loss = 1.420922\n",
      "epoch 207 loss = 1.137312\n",
      "epoch 208 loss = 1.242695\n",
      "epoch 209 loss = 1.228196\n",
      "epoch 210 loss = 1.295266\n",
      "epoch 211 loss = 1.217709\n",
      "epoch 212 loss = 1.221645\n",
      "epoch 213 loss = 1.223490\n",
      "epoch 214 loss = 1.160789\n",
      "epoch 215 loss = 1.153545\n",
      "epoch 216 loss = 1.175257\n",
      "epoch 217 loss = 1.209536\n",
      "epoch 218 loss = 1.439607\n",
      "epoch 219 loss = 1.083359\n",
      "epoch 220 loss = 1.260579\n",
      "epoch 221 loss = 1.138411\n",
      "epoch 222 loss = 1.102141\n",
      "epoch 223 loss = 1.258424\n",
      "epoch 224 loss = 1.466265\n",
      "epoch 225 loss = 1.073492\n",
      "epoch 226 loss = 1.438699\n",
      "epoch 227 loss = 1.157307\n",
      "epoch 228 loss = 1.089658\n",
      "epoch 229 loss = 1.171479\n",
      "epoch 230 loss = 1.254668\n",
      "epoch 231 loss = 1.146287\n",
      "epoch 232 loss = 1.249299\n",
      "epoch 233 loss = 1.357015\n",
      "epoch 234 loss = 1.313468\n",
      "epoch 235 loss = 1.287684\n",
      "epoch 236 loss = 1.135785\n",
      "epoch 237 loss = 1.530405\n",
      "epoch 238 loss = 1.143321\n",
      "epoch 239 loss = 1.513389\n",
      "epoch 240 loss = 1.553907\n",
      "epoch 241 loss = 1.169241\n",
      "epoch 242 loss = 1.117497\n",
      "epoch 243 loss = 1.089522\n",
      "epoch 244 loss = 1.168721\n",
      "epoch 245 loss = 1.076738\n",
      "epoch 246 loss = 1.168761\n",
      "epoch 247 loss = 1.102514\n",
      "epoch 248 loss = 1.148837\n",
      "epoch 249 loss = 1.283899\n",
      "epoch 250 loss = 1.224639\n",
      "epoch 251 loss = 1.321895\n",
      "epoch 252 loss = 1.076463\n",
      "epoch 253 loss = 1.162428\n",
      "epoch 254 loss = 1.239102\n",
      "epoch 255 loss = 1.163353\n",
      "epoch 256 loss = 1.156005\n",
      "epoch 257 loss = 1.120154\n",
      "epoch 258 loss = 1.260020\n",
      "epoch 259 loss = 1.203862\n",
      "epoch 260 loss = 1.094398\n",
      "epoch 261 loss = 1.434629\n",
      "epoch 262 loss = 1.368692\n",
      "epoch 263 loss = 1.111856\n",
      "epoch 264 loss = 1.141185\n",
      "epoch 265 loss = 1.349858\n",
      "epoch 266 loss = 1.086471\n",
      "epoch 267 loss = 1.291739\n",
      "epoch 268 loss = 1.348411\n",
      "epoch 269 loss = 1.340966\n",
      "epoch 270 loss = 1.296555\n",
      "epoch 271 loss = 1.154780\n",
      "epoch 272 loss = 1.230796\n",
      "epoch 273 loss = 1.047883\n",
      "epoch 274 loss = 1.145871\n",
      "epoch 275 loss = 1.145314\n",
      "epoch 276 loss = 1.063948\n",
      "epoch 277 loss = 1.170901\n",
      "epoch 278 loss = 1.362813\n",
      "epoch 279 loss = 1.057070\n",
      "epoch 280 loss = 1.204225\n",
      "epoch 281 loss = 1.148863\n",
      "epoch 282 loss = 1.097465\n",
      "epoch 283 loss = 1.262241\n",
      "epoch 284 loss = 1.131481\n",
      "epoch 285 loss = 1.150911\n",
      "epoch 286 loss = 1.195003\n",
      "epoch 287 loss = 1.172707\n",
      "epoch 288 loss = 1.291901\n",
      "epoch 289 loss = 1.154015\n",
      "epoch 290 loss = 1.217136\n",
      "epoch 291 loss = 1.506443\n",
      "epoch 292 loss = 1.092632\n",
      "epoch 293 loss = 1.290386\n",
      "epoch 294 loss = 1.147484\n",
      "epoch 295 loss = 1.313760\n",
      "epoch 296 loss = 1.147332\n",
      "epoch 297 loss = 1.275306\n",
      "epoch 298 loss = 1.290850\n",
      "epoch 299 loss = 1.163490\n",
      "epoch 300 loss = 1.178364\n",
      "epoch 301 loss = 1.255802\n",
      "epoch 302 loss = 1.065536\n",
      "epoch 303 loss = 1.402353\n",
      "epoch 304 loss = 1.037714\n",
      "epoch 305 loss = 1.115821\n",
      "epoch 306 loss = 1.082350\n",
      "epoch 307 loss = 1.370001\n",
      "epoch 308 loss = 1.382803\n",
      "epoch 309 loss = 1.017324\n",
      "epoch 310 loss = 1.444411\n",
      "epoch 311 loss = 1.183101\n",
      "epoch 312 loss = 1.235770\n",
      "epoch 313 loss = 1.175686\n",
      "epoch 314 loss = 1.077569\n",
      "epoch 315 loss = 1.253798\n",
      "epoch 316 loss = 1.062471\n",
      "epoch 317 loss = 1.446016\n",
      "epoch 318 loss = 1.171997\n",
      "epoch 319 loss = 1.587375\n",
      "epoch 320 loss = 1.442556\n",
      "epoch 321 loss = 1.235931\n",
      "epoch 322 loss = 1.168177\n",
      "epoch 323 loss = 1.160935\n",
      "epoch 324 loss = 1.110413\n",
      "epoch 325 loss = 1.185034\n",
      "epoch 326 loss = 1.205921\n",
      "epoch 327 loss = 1.333675\n",
      "epoch 328 loss = 1.125435\n",
      "epoch 329 loss = 1.270311\n",
      "epoch 330 loss = 1.163412\n",
      "epoch 331 loss = 1.111229\n",
      "epoch 332 loss = 1.189646\n",
      "epoch 333 loss = 1.091837\n",
      "epoch 334 loss = 1.053955\n",
      "epoch 335 loss = 1.308531\n",
      "epoch 336 loss = 1.161398\n",
      "epoch 337 loss = 1.215044\n",
      "epoch 338 loss = 1.102943\n",
      "epoch 339 loss = 1.305706\n",
      "epoch 340 loss = 1.200688\n",
      "epoch 341 loss = 1.099267\n",
      "epoch 342 loss = 1.093029\n",
      "epoch 343 loss = 1.243128\n",
      "epoch 344 loss = 1.144855\n",
      "epoch 345 loss = 1.071411\n",
      "epoch 346 loss = 1.353849\n",
      "epoch 347 loss = 1.274525\n",
      "epoch 348 loss = 1.311004\n",
      "epoch 349 loss = 1.223423\n",
      "epoch 350 loss = 1.196852\n",
      "epoch 351 loss = 1.016131\n",
      "epoch 352 loss = 1.182552\n",
      "epoch 353 loss = 1.160374\n",
      "epoch 354 loss = 1.067681\n",
      "epoch 355 loss = 1.107925\n",
      "epoch 356 loss = 1.109126\n",
      "epoch 357 loss = 1.352667\n",
      "epoch 358 loss = 1.372246\n",
      "epoch 359 loss = 1.294672\n",
      "epoch 360 loss = 1.091311\n",
      "epoch 361 loss = 1.252931\n",
      "epoch 362 loss = 1.019812\n",
      "epoch 363 loss = 1.110911\n",
      "epoch 364 loss = 1.035389\n",
      "epoch 365 loss = 1.360751\n",
      "epoch 366 loss = 1.009238\n",
      "epoch 367 loss = 1.199840\n",
      "epoch 368 loss = 1.339677\n",
      "epoch 369 loss = 1.135522\n",
      "epoch 370 loss = 1.288845\n",
      "epoch 371 loss = 1.339509\n",
      "epoch 372 loss = 1.164275\n",
      "epoch 373 loss = 1.217538\n",
      "epoch 374 loss = 1.159318\n",
      "epoch 375 loss = 1.345390\n",
      "epoch 376 loss = 1.068717\n",
      "epoch 377 loss = 1.266495\n",
      "epoch 378 loss = 1.119029\n",
      "epoch 379 loss = 1.188672\n",
      "epoch 380 loss = 1.157505\n",
      "epoch 381 loss = 1.432445\n",
      "epoch 382 loss = 1.193061\n",
      "epoch 383 loss = 1.223947\n",
      "epoch 384 loss = 1.327711\n",
      "epoch 385 loss = 1.382308\n",
      "epoch 386 loss = 1.249335\n",
      "epoch 387 loss = 1.283267\n",
      "epoch 388 loss = 1.165054\n",
      "epoch 389 loss = 1.247054\n",
      "epoch 390 loss = 1.103076\n",
      "epoch 391 loss = 1.250368\n",
      "epoch 392 loss = 1.123391\n",
      "epoch 393 loss = 1.296229\n",
      "epoch 394 loss = 1.094722\n",
      "epoch 395 loss = 1.192334\n",
      "epoch 396 loss = 1.283656\n",
      "epoch 397 loss = 1.378581\n",
      "epoch 398 loss = 1.310128\n",
      "epoch 399 loss = 1.284505\n",
      "epoch 400 loss = 1.182419\n",
      "epoch 401 loss = 1.072464\n",
      "epoch 402 loss = 1.310169\n",
      "epoch 403 loss = 1.150200\n",
      "epoch 404 loss = 1.292608\n",
      "epoch 405 loss = 1.106444\n",
      "epoch 406 loss = 1.253699\n",
      "epoch 407 loss = 1.143563\n",
      "epoch 408 loss = 1.061680\n",
      "epoch 409 loss = 1.387924\n",
      "epoch 410 loss = 1.351084\n",
      "epoch 411 loss = 1.381501\n",
      "epoch 412 loss = 1.200720\n",
      "epoch 413 loss = 1.073133\n",
      "epoch 414 loss = 1.131409\n",
      "epoch 415 loss = 1.315459\n",
      "epoch 416 loss = 1.395358\n",
      "epoch 417 loss = 1.124874\n",
      "epoch 418 loss = 1.214702\n",
      "epoch 419 loss = 1.060516\n",
      "epoch 420 loss = 1.301591\n",
      "epoch 421 loss = 1.067282\n",
      "epoch 422 loss = 1.105697\n",
      "epoch 423 loss = 1.068553\n",
      "epoch 424 loss = 1.103845\n",
      "epoch 425 loss = 1.185033\n",
      "epoch 426 loss = 1.493718\n",
      "epoch 427 loss = 1.134801\n",
      "epoch 428 loss = 1.249823\n",
      "epoch 429 loss = 1.215007\n",
      "epoch 430 loss = 1.112972\n",
      "epoch 431 loss = 1.086336\n",
      "epoch 432 loss = 1.238091\n",
      "epoch 433 loss = 1.105764\n",
      "epoch 434 loss = 1.200367\n",
      "epoch 435 loss = 1.225379\n",
      "epoch 436 loss = 1.103052\n",
      "epoch 437 loss = 1.150401\n",
      "epoch 438 loss = 1.297523\n",
      "epoch 439 loss = 1.150511\n",
      "epoch 440 loss = 1.324934\n",
      "epoch 441 loss = 1.123348\n",
      "epoch 442 loss = 1.161438\n",
      "epoch 443 loss = 1.184336\n",
      "epoch 444 loss = 1.319694\n",
      "epoch 445 loss = 1.253183\n",
      "epoch 446 loss = 1.253907\n",
      "epoch 447 loss = 1.296707\n",
      "epoch 448 loss = 1.077145\n",
      "epoch 449 loss = 1.170574\n",
      "epoch 450 loss = 1.170735\n",
      "epoch 451 loss = 1.125212\n",
      "epoch 452 loss = 1.232762\n",
      "epoch 453 loss = 1.172709\n",
      "epoch 454 loss = 1.251729\n",
      "epoch 455 loss = 1.160922\n",
      "epoch 456 loss = 1.157071\n",
      "epoch 457 loss = 1.236752\n",
      "epoch 458 loss = 1.165947\n",
      "epoch 459 loss = 1.166012\n",
      "epoch 460 loss = 1.254946\n",
      "epoch 461 loss = 1.208765\n",
      "epoch 462 loss = 1.163771\n",
      "epoch 463 loss = 1.107245\n",
      "epoch 464 loss = 1.134782\n",
      "epoch 465 loss = 1.145981\n",
      "epoch 466 loss = 1.438938\n",
      "epoch 467 loss = 1.051581\n",
      "epoch 468 loss = 1.256928\n",
      "epoch 469 loss = 1.576930\n",
      "epoch 470 loss = 1.227384\n",
      "epoch 471 loss = 1.233257\n",
      "epoch 472 loss = 1.162229\n",
      "epoch 473 loss = 1.124067\n",
      "epoch 474 loss = 1.168293\n",
      "epoch 475 loss = 1.160385\n",
      "epoch 476 loss = 1.265989\n",
      "epoch 477 loss = 1.058076\n",
      "epoch 478 loss = 1.155290\n",
      "epoch 479 loss = 1.008215\n",
      "epoch 480 loss = 1.293295\n",
      "epoch 481 loss = 1.009618\n",
      "epoch 482 loss = 1.105691\n",
      "epoch 483 loss = 1.153106\n",
      "epoch 484 loss = 1.256132\n",
      "epoch 485 loss = 1.291670\n",
      "epoch 486 loss = 1.444598\n",
      "epoch 487 loss = 1.386275\n",
      "epoch 488 loss = 1.159595\n",
      "epoch 489 loss = 1.286922\n",
      "epoch 490 loss = 1.146812\n",
      "epoch 491 loss = 1.023080\n",
      "epoch 492 loss = 1.364842\n",
      "epoch 493 loss = 1.078356\n",
      "epoch 494 loss = 1.260712\n",
      "epoch 495 loss = 1.091396\n",
      "epoch 496 loss = 1.272150\n",
      "epoch 497 loss = 1.139430\n",
      "epoch 498 loss = 1.192579\n",
      "epoch 499 loss = 1.315205\n",
      "final loss = 1.315205\n",
      "accuracy_mc = tensor(0.3618, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.3647, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.6311, device='cuda:0')\n",
      "training time = 305.55861353874207 seconds\n",
      "testing time = 3.225611925125122 seconds\n",
      "\n",
      "Training with split 3\n",
      "epoch 0 loss = 2.257146\n",
      "epoch 1 loss = 2.119609\n",
      "epoch 2 loss = 2.029800\n",
      "epoch 3 loss = 1.966916\n",
      "epoch 4 loss = 1.883163\n",
      "epoch 5 loss = 1.861073\n",
      "epoch 6 loss = 1.941290\n",
      "epoch 7 loss = 2.013295\n",
      "epoch 8 loss = 1.872368\n",
      "epoch 9 loss = 1.866631\n",
      "epoch 10 loss = 1.811761\n",
      "epoch 11 loss = 1.847492\n",
      "epoch 12 loss = 1.783899\n",
      "epoch 13 loss = 1.767733\n",
      "epoch 14 loss = 1.939918\n",
      "epoch 15 loss = 1.789417\n",
      "epoch 16 loss = 1.691345\n",
      "epoch 17 loss = 1.584406\n",
      "epoch 18 loss = 1.625610\n",
      "epoch 19 loss = 1.559224\n",
      "epoch 20 loss = 1.586565\n",
      "epoch 21 loss = 1.633652\n",
      "epoch 22 loss = 1.592839\n",
      "epoch 23 loss = 1.734994\n",
      "epoch 24 loss = 1.717752\n",
      "epoch 25 loss = 1.555520\n",
      "epoch 26 loss = 1.612775\n",
      "epoch 27 loss = 1.550814\n",
      "epoch 28 loss = 1.658807\n",
      "epoch 29 loss = 1.572706\n",
      "epoch 30 loss = 1.663542\n",
      "epoch 31 loss = 1.540565\n",
      "epoch 32 loss = 1.518183\n",
      "epoch 33 loss = 1.529873\n",
      "epoch 34 loss = 1.533534\n",
      "epoch 35 loss = 1.607228\n",
      "epoch 36 loss = 1.626315\n",
      "epoch 37 loss = 1.621301\n",
      "epoch 38 loss = 1.668256\n",
      "epoch 39 loss = 1.456431\n",
      "epoch 40 loss = 1.656593\n",
      "epoch 41 loss = 1.415113\n",
      "epoch 42 loss = 1.476274\n",
      "epoch 43 loss = 1.403186\n",
      "epoch 44 loss = 1.434951\n",
      "epoch 45 loss = 1.575021\n",
      "epoch 46 loss = 1.492837\n",
      "epoch 47 loss = 1.543450\n",
      "epoch 48 loss = 1.552828\n",
      "epoch 49 loss = 1.829278\n",
      "epoch 50 loss = 1.522951\n",
      "epoch 51 loss = 1.606828\n",
      "epoch 52 loss = 1.588417\n",
      "epoch 53 loss = 1.500932\n",
      "epoch 54 loss = 1.550752\n",
      "epoch 55 loss = 1.676527\n",
      "epoch 56 loss = 1.475367\n",
      "epoch 57 loss = 1.501814\n",
      "epoch 58 loss = 1.552403\n",
      "epoch 59 loss = 1.430831\n",
      "epoch 60 loss = 1.477153\n",
      "epoch 61 loss = 1.462971\n",
      "epoch 62 loss = 1.338429\n",
      "epoch 63 loss = 1.627968\n",
      "epoch 64 loss = 1.405861\n",
      "epoch 65 loss = 1.661714\n",
      "epoch 66 loss = 1.464558\n",
      "epoch 67 loss = 1.559936\n",
      "epoch 68 loss = 1.528708\n",
      "epoch 69 loss = 1.503162\n",
      "epoch 70 loss = 1.436760\n",
      "epoch 71 loss = 1.513324\n",
      "epoch 72 loss = 1.474691\n",
      "epoch 73 loss = 1.392065\n",
      "epoch 74 loss = 1.478835\n",
      "epoch 75 loss = 1.306966\n",
      "epoch 76 loss = 1.377884\n",
      "epoch 77 loss = 1.443461\n",
      "epoch 78 loss = 1.456172\n",
      "epoch 79 loss = 1.567137\n",
      "epoch 80 loss = 1.350617\n",
      "epoch 81 loss = 1.645274\n",
      "epoch 82 loss = 1.534352\n",
      "epoch 83 loss = 1.435495\n",
      "epoch 84 loss = 1.378765\n",
      "epoch 85 loss = 1.493718\n",
      "epoch 86 loss = 1.418405\n",
      "epoch 87 loss = 1.386925\n",
      "epoch 88 loss = 1.433267\n",
      "epoch 89 loss = 1.469197\n",
      "epoch 90 loss = 1.376300\n",
      "epoch 91 loss = 1.330737\n",
      "epoch 92 loss = 1.499977\n",
      "epoch 93 loss = 1.507271\n",
      "epoch 94 loss = 1.261454\n",
      "epoch 95 loss = 1.542686\n",
      "epoch 96 loss = 1.434867\n",
      "epoch 97 loss = 1.365193\n",
      "epoch 98 loss = 1.411712\n",
      "epoch 99 loss = 1.398161\n",
      "epoch 100 loss = 1.398523\n",
      "epoch 101 loss = 1.454531\n",
      "epoch 102 loss = 1.363994\n",
      "epoch 103 loss = 1.508655\n",
      "epoch 104 loss = 1.380923\n",
      "epoch 105 loss = 1.344972\n",
      "epoch 106 loss = 1.448668\n",
      "epoch 107 loss = 1.434080\n",
      "epoch 108 loss = 1.270746\n",
      "epoch 109 loss = 1.435727\n",
      "epoch 110 loss = 1.411866\n",
      "epoch 111 loss = 1.455023\n",
      "epoch 112 loss = 1.297136\n",
      "epoch 113 loss = 1.307144\n",
      "epoch 114 loss = 1.379919\n",
      "epoch 115 loss = 1.293368\n",
      "epoch 116 loss = 1.437955\n",
      "epoch 117 loss = 1.236631\n",
      "epoch 118 loss = 1.479239\n",
      "epoch 119 loss = 1.330748\n",
      "epoch 120 loss = 1.286560\n",
      "epoch 121 loss = 1.343812\n",
      "epoch 122 loss = 1.253594\n",
      "epoch 123 loss = 1.307598\n",
      "epoch 124 loss = 1.200158\n",
      "epoch 125 loss = 1.273688\n",
      "epoch 126 loss = 1.358130\n",
      "epoch 127 loss = 1.294749\n",
      "epoch 128 loss = 1.554042\n",
      "epoch 129 loss = 1.372075\n",
      "epoch 130 loss = 1.212348\n",
      "epoch 131 loss = 1.419203\n",
      "epoch 132 loss = 1.281614\n",
      "epoch 133 loss = 1.303096\n",
      "epoch 134 loss = 1.313782\n",
      "epoch 135 loss = 1.419824\n",
      "epoch 136 loss = 1.320870\n",
      "epoch 137 loss = 1.472990\n",
      "epoch 138 loss = 1.412677\n",
      "epoch 139 loss = 1.296884\n",
      "epoch 140 loss = 1.418956\n",
      "epoch 141 loss = 1.266716\n",
      "epoch 142 loss = 1.266150\n",
      "epoch 143 loss = 1.412648\n",
      "epoch 144 loss = 1.211552\n",
      "epoch 145 loss = 1.302469\n",
      "epoch 146 loss = 1.332697\n",
      "epoch 147 loss = 1.372158\n",
      "epoch 148 loss = 1.194508\n",
      "epoch 149 loss = 1.419720\n",
      "epoch 150 loss = 1.230311\n",
      "epoch 151 loss = 1.364379\n",
      "epoch 152 loss = 1.182892\n",
      "epoch 153 loss = 1.432440\n",
      "epoch 154 loss = 1.408881\n",
      "epoch 155 loss = 1.373536\n",
      "epoch 156 loss = 1.295561\n",
      "epoch 157 loss = 1.365782\n",
      "epoch 158 loss = 1.593918\n",
      "epoch 159 loss = 1.352503\n",
      "epoch 160 loss = 1.313775\n",
      "epoch 161 loss = 1.338097\n",
      "epoch 162 loss = 1.233015\n",
      "epoch 163 loss = 1.292963\n",
      "epoch 164 loss = 1.307246\n",
      "epoch 165 loss = 1.208779\n",
      "epoch 166 loss = 1.359604\n",
      "epoch 167 loss = 1.483319\n",
      "epoch 168 loss = 1.314848\n",
      "epoch 169 loss = 1.339594\n",
      "epoch 170 loss = 1.312634\n",
      "epoch 171 loss = 1.229639\n",
      "epoch 172 loss = 1.398883\n",
      "epoch 173 loss = 1.450961\n",
      "epoch 174 loss = 1.190411\n",
      "epoch 175 loss = 1.316348\n",
      "epoch 176 loss = 1.367438\n",
      "epoch 177 loss = 1.249800\n",
      "epoch 178 loss = 1.305061\n",
      "epoch 179 loss = 1.281919\n",
      "epoch 180 loss = 1.288308\n",
      "epoch 181 loss = 1.156587\n",
      "epoch 182 loss = 1.292335\n",
      "epoch 183 loss = 1.208574\n",
      "epoch 184 loss = 1.277914\n",
      "epoch 185 loss = 1.387242\n",
      "epoch 186 loss = 1.264141\n",
      "epoch 187 loss = 1.360511\n",
      "epoch 188 loss = 1.198268\n",
      "epoch 189 loss = 1.661270\n",
      "epoch 190 loss = 1.533743\n",
      "epoch 191 loss = 1.287766\n",
      "epoch 192 loss = 1.283627\n",
      "epoch 193 loss = 1.470299\n",
      "epoch 194 loss = 1.224566\n",
      "epoch 195 loss = 1.322204\n",
      "epoch 196 loss = 1.277005\n",
      "epoch 197 loss = 1.594707\n",
      "epoch 198 loss = 1.325370\n",
      "epoch 199 loss = 1.171252\n",
      "epoch 200 loss = 1.210768\n",
      "epoch 201 loss = 1.350099\n",
      "epoch 202 loss = 1.448935\n",
      "epoch 203 loss = 1.332819\n",
      "epoch 204 loss = 1.209083\n",
      "epoch 205 loss = 1.415780\n",
      "epoch 206 loss = 1.446638\n",
      "epoch 207 loss = 1.343291\n",
      "epoch 208 loss = 1.296454\n",
      "epoch 209 loss = 1.171634\n",
      "epoch 210 loss = 1.450054\n",
      "epoch 211 loss = 1.324780\n",
      "epoch 212 loss = 1.451936\n",
      "epoch 213 loss = 1.215442\n",
      "epoch 214 loss = 1.433470\n",
      "epoch 215 loss = 1.264556\n",
      "epoch 216 loss = 1.389908\n",
      "epoch 217 loss = 1.434934\n",
      "epoch 218 loss = 1.185279\n",
      "epoch 219 loss = 1.401455\n",
      "epoch 220 loss = 1.334244\n",
      "epoch 221 loss = 1.178123\n",
      "epoch 222 loss = 1.177202\n",
      "epoch 223 loss = 1.253031\n",
      "epoch 224 loss = 1.342270\n",
      "epoch 225 loss = 1.154425\n",
      "epoch 226 loss = 1.371831\n",
      "epoch 227 loss = 1.152257\n",
      "epoch 228 loss = 1.287559\n",
      "epoch 229 loss = 1.340452\n",
      "epoch 230 loss = 1.272841\n",
      "epoch 231 loss = 1.227412\n",
      "epoch 232 loss = 1.509601\n",
      "epoch 233 loss = 1.188656\n",
      "epoch 234 loss = 1.364366\n",
      "epoch 235 loss = 1.409711\n",
      "epoch 236 loss = 1.367687\n",
      "epoch 237 loss = 1.143420\n",
      "epoch 238 loss = 1.230283\n",
      "epoch 239 loss = 1.193283\n",
      "epoch 240 loss = 1.198987\n",
      "epoch 241 loss = 1.121360\n",
      "epoch 242 loss = 1.687196\n",
      "epoch 243 loss = 1.240880\n",
      "epoch 244 loss = 1.376941\n",
      "epoch 245 loss = 1.190982\n",
      "epoch 246 loss = 1.346217\n",
      "epoch 247 loss = 1.396938\n",
      "epoch 248 loss = 1.248502\n",
      "epoch 249 loss = 1.324113\n",
      "epoch 250 loss = 1.117770\n",
      "epoch 251 loss = 1.262396\n",
      "epoch 252 loss = 1.294256\n",
      "epoch 253 loss = 1.248183\n",
      "epoch 254 loss = 1.325799\n",
      "epoch 255 loss = 1.315696\n",
      "epoch 256 loss = 1.372048\n",
      "epoch 257 loss = 1.274231\n",
      "epoch 258 loss = 1.220912\n",
      "epoch 259 loss = 1.229779\n",
      "epoch 260 loss = 1.286371\n",
      "epoch 261 loss = 1.201465\n",
      "epoch 262 loss = 1.393345\n",
      "epoch 263 loss = 1.410517\n",
      "epoch 264 loss = 1.257403\n",
      "epoch 265 loss = 1.287427\n",
      "epoch 266 loss = 1.430843\n",
      "epoch 267 loss = 1.281400\n",
      "epoch 268 loss = 1.423625\n",
      "epoch 269 loss = 1.107641\n",
      "epoch 270 loss = 1.278095\n",
      "epoch 271 loss = 1.202418\n",
      "epoch 272 loss = 1.187965\n",
      "epoch 273 loss = 1.361631\n",
      "epoch 274 loss = 1.404649\n",
      "epoch 275 loss = 1.473489\n",
      "epoch 276 loss = 1.335852\n",
      "epoch 277 loss = 1.119444\n",
      "epoch 278 loss = 1.336675\n",
      "epoch 279 loss = 1.215235\n",
      "epoch 280 loss = 1.214750\n",
      "epoch 281 loss = 1.242650\n",
      "epoch 282 loss = 1.252046\n",
      "epoch 283 loss = 1.376654\n",
      "epoch 284 loss = 1.304013\n",
      "epoch 285 loss = 1.323219\n",
      "epoch 286 loss = 1.226818\n",
      "epoch 287 loss = 1.335176\n",
      "epoch 288 loss = 1.253066\n",
      "epoch 289 loss = 1.335049\n",
      "epoch 290 loss = 1.418181\n",
      "epoch 291 loss = 1.245208\n",
      "epoch 292 loss = 1.534606\n",
      "epoch 293 loss = 1.219536\n",
      "epoch 294 loss = 1.272463\n",
      "epoch 295 loss = 1.186455\n",
      "epoch 296 loss = 1.317853\n",
      "epoch 297 loss = 1.256289\n",
      "epoch 298 loss = 1.362719\n",
      "epoch 299 loss = 1.257485\n",
      "epoch 300 loss = 1.195316\n",
      "epoch 301 loss = 1.338813\n",
      "epoch 302 loss = 1.273311\n",
      "epoch 303 loss = 1.270912\n",
      "epoch 304 loss = 1.436009\n",
      "epoch 305 loss = 1.527372\n",
      "epoch 306 loss = 1.216851\n",
      "epoch 307 loss = 1.321315\n",
      "epoch 308 loss = 1.171702\n",
      "epoch 309 loss = 1.086155\n",
      "epoch 310 loss = 1.446169\n",
      "epoch 311 loss = 1.266623\n",
      "epoch 312 loss = 1.307321\n",
      "epoch 313 loss = 1.504471\n",
      "epoch 314 loss = 1.198426\n",
      "epoch 315 loss = 1.352227\n",
      "epoch 316 loss = 1.234324\n",
      "epoch 317 loss = 1.297828\n",
      "epoch 318 loss = 1.256729\n",
      "epoch 319 loss = 1.296041\n",
      "epoch 320 loss = 1.341924\n",
      "epoch 321 loss = 1.191506\n",
      "epoch 322 loss = 1.238340\n",
      "epoch 323 loss = 1.241122\n",
      "epoch 324 loss = 1.226627\n",
      "epoch 325 loss = 1.468596\n",
      "epoch 326 loss = 1.334552\n",
      "epoch 327 loss = 1.355527\n",
      "epoch 328 loss = 1.516020\n",
      "epoch 329 loss = 1.261299\n",
      "epoch 330 loss = 1.289834\n",
      "epoch 331 loss = 1.269720\n",
      "epoch 332 loss = 1.403749\n",
      "epoch 333 loss = 1.200572\n",
      "epoch 334 loss = 1.283732\n",
      "epoch 335 loss = 1.360807\n",
      "epoch 336 loss = 1.294569\n",
      "epoch 337 loss = 1.295931\n",
      "epoch 338 loss = 1.513854\n",
      "epoch 339 loss = 1.387838\n",
      "epoch 340 loss = 1.356357\n",
      "epoch 341 loss = 1.276580\n",
      "epoch 342 loss = 1.278891\n",
      "epoch 343 loss = 1.387818\n",
      "epoch 344 loss = 1.410602\n",
      "epoch 345 loss = 1.135421\n",
      "epoch 346 loss = 1.334448\n",
      "epoch 347 loss = 1.209397\n",
      "epoch 348 loss = 1.182709\n",
      "epoch 349 loss = 1.288912\n",
      "epoch 350 loss = 1.373506\n",
      "epoch 351 loss = 1.284860\n",
      "epoch 352 loss = 1.260411\n",
      "epoch 353 loss = 1.480451\n",
      "epoch 354 loss = 1.344871\n",
      "epoch 355 loss = 1.333241\n",
      "epoch 356 loss = 1.126173\n",
      "epoch 357 loss = 1.144616\n",
      "epoch 358 loss = 1.209348\n",
      "epoch 359 loss = 1.324345\n",
      "epoch 360 loss = 1.150671\n",
      "epoch 361 loss = 1.350191\n",
      "epoch 362 loss = 1.164384\n",
      "epoch 363 loss = 1.356155\n",
      "epoch 364 loss = 1.376449\n",
      "epoch 365 loss = 1.532357\n",
      "epoch 366 loss = 1.381504\n",
      "epoch 367 loss = 1.271396\n",
      "epoch 368 loss = 1.270063\n",
      "epoch 369 loss = 1.196325\n",
      "epoch 370 loss = 1.179726\n",
      "epoch 371 loss = 1.356620\n",
      "epoch 372 loss = 1.352696\n",
      "epoch 373 loss = 1.136844\n",
      "epoch 374 loss = 1.106928\n",
      "epoch 375 loss = 1.351576\n",
      "epoch 376 loss = 1.268391\n",
      "epoch 377 loss = 1.166591\n",
      "epoch 378 loss = 1.306719\n",
      "epoch 379 loss = 1.293020\n",
      "epoch 380 loss = 1.283658\n",
      "epoch 381 loss = 1.339552\n",
      "epoch 382 loss = 1.165616\n",
      "epoch 383 loss = 1.204851\n",
      "epoch 384 loss = 1.348214\n",
      "epoch 385 loss = 1.375059\n",
      "epoch 386 loss = 1.292118\n",
      "epoch 387 loss = 1.496851\n",
      "epoch 388 loss = 1.316128\n",
      "epoch 389 loss = 1.187082\n",
      "epoch 390 loss = 1.189842\n",
      "epoch 391 loss = 1.221916\n",
      "epoch 392 loss = 1.310320\n",
      "epoch 393 loss = 1.260202\n",
      "epoch 394 loss = 1.354717\n",
      "epoch 395 loss = 1.275864\n",
      "epoch 396 loss = 1.226344\n",
      "epoch 397 loss = 1.141793\n",
      "epoch 398 loss = 1.485779\n",
      "epoch 399 loss = 1.255559\n",
      "epoch 400 loss = 1.457294\n",
      "epoch 401 loss = 1.391361\n",
      "epoch 402 loss = 1.405876\n",
      "epoch 403 loss = 1.125239\n",
      "epoch 404 loss = 1.272182\n",
      "epoch 405 loss = 1.340237\n",
      "epoch 406 loss = 1.088962\n",
      "epoch 407 loss = 1.235021\n",
      "epoch 408 loss = 1.434684\n",
      "epoch 409 loss = 1.391608\n",
      "epoch 410 loss = 1.297349\n",
      "epoch 411 loss = 1.350840\n",
      "epoch 412 loss = 1.355083\n",
      "epoch 413 loss = 1.321816\n",
      "epoch 414 loss = 1.228552\n",
      "epoch 415 loss = 1.224047\n",
      "epoch 416 loss = 1.394306\n",
      "epoch 417 loss = 1.547162\n",
      "epoch 418 loss = 1.131580\n",
      "epoch 419 loss = 1.577646\n",
      "epoch 420 loss = 1.347157\n",
      "epoch 421 loss = 1.392180\n",
      "epoch 422 loss = 1.426135\n",
      "epoch 423 loss = 1.240526\n",
      "epoch 424 loss = 1.184565\n",
      "epoch 425 loss = 1.480595\n",
      "epoch 426 loss = 1.258729\n",
      "epoch 427 loss = 1.244121\n",
      "epoch 428 loss = 1.271364\n",
      "epoch 429 loss = 1.243505\n",
      "epoch 430 loss = 1.322453\n",
      "epoch 431 loss = 1.289005\n",
      "epoch 432 loss = 1.145787\n",
      "epoch 433 loss = 1.292538\n",
      "epoch 434 loss = 1.410406\n",
      "epoch 435 loss = 1.373277\n",
      "epoch 436 loss = 1.459529\n",
      "epoch 437 loss = 1.304790\n",
      "epoch 438 loss = 1.429311\n",
      "epoch 439 loss = 1.375309\n",
      "epoch 440 loss = 1.335163\n",
      "epoch 441 loss = 1.211327\n",
      "epoch 442 loss = 1.281225\n",
      "epoch 443 loss = 1.287529\n",
      "epoch 444 loss = 1.401199\n",
      "epoch 445 loss = 1.313001\n",
      "epoch 446 loss = 1.277671\n",
      "epoch 447 loss = 1.303684\n",
      "epoch 448 loss = 1.203325\n",
      "epoch 449 loss = 1.305351\n",
      "epoch 450 loss = 1.309744\n",
      "epoch 451 loss = 1.356147\n",
      "epoch 452 loss = 1.456572\n",
      "epoch 453 loss = 1.219103\n",
      "epoch 454 loss = 1.204023\n",
      "epoch 455 loss = 1.328725\n",
      "epoch 456 loss = 1.265519\n",
      "epoch 457 loss = 1.497978\n",
      "epoch 458 loss = 1.370037\n",
      "epoch 459 loss = 1.349984\n",
      "epoch 460 loss = 1.211589\n",
      "epoch 461 loss = 1.634610\n",
      "epoch 462 loss = 1.105630\n",
      "epoch 463 loss = 1.446892\n",
      "epoch 464 loss = 1.112267\n",
      "epoch 465 loss = 1.227793\n",
      "epoch 466 loss = 1.189162\n",
      "epoch 467 loss = 1.225315\n",
      "epoch 468 loss = 1.378269\n",
      "epoch 469 loss = 1.368622\n",
      "epoch 470 loss = 1.369472\n",
      "epoch 471 loss = 1.213559\n",
      "epoch 472 loss = 1.286602\n",
      "epoch 473 loss = 1.229943\n",
      "epoch 474 loss = 1.153259\n",
      "epoch 475 loss = 1.366517\n",
      "epoch 476 loss = 1.348468\n",
      "epoch 477 loss = 1.298109\n",
      "epoch 478 loss = 1.266053\n",
      "epoch 479 loss = 1.210819\n",
      "epoch 480 loss = 1.263075\n",
      "epoch 481 loss = 1.112177\n",
      "epoch 482 loss = 1.404436\n",
      "epoch 483 loss = 1.326080\n",
      "epoch 484 loss = 1.100302\n",
      "epoch 485 loss = 1.259465\n",
      "epoch 486 loss = 1.168400\n",
      "epoch 487 loss = 1.556295\n",
      "epoch 488 loss = 1.242909\n",
      "epoch 489 loss = 1.228155\n",
      "epoch 490 loss = 1.302851\n",
      "epoch 491 loss = 1.229604\n",
      "epoch 492 loss = 1.315145\n",
      "epoch 493 loss = 1.325837\n",
      "epoch 494 loss = 1.267507\n",
      "epoch 495 loss = 1.251482\n",
      "epoch 496 loss = 1.166174\n",
      "epoch 497 loss = 1.346128\n",
      "epoch 498 loss = 1.296664\n",
      "epoch 499 loss = 1.303516\n",
      "final loss = 1.303516\n",
      "accuracy_mc = tensor(0.3586, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.3695, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.7267, device='cuda:0')\n",
      "training time = 304.8841941356659 seconds\n",
      "testing time = 3.2076914310455322 seconds\n",
      "\n",
      "Training with split 4\n",
      "epoch 0 loss = 2.241990\n",
      "epoch 1 loss = 1.985012\n",
      "epoch 2 loss = 1.846960\n",
      "epoch 3 loss = 1.861263\n",
      "epoch 4 loss = 1.892935\n",
      "epoch 5 loss = 1.813002\n",
      "epoch 6 loss = 1.872433\n",
      "epoch 7 loss = 2.021134\n",
      "epoch 8 loss = 1.845749\n",
      "epoch 9 loss = 1.844982\n",
      "epoch 10 loss = 1.862417\n",
      "epoch 11 loss = 1.914197\n",
      "epoch 12 loss = 1.817003\n",
      "epoch 13 loss = 1.861912\n",
      "epoch 14 loss = 1.960378\n",
      "epoch 15 loss = 1.786069\n",
      "epoch 16 loss = 1.826420\n",
      "epoch 17 loss = 1.677688\n",
      "epoch 18 loss = 1.834049\n",
      "epoch 19 loss = 1.672793\n",
      "epoch 20 loss = 1.781773\n",
      "epoch 21 loss = 1.875557\n",
      "epoch 22 loss = 1.735077\n",
      "epoch 23 loss = 1.559218\n",
      "epoch 24 loss = 1.757347\n",
      "epoch 25 loss = 1.652463\n",
      "epoch 26 loss = 1.785293\n",
      "epoch 27 loss = 1.617110\n",
      "epoch 28 loss = 1.635379\n",
      "epoch 29 loss = 1.565369\n",
      "epoch 30 loss = 1.597638\n",
      "epoch 31 loss = 1.637033\n",
      "epoch 32 loss = 1.566423\n",
      "epoch 33 loss = 1.867649\n",
      "epoch 34 loss = 1.636453\n",
      "epoch 35 loss = 1.668567\n",
      "epoch 36 loss = 1.764264\n",
      "epoch 37 loss = 1.647039\n",
      "epoch 38 loss = 1.463486\n",
      "epoch 39 loss = 1.592292\n",
      "epoch 40 loss = 1.624685\n",
      "epoch 41 loss = 1.584493\n",
      "epoch 42 loss = 1.692731\n",
      "epoch 43 loss = 1.645813\n",
      "epoch 44 loss = 1.577767\n",
      "epoch 45 loss = 1.591291\n",
      "epoch 46 loss = 1.473792\n",
      "epoch 47 loss = 1.521553\n",
      "epoch 48 loss = 1.441470\n",
      "epoch 49 loss = 1.412771\n",
      "epoch 50 loss = 1.453181\n",
      "epoch 51 loss = 1.517732\n",
      "epoch 52 loss = 1.597921\n",
      "epoch 53 loss = 1.564257\n",
      "epoch 54 loss = 1.618889\n",
      "epoch 55 loss = 1.479980\n",
      "epoch 56 loss = 1.605695\n",
      "epoch 57 loss = 1.451120\n",
      "epoch 58 loss = 1.702581\n",
      "epoch 59 loss = 1.438934\n",
      "epoch 60 loss = 1.512200\n",
      "epoch 61 loss = 1.630971\n",
      "epoch 62 loss = 1.542538\n",
      "epoch 63 loss = 1.488435\n",
      "epoch 64 loss = 1.409964\n",
      "epoch 65 loss = 1.458348\n",
      "epoch 66 loss = 1.347229\n",
      "epoch 67 loss = 1.525322\n",
      "epoch 68 loss = 1.609560\n",
      "epoch 69 loss = 1.524247\n",
      "epoch 70 loss = 1.341776\n",
      "epoch 71 loss = 1.570154\n",
      "epoch 72 loss = 1.304999\n",
      "epoch 73 loss = 1.357418\n",
      "epoch 74 loss = 1.352340\n",
      "epoch 75 loss = 1.420889\n",
      "epoch 76 loss = 1.540619\n",
      "epoch 77 loss = 1.314107\n",
      "epoch 78 loss = 1.393070\n",
      "epoch 79 loss = 1.322161\n",
      "epoch 80 loss = 1.385458\n",
      "epoch 81 loss = 1.549753\n",
      "epoch 82 loss = 1.485798\n",
      "epoch 83 loss = 1.477717\n",
      "epoch 84 loss = 1.426689\n",
      "epoch 85 loss = 1.246397\n",
      "epoch 86 loss = 1.392947\n",
      "epoch 87 loss = 1.625996\n",
      "epoch 88 loss = 1.326260\n",
      "epoch 89 loss = 1.306073\n",
      "epoch 90 loss = 1.359506\n",
      "epoch 91 loss = 1.165713\n",
      "epoch 92 loss = 1.537956\n",
      "epoch 93 loss = 1.322570\n",
      "epoch 94 loss = 1.326513\n",
      "epoch 95 loss = 1.360532\n",
      "epoch 96 loss = 1.399904\n",
      "epoch 97 loss = 1.242799\n",
      "epoch 98 loss = 1.409321\n",
      "epoch 99 loss = 1.342176\n",
      "epoch 100 loss = 1.294434\n",
      "epoch 101 loss = 1.512731\n",
      "epoch 102 loss = 1.220260\n",
      "epoch 103 loss = 1.477071\n",
      "epoch 104 loss = 1.232794\n",
      "epoch 105 loss = 1.381955\n",
      "epoch 106 loss = 1.331387\n",
      "epoch 107 loss = 1.374997\n",
      "epoch 108 loss = 1.353987\n",
      "epoch 109 loss = 1.594502\n",
      "epoch 110 loss = 1.294361\n",
      "epoch 111 loss = 1.292124\n",
      "epoch 112 loss = 1.306144\n",
      "epoch 113 loss = 1.238911\n",
      "epoch 114 loss = 1.418181\n",
      "epoch 115 loss = 1.279819\n",
      "epoch 116 loss = 1.375896\n",
      "epoch 117 loss = 1.389266\n",
      "epoch 118 loss = 1.260023\n",
      "epoch 119 loss = 1.185977\n",
      "epoch 120 loss = 1.221789\n",
      "epoch 121 loss = 1.412464\n",
      "epoch 122 loss = 1.416824\n",
      "epoch 123 loss = 1.286209\n",
      "epoch 124 loss = 1.400651\n",
      "epoch 125 loss = 1.185920\n",
      "epoch 126 loss = 1.411871\n",
      "epoch 127 loss = 1.326337\n",
      "epoch 128 loss = 1.282854\n",
      "epoch 129 loss = 1.330106\n",
      "epoch 130 loss = 1.185770\n",
      "epoch 131 loss = 1.374326\n",
      "epoch 132 loss = 1.291140\n",
      "epoch 133 loss = 1.314726\n",
      "epoch 134 loss = 1.480743\n",
      "epoch 135 loss = 1.211362\n",
      "epoch 136 loss = 1.197488\n",
      "epoch 137 loss = 1.315541\n",
      "epoch 138 loss = 1.447120\n",
      "epoch 139 loss = 1.234016\n",
      "epoch 140 loss = 1.123423\n",
      "epoch 141 loss = 1.223740\n",
      "epoch 142 loss = 1.282165\n",
      "epoch 143 loss = 1.441334\n",
      "epoch 144 loss = 1.303458\n",
      "epoch 145 loss = 1.294707\n",
      "epoch 146 loss = 1.169392\n",
      "epoch 147 loss = 1.420426\n",
      "epoch 148 loss = 1.359616\n",
      "epoch 149 loss = 1.404421\n",
      "epoch 150 loss = 1.155800\n",
      "epoch 151 loss = 1.292807\n",
      "epoch 152 loss = 1.198353\n",
      "epoch 153 loss = 1.248002\n",
      "epoch 154 loss = 1.176728\n",
      "epoch 155 loss = 1.298900\n",
      "epoch 156 loss = 1.455428\n",
      "epoch 157 loss = 1.133360\n",
      "epoch 158 loss = 1.406674\n",
      "epoch 159 loss = 1.393055\n",
      "epoch 160 loss = 1.339874\n",
      "epoch 161 loss = 1.150825\n",
      "epoch 162 loss = 1.142609\n",
      "epoch 163 loss = 1.292656\n",
      "epoch 164 loss = 1.278935\n",
      "epoch 165 loss = 1.394482\n",
      "epoch 166 loss = 1.496963\n",
      "epoch 167 loss = 1.245057\n",
      "epoch 168 loss = 1.238833\n",
      "epoch 169 loss = 1.318117\n",
      "epoch 170 loss = 1.430041\n",
      "epoch 171 loss = 1.180835\n",
      "epoch 172 loss = 1.370261\n",
      "epoch 173 loss = 1.093513\n",
      "epoch 174 loss = 1.214717\n",
      "epoch 175 loss = 1.389981\n",
      "epoch 176 loss = 1.252816\n",
      "epoch 177 loss = 1.266106\n",
      "epoch 178 loss = 1.403254\n",
      "epoch 179 loss = 1.166865\n",
      "epoch 180 loss = 1.238765\n",
      "epoch 181 loss = 1.269107\n",
      "epoch 182 loss = 1.311618\n",
      "epoch 183 loss = 1.036919\n",
      "epoch 184 loss = 1.209162\n",
      "epoch 185 loss = 1.258766\n",
      "epoch 186 loss = 1.351261\n",
      "epoch 187 loss = 1.113392\n",
      "epoch 188 loss = 1.246945\n",
      "epoch 189 loss = 1.242094\n",
      "epoch 190 loss = 1.224713\n",
      "epoch 191 loss = 1.230011\n",
      "epoch 192 loss = 1.204529\n",
      "epoch 193 loss = 1.328506\n",
      "epoch 194 loss = 1.131764\n",
      "epoch 195 loss = 1.254266\n",
      "epoch 196 loss = 1.154223\n",
      "epoch 197 loss = 1.205157\n",
      "epoch 198 loss = 1.170819\n",
      "epoch 199 loss = 1.307227\n",
      "epoch 200 loss = 1.092614\n",
      "epoch 201 loss = 1.121779\n",
      "epoch 202 loss = 1.156145\n",
      "epoch 203 loss = 1.182335\n",
      "epoch 204 loss = 1.166422\n",
      "epoch 205 loss = 1.327060\n",
      "epoch 206 loss = 1.098043\n",
      "epoch 207 loss = 1.441912\n",
      "epoch 208 loss = 1.216580\n",
      "epoch 209 loss = 1.110585\n",
      "epoch 210 loss = 1.227162\n",
      "epoch 211 loss = 1.139854\n",
      "epoch 212 loss = 1.296728\n",
      "epoch 213 loss = 1.156476\n",
      "epoch 214 loss = 1.108285\n",
      "epoch 215 loss = 1.283363\n",
      "epoch 216 loss = 1.113076\n",
      "epoch 217 loss = 1.346276\n",
      "epoch 218 loss = 1.099409\n",
      "epoch 219 loss = 1.329828\n",
      "epoch 220 loss = 1.119516\n",
      "epoch 221 loss = 1.201986\n",
      "epoch 222 loss = 1.186100\n",
      "epoch 223 loss = 1.105766\n",
      "epoch 224 loss = 1.073926\n",
      "epoch 225 loss = 1.061322\n",
      "epoch 226 loss = 1.068362\n",
      "epoch 227 loss = 1.197302\n",
      "epoch 228 loss = 1.125637\n",
      "epoch 229 loss = 1.257145\n",
      "epoch 230 loss = 1.095430\n",
      "epoch 231 loss = 1.118957\n",
      "epoch 232 loss = 1.115441\n",
      "epoch 233 loss = 1.080172\n",
      "epoch 234 loss = 1.054305\n",
      "epoch 235 loss = 1.094319\n",
      "epoch 236 loss = 1.188321\n",
      "epoch 237 loss = 1.309809\n",
      "epoch 238 loss = 1.217339\n",
      "epoch 239 loss = 1.110730\n",
      "epoch 240 loss = 1.236333\n",
      "epoch 241 loss = 1.114019\n",
      "epoch 242 loss = 1.197668\n",
      "epoch 243 loss = 1.311175\n",
      "epoch 244 loss = 1.140876\n",
      "epoch 245 loss = 1.217606\n",
      "epoch 246 loss = 1.119546\n",
      "epoch 247 loss = 1.165277\n",
      "epoch 248 loss = 0.970871\n",
      "epoch 249 loss = 1.174025\n",
      "epoch 250 loss = 1.076462\n",
      "epoch 251 loss = 1.132525\n",
      "epoch 252 loss = 1.197323\n",
      "epoch 253 loss = 1.134187\n",
      "epoch 254 loss = 1.048724\n",
      "epoch 255 loss = 1.344280\n",
      "epoch 256 loss = 1.155546\n",
      "epoch 257 loss = 1.426309\n",
      "epoch 258 loss = 1.235182\n",
      "epoch 259 loss = 1.040963\n",
      "epoch 260 loss = 1.227020\n",
      "epoch 261 loss = 1.022567\n",
      "epoch 262 loss = 1.133476\n",
      "epoch 263 loss = 1.448509\n",
      "epoch 264 loss = 1.317185\n",
      "epoch 265 loss = 0.963681\n",
      "epoch 266 loss = 1.023504\n",
      "epoch 267 loss = 1.122315\n",
      "epoch 268 loss = 1.105005\n",
      "epoch 269 loss = 1.266033\n",
      "epoch 270 loss = 1.059299\n",
      "epoch 271 loss = 1.062029\n",
      "epoch 272 loss = 1.074824\n",
      "epoch 273 loss = 1.294047\n",
      "epoch 274 loss = 1.252071\n",
      "epoch 275 loss = 1.201880\n",
      "epoch 276 loss = 1.205276\n",
      "epoch 277 loss = 1.071307\n",
      "epoch 278 loss = 1.218422\n",
      "epoch 279 loss = 1.340893\n",
      "epoch 280 loss = 1.031715\n",
      "epoch 281 loss = 1.298331\n",
      "epoch 282 loss = 1.008285\n",
      "epoch 283 loss = 1.397165\n",
      "epoch 284 loss = 1.130106\n",
      "epoch 285 loss = 1.225602\n",
      "epoch 286 loss = 1.322997\n",
      "epoch 287 loss = 1.075207\n",
      "epoch 288 loss = 1.134870\n",
      "epoch 289 loss = 1.073332\n",
      "epoch 290 loss = 1.131630\n",
      "epoch 291 loss = 1.077506\n",
      "epoch 292 loss = 0.984882\n",
      "epoch 293 loss = 1.080612\n",
      "epoch 294 loss = 1.303657\n",
      "epoch 295 loss = 1.120612\n",
      "epoch 296 loss = 1.233407\n",
      "epoch 297 loss = 1.173847\n",
      "epoch 298 loss = 1.143015\n",
      "epoch 299 loss = 1.160418\n",
      "epoch 300 loss = 1.118025\n",
      "epoch 301 loss = 1.128904\n",
      "epoch 302 loss = 1.221898\n",
      "epoch 303 loss = 1.103315\n",
      "epoch 304 loss = 1.122846\n",
      "epoch 305 loss = 1.141595\n",
      "epoch 306 loss = 1.109141\n",
      "epoch 307 loss = 1.246409\n",
      "epoch 308 loss = 1.284924\n",
      "epoch 309 loss = 1.207282\n",
      "epoch 310 loss = 1.216127\n",
      "epoch 311 loss = 1.244650\n",
      "epoch 312 loss = 0.938055\n",
      "epoch 313 loss = 1.435557\n",
      "epoch 314 loss = 1.303032\n",
      "epoch 315 loss = 1.125134\n",
      "epoch 316 loss = 1.241062\n",
      "epoch 317 loss = 1.084124\n",
      "epoch 318 loss = 1.170535\n",
      "epoch 319 loss = 0.971087\n",
      "epoch 320 loss = 1.097800\n",
      "epoch 321 loss = 1.242592\n",
      "epoch 322 loss = 1.081952\n",
      "epoch 323 loss = 1.276384\n",
      "epoch 324 loss = 1.252367\n",
      "epoch 325 loss = 1.110266\n",
      "epoch 326 loss = 1.165618\n",
      "epoch 327 loss = 1.073213\n",
      "epoch 328 loss = 1.085952\n",
      "epoch 329 loss = 1.054395\n",
      "epoch 330 loss = 1.169744\n",
      "epoch 331 loss = 1.121598\n",
      "epoch 332 loss = 1.020047\n",
      "epoch 333 loss = 1.177950\n",
      "epoch 334 loss = 1.119599\n",
      "epoch 335 loss = 1.006715\n",
      "epoch 336 loss = 1.177760\n",
      "epoch 337 loss = 1.424484\n",
      "epoch 338 loss = 1.037440\n",
      "epoch 339 loss = 1.152089\n",
      "epoch 340 loss = 1.092594\n",
      "epoch 341 loss = 1.155223\n",
      "epoch 342 loss = 1.248024\n",
      "epoch 343 loss = 1.068378\n",
      "epoch 344 loss = 1.197384\n",
      "epoch 345 loss = 1.356513\n",
      "epoch 346 loss = 1.039061\n",
      "epoch 347 loss = 1.177147\n",
      "epoch 348 loss = 1.143433\n",
      "epoch 349 loss = 1.012494\n",
      "epoch 350 loss = 1.002702\n",
      "epoch 351 loss = 1.122619\n",
      "epoch 352 loss = 1.141698\n",
      "epoch 353 loss = 1.147000\n",
      "epoch 354 loss = 1.318715\n",
      "epoch 355 loss = 1.352489\n",
      "epoch 356 loss = 1.041853\n",
      "epoch 357 loss = 1.098645\n",
      "epoch 358 loss = 1.198380\n",
      "epoch 359 loss = 1.109474\n",
      "epoch 360 loss = 1.086001\n",
      "epoch 361 loss = 1.146379\n",
      "epoch 362 loss = 1.139591\n",
      "epoch 363 loss = 1.212538\n",
      "epoch 364 loss = 1.365565\n",
      "epoch 365 loss = 1.208092\n",
      "epoch 366 loss = 1.101275\n",
      "epoch 367 loss = 1.178965\n",
      "epoch 368 loss = 1.259253\n",
      "epoch 369 loss = 1.225441\n",
      "epoch 370 loss = 1.294579\n",
      "epoch 371 loss = 0.979723\n",
      "epoch 372 loss = 1.252235\n",
      "epoch 373 loss = 1.154398\n",
      "epoch 374 loss = 1.087365\n",
      "epoch 375 loss = 1.321635\n",
      "epoch 376 loss = 1.133681\n",
      "epoch 377 loss = 1.097290\n",
      "epoch 378 loss = 1.214088\n",
      "epoch 379 loss = 0.988942\n",
      "epoch 380 loss = 0.980834\n",
      "epoch 381 loss = 1.140672\n",
      "epoch 382 loss = 1.413015\n",
      "epoch 383 loss = 1.207168\n",
      "epoch 384 loss = 1.103724\n",
      "epoch 385 loss = 0.995762\n",
      "epoch 386 loss = 1.030947\n",
      "epoch 387 loss = 1.135378\n",
      "epoch 388 loss = 0.993956\n",
      "epoch 389 loss = 1.100732\n",
      "epoch 390 loss = 1.215885\n",
      "epoch 391 loss = 1.061556\n",
      "epoch 392 loss = 1.389754\n",
      "epoch 393 loss = 1.138481\n",
      "epoch 394 loss = 1.327070\n",
      "epoch 395 loss = 0.954031\n",
      "epoch 396 loss = 1.144105\n",
      "epoch 397 loss = 1.159815\n",
      "epoch 398 loss = 1.119123\n",
      "epoch 399 loss = 0.972783\n",
      "epoch 400 loss = 1.180152\n",
      "epoch 401 loss = 0.978092\n",
      "epoch 402 loss = 1.100679\n",
      "epoch 403 loss = 1.102860\n",
      "epoch 404 loss = 1.154829\n",
      "epoch 405 loss = 1.090637\n",
      "epoch 406 loss = 1.147289\n",
      "epoch 407 loss = 1.244383\n",
      "epoch 408 loss = 1.306765\n",
      "epoch 409 loss = 1.001811\n",
      "epoch 410 loss = 1.164610\n",
      "epoch 411 loss = 1.052408\n",
      "epoch 412 loss = 1.039338\n",
      "epoch 413 loss = 0.917213\n",
      "epoch 414 loss = 1.255835\n",
      "epoch 415 loss = 1.171243\n",
      "epoch 416 loss = 0.922280\n",
      "epoch 417 loss = 1.049080\n",
      "epoch 418 loss = 1.246420\n",
      "epoch 419 loss = 1.252247\n",
      "epoch 420 loss = 1.148266\n",
      "epoch 421 loss = 1.262324\n",
      "epoch 422 loss = 0.914805\n",
      "epoch 423 loss = 1.258349\n",
      "epoch 424 loss = 1.092065\n",
      "epoch 425 loss = 0.972847\n",
      "epoch 426 loss = 1.166950\n",
      "epoch 427 loss = 1.126689\n",
      "epoch 428 loss = 1.098316\n",
      "epoch 429 loss = 1.006856\n",
      "epoch 430 loss = 1.145032\n",
      "epoch 431 loss = 1.033372\n",
      "epoch 432 loss = 1.134487\n",
      "epoch 433 loss = 1.082752\n",
      "epoch 434 loss = 1.133612\n",
      "epoch 435 loss = 1.306157\n",
      "epoch 436 loss = 1.166018\n",
      "epoch 437 loss = 1.062350\n",
      "epoch 438 loss = 1.022624\n",
      "epoch 439 loss = 1.013578\n",
      "epoch 440 loss = 1.049181\n",
      "epoch 441 loss = 1.271239\n",
      "epoch 442 loss = 1.102295\n",
      "epoch 443 loss = 1.092529\n",
      "epoch 444 loss = 1.262772\n",
      "epoch 445 loss = 1.021389\n",
      "epoch 446 loss = 1.188864\n",
      "epoch 447 loss = 1.015818\n",
      "epoch 448 loss = 1.057897\n",
      "epoch 449 loss = 1.231837\n",
      "epoch 450 loss = 1.026080\n",
      "epoch 451 loss = 1.104314\n",
      "epoch 452 loss = 1.082418\n",
      "epoch 453 loss = 1.071940\n",
      "epoch 454 loss = 1.052269\n",
      "epoch 455 loss = 0.984265\n",
      "epoch 456 loss = 1.094567\n",
      "epoch 457 loss = 1.010205\n",
      "epoch 458 loss = 0.972055\n",
      "epoch 459 loss = 1.555608\n",
      "epoch 460 loss = 1.137083\n",
      "epoch 461 loss = 1.109468\n",
      "epoch 462 loss = 1.074272\n",
      "epoch 463 loss = 0.986370\n",
      "epoch 464 loss = 1.024217\n",
      "epoch 465 loss = 1.111675\n",
      "epoch 466 loss = 1.174989\n",
      "epoch 467 loss = 0.932529\n",
      "epoch 468 loss = 0.951951\n",
      "epoch 469 loss = 1.058299\n",
      "epoch 470 loss = 1.333977\n",
      "epoch 471 loss = 0.877550\n",
      "epoch 472 loss = 0.910546\n",
      "epoch 473 loss = 1.195134\n",
      "epoch 474 loss = 0.941349\n",
      "epoch 475 loss = 1.315857\n",
      "epoch 476 loss = 1.047381\n",
      "epoch 477 loss = 1.012676\n",
      "epoch 478 loss = 1.064077\n",
      "epoch 479 loss = 1.090511\n",
      "epoch 480 loss = 1.004585\n",
      "epoch 481 loss = 1.027518\n",
      "epoch 482 loss = 1.128558\n",
      "epoch 483 loss = 1.041252\n",
      "epoch 484 loss = 1.251753\n",
      "epoch 485 loss = 0.976315\n",
      "epoch 486 loss = 1.036332\n",
      "epoch 487 loss = 1.047436\n",
      "epoch 488 loss = 0.993506\n",
      "epoch 489 loss = 1.298694\n",
      "epoch 490 loss = 1.007256\n",
      "epoch 491 loss = 0.990435\n",
      "epoch 492 loss = 1.135587\n",
      "epoch 493 loss = 1.244035\n",
      "epoch 494 loss = 1.058924\n",
      "epoch 495 loss = 0.882981\n",
      "epoch 496 loss = 0.956802\n",
      "epoch 497 loss = 1.375259\n",
      "epoch 498 loss = 1.010205\n",
      "epoch 499 loss = 1.053520\n",
      "final loss = 1.053520\n",
      "accuracy_mc = tensor(0.4670, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.4735, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.5222, device='cuda:0')\n",
      "training time = 304.5553948879242 seconds\n",
      "testing time = 3.2225582599639893 seconds\n",
      "\n",
      "Training with split 5\n",
      "epoch 0 loss = 2.245479\n",
      "epoch 1 loss = 2.155475\n",
      "epoch 2 loss = 2.093882\n",
      "epoch 3 loss = 2.188280\n",
      "epoch 4 loss = 2.039409\n",
      "epoch 5 loss = 2.013422\n",
      "epoch 6 loss = 2.178828\n",
      "epoch 7 loss = 2.077251\n",
      "epoch 8 loss = 2.095555\n",
      "epoch 9 loss = 1.936534\n",
      "epoch 10 loss = 2.030255\n",
      "epoch 11 loss = 2.011514\n",
      "epoch 12 loss = 1.997695\n",
      "epoch 13 loss = 2.195591\n",
      "epoch 14 loss = 2.063480\n",
      "epoch 15 loss = 1.889246\n",
      "epoch 16 loss = 1.942526\n",
      "epoch 17 loss = 2.075206\n",
      "epoch 18 loss = 1.945084\n",
      "epoch 19 loss = 2.068529\n",
      "epoch 20 loss = 1.895979\n",
      "epoch 21 loss = 1.898697\n",
      "epoch 22 loss = 2.038697\n",
      "epoch 23 loss = 1.973560\n",
      "epoch 24 loss = 1.859255\n",
      "epoch 25 loss = 1.924289\n",
      "epoch 26 loss = 2.023898\n",
      "epoch 27 loss = 1.959840\n",
      "epoch 28 loss = 1.943488\n",
      "epoch 29 loss = 1.829609\n",
      "epoch 30 loss = 1.934456\n",
      "epoch 31 loss = 1.878470\n",
      "epoch 32 loss = 2.010005\n",
      "epoch 33 loss = 1.867918\n",
      "epoch 34 loss = 1.874986\n",
      "epoch 35 loss = 1.728035\n",
      "epoch 36 loss = 1.846960\n",
      "epoch 37 loss = 1.748180\n",
      "epoch 38 loss = 1.937951\n",
      "epoch 39 loss = 1.989404\n",
      "epoch 40 loss = 1.934623\n",
      "epoch 41 loss = 1.875427\n",
      "epoch 42 loss = 1.820697\n",
      "epoch 43 loss = 1.923116\n",
      "epoch 44 loss = 1.907686\n",
      "epoch 45 loss = 1.729601\n",
      "epoch 46 loss = 1.897964\n",
      "epoch 47 loss = 1.900282\n",
      "epoch 48 loss = 1.782679\n",
      "epoch 49 loss = 1.844787\n",
      "epoch 50 loss = 2.043970\n",
      "epoch 51 loss = 1.917377\n",
      "epoch 52 loss = 1.904372\n",
      "epoch 53 loss = 1.876553\n",
      "epoch 54 loss = 1.628394\n",
      "epoch 55 loss = 1.715308\n",
      "epoch 56 loss = 1.776849\n",
      "epoch 57 loss = 1.833480\n",
      "epoch 58 loss = 1.811616\n",
      "epoch 59 loss = 1.798854\n",
      "epoch 60 loss = 1.823105\n",
      "epoch 61 loss = 1.748917\n",
      "epoch 62 loss = 1.724475\n",
      "epoch 63 loss = 1.721609\n",
      "epoch 64 loss = 1.751402\n",
      "epoch 65 loss = 1.840826\n",
      "epoch 66 loss = 1.862192\n",
      "epoch 67 loss = 1.774205\n",
      "epoch 68 loss = 1.645795\n",
      "epoch 69 loss = 1.682777\n",
      "epoch 70 loss = 1.819264\n",
      "epoch 71 loss = 1.660493\n",
      "epoch 72 loss = 1.830007\n",
      "epoch 73 loss = 1.750351\n",
      "epoch 74 loss = 1.726086\n",
      "epoch 75 loss = 1.594287\n",
      "epoch 76 loss = 1.577131\n",
      "epoch 77 loss = 1.805880\n",
      "epoch 78 loss = 1.709916\n",
      "epoch 79 loss = 1.627389\n",
      "epoch 80 loss = 1.547046\n",
      "epoch 81 loss = 1.831558\n",
      "epoch 82 loss = 1.738263\n",
      "epoch 83 loss = 1.724241\n",
      "epoch 84 loss = 1.616025\n",
      "epoch 85 loss = 1.638026\n",
      "epoch 86 loss = 1.681912\n",
      "epoch 87 loss = 1.660204\n",
      "epoch 88 loss = 1.651808\n",
      "epoch 89 loss = 1.618293\n",
      "epoch 90 loss = 1.695763\n",
      "epoch 91 loss = 1.520887\n",
      "epoch 92 loss = 1.703856\n",
      "epoch 93 loss = 1.624916\n",
      "epoch 94 loss = 1.558151\n",
      "epoch 95 loss = 1.641679\n",
      "epoch 96 loss = 1.678693\n",
      "epoch 97 loss = 1.512028\n",
      "epoch 98 loss = 1.608194\n",
      "epoch 99 loss = 1.714504\n",
      "epoch 100 loss = 1.704261\n",
      "epoch 101 loss = 1.593506\n",
      "epoch 102 loss = 1.588903\n",
      "epoch 103 loss = 1.590863\n",
      "epoch 104 loss = 1.551601\n",
      "epoch 105 loss = 1.627914\n",
      "epoch 106 loss = 1.611890\n",
      "epoch 107 loss = 1.522077\n",
      "epoch 108 loss = 1.402753\n",
      "epoch 109 loss = 1.635576\n",
      "epoch 110 loss = 1.394728\n",
      "epoch 111 loss = 1.653354\n",
      "epoch 112 loss = 1.682309\n",
      "epoch 113 loss = 1.488539\n",
      "epoch 114 loss = 1.581328\n",
      "epoch 115 loss = 1.617119\n",
      "epoch 116 loss = 1.565345\n",
      "epoch 117 loss = 1.530514\n",
      "epoch 118 loss = 1.595169\n",
      "epoch 119 loss = 1.533242\n",
      "epoch 120 loss = 1.493102\n",
      "epoch 121 loss = 1.696635\n",
      "epoch 122 loss = 1.705840\n",
      "epoch 123 loss = 1.659251\n",
      "epoch 124 loss = 1.515602\n",
      "epoch 125 loss = 1.531588\n",
      "epoch 126 loss = 1.644723\n",
      "epoch 127 loss = 1.641476\n",
      "epoch 128 loss = 1.725787\n",
      "epoch 129 loss = 1.702897\n",
      "epoch 130 loss = 1.737612\n",
      "epoch 131 loss = 1.620372\n",
      "epoch 132 loss = 1.558427\n",
      "epoch 133 loss = 1.464497\n",
      "epoch 134 loss = 1.631352\n",
      "epoch 135 loss = 1.405304\n",
      "epoch 136 loss = 1.536992\n",
      "epoch 137 loss = 1.641730\n",
      "epoch 138 loss = 1.504854\n",
      "epoch 139 loss = 1.641546\n",
      "epoch 140 loss = 1.586848\n",
      "epoch 141 loss = 1.662238\n",
      "epoch 142 loss = 1.598467\n",
      "epoch 143 loss = 1.643013\n",
      "epoch 144 loss = 1.630679\n",
      "epoch 145 loss = 1.431803\n",
      "epoch 146 loss = 1.653583\n",
      "epoch 147 loss = 1.474145\n",
      "epoch 148 loss = 1.574801\n",
      "epoch 149 loss = 1.575286\n",
      "epoch 150 loss = 1.453777\n",
      "epoch 151 loss = 1.546675\n",
      "epoch 152 loss = 1.616506\n",
      "epoch 153 loss = 1.583868\n",
      "epoch 154 loss = 1.411942\n",
      "epoch 155 loss = 1.588912\n",
      "epoch 156 loss = 1.414840\n",
      "epoch 157 loss = 1.443938\n",
      "epoch 158 loss = 1.468025\n",
      "epoch 159 loss = 1.515544\n",
      "epoch 160 loss = 1.591906\n",
      "epoch 161 loss = 1.724119\n",
      "epoch 162 loss = 1.651589\n",
      "epoch 163 loss = 1.533057\n",
      "epoch 164 loss = 1.591277\n",
      "epoch 165 loss = 1.549093\n",
      "epoch 166 loss = 1.544458\n",
      "epoch 167 loss = 1.546069\n",
      "epoch 168 loss = 1.406181\n",
      "epoch 169 loss = 1.475506\n",
      "epoch 170 loss = 1.657348\n",
      "epoch 171 loss = 1.460889\n",
      "epoch 172 loss = 1.531360\n",
      "epoch 173 loss = 1.313952\n",
      "epoch 174 loss = 1.771813\n",
      "epoch 175 loss = 1.526800\n",
      "epoch 176 loss = 1.389903\n",
      "epoch 177 loss = 1.706013\n",
      "epoch 178 loss = 1.453701\n",
      "epoch 179 loss = 1.550636\n",
      "epoch 180 loss = 1.664201\n",
      "epoch 181 loss = 1.618247\n",
      "epoch 182 loss = 1.394115\n",
      "epoch 183 loss = 1.640224\n",
      "epoch 184 loss = 1.392447\n",
      "epoch 185 loss = 1.453146\n",
      "epoch 186 loss = 1.371229\n",
      "epoch 187 loss = 1.481958\n",
      "epoch 188 loss = 1.471244\n",
      "epoch 189 loss = 1.581065\n",
      "epoch 190 loss = 1.373371\n",
      "epoch 191 loss = 1.462567\n",
      "epoch 192 loss = 1.451175\n",
      "epoch 193 loss = 1.451606\n",
      "epoch 194 loss = 1.319621\n",
      "epoch 195 loss = 1.404921\n",
      "epoch 196 loss = 1.733090\n",
      "epoch 197 loss = 1.657451\n",
      "epoch 198 loss = 1.409070\n",
      "epoch 199 loss = 1.712062\n",
      "epoch 200 loss = 1.532947\n",
      "epoch 201 loss = 1.624343\n",
      "epoch 202 loss = 1.568643\n",
      "epoch 203 loss = 1.335568\n",
      "epoch 204 loss = 1.553089\n",
      "epoch 205 loss = 1.443558\n",
      "epoch 206 loss = 1.435303\n",
      "epoch 207 loss = 1.406038\n",
      "epoch 208 loss = 1.391262\n",
      "epoch 209 loss = 1.598661\n",
      "epoch 210 loss = 1.662205\n",
      "epoch 211 loss = 1.507413\n",
      "epoch 212 loss = 1.491312\n",
      "epoch 213 loss = 1.326513\n",
      "epoch 214 loss = 1.652146\n",
      "epoch 215 loss = 1.344840\n",
      "epoch 216 loss = 1.535367\n",
      "epoch 217 loss = 1.595530\n",
      "epoch 218 loss = 1.541072\n",
      "epoch 219 loss = 1.711231\n",
      "epoch 220 loss = 1.678320\n",
      "epoch 221 loss = 1.603072\n",
      "epoch 222 loss = 1.581522\n",
      "epoch 223 loss = 1.573910\n",
      "epoch 224 loss = 1.401622\n",
      "epoch 225 loss = 1.452938\n",
      "epoch 226 loss = 1.466750\n",
      "epoch 227 loss = 1.559394\n",
      "epoch 228 loss = 1.570757\n",
      "epoch 229 loss = 1.560267\n",
      "epoch 230 loss = 1.475774\n",
      "epoch 231 loss = 1.440426\n",
      "epoch 232 loss = 1.436291\n",
      "epoch 233 loss = 1.535996\n",
      "epoch 234 loss = 1.403615\n",
      "epoch 235 loss = 1.715519\n",
      "epoch 236 loss = 1.625820\n",
      "epoch 237 loss = 1.634322\n",
      "epoch 238 loss = 1.613445\n",
      "epoch 239 loss = 1.401940\n",
      "epoch 240 loss = 1.507736\n",
      "epoch 241 loss = 1.586346\n",
      "epoch 242 loss = 1.445392\n",
      "epoch 243 loss = 1.364315\n",
      "epoch 244 loss = 1.522528\n",
      "epoch 245 loss = 1.469142\n",
      "epoch 246 loss = 1.485848\n",
      "epoch 247 loss = 1.712341\n",
      "epoch 248 loss = 1.388258\n",
      "epoch 249 loss = 1.450492\n",
      "epoch 250 loss = 1.499170\n",
      "epoch 251 loss = 1.467495\n",
      "epoch 252 loss = 1.473585\n",
      "epoch 253 loss = 1.476459\n",
      "epoch 254 loss = 1.583491\n",
      "epoch 255 loss = 1.486710\n",
      "epoch 256 loss = 1.423319\n",
      "epoch 257 loss = 1.503503\n",
      "epoch 258 loss = 1.471254\n",
      "epoch 259 loss = 1.491782\n",
      "epoch 260 loss = 1.689615\n",
      "epoch 261 loss = 1.485772\n",
      "epoch 262 loss = 1.591657\n",
      "epoch 263 loss = 1.599263\n",
      "epoch 264 loss = 1.532601\n",
      "epoch 265 loss = 1.482583\n",
      "epoch 266 loss = 1.746993\n",
      "epoch 267 loss = 1.462512\n",
      "epoch 268 loss = 1.396107\n",
      "epoch 269 loss = 1.351762\n",
      "epoch 270 loss = 1.555598\n",
      "epoch 271 loss = 1.446974\n",
      "epoch 272 loss = 1.474743\n",
      "epoch 273 loss = 1.529850\n",
      "epoch 274 loss = 1.343421\n",
      "epoch 275 loss = 1.411269\n",
      "epoch 276 loss = 1.589960\n",
      "epoch 277 loss = 1.416891\n",
      "epoch 278 loss = 1.506766\n",
      "epoch 279 loss = 1.386647\n",
      "epoch 280 loss = 1.486713\n",
      "epoch 281 loss = 1.492257\n",
      "epoch 282 loss = 1.520916\n",
      "epoch 283 loss = 1.593873\n",
      "epoch 284 loss = 1.649798\n",
      "epoch 285 loss = 1.544185\n",
      "epoch 286 loss = 1.489384\n",
      "epoch 287 loss = 1.472749\n",
      "epoch 288 loss = 1.446438\n",
      "epoch 289 loss = 1.415137\n",
      "epoch 290 loss = 1.605831\n",
      "epoch 291 loss = 1.383459\n",
      "epoch 292 loss = 1.323231\n",
      "epoch 293 loss = 1.402469\n",
      "epoch 294 loss = 1.588239\n",
      "epoch 295 loss = 1.683067\n",
      "epoch 296 loss = 1.362606\n",
      "epoch 297 loss = 1.496587\n",
      "epoch 298 loss = 1.583428\n",
      "epoch 299 loss = 1.287213\n",
      "epoch 300 loss = 1.498003\n",
      "epoch 301 loss = 1.442408\n",
      "epoch 302 loss = 1.450223\n",
      "epoch 303 loss = 1.338042\n",
      "epoch 304 loss = 1.403147\n",
      "epoch 305 loss = 1.529873\n",
      "epoch 306 loss = 1.472689\n",
      "epoch 307 loss = 1.422947\n",
      "epoch 308 loss = 1.376081\n",
      "epoch 309 loss = 1.443558\n",
      "epoch 310 loss = 1.316997\n",
      "epoch 311 loss = 1.338486\n",
      "epoch 312 loss = 1.533764\n",
      "epoch 313 loss = 1.464973\n",
      "epoch 314 loss = 1.478075\n",
      "epoch 315 loss = 1.508871\n",
      "epoch 316 loss = 1.340851\n",
      "epoch 317 loss = 1.523242\n",
      "epoch 318 loss = 1.439129\n",
      "epoch 319 loss = 1.376350\n",
      "epoch 320 loss = 1.410393\n",
      "epoch 321 loss = 1.486101\n",
      "epoch 322 loss = 1.380790\n",
      "epoch 323 loss = 1.483362\n",
      "epoch 324 loss = 1.501751\n",
      "epoch 325 loss = 1.362633\n",
      "epoch 326 loss = 1.427160\n",
      "epoch 327 loss = 1.432355\n",
      "epoch 328 loss = 1.588724\n",
      "epoch 329 loss = 1.700434\n",
      "epoch 330 loss = 1.602965\n",
      "epoch 331 loss = 1.452453\n",
      "epoch 332 loss = 1.480092\n",
      "epoch 333 loss = 1.518669\n",
      "epoch 334 loss = 1.344399\n",
      "epoch 335 loss = 1.684812\n",
      "epoch 336 loss = 1.527426\n",
      "epoch 337 loss = 1.297977\n",
      "epoch 338 loss = 1.511427\n",
      "epoch 339 loss = 1.310679\n",
      "epoch 340 loss = 1.552002\n",
      "epoch 341 loss = 1.528727\n",
      "epoch 342 loss = 1.492236\n",
      "epoch 343 loss = 1.327249\n",
      "epoch 344 loss = 1.660021\n",
      "epoch 345 loss = 1.472669\n",
      "epoch 346 loss = 1.273474\n",
      "epoch 347 loss = 1.513117\n",
      "epoch 348 loss = 1.404069\n",
      "epoch 349 loss = 1.346821\n",
      "epoch 350 loss = 1.398362\n",
      "epoch 351 loss = 1.363129\n",
      "epoch 352 loss = 1.483388\n",
      "epoch 353 loss = 1.514990\n",
      "epoch 354 loss = 1.457191\n",
      "epoch 355 loss = 1.576319\n",
      "epoch 356 loss = 1.410537\n",
      "epoch 357 loss = 1.494978\n",
      "epoch 358 loss = 1.518196\n",
      "epoch 359 loss = 1.678990\n",
      "epoch 360 loss = 1.706814\n",
      "epoch 361 loss = 1.396045\n",
      "epoch 362 loss = 1.472158\n",
      "epoch 363 loss = 1.579037\n",
      "epoch 364 loss = 1.444105\n",
      "epoch 365 loss = 1.471220\n",
      "epoch 366 loss = 1.399129\n",
      "epoch 367 loss = 1.487964\n",
      "epoch 368 loss = 1.619214\n",
      "epoch 369 loss = 1.433417\n",
      "epoch 370 loss = 1.500970\n",
      "epoch 371 loss = 1.615234\n",
      "epoch 372 loss = 1.436347\n",
      "epoch 373 loss = 1.404961\n",
      "epoch 374 loss = 1.294286\n",
      "epoch 375 loss = 1.627513\n",
      "epoch 376 loss = 1.319143\n",
      "epoch 377 loss = 1.325581\n",
      "epoch 378 loss = 1.449564\n",
      "epoch 379 loss = 1.615206\n",
      "epoch 380 loss = 1.436607\n",
      "epoch 381 loss = 1.612876\n",
      "epoch 382 loss = 1.481971\n",
      "epoch 383 loss = 1.408621\n",
      "epoch 384 loss = 1.636413\n",
      "epoch 385 loss = 1.525672\n",
      "epoch 386 loss = 1.626669\n",
      "epoch 387 loss = 1.321620\n",
      "epoch 388 loss = 1.470875\n",
      "epoch 389 loss = 1.352227\n",
      "epoch 390 loss = 1.371470\n",
      "epoch 391 loss = 1.491659\n",
      "epoch 392 loss = 1.422983\n",
      "epoch 393 loss = 1.717967\n",
      "epoch 394 loss = 1.667705\n",
      "epoch 395 loss = 1.457431\n",
      "epoch 396 loss = 1.489815\n",
      "epoch 397 loss = 1.557742\n",
      "epoch 398 loss = 1.285250\n",
      "epoch 399 loss = 1.585298\n",
      "epoch 400 loss = 1.611509\n",
      "epoch 401 loss = 1.491735\n",
      "epoch 402 loss = 1.590961\n",
      "epoch 403 loss = 1.376626\n",
      "epoch 404 loss = 1.561009\n",
      "epoch 405 loss = 1.473796\n",
      "epoch 406 loss = 1.370976\n",
      "epoch 407 loss = 1.405049\n",
      "epoch 408 loss = 1.694914\n",
      "epoch 409 loss = 1.360827\n",
      "epoch 410 loss = 1.709311\n",
      "epoch 411 loss = 1.448773\n",
      "epoch 412 loss = 1.345842\n",
      "epoch 413 loss = 1.385605\n",
      "epoch 414 loss = 1.419472\n",
      "epoch 415 loss = 1.521371\n",
      "epoch 416 loss = 1.583551\n",
      "epoch 417 loss = 1.460385\n",
      "epoch 418 loss = 1.472232\n",
      "epoch 419 loss = 1.445433\n",
      "epoch 420 loss = 1.588823\n",
      "epoch 421 loss = 1.691253\n",
      "epoch 422 loss = 1.477770\n",
      "epoch 423 loss = 1.490447\n",
      "epoch 424 loss = 1.361609\n",
      "epoch 425 loss = 1.411667\n",
      "epoch 426 loss = 1.467874\n",
      "epoch 427 loss = 1.442583\n",
      "epoch 428 loss = 1.560839\n",
      "epoch 429 loss = 1.398931\n",
      "epoch 430 loss = 1.274329\n",
      "epoch 431 loss = 1.530003\n",
      "epoch 432 loss = 1.565217\n",
      "epoch 433 loss = 1.349252\n",
      "epoch 434 loss = 1.461473\n",
      "epoch 435 loss = 1.519335\n",
      "epoch 436 loss = 1.735094\n",
      "epoch 437 loss = 1.431477\n",
      "epoch 438 loss = 1.503144\n",
      "epoch 439 loss = 1.457655\n",
      "epoch 440 loss = 1.780286\n",
      "epoch 441 loss = 1.440842\n",
      "epoch 442 loss = 1.311183\n",
      "epoch 443 loss = 1.361714\n",
      "epoch 444 loss = 1.388231\n",
      "epoch 445 loss = 1.323676\n",
      "epoch 446 loss = 1.517162\n",
      "epoch 447 loss = 1.450217\n",
      "epoch 448 loss = 1.594950\n",
      "epoch 449 loss = 1.507977\n",
      "epoch 450 loss = 1.451093\n",
      "epoch 451 loss = 1.487304\n",
      "epoch 452 loss = 1.306035\n",
      "epoch 453 loss = 1.419669\n",
      "epoch 454 loss = 1.510208\n",
      "epoch 455 loss = 1.515885\n",
      "epoch 456 loss = 1.385076\n",
      "epoch 457 loss = 1.480598\n",
      "epoch 458 loss = 1.331106\n",
      "epoch 459 loss = 1.559750\n",
      "epoch 460 loss = 1.452156\n",
      "epoch 461 loss = 1.368574\n",
      "epoch 462 loss = 1.542438\n",
      "epoch 463 loss = 1.448710\n",
      "epoch 464 loss = 1.394363\n",
      "epoch 465 loss = 1.526095\n",
      "epoch 466 loss = 1.358560\n",
      "epoch 467 loss = 1.452794\n",
      "epoch 468 loss = 1.444023\n",
      "epoch 469 loss = 1.339872\n",
      "epoch 470 loss = 1.378559\n",
      "epoch 471 loss = 1.535306\n",
      "epoch 472 loss = 1.328498\n",
      "epoch 473 loss = 1.260949\n",
      "epoch 474 loss = 1.382490\n",
      "epoch 475 loss = 1.285325\n",
      "epoch 476 loss = 1.386381\n",
      "epoch 477 loss = 1.500479\n",
      "epoch 478 loss = 1.432874\n",
      "epoch 479 loss = 1.490336\n",
      "epoch 480 loss = 1.417867\n",
      "epoch 481 loss = 1.390315\n",
      "epoch 482 loss = 1.346088\n",
      "epoch 483 loss = 1.439474\n",
      "epoch 484 loss = 1.448568\n",
      "epoch 485 loss = 1.563638\n",
      "epoch 486 loss = 1.528613\n",
      "epoch 487 loss = 1.475406\n",
      "epoch 488 loss = 1.457417\n",
      "epoch 489 loss = 1.598881\n",
      "epoch 490 loss = 1.450824\n",
      "epoch 491 loss = 1.407095\n",
      "epoch 492 loss = 1.593191\n",
      "epoch 493 loss = 1.488711\n",
      "epoch 494 loss = 1.296521\n",
      "epoch 495 loss = 1.349515\n",
      "epoch 496 loss = 1.488192\n",
      "epoch 497 loss = 1.527686\n",
      "epoch 498 loss = 1.331060\n",
      "epoch 499 loss = 1.531704\n",
      "final loss = 1.531704\n",
      "accuracy_mc = tensor(0.4435, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.4339, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.7329, device='cuda:0')\n",
      "training time = 304.5328998565674 seconds\n",
      "testing time = 3.1999268531799316 seconds\n",
      "\n",
      "Training with split 6\n",
      "epoch 0 loss = 2.328030\n",
      "epoch 1 loss = 2.243885\n",
      "epoch 2 loss = 2.327522\n",
      "epoch 3 loss = 2.383881\n",
      "epoch 4 loss = 2.126156\n",
      "epoch 5 loss = 2.392122\n",
      "epoch 6 loss = 2.188960\n",
      "epoch 7 loss = 2.239287\n",
      "epoch 8 loss = 2.363643\n",
      "epoch 9 loss = 2.314161\n",
      "epoch 10 loss = 2.292653\n",
      "epoch 11 loss = 2.193685\n",
      "epoch 12 loss = 2.167553\n",
      "epoch 13 loss = 2.271007\n",
      "epoch 14 loss = 2.144233\n",
      "epoch 15 loss = 2.190367\n",
      "epoch 16 loss = 2.305612\n",
      "epoch 17 loss = 2.221532\n",
      "epoch 18 loss = 2.217025\n",
      "epoch 19 loss = 2.212671\n",
      "epoch 20 loss = 2.225398\n",
      "epoch 21 loss = 2.190221\n",
      "epoch 22 loss = 1.959489\n",
      "epoch 23 loss = 2.170908\n",
      "epoch 24 loss = 2.184330\n",
      "epoch 25 loss = 1.942095\n",
      "epoch 26 loss = 2.117425\n",
      "epoch 27 loss = 2.062120\n",
      "epoch 28 loss = 2.170964\n",
      "epoch 29 loss = 2.005803\n",
      "epoch 30 loss = 2.138101\n",
      "epoch 31 loss = 2.144989\n",
      "epoch 32 loss = 1.921303\n",
      "epoch 33 loss = 1.957382\n",
      "epoch 34 loss = 2.061974\n",
      "epoch 35 loss = 1.977208\n",
      "epoch 36 loss = 1.950998\n",
      "epoch 37 loss = 2.018261\n",
      "epoch 38 loss = 1.915068\n",
      "epoch 39 loss = 1.994921\n",
      "epoch 40 loss = 1.962300\n",
      "epoch 41 loss = 1.893208\n",
      "epoch 42 loss = 1.913263\n",
      "epoch 43 loss = 1.803695\n",
      "epoch 44 loss = 2.013888\n",
      "epoch 45 loss = 1.936619\n",
      "epoch 46 loss = 1.892704\n",
      "epoch 47 loss = 1.887634\n",
      "epoch 48 loss = 1.980903\n",
      "epoch 49 loss = 1.949413\n",
      "epoch 50 loss = 1.909337\n",
      "epoch 51 loss = 1.888398\n",
      "epoch 52 loss = 2.015961\n",
      "epoch 53 loss = 2.003019\n",
      "epoch 54 loss = 1.718696\n",
      "epoch 55 loss = 2.098011\n",
      "epoch 56 loss = 1.909388\n",
      "epoch 57 loss = 1.979660\n",
      "epoch 58 loss = 1.906896\n",
      "epoch 59 loss = 1.659234\n",
      "epoch 60 loss = 1.811458\n",
      "epoch 61 loss = 1.788604\n",
      "epoch 62 loss = 1.849149\n",
      "epoch 63 loss = 1.762974\n",
      "epoch 64 loss = 1.733045\n",
      "epoch 65 loss = 1.882281\n",
      "epoch 66 loss = 1.875999\n",
      "epoch 67 loss = 1.962495\n",
      "epoch 68 loss = 1.914298\n",
      "epoch 69 loss = 1.821237\n",
      "epoch 70 loss = 1.821750\n",
      "epoch 71 loss = 1.853706\n",
      "epoch 72 loss = 1.711071\n",
      "epoch 73 loss = 1.870876\n",
      "epoch 74 loss = 1.677422\n",
      "epoch 75 loss = 1.601369\n",
      "epoch 76 loss = 1.694790\n",
      "epoch 77 loss = 1.780384\n",
      "epoch 78 loss = 1.652078\n",
      "epoch 79 loss = 1.866303\n",
      "epoch 80 loss = 1.611797\n",
      "epoch 81 loss = 1.646255\n",
      "epoch 82 loss = 1.706022\n",
      "epoch 83 loss = 1.743599\n",
      "epoch 84 loss = 1.686934\n",
      "epoch 85 loss = 1.491224\n",
      "epoch 86 loss = 1.777091\n",
      "epoch 87 loss = 1.824105\n",
      "epoch 88 loss = 1.836962\n",
      "epoch 89 loss = 1.823947\n",
      "epoch 90 loss = 1.672103\n",
      "epoch 91 loss = 1.575969\n",
      "epoch 92 loss = 1.562285\n",
      "epoch 93 loss = 1.751074\n",
      "epoch 94 loss = 1.452169\n",
      "epoch 95 loss = 1.815519\n",
      "epoch 96 loss = 1.730722\n",
      "epoch 97 loss = 1.647443\n",
      "epoch 98 loss = 1.557338\n",
      "epoch 99 loss = 1.674336\n",
      "epoch 100 loss = 1.653196\n",
      "epoch 101 loss = 1.609403\n",
      "epoch 102 loss = 1.406987\n",
      "epoch 103 loss = 1.583248\n",
      "epoch 104 loss = 1.714355\n",
      "epoch 105 loss = 1.761443\n",
      "epoch 106 loss = 1.512532\n",
      "epoch 107 loss = 1.462618\n",
      "epoch 108 loss = 1.555834\n",
      "epoch 109 loss = 1.711348\n",
      "epoch 110 loss = 1.634556\n",
      "epoch 111 loss = 1.544908\n",
      "epoch 112 loss = 1.574803\n",
      "epoch 113 loss = 1.863408\n",
      "epoch 114 loss = 1.444308\n",
      "epoch 115 loss = 1.672957\n",
      "epoch 116 loss = 1.446059\n",
      "epoch 117 loss = 1.462587\n",
      "epoch 118 loss = 1.618922\n",
      "epoch 119 loss = 1.470401\n",
      "epoch 120 loss = 1.478030\n",
      "epoch 121 loss = 1.610062\n",
      "epoch 122 loss = 1.733380\n",
      "epoch 123 loss = 1.342365\n",
      "epoch 124 loss = 1.567279\n",
      "epoch 125 loss = 1.437817\n",
      "epoch 126 loss = 1.632645\n",
      "epoch 127 loss = 1.610011\n",
      "epoch 128 loss = 1.398496\n",
      "epoch 129 loss = 1.588006\n",
      "epoch 130 loss = 1.360103\n",
      "epoch 131 loss = 1.749224\n",
      "epoch 132 loss = 1.533346\n",
      "epoch 133 loss = 1.580408\n",
      "epoch 134 loss = 1.526785\n",
      "epoch 135 loss = 1.435704\n",
      "epoch 136 loss = 1.476527\n",
      "epoch 137 loss = 1.680827\n",
      "epoch 138 loss = 1.808903\n",
      "epoch 139 loss = 1.493469\n",
      "epoch 140 loss = 1.564678\n",
      "epoch 141 loss = 1.501357\n",
      "epoch 142 loss = 1.487352\n",
      "epoch 143 loss = 1.544060\n",
      "epoch 144 loss = 1.618807\n",
      "epoch 145 loss = 1.551367\n",
      "epoch 146 loss = 1.396828\n",
      "epoch 147 loss = 1.513723\n",
      "epoch 148 loss = 1.639450\n",
      "epoch 149 loss = 1.467813\n",
      "epoch 150 loss = 1.441630\n",
      "epoch 151 loss = 1.583579\n",
      "epoch 152 loss = 1.406281\n",
      "epoch 153 loss = 1.361978\n",
      "epoch 154 loss = 1.680975\n",
      "epoch 155 loss = 1.602924\n",
      "epoch 156 loss = 1.444137\n",
      "epoch 157 loss = 1.454969\n",
      "epoch 158 loss = 1.565749\n",
      "epoch 159 loss = 1.539587\n",
      "epoch 160 loss = 1.477099\n",
      "epoch 161 loss = 1.441885\n",
      "epoch 162 loss = 1.424146\n",
      "epoch 163 loss = 1.520183\n",
      "epoch 164 loss = 1.495401\n",
      "epoch 165 loss = 1.493141\n",
      "epoch 166 loss = 1.471220\n",
      "epoch 167 loss = 1.431690\n",
      "epoch 168 loss = 1.525237\n",
      "epoch 169 loss = 1.318829\n",
      "epoch 170 loss = 1.469593\n",
      "epoch 171 loss = 1.525729\n",
      "epoch 172 loss = 1.519534\n",
      "epoch 173 loss = 1.289066\n",
      "epoch 174 loss = 1.432056\n",
      "epoch 175 loss = 1.516914\n",
      "epoch 176 loss = 1.446543\n",
      "epoch 177 loss = 1.359873\n",
      "epoch 178 loss = 1.416985\n",
      "epoch 179 loss = 1.585014\n",
      "epoch 180 loss = 1.449837\n",
      "epoch 181 loss = 1.244142\n",
      "epoch 182 loss = 1.662485\n",
      "epoch 183 loss = 1.449689\n",
      "epoch 184 loss = 1.522706\n",
      "epoch 185 loss = 1.428617\n",
      "epoch 186 loss = 1.487043\n",
      "epoch 187 loss = 1.499193\n",
      "epoch 188 loss = 1.421163\n",
      "epoch 189 loss = 1.624018\n",
      "epoch 190 loss = 1.348655\n",
      "epoch 191 loss = 1.438394\n",
      "epoch 192 loss = 1.377309\n",
      "epoch 193 loss = 1.356975\n",
      "epoch 194 loss = 1.369290\n",
      "epoch 195 loss = 1.636027\n",
      "epoch 196 loss = 1.467620\n",
      "epoch 197 loss = 1.408805\n",
      "epoch 198 loss = 1.502387\n",
      "epoch 199 loss = 1.452992\n",
      "epoch 200 loss = 1.449258\n",
      "epoch 201 loss = 1.475070\n",
      "epoch 202 loss = 1.417016\n",
      "epoch 203 loss = 1.373208\n",
      "epoch 204 loss = 1.368835\n",
      "epoch 205 loss = 1.452064\n",
      "epoch 206 loss = 1.468480\n",
      "epoch 207 loss = 1.435465\n",
      "epoch 208 loss = 1.604726\n",
      "epoch 209 loss = 1.554468\n",
      "epoch 210 loss = 1.449780\n",
      "epoch 211 loss = 1.406974\n",
      "epoch 212 loss = 1.420134\n",
      "epoch 213 loss = 1.470308\n",
      "epoch 214 loss = 1.424329\n",
      "epoch 215 loss = 1.734610\n",
      "epoch 216 loss = 1.586294\n",
      "epoch 217 loss = 1.495728\n",
      "epoch 218 loss = 1.572594\n",
      "epoch 219 loss = 1.408514\n",
      "epoch 220 loss = 1.274988\n",
      "epoch 221 loss = 1.783911\n",
      "epoch 222 loss = 1.681519\n",
      "epoch 223 loss = 1.633800\n",
      "epoch 224 loss = 1.362478\n",
      "epoch 225 loss = 1.450549\n",
      "epoch 226 loss = 1.535691\n",
      "epoch 227 loss = 1.567085\n",
      "epoch 228 loss = 1.448966\n",
      "epoch 229 loss = 1.509004\n",
      "epoch 230 loss = 1.387939\n",
      "epoch 231 loss = 1.466228\n",
      "epoch 232 loss = 1.422627\n",
      "epoch 233 loss = 1.513354\n",
      "epoch 234 loss = 1.694466\n",
      "epoch 235 loss = 1.367187\n",
      "epoch 236 loss = 1.403992\n",
      "epoch 237 loss = 1.412925\n",
      "epoch 238 loss = 1.571728\n",
      "epoch 239 loss = 1.845037\n",
      "epoch 240 loss = 1.410803\n",
      "epoch 241 loss = 1.693460\n",
      "epoch 242 loss = 1.549306\n",
      "epoch 243 loss = 1.528641\n",
      "epoch 244 loss = 1.458708\n",
      "epoch 245 loss = 1.338820\n",
      "epoch 246 loss = 1.314288\n",
      "epoch 247 loss = 1.337609\n",
      "epoch 248 loss = 1.482930\n",
      "epoch 249 loss = 1.428017\n",
      "epoch 250 loss = 1.471590\n",
      "epoch 251 loss = 1.564816\n",
      "epoch 252 loss = 1.656071\n",
      "epoch 253 loss = 1.393920\n",
      "epoch 254 loss = 1.425615\n",
      "epoch 255 loss = 1.530611\n",
      "epoch 256 loss = 1.614547\n",
      "epoch 257 loss = 1.342163\n",
      "epoch 258 loss = 1.706091\n",
      "epoch 259 loss = 1.466636\n",
      "epoch 260 loss = 1.409504\n",
      "epoch 261 loss = 1.452007\n",
      "epoch 262 loss = 1.461833\n",
      "epoch 263 loss = 1.446129\n",
      "epoch 264 loss = 1.431505\n",
      "epoch 265 loss = 1.361014\n",
      "epoch 266 loss = 1.460262\n",
      "epoch 267 loss = 1.401602\n",
      "epoch 268 loss = 1.304738\n",
      "epoch 269 loss = 1.389760\n",
      "epoch 270 loss = 1.614685\n",
      "epoch 271 loss = 1.366233\n",
      "epoch 272 loss = 1.478944\n",
      "epoch 273 loss = 1.502452\n",
      "epoch 274 loss = 1.522862\n",
      "epoch 275 loss = 1.438792\n",
      "epoch 276 loss = 1.632170\n",
      "epoch 277 loss = 1.357629\n",
      "epoch 278 loss = 1.467295\n",
      "epoch 279 loss = 1.390212\n",
      "epoch 280 loss = 1.484105\n",
      "epoch 281 loss = 1.437711\n",
      "epoch 282 loss = 1.499973\n",
      "epoch 283 loss = 1.446876\n",
      "epoch 284 loss = 1.360016\n",
      "epoch 285 loss = 1.375255\n",
      "epoch 286 loss = 1.323153\n",
      "epoch 287 loss = 1.678672\n",
      "epoch 288 loss = 1.497959\n",
      "epoch 289 loss = 1.547258\n",
      "epoch 290 loss = 1.355359\n",
      "epoch 291 loss = 1.334729\n",
      "epoch 292 loss = 1.378528\n",
      "epoch 293 loss = 1.463146\n",
      "epoch 294 loss = 1.450877\n",
      "epoch 295 loss = 1.333611\n",
      "epoch 296 loss = 1.518083\n",
      "epoch 297 loss = 1.498973\n",
      "epoch 298 loss = 1.609909\n",
      "epoch 299 loss = 1.262729\n",
      "epoch 300 loss = 1.454708\n",
      "epoch 301 loss = 1.421004\n",
      "epoch 302 loss = 1.426633\n",
      "epoch 303 loss = 1.476300\n",
      "epoch 304 loss = 1.633256\n",
      "epoch 305 loss = 1.444248\n",
      "epoch 306 loss = 1.556072\n",
      "epoch 307 loss = 1.311618\n",
      "epoch 308 loss = 1.419973\n",
      "epoch 309 loss = 1.336021\n",
      "epoch 310 loss = 1.644628\n",
      "epoch 311 loss = 1.511260\n",
      "epoch 312 loss = 1.429173\n",
      "epoch 313 loss = 1.384445\n",
      "epoch 314 loss = 1.346967\n",
      "epoch 315 loss = 1.494037\n",
      "epoch 316 loss = 1.395668\n",
      "epoch 317 loss = 1.328798\n",
      "epoch 318 loss = 1.266089\n",
      "epoch 319 loss = 1.286892\n",
      "epoch 320 loss = 1.787305\n",
      "epoch 321 loss = 1.473898\n",
      "epoch 322 loss = 1.615924\n",
      "epoch 323 loss = 1.684240\n",
      "epoch 324 loss = 1.416384\n",
      "epoch 325 loss = 1.300190\n",
      "epoch 326 loss = 1.486444\n",
      "epoch 327 loss = 1.442846\n",
      "epoch 328 loss = 1.449461\n",
      "epoch 329 loss = 1.401315\n",
      "epoch 330 loss = 1.383137\n",
      "epoch 331 loss = 1.473176\n",
      "epoch 332 loss = 1.593832\n",
      "epoch 333 loss = 1.369337\n",
      "epoch 334 loss = 1.523045\n",
      "epoch 335 loss = 1.454780\n",
      "epoch 336 loss = 1.338107\n",
      "epoch 337 loss = 1.468551\n",
      "epoch 338 loss = 1.546845\n",
      "epoch 339 loss = 1.460646\n",
      "epoch 340 loss = 1.454448\n",
      "epoch 341 loss = 1.324875\n",
      "epoch 342 loss = 1.435696\n",
      "epoch 343 loss = 1.440600\n",
      "epoch 344 loss = 1.351027\n",
      "epoch 345 loss = 1.593274\n",
      "epoch 346 loss = 1.590611\n",
      "epoch 347 loss = 1.402256\n",
      "epoch 348 loss = 1.534756\n",
      "epoch 349 loss = 1.458607\n",
      "epoch 350 loss = 1.355248\n",
      "epoch 351 loss = 1.431417\n",
      "epoch 352 loss = 1.371439\n",
      "epoch 353 loss = 1.502468\n",
      "epoch 354 loss = 1.279406\n",
      "epoch 355 loss = 1.340599\n",
      "epoch 356 loss = 1.386317\n",
      "epoch 357 loss = 1.523745\n",
      "epoch 358 loss = 1.415147\n",
      "epoch 359 loss = 1.318456\n",
      "epoch 360 loss = 1.456897\n",
      "epoch 361 loss = 1.387516\n",
      "epoch 362 loss = 1.728828\n",
      "epoch 363 loss = 1.490155\n",
      "epoch 364 loss = 1.389548\n",
      "epoch 365 loss = 1.419657\n",
      "epoch 366 loss = 1.523516\n",
      "epoch 367 loss = 1.470274\n",
      "epoch 368 loss = 1.278591\n",
      "epoch 369 loss = 1.591313\n",
      "epoch 370 loss = 1.329645\n",
      "epoch 371 loss = 1.501478\n",
      "epoch 372 loss = 1.505404\n",
      "epoch 373 loss = 1.460490\n",
      "epoch 374 loss = 1.373355\n",
      "epoch 375 loss = 1.345884\n",
      "epoch 376 loss = 1.507764\n",
      "epoch 377 loss = 1.492238\n",
      "epoch 378 loss = 1.471839\n",
      "epoch 379 loss = 1.313272\n",
      "epoch 380 loss = 1.401864\n",
      "epoch 381 loss = 1.363831\n",
      "epoch 382 loss = 1.456613\n",
      "epoch 383 loss = 1.425907\n",
      "epoch 384 loss = 1.412941\n",
      "epoch 385 loss = 1.594993\n",
      "epoch 386 loss = 1.400887\n",
      "epoch 387 loss = 1.539188\n",
      "epoch 388 loss = 1.360048\n",
      "epoch 389 loss = 1.371623\n",
      "epoch 390 loss = 1.582315\n",
      "epoch 391 loss = 1.352614\n",
      "epoch 392 loss = 1.338087\n",
      "epoch 393 loss = 1.479290\n",
      "epoch 394 loss = 1.363391\n",
      "epoch 395 loss = 1.443541\n",
      "epoch 396 loss = 1.372616\n",
      "epoch 397 loss = 1.501927\n",
      "epoch 398 loss = 1.365319\n",
      "epoch 399 loss = 1.557603\n",
      "epoch 400 loss = 1.455664\n",
      "epoch 401 loss = 1.410565\n",
      "epoch 402 loss = 1.627034\n",
      "epoch 403 loss = 1.696157\n",
      "epoch 404 loss = 1.426800\n",
      "epoch 405 loss = 1.459957\n",
      "epoch 406 loss = 1.484359\n",
      "epoch 407 loss = 1.683130\n",
      "epoch 408 loss = 1.518265\n",
      "epoch 409 loss = 1.317026\n",
      "epoch 410 loss = 1.392632\n",
      "epoch 411 loss = 1.571004\n",
      "epoch 412 loss = 1.386230\n",
      "epoch 413 loss = 1.465317\n",
      "epoch 414 loss = 1.519762\n",
      "epoch 415 loss = 1.405449\n",
      "epoch 416 loss = 1.579165\n",
      "epoch 417 loss = 1.607722\n",
      "epoch 418 loss = 1.335785\n",
      "epoch 419 loss = 1.518467\n",
      "epoch 420 loss = 1.479591\n",
      "epoch 421 loss = 1.564952\n",
      "epoch 422 loss = 1.299345\n",
      "epoch 423 loss = 1.692649\n",
      "epoch 424 loss = 1.525935\n",
      "epoch 425 loss = 1.343547\n",
      "epoch 426 loss = 1.673016\n",
      "epoch 427 loss = 1.415348\n",
      "epoch 428 loss = 1.561823\n",
      "epoch 429 loss = 1.460046\n",
      "epoch 430 loss = 1.573206\n",
      "epoch 431 loss = 1.316029\n",
      "epoch 432 loss = 1.533709\n",
      "epoch 433 loss = 1.434323\n",
      "epoch 434 loss = 1.464727\n",
      "epoch 435 loss = 1.487360\n",
      "epoch 436 loss = 1.637415\n",
      "epoch 437 loss = 1.647367\n",
      "epoch 438 loss = 1.381142\n",
      "epoch 439 loss = 1.417779\n",
      "epoch 440 loss = 1.481751\n",
      "epoch 441 loss = 1.693576\n",
      "epoch 442 loss = 1.451452\n",
      "epoch 443 loss = 1.333369\n",
      "epoch 444 loss = 1.312702\n",
      "epoch 445 loss = 1.456224\n",
      "epoch 446 loss = 1.530085\n",
      "epoch 447 loss = 1.449941\n",
      "epoch 448 loss = 1.746541\n",
      "epoch 449 loss = 1.643217\n",
      "epoch 450 loss = 1.468648\n",
      "epoch 451 loss = 1.412573\n",
      "epoch 452 loss = 1.454781\n",
      "epoch 453 loss = 1.575330\n",
      "epoch 454 loss = 1.399174\n",
      "epoch 455 loss = 1.358335\n",
      "epoch 456 loss = 1.423371\n",
      "epoch 457 loss = 1.265238\n",
      "epoch 458 loss = 1.571611\n",
      "epoch 459 loss = 1.459571\n",
      "epoch 460 loss = 1.526074\n",
      "epoch 461 loss = 1.312370\n",
      "epoch 462 loss = 1.403933\n",
      "epoch 463 loss = 1.523618\n",
      "epoch 464 loss = 1.386111\n",
      "epoch 465 loss = 1.278538\n",
      "epoch 466 loss = 1.410120\n",
      "epoch 467 loss = 1.532979\n",
      "epoch 468 loss = 1.428966\n",
      "epoch 469 loss = 1.434631\n",
      "epoch 470 loss = 1.326037\n",
      "epoch 471 loss = 1.343229\n",
      "epoch 472 loss = 1.390794\n",
      "epoch 473 loss = 1.616772\n",
      "epoch 474 loss = 1.787946\n",
      "epoch 475 loss = 1.287559\n",
      "epoch 476 loss = 1.504487\n",
      "epoch 477 loss = 1.381192\n",
      "epoch 478 loss = 1.394686\n",
      "epoch 479 loss = 1.452781\n",
      "epoch 480 loss = 1.434696\n",
      "epoch 481 loss = 1.361801\n",
      "epoch 482 loss = 1.590922\n",
      "epoch 483 loss = 1.533088\n",
      "epoch 484 loss = 1.457464\n",
      "epoch 485 loss = 1.505773\n",
      "epoch 486 loss = 1.284795\n",
      "epoch 487 loss = 1.329356\n",
      "epoch 488 loss = 1.434633\n",
      "epoch 489 loss = 1.470437\n",
      "epoch 490 loss = 1.693071\n",
      "epoch 491 loss = 1.591974\n",
      "epoch 492 loss = 1.569066\n",
      "epoch 493 loss = 1.417046\n",
      "epoch 494 loss = 1.390869\n",
      "epoch 495 loss = 1.475461\n",
      "epoch 496 loss = 1.374088\n",
      "epoch 497 loss = 1.484735\n",
      "epoch 498 loss = 1.356355\n",
      "epoch 499 loss = 1.459889\n",
      "final loss = 1.459889\n",
      "accuracy_mc = tensor(0.4225, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.4296, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.5377, device='cuda:0')\n",
      "training time = 304.5422031879425 seconds\n",
      "testing time = 3.2380189895629883 seconds\n",
      "\n",
      "Training with split 7\n",
      "epoch 0 loss = 2.222167\n",
      "epoch 1 loss = 2.053183\n",
      "epoch 2 loss = 2.013677\n",
      "epoch 3 loss = 1.926648\n",
      "epoch 4 loss = 1.873709\n",
      "epoch 5 loss = 1.909292\n",
      "epoch 6 loss = 1.862748\n",
      "epoch 7 loss = 2.002444\n",
      "epoch 8 loss = 1.896401\n",
      "epoch 9 loss = 1.793701\n",
      "epoch 10 loss = 1.763676\n",
      "epoch 11 loss = 1.900754\n",
      "epoch 12 loss = 1.782484\n",
      "epoch 13 loss = 1.863316\n",
      "epoch 14 loss = 1.760953\n",
      "epoch 15 loss = 1.788262\n",
      "epoch 16 loss = 1.677879\n",
      "epoch 17 loss = 1.714982\n",
      "epoch 18 loss = 1.767545\n",
      "epoch 19 loss = 1.716237\n",
      "epoch 20 loss = 1.678113\n",
      "epoch 21 loss = 1.743056\n",
      "epoch 22 loss = 1.712695\n",
      "epoch 23 loss = 1.679364\n",
      "epoch 24 loss = 1.709536\n",
      "epoch 25 loss = 1.651787\n",
      "epoch 26 loss = 1.740159\n",
      "epoch 27 loss = 1.878708\n",
      "epoch 28 loss = 1.833535\n",
      "epoch 29 loss = 1.842393\n",
      "epoch 30 loss = 1.680194\n",
      "epoch 31 loss = 1.908622\n",
      "epoch 32 loss = 1.621331\n",
      "epoch 33 loss = 1.710964\n",
      "epoch 34 loss = 1.658791\n",
      "epoch 35 loss = 1.646905\n",
      "epoch 36 loss = 1.611564\n",
      "epoch 37 loss = 1.528247\n",
      "epoch 38 loss = 1.632887\n",
      "epoch 39 loss = 1.642068\n",
      "epoch 40 loss = 1.737386\n",
      "epoch 41 loss = 1.653585\n",
      "epoch 42 loss = 1.549759\n",
      "epoch 43 loss = 1.536567\n",
      "epoch 44 loss = 1.617414\n",
      "epoch 45 loss = 1.532997\n",
      "epoch 46 loss = 1.692088\n",
      "epoch 47 loss = 1.522912\n",
      "epoch 48 loss = 1.601909\n",
      "epoch 49 loss = 1.457103\n",
      "epoch 50 loss = 1.752118\n",
      "epoch 51 loss = 1.514257\n",
      "epoch 52 loss = 1.617726\n",
      "epoch 53 loss = 1.662147\n",
      "epoch 54 loss = 1.716801\n",
      "epoch 55 loss = 1.690205\n",
      "epoch 56 loss = 1.541720\n",
      "epoch 57 loss = 1.381123\n",
      "epoch 58 loss = 1.616174\n",
      "epoch 59 loss = 1.699202\n",
      "epoch 60 loss = 1.591805\n",
      "epoch 61 loss = 1.523105\n",
      "epoch 62 loss = 1.483016\n",
      "epoch 63 loss = 1.483321\n",
      "epoch 64 loss = 1.557625\n",
      "epoch 65 loss = 1.460418\n",
      "epoch 66 loss = 1.594727\n",
      "epoch 67 loss = 1.554784\n",
      "epoch 68 loss = 1.543495\n",
      "epoch 69 loss = 1.463686\n",
      "epoch 70 loss = 1.551154\n",
      "epoch 71 loss = 1.468545\n",
      "epoch 72 loss = 1.502081\n",
      "epoch 73 loss = 1.414308\n",
      "epoch 74 loss = 1.357190\n",
      "epoch 75 loss = 1.444000\n",
      "epoch 76 loss = 1.443717\n",
      "epoch 77 loss = 1.547076\n",
      "epoch 78 loss = 1.446803\n",
      "epoch 79 loss = 1.368151\n",
      "epoch 80 loss = 1.842270\n",
      "epoch 81 loss = 1.443514\n",
      "epoch 82 loss = 1.432830\n",
      "epoch 83 loss = 1.462226\n",
      "epoch 84 loss = 1.393543\n",
      "epoch 85 loss = 1.313525\n",
      "epoch 86 loss = 1.364594\n",
      "epoch 87 loss = 1.319334\n",
      "epoch 88 loss = 1.370900\n",
      "epoch 89 loss = 1.408284\n",
      "epoch 90 loss = 1.546747\n",
      "epoch 91 loss = 1.498809\n",
      "epoch 92 loss = 1.431104\n",
      "epoch 93 loss = 1.381953\n",
      "epoch 94 loss = 1.299277\n",
      "epoch 95 loss = 1.322345\n",
      "epoch 96 loss = 1.362501\n",
      "epoch 97 loss = 1.359988\n",
      "epoch 98 loss = 1.328918\n",
      "epoch 99 loss = 1.432778\n",
      "epoch 100 loss = 1.444242\n",
      "epoch 101 loss = 1.616313\n",
      "epoch 102 loss = 1.542204\n",
      "epoch 103 loss = 1.388041\n",
      "epoch 104 loss = 1.416317\n",
      "epoch 105 loss = 1.421145\n",
      "epoch 106 loss = 1.479029\n",
      "epoch 107 loss = 1.459564\n",
      "epoch 108 loss = 1.366511\n",
      "epoch 109 loss = 1.401681\n",
      "epoch 110 loss = 1.516554\n",
      "epoch 111 loss = 1.448874\n",
      "epoch 112 loss = 1.532399\n",
      "epoch 113 loss = 1.297415\n",
      "epoch 114 loss = 1.538351\n",
      "epoch 115 loss = 1.420161\n",
      "epoch 116 loss = 1.453401\n",
      "epoch 117 loss = 1.373841\n",
      "epoch 118 loss = 1.240284\n",
      "epoch 119 loss = 1.557058\n",
      "epoch 120 loss = 1.658228\n",
      "epoch 121 loss = 1.480730\n",
      "epoch 122 loss = 1.633861\n",
      "epoch 123 loss = 1.691094\n",
      "epoch 124 loss = 1.337140\n",
      "epoch 125 loss = 1.381784\n",
      "epoch 126 loss = 1.693576\n",
      "epoch 127 loss = 1.386686\n",
      "epoch 128 loss = 1.370174\n",
      "epoch 129 loss = 1.541040\n",
      "epoch 130 loss = 1.544322\n",
      "epoch 131 loss = 1.435525\n",
      "epoch 132 loss = 1.353691\n",
      "epoch 133 loss = 1.623828\n",
      "epoch 134 loss = 1.417418\n",
      "epoch 135 loss = 1.588748\n",
      "epoch 136 loss = 1.336581\n",
      "epoch 137 loss = 1.356688\n",
      "epoch 138 loss = 1.407153\n",
      "epoch 139 loss = 1.325933\n",
      "epoch 140 loss = 1.419407\n",
      "epoch 141 loss = 1.472301\n",
      "epoch 142 loss = 1.433835\n",
      "epoch 143 loss = 1.406730\n",
      "epoch 144 loss = 1.542136\n",
      "epoch 145 loss = 1.361326\n",
      "epoch 146 loss = 1.608448\n",
      "epoch 147 loss = 1.617635\n",
      "epoch 148 loss = 1.355427\n",
      "epoch 149 loss = 1.446788\n",
      "epoch 150 loss = 1.483084\n",
      "epoch 151 loss = 1.375138\n",
      "epoch 152 loss = 1.477491\n",
      "epoch 153 loss = 1.520719\n",
      "epoch 154 loss = 1.345350\n",
      "epoch 155 loss = 1.560329\n",
      "epoch 156 loss = 1.532641\n",
      "epoch 157 loss = 1.308702\n",
      "epoch 158 loss = 1.348351\n",
      "epoch 159 loss = 1.642237\n",
      "epoch 160 loss = 1.504083\n",
      "epoch 161 loss = 1.635077\n",
      "epoch 162 loss = 1.377455\n",
      "epoch 163 loss = 1.622769\n",
      "epoch 164 loss = 1.562495\n",
      "epoch 165 loss = 1.471926\n",
      "epoch 166 loss = 1.449862\n",
      "epoch 167 loss = 1.571673\n",
      "epoch 168 loss = 1.393187\n",
      "epoch 169 loss = 1.336498\n",
      "epoch 170 loss = 1.574252\n",
      "epoch 171 loss = 1.612122\n",
      "epoch 172 loss = 1.506585\n",
      "epoch 173 loss = 1.462961\n",
      "epoch 174 loss = 1.414064\n",
      "epoch 175 loss = 1.453462\n",
      "epoch 176 loss = 1.322965\n",
      "epoch 177 loss = 1.495672\n",
      "epoch 178 loss = 1.436046\n",
      "epoch 179 loss = 1.580405\n",
      "epoch 180 loss = 1.535212\n",
      "epoch 181 loss = 1.402449\n",
      "epoch 182 loss = 1.541189\n",
      "epoch 183 loss = 1.512768\n",
      "epoch 184 loss = 1.356135\n",
      "epoch 185 loss = 1.371126\n",
      "epoch 186 loss = 1.405626\n",
      "epoch 187 loss = 1.420611\n",
      "epoch 188 loss = 1.575044\n",
      "epoch 189 loss = 1.495091\n",
      "epoch 190 loss = 1.386901\n",
      "epoch 191 loss = 1.350351\n",
      "epoch 192 loss = 1.459845\n",
      "epoch 193 loss = 1.363857\n",
      "epoch 194 loss = 1.497180\n",
      "epoch 195 loss = 1.383007\n",
      "epoch 196 loss = 1.584920\n",
      "epoch 197 loss = 1.376887\n",
      "epoch 198 loss = 1.314180\n",
      "epoch 199 loss = 1.520851\n",
      "epoch 200 loss = 1.330601\n",
      "epoch 201 loss = 1.439679\n",
      "epoch 202 loss = 1.480788\n",
      "epoch 203 loss = 1.367142\n",
      "epoch 204 loss = 1.384833\n",
      "epoch 205 loss = 1.325519\n",
      "epoch 206 loss = 1.456846\n",
      "epoch 207 loss = 1.416632\n",
      "epoch 208 loss = 1.344667\n",
      "epoch 209 loss = 1.493867\n",
      "epoch 210 loss = 1.565261\n",
      "epoch 211 loss = 1.355313\n",
      "epoch 212 loss = 1.443387\n",
      "epoch 213 loss = 1.379243\n",
      "epoch 214 loss = 1.419719\n",
      "epoch 215 loss = 1.496187\n",
      "epoch 216 loss = 1.542812\n",
      "epoch 217 loss = 1.412515\n",
      "epoch 218 loss = 1.416785\n",
      "epoch 219 loss = 1.318085\n",
      "epoch 220 loss = 1.345019\n",
      "epoch 221 loss = 1.422375\n",
      "epoch 222 loss = 1.335950\n",
      "epoch 223 loss = 1.577664\n",
      "epoch 224 loss = 1.459969\n",
      "epoch 225 loss = 1.458828\n",
      "epoch 226 loss = 1.314850\n",
      "epoch 227 loss = 1.326312\n",
      "epoch 228 loss = 1.397476\n",
      "epoch 229 loss = 1.514776\n",
      "epoch 230 loss = 1.352508\n",
      "epoch 231 loss = 1.275843\n",
      "epoch 232 loss = 1.380005\n",
      "epoch 233 loss = 1.416582\n",
      "epoch 234 loss = 1.505483\n",
      "epoch 235 loss = 1.498271\n",
      "epoch 236 loss = 1.445071\n",
      "epoch 237 loss = 1.518952\n",
      "epoch 238 loss = 1.434328\n",
      "epoch 239 loss = 1.507884\n",
      "epoch 240 loss = 1.458945\n",
      "epoch 241 loss = 1.415741\n",
      "epoch 242 loss = 1.360660\n",
      "epoch 243 loss = 1.444735\n",
      "epoch 244 loss = 1.444513\n",
      "epoch 245 loss = 1.342591\n",
      "epoch 246 loss = 1.388602\n",
      "epoch 247 loss = 1.426490\n",
      "epoch 248 loss = 1.449560\n",
      "epoch 249 loss = 1.357267\n",
      "epoch 250 loss = 1.559253\n",
      "epoch 251 loss = 1.554576\n",
      "epoch 252 loss = 1.396438\n",
      "epoch 253 loss = 1.245816\n",
      "epoch 254 loss = 1.539183\n",
      "epoch 255 loss = 1.419398\n",
      "epoch 256 loss = 1.445406\n",
      "epoch 257 loss = 1.390983\n",
      "epoch 258 loss = 1.474814\n",
      "epoch 259 loss = 1.402912\n",
      "epoch 260 loss = 1.422309\n",
      "epoch 261 loss = 1.295059\n",
      "epoch 262 loss = 1.372854\n",
      "epoch 263 loss = 1.437851\n",
      "epoch 264 loss = 1.275253\n",
      "epoch 265 loss = 1.403184\n",
      "epoch 266 loss = 1.461912\n",
      "epoch 267 loss = 1.538241\n",
      "epoch 268 loss = 1.530300\n",
      "epoch 269 loss = 1.554157\n",
      "epoch 270 loss = 1.413064\n",
      "epoch 271 loss = 1.379226\n",
      "epoch 272 loss = 1.402001\n",
      "epoch 273 loss = 1.511167\n",
      "epoch 274 loss = 1.587032\n",
      "epoch 275 loss = 1.335866\n",
      "epoch 276 loss = 1.341705\n",
      "epoch 277 loss = 1.586994\n",
      "epoch 278 loss = 1.310374\n",
      "epoch 279 loss = 1.477307\n",
      "epoch 280 loss = 1.393566\n",
      "epoch 281 loss = 1.518434\n",
      "epoch 282 loss = 1.384209\n",
      "epoch 283 loss = 1.565482\n",
      "epoch 284 loss = 1.394975\n",
      "epoch 285 loss = 1.406842\n",
      "epoch 286 loss = 1.355865\n",
      "epoch 287 loss = 1.483386\n",
      "epoch 288 loss = 1.317166\n",
      "epoch 289 loss = 1.287657\n",
      "epoch 290 loss = 1.620434\n",
      "epoch 291 loss = 1.396134\n",
      "epoch 292 loss = 1.269331\n",
      "epoch 293 loss = 1.390803\n",
      "epoch 294 loss = 1.339995\n",
      "epoch 295 loss = 1.467547\n",
      "epoch 296 loss = 1.476355\n",
      "epoch 297 loss = 1.464171\n",
      "epoch 298 loss = 1.454240\n",
      "epoch 299 loss = 1.494538\n",
      "epoch 300 loss = 1.360131\n",
      "epoch 301 loss = 1.299032\n",
      "epoch 302 loss = 1.492997\n",
      "epoch 303 loss = 1.272680\n",
      "epoch 304 loss = 1.301279\n",
      "epoch 305 loss = 1.397174\n",
      "epoch 306 loss = 1.319722\n",
      "epoch 307 loss = 1.327631\n",
      "epoch 308 loss = 1.470822\n",
      "epoch 309 loss = 1.423737\n",
      "epoch 310 loss = 1.307879\n",
      "epoch 311 loss = 1.388719\n",
      "epoch 312 loss = 1.557471\n",
      "epoch 313 loss = 1.640982\n",
      "epoch 314 loss = 1.503721\n",
      "epoch 315 loss = 1.440272\n",
      "epoch 316 loss = 1.325231\n",
      "epoch 317 loss = 1.377884\n",
      "epoch 318 loss = 1.319893\n",
      "epoch 319 loss = 1.373678\n",
      "epoch 320 loss = 1.313418\n",
      "epoch 321 loss = 1.356506\n",
      "epoch 322 loss = 1.355867\n",
      "epoch 323 loss = 1.486799\n",
      "epoch 324 loss = 1.345191\n",
      "epoch 325 loss = 1.390923\n",
      "epoch 326 loss = 1.329136\n",
      "epoch 327 loss = 1.512607\n",
      "epoch 328 loss = 1.442556\n",
      "epoch 329 loss = 1.382916\n",
      "epoch 330 loss = 1.334845\n",
      "epoch 331 loss = 1.310604\n",
      "epoch 332 loss = 1.474931\n",
      "epoch 333 loss = 1.398514\n",
      "epoch 334 loss = 1.298480\n",
      "epoch 335 loss = 1.424185\n",
      "epoch 336 loss = 1.429032\n",
      "epoch 337 loss = 1.301642\n",
      "epoch 338 loss = 1.470852\n",
      "epoch 339 loss = 1.390496\n",
      "epoch 340 loss = 1.481644\n",
      "epoch 341 loss = 1.374372\n",
      "epoch 342 loss = 1.410693\n",
      "epoch 343 loss = 1.351091\n",
      "epoch 344 loss = 1.222779\n",
      "epoch 345 loss = 1.234528\n",
      "epoch 346 loss = 1.480116\n",
      "epoch 347 loss = 1.372919\n",
      "epoch 348 loss = 1.292102\n",
      "epoch 349 loss = 1.325945\n",
      "epoch 350 loss = 1.658176\n",
      "epoch 351 loss = 1.223353\n",
      "epoch 352 loss = 1.333743\n",
      "epoch 353 loss = 1.429081\n",
      "epoch 354 loss = 1.422248\n",
      "epoch 355 loss = 1.536154\n",
      "epoch 356 loss = 1.387246\n",
      "epoch 357 loss = 1.393508\n",
      "epoch 358 loss = 1.414172\n",
      "epoch 359 loss = 1.335762\n",
      "epoch 360 loss = 1.357835\n",
      "epoch 361 loss = 1.464417\n",
      "epoch 362 loss = 1.415827\n",
      "epoch 363 loss = 1.287668\n",
      "epoch 364 loss = 1.479278\n",
      "epoch 365 loss = 1.462341\n",
      "epoch 366 loss = 1.377146\n",
      "epoch 367 loss = 1.194966\n",
      "epoch 368 loss = 1.359173\n",
      "epoch 369 loss = 1.476868\n",
      "epoch 370 loss = 1.594464\n",
      "epoch 371 loss = 1.415453\n",
      "epoch 372 loss = 1.740035\n",
      "epoch 373 loss = 1.449160\n",
      "epoch 374 loss = 1.318359\n",
      "epoch 375 loss = 1.290983\n",
      "epoch 376 loss = 1.433581\n",
      "epoch 377 loss = 1.501335\n",
      "epoch 378 loss = 1.463885\n",
      "epoch 379 loss = 1.391252\n",
      "epoch 380 loss = 1.309800\n",
      "epoch 381 loss = 1.413800\n",
      "epoch 382 loss = 1.308901\n",
      "epoch 383 loss = 1.402312\n",
      "epoch 384 loss = 1.347737\n",
      "epoch 385 loss = 1.466795\n",
      "epoch 386 loss = 1.296617\n",
      "epoch 387 loss = 1.314195\n",
      "epoch 388 loss = 1.409005\n",
      "epoch 389 loss = 1.481409\n",
      "epoch 390 loss = 1.493341\n",
      "epoch 391 loss = 1.349717\n",
      "epoch 392 loss = 1.399646\n",
      "epoch 393 loss = 1.464122\n",
      "epoch 394 loss = 1.419681\n",
      "epoch 395 loss = 1.625661\n",
      "epoch 396 loss = 1.405513\n",
      "epoch 397 loss = 1.238102\n",
      "epoch 398 loss = 1.462186\n",
      "epoch 399 loss = 1.435030\n",
      "epoch 400 loss = 1.380084\n",
      "epoch 401 loss = 1.283463\n",
      "epoch 402 loss = 1.358689\n",
      "epoch 403 loss = 1.364809\n",
      "epoch 404 loss = 1.515486\n",
      "epoch 405 loss = 1.475033\n",
      "epoch 406 loss = 1.284137\n",
      "epoch 407 loss = 1.269034\n",
      "epoch 408 loss = 1.576500\n",
      "epoch 409 loss = 1.310189\n",
      "epoch 410 loss = 1.466018\n",
      "epoch 411 loss = 1.478896\n",
      "epoch 412 loss = 1.436094\n",
      "epoch 413 loss = 1.325552\n",
      "epoch 414 loss = 1.387090\n",
      "epoch 415 loss = 1.449736\n",
      "epoch 416 loss = 1.343977\n",
      "epoch 417 loss = 1.350409\n",
      "epoch 418 loss = 1.394070\n",
      "epoch 419 loss = 1.529800\n",
      "epoch 420 loss = 1.371550\n",
      "epoch 421 loss = 1.297866\n",
      "epoch 422 loss = 1.234123\n",
      "epoch 423 loss = 1.335714\n",
      "epoch 424 loss = 1.322161\n",
      "epoch 425 loss = 1.565246\n",
      "epoch 426 loss = 1.466598\n",
      "epoch 427 loss = 1.190528\n",
      "epoch 428 loss = 1.274174\n",
      "epoch 429 loss = 1.317727\n",
      "epoch 430 loss = 1.428969\n",
      "epoch 431 loss = 1.638616\n",
      "epoch 432 loss = 1.381907\n",
      "epoch 433 loss = 1.374837\n",
      "epoch 434 loss = 1.524913\n",
      "epoch 435 loss = 1.367330\n",
      "epoch 436 loss = 1.451577\n",
      "epoch 437 loss = 1.523467\n",
      "epoch 438 loss = 1.417430\n",
      "epoch 439 loss = 1.371124\n",
      "epoch 440 loss = 1.461089\n",
      "epoch 441 loss = 1.288130\n",
      "epoch 442 loss = 1.470310\n",
      "epoch 443 loss = 1.353602\n",
      "epoch 444 loss = 1.322434\n",
      "epoch 445 loss = 1.257888\n",
      "epoch 446 loss = 1.208164\n",
      "epoch 447 loss = 1.332103\n",
      "epoch 448 loss = 1.313547\n",
      "epoch 449 loss = 1.336936\n",
      "epoch 450 loss = 1.372763\n",
      "epoch 451 loss = 1.356430\n",
      "epoch 452 loss = 1.338552\n",
      "epoch 453 loss = 1.526200\n",
      "epoch 454 loss = 1.324612\n",
      "epoch 455 loss = 1.302179\n",
      "epoch 456 loss = 1.296662\n",
      "epoch 457 loss = 1.474158\n",
      "epoch 458 loss = 1.579763\n",
      "epoch 459 loss = 1.384010\n",
      "epoch 460 loss = 1.409167\n",
      "epoch 461 loss = 1.373961\n",
      "epoch 462 loss = 1.347996\n",
      "epoch 463 loss = 1.287855\n",
      "epoch 464 loss = 1.491898\n",
      "epoch 465 loss = 1.197716\n",
      "epoch 466 loss = 1.426273\n",
      "epoch 467 loss = 1.233790\n",
      "epoch 468 loss = 1.400472\n",
      "epoch 469 loss = 1.537357\n",
      "epoch 470 loss = 1.330682\n",
      "epoch 471 loss = 1.422963\n",
      "epoch 472 loss = 1.272799\n",
      "epoch 473 loss = 1.297941\n",
      "epoch 474 loss = 1.486201\n",
      "epoch 475 loss = 1.398421\n",
      "epoch 476 loss = 1.356403\n",
      "epoch 477 loss = 1.457158\n",
      "epoch 478 loss = 1.567351\n",
      "epoch 479 loss = 1.474428\n",
      "epoch 480 loss = 1.350172\n",
      "epoch 481 loss = 1.217865\n",
      "epoch 482 loss = 1.340528\n",
      "epoch 483 loss = 1.259441\n",
      "epoch 484 loss = 1.258545\n",
      "epoch 485 loss = 1.245052\n",
      "epoch 486 loss = 1.225323\n",
      "epoch 487 loss = 1.504170\n",
      "epoch 488 loss = 1.299007\n",
      "epoch 489 loss = 1.350163\n",
      "epoch 490 loss = 1.519675\n",
      "epoch 491 loss = 1.230477\n",
      "epoch 492 loss = 1.393251\n",
      "epoch 493 loss = 1.541346\n",
      "epoch 494 loss = 1.437556\n",
      "epoch 495 loss = 1.351995\n",
      "epoch 496 loss = 1.531586\n",
      "epoch 497 loss = 1.257166\n",
      "epoch 498 loss = 1.412848\n",
      "epoch 499 loss = 1.364970\n",
      "final loss = 1.364970\n",
      "accuracy_mc = tensor(0.4243, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.4142, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.6676, device='cuda:0')\n",
      "training time = 303.54941296577454 seconds\n",
      "testing time = 3.180112838745117 seconds\n",
      "\n",
      "Training with split 8\n",
      "epoch 0 loss = 2.296001\n",
      "epoch 1 loss = 2.096230\n",
      "epoch 2 loss = 1.986487\n",
      "epoch 3 loss = 2.096381\n",
      "epoch 4 loss = 2.000787\n",
      "epoch 5 loss = 2.053305\n",
      "epoch 6 loss = 1.871576\n",
      "epoch 7 loss = 1.970976\n",
      "epoch 8 loss = 1.856308\n",
      "epoch 9 loss = 1.845089\n",
      "epoch 10 loss = 1.854200\n",
      "epoch 11 loss = 1.824139\n",
      "epoch 12 loss = 1.724606\n",
      "epoch 13 loss = 1.858453\n",
      "epoch 14 loss = 1.865905\n",
      "epoch 15 loss = 1.758256\n",
      "epoch 16 loss = 1.815422\n",
      "epoch 17 loss = 1.717327\n",
      "epoch 18 loss = 1.813228\n",
      "epoch 19 loss = 1.784490\n",
      "epoch 20 loss = 1.748459\n",
      "epoch 21 loss = 1.699887\n",
      "epoch 22 loss = 1.729071\n",
      "epoch 23 loss = 1.811331\n",
      "epoch 24 loss = 1.702343\n",
      "epoch 25 loss = 1.648336\n",
      "epoch 26 loss = 1.741846\n",
      "epoch 27 loss = 1.724925\n",
      "epoch 28 loss = 1.758992\n",
      "epoch 29 loss = 1.716362\n",
      "epoch 30 loss = 1.792977\n",
      "epoch 31 loss = 1.644822\n",
      "epoch 32 loss = 1.726719\n",
      "epoch 33 loss = 1.726643\n",
      "epoch 34 loss = 1.610085\n",
      "epoch 35 loss = 1.651898\n",
      "epoch 36 loss = 1.655461\n",
      "epoch 37 loss = 1.627093\n",
      "epoch 38 loss = 1.798813\n",
      "epoch 39 loss = 1.542091\n",
      "epoch 40 loss = 1.749269\n",
      "epoch 41 loss = 1.705809\n",
      "epoch 42 loss = 1.656301\n",
      "epoch 43 loss = 1.785792\n",
      "epoch 44 loss = 1.599521\n",
      "epoch 45 loss = 1.641891\n",
      "epoch 46 loss = 1.679066\n",
      "epoch 47 loss = 1.749603\n",
      "epoch 48 loss = 1.706307\n",
      "epoch 49 loss = 1.652309\n",
      "epoch 50 loss = 1.731719\n",
      "epoch 51 loss = 1.624155\n",
      "epoch 52 loss = 1.577460\n",
      "epoch 53 loss = 1.649296\n",
      "epoch 54 loss = 1.583110\n",
      "epoch 55 loss = 1.719107\n",
      "epoch 56 loss = 1.597635\n",
      "epoch 57 loss = 1.592335\n",
      "epoch 58 loss = 1.721237\n",
      "epoch 59 loss = 1.634815\n",
      "epoch 60 loss = 1.577462\n",
      "epoch 61 loss = 1.766864\n",
      "epoch 62 loss = 1.706985\n",
      "epoch 63 loss = 1.647111\n",
      "epoch 64 loss = 1.556029\n",
      "epoch 65 loss = 1.639820\n",
      "epoch 66 loss = 1.801488\n",
      "epoch 67 loss = 1.558509\n",
      "epoch 68 loss = 1.581211\n",
      "epoch 69 loss = 1.706766\n",
      "epoch 70 loss = 1.653580\n",
      "epoch 71 loss = 1.594655\n",
      "epoch 72 loss = 1.580692\n",
      "epoch 73 loss = 1.643561\n",
      "epoch 74 loss = 1.621229\n",
      "epoch 75 loss = 1.570326\n",
      "epoch 76 loss = 1.664317\n",
      "epoch 77 loss = 1.489679\n",
      "epoch 78 loss = 1.618104\n",
      "epoch 79 loss = 1.545681\n",
      "epoch 80 loss = 1.668777\n",
      "epoch 81 loss = 1.581319\n",
      "epoch 82 loss = 1.598774\n",
      "epoch 83 loss = 1.716810\n",
      "epoch 84 loss = 1.516901\n",
      "epoch 85 loss = 1.722973\n",
      "epoch 86 loss = 1.540567\n",
      "epoch 87 loss = 1.727604\n",
      "epoch 88 loss = 1.688043\n",
      "epoch 89 loss = 1.617935\n",
      "epoch 90 loss = 1.419559\n",
      "epoch 91 loss = 1.663137\n",
      "epoch 92 loss = 1.580054\n",
      "epoch 93 loss = 1.547366\n",
      "epoch 94 loss = 1.647562\n",
      "epoch 95 loss = 1.620770\n",
      "epoch 96 loss = 1.646155\n",
      "epoch 97 loss = 1.600916\n",
      "epoch 98 loss = 1.504159\n",
      "epoch 99 loss = 1.478295\n",
      "epoch 100 loss = 1.604161\n",
      "epoch 101 loss = 1.633496\n",
      "epoch 102 loss = 1.623333\n",
      "epoch 103 loss = 1.752298\n",
      "epoch 104 loss = 1.403218\n",
      "epoch 105 loss = 1.666427\n",
      "epoch 106 loss = 1.628600\n",
      "epoch 107 loss = 1.487887\n",
      "epoch 108 loss = 1.580577\n",
      "epoch 109 loss = 1.558333\n",
      "epoch 110 loss = 1.544777\n",
      "epoch 111 loss = 1.579620\n",
      "epoch 112 loss = 1.437272\n",
      "epoch 113 loss = 1.387818\n",
      "epoch 114 loss = 1.410336\n",
      "epoch 115 loss = 1.380176\n",
      "epoch 116 loss = 1.489177\n",
      "epoch 117 loss = 1.489991\n",
      "epoch 118 loss = 1.505514\n",
      "epoch 119 loss = 1.526636\n",
      "epoch 120 loss = 1.536584\n",
      "epoch 121 loss = 1.614945\n",
      "epoch 122 loss = 1.562513\n",
      "epoch 123 loss = 1.455034\n",
      "epoch 124 loss = 1.514759\n",
      "epoch 125 loss = 1.373321\n",
      "epoch 126 loss = 1.646815\n",
      "epoch 127 loss = 1.402821\n",
      "epoch 128 loss = 1.620406\n",
      "epoch 129 loss = 1.517829\n",
      "epoch 130 loss = 1.561047\n",
      "epoch 131 loss = 1.533829\n",
      "epoch 132 loss = 1.664130\n",
      "epoch 133 loss = 1.688740\n",
      "epoch 134 loss = 1.573359\n",
      "epoch 135 loss = 1.502378\n",
      "epoch 136 loss = 1.495539\n",
      "epoch 137 loss = 1.503258\n",
      "epoch 138 loss = 1.762926\n",
      "epoch 139 loss = 1.556788\n",
      "epoch 140 loss = 1.491750\n",
      "epoch 141 loss = 1.643827\n",
      "epoch 142 loss = 1.570072\n",
      "epoch 143 loss = 1.422973\n",
      "epoch 144 loss = 1.363482\n",
      "epoch 145 loss = 1.296234\n",
      "epoch 146 loss = 1.702086\n",
      "epoch 147 loss = 1.587086\n",
      "epoch 148 loss = 1.379513\n",
      "epoch 149 loss = 1.322335\n",
      "epoch 150 loss = 1.472946\n",
      "epoch 151 loss = 1.438529\n",
      "epoch 152 loss = 1.429535\n",
      "epoch 153 loss = 1.526471\n",
      "epoch 154 loss = 1.550447\n",
      "epoch 155 loss = 1.491345\n",
      "epoch 156 loss = 1.630261\n",
      "epoch 157 loss = 1.398748\n",
      "epoch 158 loss = 1.587389\n",
      "epoch 159 loss = 1.626980\n",
      "epoch 160 loss = 1.603326\n",
      "epoch 161 loss = 1.530109\n",
      "epoch 162 loss = 1.416639\n",
      "epoch 163 loss = 1.523236\n",
      "epoch 164 loss = 1.332169\n",
      "epoch 165 loss = 1.356179\n",
      "epoch 166 loss = 1.507563\n",
      "epoch 167 loss = 1.418455\n",
      "epoch 168 loss = 1.372264\n",
      "epoch 169 loss = 1.518482\n",
      "epoch 170 loss = 1.391917\n",
      "epoch 171 loss = 1.476044\n",
      "epoch 172 loss = 1.512713\n",
      "epoch 173 loss = 1.385567\n",
      "epoch 174 loss = 1.468395\n",
      "epoch 175 loss = 1.670106\n",
      "epoch 176 loss = 1.484033\n",
      "epoch 177 loss = 1.521138\n",
      "epoch 178 loss = 1.352075\n",
      "epoch 179 loss = 1.357207\n",
      "epoch 180 loss = 1.433519\n",
      "epoch 181 loss = 1.618065\n",
      "epoch 182 loss = 1.462819\n",
      "epoch 183 loss = 1.287413\n",
      "epoch 184 loss = 1.426860\n",
      "epoch 185 loss = 1.516021\n",
      "epoch 186 loss = 1.337111\n",
      "epoch 187 loss = 1.567969\n",
      "epoch 188 loss = 1.312980\n",
      "epoch 189 loss = 1.534533\n",
      "epoch 190 loss = 1.469001\n",
      "epoch 191 loss = 1.537011\n",
      "epoch 192 loss = 1.586512\n",
      "epoch 193 loss = 1.492770\n",
      "epoch 194 loss = 1.345480\n",
      "epoch 195 loss = 1.518942\n",
      "epoch 196 loss = 1.383044\n",
      "epoch 197 loss = 1.420656\n",
      "epoch 198 loss = 1.366127\n",
      "epoch 199 loss = 1.487585\n",
      "epoch 200 loss = 1.461513\n",
      "epoch 201 loss = 1.357435\n",
      "epoch 202 loss = 1.428256\n",
      "epoch 203 loss = 1.441024\n",
      "epoch 204 loss = 1.333552\n",
      "epoch 205 loss = 1.321807\n",
      "epoch 206 loss = 1.675635\n",
      "epoch 207 loss = 1.309168\n",
      "epoch 208 loss = 1.279864\n",
      "epoch 209 loss = 1.333870\n",
      "epoch 210 loss = 1.451128\n",
      "epoch 211 loss = 1.562051\n",
      "epoch 212 loss = 1.436718\n",
      "epoch 213 loss = 1.298625\n",
      "epoch 214 loss = 1.354427\n",
      "epoch 215 loss = 1.313066\n",
      "epoch 216 loss = 1.422989\n",
      "epoch 217 loss = 1.292156\n",
      "epoch 218 loss = 1.500578\n",
      "epoch 219 loss = 1.556613\n",
      "epoch 220 loss = 1.399703\n",
      "epoch 221 loss = 1.418217\n",
      "epoch 222 loss = 1.293422\n",
      "epoch 223 loss = 1.595117\n",
      "epoch 224 loss = 1.201840\n",
      "epoch 225 loss = 1.292398\n",
      "epoch 226 loss = 1.305905\n",
      "epoch 227 loss = 1.216691\n",
      "epoch 228 loss = 1.461332\n",
      "epoch 229 loss = 1.611575\n",
      "epoch 230 loss = 1.256747\n",
      "epoch 231 loss = 1.407986\n",
      "epoch 232 loss = 1.309329\n",
      "epoch 233 loss = 1.292645\n",
      "epoch 234 loss = 1.258286\n",
      "epoch 235 loss = 1.408502\n",
      "epoch 236 loss = 1.606383\n",
      "epoch 237 loss = 1.441351\n",
      "epoch 238 loss = 1.534240\n",
      "epoch 239 loss = 1.486890\n",
      "epoch 240 loss = 1.446088\n",
      "epoch 241 loss = 1.366145\n",
      "epoch 242 loss = 1.355667\n",
      "epoch 243 loss = 1.382221\n",
      "epoch 244 loss = 1.443220\n",
      "epoch 245 loss = 1.266425\n",
      "epoch 246 loss = 1.564001\n",
      "epoch 247 loss = 1.393958\n",
      "epoch 248 loss = 1.449457\n",
      "epoch 249 loss = 1.324750\n",
      "epoch 250 loss = 1.331516\n",
      "epoch 251 loss = 1.374748\n",
      "epoch 252 loss = 1.303104\n",
      "epoch 253 loss = 1.443472\n",
      "epoch 254 loss = 1.466958\n",
      "epoch 255 loss = 1.244728\n",
      "epoch 256 loss = 1.363392\n",
      "epoch 257 loss = 1.339521\n",
      "epoch 258 loss = 1.327159\n",
      "epoch 259 loss = 1.349976\n",
      "epoch 260 loss = 1.383805\n",
      "epoch 261 loss = 1.351226\n",
      "epoch 262 loss = 1.539461\n",
      "epoch 263 loss = 1.291480\n",
      "epoch 264 loss = 1.511999\n",
      "epoch 265 loss = 1.448392\n",
      "epoch 266 loss = 1.255581\n",
      "epoch 267 loss = 1.294786\n",
      "epoch 268 loss = 1.441000\n",
      "epoch 269 loss = 1.293200\n",
      "epoch 270 loss = 1.479026\n",
      "epoch 271 loss = 1.311408\n",
      "epoch 272 loss = 1.359753\n",
      "epoch 273 loss = 1.271571\n",
      "epoch 274 loss = 1.340487\n",
      "epoch 275 loss = 1.223557\n",
      "epoch 276 loss = 1.285955\n",
      "epoch 277 loss = 1.363479\n",
      "epoch 278 loss = 1.346853\n",
      "epoch 279 loss = 1.331392\n",
      "epoch 280 loss = 1.340571\n",
      "epoch 281 loss = 1.459788\n",
      "epoch 282 loss = 1.236969\n",
      "epoch 283 loss = 1.209896\n",
      "epoch 284 loss = 1.191769\n",
      "epoch 285 loss = 1.320976\n",
      "epoch 286 loss = 1.094481\n",
      "epoch 287 loss = 1.495363\n",
      "epoch 288 loss = 1.374331\n",
      "epoch 289 loss = 1.615161\n",
      "epoch 290 loss = 1.451090\n",
      "epoch 291 loss = 1.231904\n",
      "epoch 292 loss = 1.333106\n",
      "epoch 293 loss = 1.297491\n",
      "epoch 294 loss = 1.733662\n",
      "epoch 295 loss = 1.596786\n",
      "epoch 296 loss = 1.361223\n",
      "epoch 297 loss = 1.254617\n",
      "epoch 298 loss = 1.440001\n",
      "epoch 299 loss = 1.267627\n",
      "epoch 300 loss = 1.228041\n",
      "epoch 301 loss = 1.503613\n",
      "epoch 302 loss = 1.249704\n",
      "epoch 303 loss = 1.314194\n",
      "epoch 304 loss = 1.327650\n",
      "epoch 305 loss = 1.418088\n",
      "epoch 306 loss = 1.308910\n",
      "epoch 307 loss = 1.505457\n",
      "epoch 308 loss = 1.414098\n",
      "epoch 309 loss = 1.292209\n",
      "epoch 310 loss = 1.365543\n",
      "epoch 311 loss = 1.380542\n",
      "epoch 312 loss = 1.288566\n",
      "epoch 313 loss = 1.360832\n",
      "epoch 314 loss = 1.220938\n",
      "epoch 315 loss = 1.411029\n",
      "epoch 316 loss = 1.331611\n",
      "epoch 317 loss = 1.276817\n",
      "epoch 318 loss = 1.287341\n",
      "epoch 319 loss = 1.265423\n",
      "epoch 320 loss = 1.202120\n",
      "epoch 321 loss = 1.389202\n",
      "epoch 322 loss = 1.386903\n",
      "epoch 323 loss = 1.527750\n",
      "epoch 324 loss = 1.388315\n",
      "epoch 325 loss = 1.337460\n",
      "epoch 326 loss = 1.379539\n",
      "epoch 327 loss = 1.347285\n",
      "epoch 328 loss = 1.186285\n",
      "epoch 329 loss = 1.280015\n",
      "epoch 330 loss = 1.539112\n",
      "epoch 331 loss = 1.385431\n",
      "epoch 332 loss = 1.502070\n",
      "epoch 333 loss = 1.293347\n",
      "epoch 334 loss = 1.765221\n",
      "epoch 335 loss = 1.311974\n",
      "epoch 336 loss = 1.522307\n",
      "epoch 337 loss = 1.175782\n",
      "epoch 338 loss = 1.397221\n",
      "epoch 339 loss = 1.396314\n",
      "epoch 340 loss = 1.278182\n",
      "epoch 341 loss = 1.360518\n",
      "epoch 342 loss = 1.223176\n",
      "epoch 343 loss = 1.312064\n",
      "epoch 344 loss = 1.564479\n",
      "epoch 345 loss = 1.378031\n",
      "epoch 346 loss = 1.412851\n",
      "epoch 347 loss = 1.341232\n",
      "epoch 348 loss = 1.340020\n",
      "epoch 349 loss = 1.254555\n",
      "epoch 350 loss = 1.414701\n",
      "epoch 351 loss = 1.511486\n",
      "epoch 352 loss = 1.350577\n",
      "epoch 353 loss = 1.303968\n",
      "epoch 354 loss = 1.205655\n",
      "epoch 355 loss = 1.365433\n",
      "epoch 356 loss = 1.334555\n",
      "epoch 357 loss = 1.327511\n",
      "epoch 358 loss = 1.252912\n",
      "epoch 359 loss = 1.428595\n",
      "epoch 360 loss = 1.213345\n",
      "epoch 361 loss = 1.338139\n",
      "epoch 362 loss = 1.334184\n",
      "epoch 363 loss = 1.668107\n",
      "epoch 364 loss = 1.409306\n",
      "epoch 365 loss = 1.315205\n",
      "epoch 366 loss = 1.440947\n",
      "epoch 367 loss = 1.415154\n",
      "epoch 368 loss = 1.421119\n",
      "epoch 369 loss = 1.306552\n",
      "epoch 370 loss = 1.284652\n",
      "epoch 371 loss = 1.315634\n",
      "epoch 372 loss = 1.249621\n",
      "epoch 373 loss = 1.306765\n",
      "epoch 374 loss = 1.348468\n",
      "epoch 375 loss = 1.377294\n",
      "epoch 376 loss = 1.356628\n",
      "epoch 377 loss = 1.356602\n",
      "epoch 378 loss = 1.208757\n",
      "epoch 379 loss = 1.339420\n",
      "epoch 380 loss = 1.293745\n",
      "epoch 381 loss = 1.503107\n",
      "epoch 382 loss = 1.468601\n",
      "epoch 383 loss = 1.117100\n",
      "epoch 384 loss = 1.558703\n",
      "epoch 385 loss = 1.344002\n",
      "epoch 386 loss = 1.523245\n",
      "epoch 387 loss = 1.224990\n",
      "epoch 388 loss = 1.277262\n",
      "epoch 389 loss = 1.435460\n",
      "epoch 390 loss = 1.426167\n",
      "epoch 391 loss = 1.283952\n",
      "epoch 392 loss = 1.352541\n",
      "epoch 393 loss = 1.265823\n",
      "epoch 394 loss = 1.206565\n",
      "epoch 395 loss = 1.238315\n",
      "epoch 396 loss = 1.239295\n",
      "epoch 397 loss = 1.169135\n",
      "epoch 398 loss = 1.514272\n",
      "epoch 399 loss = 1.506641\n",
      "epoch 400 loss = 1.478384\n",
      "epoch 401 loss = 1.438823\n",
      "epoch 402 loss = 1.326098\n",
      "epoch 403 loss = 1.462304\n",
      "epoch 404 loss = 1.289518\n",
      "epoch 405 loss = 1.247683\n",
      "epoch 406 loss = 1.593014\n",
      "epoch 407 loss = 1.387910\n",
      "epoch 408 loss = 1.348767\n",
      "epoch 409 loss = 1.261920\n",
      "epoch 410 loss = 1.330843\n",
      "epoch 411 loss = 1.269235\n",
      "epoch 412 loss = 1.289079\n",
      "epoch 413 loss = 1.266167\n",
      "epoch 414 loss = 1.402264\n",
      "epoch 415 loss = 1.296327\n",
      "epoch 416 loss = 1.429283\n",
      "epoch 417 loss = 1.411797\n",
      "epoch 418 loss = 1.284887\n",
      "epoch 419 loss = 1.445707\n",
      "epoch 420 loss = 1.265175\n",
      "epoch 421 loss = 1.313011\n",
      "epoch 422 loss = 1.488932\n",
      "epoch 423 loss = 1.244170\n",
      "epoch 424 loss = 1.347775\n",
      "epoch 425 loss = 1.439514\n",
      "epoch 426 loss = 1.332780\n",
      "epoch 427 loss = 1.309569\n",
      "epoch 428 loss = 1.233695\n",
      "epoch 429 loss = 1.371510\n",
      "epoch 430 loss = 1.274353\n",
      "epoch 431 loss = 1.230040\n",
      "epoch 432 loss = 1.193018\n",
      "epoch 433 loss = 1.387612\n",
      "epoch 434 loss = 1.283631\n",
      "epoch 435 loss = 1.367594\n",
      "epoch 436 loss = 1.320130\n",
      "epoch 437 loss = 1.418504\n",
      "epoch 438 loss = 1.561560\n",
      "epoch 439 loss = 1.285947\n",
      "epoch 440 loss = 1.235566\n",
      "epoch 441 loss = 1.424322\n",
      "epoch 442 loss = 1.342747\n",
      "epoch 443 loss = 1.453625\n",
      "epoch 444 loss = 1.487461\n",
      "epoch 445 loss = 1.254292\n",
      "epoch 446 loss = 1.244557\n",
      "epoch 447 loss = 1.372474\n",
      "epoch 448 loss = 1.399010\n",
      "epoch 449 loss = 1.276907\n",
      "epoch 450 loss = 1.456185\n",
      "epoch 451 loss = 1.258795\n",
      "epoch 452 loss = 1.333458\n",
      "epoch 453 loss = 1.288769\n",
      "epoch 454 loss = 1.300594\n",
      "epoch 455 loss = 1.366024\n",
      "epoch 456 loss = 1.359372\n",
      "epoch 457 loss = 1.302130\n",
      "epoch 458 loss = 1.264776\n",
      "epoch 459 loss = 1.193820\n",
      "epoch 460 loss = 1.208347\n",
      "epoch 461 loss = 1.249082\n",
      "epoch 462 loss = 1.493368\n",
      "epoch 463 loss = 1.328235\n",
      "epoch 464 loss = 1.507805\n",
      "epoch 465 loss = 1.256834\n",
      "epoch 466 loss = 1.356910\n",
      "epoch 467 loss = 1.238555\n",
      "epoch 468 loss = 1.198276\n",
      "epoch 469 loss = 1.276400\n",
      "epoch 470 loss = 1.344769\n",
      "epoch 471 loss = 1.316709\n",
      "epoch 472 loss = 1.382629\n",
      "epoch 473 loss = 1.326515\n",
      "epoch 474 loss = 1.372853\n",
      "epoch 475 loss = 1.256277\n",
      "epoch 476 loss = 1.297317\n",
      "epoch 477 loss = 1.323999\n",
      "epoch 478 loss = 1.306450\n",
      "epoch 479 loss = 1.377290\n",
      "epoch 480 loss = 1.254183\n",
      "epoch 481 loss = 1.390324\n",
      "epoch 482 loss = 1.500222\n",
      "epoch 483 loss = 1.217224\n",
      "epoch 484 loss = 1.372014\n",
      "epoch 485 loss = 1.265650\n",
      "epoch 486 loss = 1.371046\n",
      "epoch 487 loss = 1.274241\n",
      "epoch 488 loss = 1.291248\n",
      "epoch 489 loss = 1.277642\n",
      "epoch 490 loss = 1.366081\n",
      "epoch 491 loss = 1.362450\n",
      "epoch 492 loss = 1.192350\n",
      "epoch 493 loss = 1.376648\n",
      "epoch 494 loss = 1.243339\n",
      "epoch 495 loss = 1.257201\n",
      "epoch 496 loss = 1.326375\n",
      "epoch 497 loss = 1.208369\n",
      "epoch 498 loss = 1.594686\n",
      "epoch 499 loss = 1.362127\n",
      "final loss = 1.362127\n",
      "accuracy_mc = tensor(0.4615, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.4550, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.6386, device='cuda:0')\n",
      "training time = 304.5924503803253 seconds\n",
      "testing time = 3.1848549842834473 seconds\n",
      "\n",
      "Training with split 9\n",
      "epoch 0 loss = 2.261541\n",
      "epoch 1 loss = 2.178522\n",
      "epoch 2 loss = 2.033939\n",
      "epoch 3 loss = 2.102030\n",
      "epoch 4 loss = 1.986141\n",
      "epoch 5 loss = 2.043602\n",
      "epoch 6 loss = 1.931633\n",
      "epoch 7 loss = 2.009799\n",
      "epoch 8 loss = 1.945654\n",
      "epoch 9 loss = 1.919002\n",
      "epoch 10 loss = 1.867160\n",
      "epoch 11 loss = 1.902216\n",
      "epoch 12 loss = 1.915659\n",
      "epoch 13 loss = 1.938995\n",
      "epoch 14 loss = 2.057744\n",
      "epoch 15 loss = 1.953133\n",
      "epoch 16 loss = 1.915796\n",
      "epoch 17 loss = 1.880736\n",
      "epoch 18 loss = 2.005294\n",
      "epoch 19 loss = 1.833704\n",
      "epoch 20 loss = 1.857592\n",
      "epoch 21 loss = 1.834263\n",
      "epoch 22 loss = 1.800145\n",
      "epoch 23 loss = 1.842780\n",
      "epoch 24 loss = 1.909421\n",
      "epoch 25 loss = 1.903058\n",
      "epoch 26 loss = 1.696250\n",
      "epoch 27 loss = 1.839856\n",
      "epoch 28 loss = 1.831108\n",
      "epoch 29 loss = 1.956343\n",
      "epoch 30 loss = 1.709722\n",
      "epoch 31 loss = 1.797532\n",
      "epoch 32 loss = 1.817310\n",
      "epoch 33 loss = 1.753034\n",
      "epoch 34 loss = 1.704887\n",
      "epoch 35 loss = 1.793503\n",
      "epoch 36 loss = 1.792326\n",
      "epoch 37 loss = 1.792604\n",
      "epoch 38 loss = 1.714843\n",
      "epoch 39 loss = 1.680997\n",
      "epoch 40 loss = 1.690678\n",
      "epoch 41 loss = 1.757571\n",
      "epoch 42 loss = 1.761299\n",
      "epoch 43 loss = 1.673151\n",
      "epoch 44 loss = 1.736958\n",
      "epoch 45 loss = 1.767028\n",
      "epoch 46 loss = 1.729182\n",
      "epoch 47 loss = 1.759226\n",
      "epoch 48 loss = 1.633296\n",
      "epoch 49 loss = 1.790655\n",
      "epoch 50 loss = 1.797401\n",
      "epoch 51 loss = 1.811004\n",
      "epoch 52 loss = 1.753373\n",
      "epoch 53 loss = 1.716801\n",
      "epoch 54 loss = 1.740194\n",
      "epoch 55 loss = 1.743529\n",
      "epoch 56 loss = 1.633281\n",
      "epoch 57 loss = 1.650748\n",
      "epoch 58 loss = 1.861023\n",
      "epoch 59 loss = 1.876682\n",
      "epoch 60 loss = 1.629730\n",
      "epoch 61 loss = 1.622789\n",
      "epoch 62 loss = 1.748162\n",
      "epoch 63 loss = 1.659040\n",
      "epoch 64 loss = 1.614432\n",
      "epoch 65 loss = 1.659977\n",
      "epoch 66 loss = 1.729982\n",
      "epoch 67 loss = 1.613544\n",
      "epoch 68 loss = 1.769228\n",
      "epoch 69 loss = 1.901454\n",
      "epoch 70 loss = 1.890937\n",
      "epoch 71 loss = 1.667910\n",
      "epoch 72 loss = 1.688722\n",
      "epoch 73 loss = 1.630062\n",
      "epoch 74 loss = 1.604139\n",
      "epoch 75 loss = 1.715364\n",
      "epoch 76 loss = 1.602305\n",
      "epoch 77 loss = 1.607640\n",
      "epoch 78 loss = 1.769413\n",
      "epoch 79 loss = 1.598032\n",
      "epoch 80 loss = 1.698153\n",
      "epoch 81 loss = 1.625656\n",
      "epoch 82 loss = 1.628133\n",
      "epoch 83 loss = 1.573273\n",
      "epoch 84 loss = 1.604668\n",
      "epoch 85 loss = 1.606606\n",
      "epoch 86 loss = 1.670725\n",
      "epoch 87 loss = 1.584762\n",
      "epoch 88 loss = 1.543647\n",
      "epoch 89 loss = 1.660297\n",
      "epoch 90 loss = 1.580548\n",
      "epoch 91 loss = 1.550118\n",
      "epoch 92 loss = 1.870022\n",
      "epoch 93 loss = 1.659306\n",
      "epoch 94 loss = 1.655432\n",
      "epoch 95 loss = 1.574596\n",
      "epoch 96 loss = 1.541281\n",
      "epoch 97 loss = 1.560000\n",
      "epoch 98 loss = 1.685134\n",
      "epoch 99 loss = 1.515470\n",
      "epoch 100 loss = 1.569616\n",
      "epoch 101 loss = 1.477168\n",
      "epoch 102 loss = 1.525250\n",
      "epoch 103 loss = 1.513417\n",
      "epoch 104 loss = 1.533447\n",
      "epoch 105 loss = 1.522577\n",
      "epoch 106 loss = 1.509846\n",
      "epoch 107 loss = 1.588400\n",
      "epoch 108 loss = 1.657878\n",
      "epoch 109 loss = 1.405380\n",
      "epoch 110 loss = 1.444772\n",
      "epoch 111 loss = 1.462194\n",
      "epoch 112 loss = 1.357445\n",
      "epoch 113 loss = 1.477833\n",
      "epoch 114 loss = 1.444184\n",
      "epoch 115 loss = 1.517252\n",
      "epoch 116 loss = 1.562618\n",
      "epoch 117 loss = 1.613838\n",
      "epoch 118 loss = 1.421019\n",
      "epoch 119 loss = 1.636179\n",
      "epoch 120 loss = 1.333184\n",
      "epoch 121 loss = 1.286319\n",
      "epoch 122 loss = 1.351811\n",
      "epoch 123 loss = 1.346386\n",
      "epoch 124 loss = 1.481254\n",
      "epoch 125 loss = 1.592494\n",
      "epoch 126 loss = 1.480483\n",
      "epoch 127 loss = 1.425685\n",
      "epoch 128 loss = 1.430511\n",
      "epoch 129 loss = 1.589079\n",
      "epoch 130 loss = 1.488373\n",
      "epoch 131 loss = 1.419708\n",
      "epoch 132 loss = 1.348735\n",
      "epoch 133 loss = 1.522817\n",
      "epoch 134 loss = 1.394276\n",
      "epoch 135 loss = 1.572264\n",
      "epoch 136 loss = 1.584496\n",
      "epoch 137 loss = 1.554926\n",
      "epoch 138 loss = 1.458666\n",
      "epoch 139 loss = 1.405666\n",
      "epoch 140 loss = 1.353533\n",
      "epoch 141 loss = 1.605318\n",
      "epoch 142 loss = 1.480143\n",
      "epoch 143 loss = 1.505855\n",
      "epoch 144 loss = 1.364009\n",
      "epoch 145 loss = 1.493543\n",
      "epoch 146 loss = 1.642354\n",
      "epoch 147 loss = 1.481878\n",
      "epoch 148 loss = 1.531521\n",
      "epoch 149 loss = 1.547902\n",
      "epoch 150 loss = 1.490299\n",
      "epoch 151 loss = 1.549787\n",
      "epoch 152 loss = 1.516677\n",
      "epoch 153 loss = 1.401514\n",
      "epoch 154 loss = 1.596442\n",
      "epoch 155 loss = 1.605958\n",
      "epoch 156 loss = 1.400341\n",
      "epoch 157 loss = 1.598718\n",
      "epoch 158 loss = 1.428458\n",
      "epoch 159 loss = 1.551148\n",
      "epoch 160 loss = 1.483663\n",
      "epoch 161 loss = 1.356299\n",
      "epoch 162 loss = 1.452481\n",
      "epoch 163 loss = 1.409343\n",
      "epoch 164 loss = 1.512861\n",
      "epoch 165 loss = 1.430144\n",
      "epoch 166 loss = 1.545352\n",
      "epoch 167 loss = 1.518797\n",
      "epoch 168 loss = 1.523984\n",
      "epoch 169 loss = 1.440506\n",
      "epoch 170 loss = 1.547299\n",
      "epoch 171 loss = 1.430697\n",
      "epoch 172 loss = 1.426265\n",
      "epoch 173 loss = 1.346599\n",
      "epoch 174 loss = 1.507362\n",
      "epoch 175 loss = 1.489686\n",
      "epoch 176 loss = 1.340468\n",
      "epoch 177 loss = 1.475283\n",
      "epoch 178 loss = 1.530063\n",
      "epoch 179 loss = 1.286511\n",
      "epoch 180 loss = 1.603096\n",
      "epoch 181 loss = 1.373895\n",
      "epoch 182 loss = 1.439509\n",
      "epoch 183 loss = 1.593201\n",
      "epoch 184 loss = 1.436125\n",
      "epoch 185 loss = 1.448284\n",
      "epoch 186 loss = 1.335930\n",
      "epoch 187 loss = 1.549882\n",
      "epoch 188 loss = 1.611620\n",
      "epoch 189 loss = 1.386324\n",
      "epoch 190 loss = 1.534416\n",
      "epoch 191 loss = 1.420637\n",
      "epoch 192 loss = 1.495960\n",
      "epoch 193 loss = 1.557533\n",
      "epoch 194 loss = 1.436646\n",
      "epoch 195 loss = 1.591220\n",
      "epoch 196 loss = 1.597602\n",
      "epoch 197 loss = 1.312039\n",
      "epoch 198 loss = 1.595387\n",
      "epoch 199 loss = 1.621444\n",
      "epoch 200 loss = 1.310893\n",
      "epoch 201 loss = 1.377245\n",
      "epoch 202 loss = 1.575075\n",
      "epoch 203 loss = 1.419301\n",
      "epoch 204 loss = 1.373007\n",
      "epoch 205 loss = 1.546263\n",
      "epoch 206 loss = 1.468519\n",
      "epoch 207 loss = 1.561443\n",
      "epoch 208 loss = 1.349990\n",
      "epoch 209 loss = 1.447172\n",
      "epoch 210 loss = 1.661764\n",
      "epoch 211 loss = 1.593107\n",
      "epoch 212 loss = 1.383611\n",
      "epoch 213 loss = 1.465606\n",
      "epoch 214 loss = 1.484041\n",
      "epoch 215 loss = 1.515756\n",
      "epoch 216 loss = 1.425534\n",
      "epoch 217 loss = 1.485375\n",
      "epoch 218 loss = 1.384885\n",
      "epoch 219 loss = 1.448848\n",
      "epoch 220 loss = 1.453246\n",
      "epoch 221 loss = 1.379602\n",
      "epoch 222 loss = 1.322705\n",
      "epoch 223 loss = 1.403308\n",
      "epoch 224 loss = 1.570827\n",
      "epoch 225 loss = 1.467950\n",
      "epoch 226 loss = 1.601303\n",
      "epoch 227 loss = 1.484108\n",
      "epoch 228 loss = 1.564716\n",
      "epoch 229 loss = 1.354824\n",
      "epoch 230 loss = 1.340275\n",
      "epoch 231 loss = 1.382925\n",
      "epoch 232 loss = 1.314936\n",
      "epoch 233 loss = 1.419522\n",
      "epoch 234 loss = 1.524199\n",
      "epoch 235 loss = 1.468030\n",
      "epoch 236 loss = 1.411459\n",
      "epoch 237 loss = 1.361372\n",
      "epoch 238 loss = 1.606877\n",
      "epoch 239 loss = 1.413404\n",
      "epoch 240 loss = 1.272956\n",
      "epoch 241 loss = 1.389949\n",
      "epoch 242 loss = 1.569679\n",
      "epoch 243 loss = 1.439585\n",
      "epoch 244 loss = 1.546689\n",
      "epoch 245 loss = 1.463081\n",
      "epoch 246 loss = 1.560198\n",
      "epoch 247 loss = 1.590406\n",
      "epoch 248 loss = 1.406368\n",
      "epoch 249 loss = 1.428728\n",
      "epoch 250 loss = 1.608003\n",
      "epoch 251 loss = 1.315938\n",
      "epoch 252 loss = 1.345261\n",
      "epoch 253 loss = 1.390757\n",
      "epoch 254 loss = 1.333187\n",
      "epoch 255 loss = 1.421160\n",
      "epoch 256 loss = 1.408596\n",
      "epoch 257 loss = 1.604609\n",
      "epoch 258 loss = 1.344507\n",
      "epoch 259 loss = 1.575919\n",
      "epoch 260 loss = 1.369214\n",
      "epoch 261 loss = 1.501832\n",
      "epoch 262 loss = 1.388171\n",
      "epoch 263 loss = 1.533944\n",
      "epoch 264 loss = 1.432948\n",
      "epoch 265 loss = 1.558376\n",
      "epoch 266 loss = 1.618255\n",
      "epoch 267 loss = 1.530389\n",
      "epoch 268 loss = 1.375692\n",
      "epoch 269 loss = 1.328963\n",
      "epoch 270 loss = 1.492228\n",
      "epoch 271 loss = 1.589559\n",
      "epoch 272 loss = 1.430207\n",
      "epoch 273 loss = 1.491612\n",
      "epoch 274 loss = 1.398239\n",
      "epoch 275 loss = 1.425585\n",
      "epoch 276 loss = 1.795274\n",
      "epoch 277 loss = 1.344265\n",
      "epoch 278 loss = 1.480521\n",
      "epoch 279 loss = 1.600432\n",
      "epoch 280 loss = 1.552832\n",
      "epoch 281 loss = 1.461076\n",
      "epoch 282 loss = 1.522305\n",
      "epoch 283 loss = 1.327449\n",
      "epoch 284 loss = 1.507731\n",
      "epoch 285 loss = 1.451117\n",
      "epoch 286 loss = 1.353351\n",
      "epoch 287 loss = 1.246087\n",
      "epoch 288 loss = 1.544508\n",
      "epoch 289 loss = 1.387525\n",
      "epoch 290 loss = 1.564116\n",
      "epoch 291 loss = 1.603385\n",
      "epoch 292 loss = 1.460473\n",
      "epoch 293 loss = 1.591478\n",
      "epoch 294 loss = 1.473329\n",
      "epoch 295 loss = 1.445294\n",
      "epoch 296 loss = 1.491573\n",
      "epoch 297 loss = 1.515710\n",
      "epoch 298 loss = 1.406594\n",
      "epoch 299 loss = 1.566038\n",
      "epoch 300 loss = 1.493816\n",
      "epoch 301 loss = 1.796159\n",
      "epoch 302 loss = 1.383446\n",
      "epoch 303 loss = 1.386470\n",
      "epoch 304 loss = 1.441485\n",
      "epoch 305 loss = 1.432645\n",
      "epoch 306 loss = 1.391785\n",
      "epoch 307 loss = 1.418255\n",
      "epoch 308 loss = 1.471735\n",
      "epoch 309 loss = 1.499504\n",
      "epoch 310 loss = 1.341500\n",
      "epoch 311 loss = 1.463659\n",
      "epoch 312 loss = 1.292577\n",
      "epoch 313 loss = 1.374892\n",
      "epoch 314 loss = 1.469912\n",
      "epoch 315 loss = 1.577327\n",
      "epoch 316 loss = 1.539302\n",
      "epoch 317 loss = 1.330694\n",
      "epoch 318 loss = 1.415083\n",
      "epoch 319 loss = 1.448839\n",
      "epoch 320 loss = 1.345975\n",
      "epoch 321 loss = 1.352896\n",
      "epoch 322 loss = 1.353983\n",
      "epoch 323 loss = 1.503578\n",
      "epoch 324 loss = 1.344043\n",
      "epoch 325 loss = 1.524524\n",
      "epoch 326 loss = 1.567116\n",
      "epoch 327 loss = 1.524931\n",
      "epoch 328 loss = 1.492470\n",
      "epoch 329 loss = 1.390504\n",
      "epoch 330 loss = 1.350563\n",
      "epoch 331 loss = 1.308472\n",
      "epoch 332 loss = 1.603244\n",
      "epoch 333 loss = 1.433663\n",
      "epoch 334 loss = 1.483504\n",
      "epoch 335 loss = 1.564301\n",
      "epoch 336 loss = 1.389933\n",
      "epoch 337 loss = 1.314469\n",
      "epoch 338 loss = 1.515440\n",
      "epoch 339 loss = 1.373420\n",
      "epoch 340 loss = 1.425346\n",
      "epoch 341 loss = 1.319685\n",
      "epoch 342 loss = 1.471537\n",
      "epoch 343 loss = 1.450401\n",
      "epoch 344 loss = 1.601238\n",
      "epoch 345 loss = 1.631622\n",
      "epoch 346 loss = 1.479306\n",
      "epoch 347 loss = 1.353565\n",
      "epoch 348 loss = 1.414748\n",
      "epoch 349 loss = 1.320242\n",
      "epoch 350 loss = 1.565531\n",
      "epoch 351 loss = 1.378950\n",
      "epoch 352 loss = 1.481020\n",
      "epoch 353 loss = 1.470100\n",
      "epoch 354 loss = 1.544914\n",
      "epoch 355 loss = 1.561076\n",
      "epoch 356 loss = 1.391815\n",
      "epoch 357 loss = 1.656005\n",
      "epoch 358 loss = 1.350659\n",
      "epoch 359 loss = 1.471439\n",
      "epoch 360 loss = 1.359204\n",
      "epoch 361 loss = 1.314180\n",
      "epoch 362 loss = 1.414067\n",
      "epoch 363 loss = 1.319277\n",
      "epoch 364 loss = 1.365927\n",
      "epoch 365 loss = 1.406277\n",
      "epoch 366 loss = 1.542986\n",
      "epoch 367 loss = 1.374006\n",
      "epoch 368 loss = 1.536223\n",
      "epoch 369 loss = 1.413469\n",
      "epoch 370 loss = 1.431089\n",
      "epoch 371 loss = 1.378730\n",
      "epoch 372 loss = 1.290942\n",
      "epoch 373 loss = 1.388427\n",
      "epoch 374 loss = 1.490594\n",
      "epoch 375 loss = 1.344620\n",
      "epoch 376 loss = 1.395502\n",
      "epoch 377 loss = 1.550192\n",
      "epoch 378 loss = 1.431387\n",
      "epoch 379 loss = 1.458954\n",
      "epoch 380 loss = 1.317284\n",
      "epoch 381 loss = 1.389601\n",
      "epoch 382 loss = 1.384850\n",
      "epoch 383 loss = 1.611032\n",
      "epoch 384 loss = 1.516848\n",
      "epoch 385 loss = 1.440205\n",
      "epoch 386 loss = 1.451232\n",
      "epoch 387 loss = 1.505812\n",
      "epoch 388 loss = 1.568563\n",
      "epoch 389 loss = 1.443660\n",
      "epoch 390 loss = 1.459458\n",
      "epoch 391 loss = 1.414384\n",
      "epoch 392 loss = 1.679903\n",
      "epoch 393 loss = 1.552654\n",
      "epoch 394 loss = 1.486605\n",
      "epoch 395 loss = 1.374336\n",
      "epoch 396 loss = 1.393638\n",
      "epoch 397 loss = 1.369969\n",
      "epoch 398 loss = 1.354845\n",
      "epoch 399 loss = 1.405031\n",
      "epoch 400 loss = 1.508495\n",
      "epoch 401 loss = 1.710028\n",
      "epoch 402 loss = 1.451848\n",
      "epoch 403 loss = 1.382374\n",
      "epoch 404 loss = 1.345676\n",
      "epoch 405 loss = 1.386946\n",
      "epoch 406 loss = 1.405614\n",
      "epoch 407 loss = 1.713647\n",
      "epoch 408 loss = 1.411461\n",
      "epoch 409 loss = 1.498603\n",
      "epoch 410 loss = 1.476125\n",
      "epoch 411 loss = 1.473332\n",
      "epoch 412 loss = 1.411547\n",
      "epoch 413 loss = 1.299780\n",
      "epoch 414 loss = 1.547813\n",
      "epoch 415 loss = 1.341316\n",
      "epoch 416 loss = 1.492737\n",
      "epoch 417 loss = 1.466055\n",
      "epoch 418 loss = 1.282975\n",
      "epoch 419 loss = 1.574536\n",
      "epoch 420 loss = 1.482542\n",
      "epoch 421 loss = 1.422289\n",
      "epoch 422 loss = 1.426698\n",
      "epoch 423 loss = 1.438133\n",
      "epoch 424 loss = 1.389993\n",
      "epoch 425 loss = 1.430815\n",
      "epoch 426 loss = 1.651254\n",
      "epoch 427 loss = 1.452418\n",
      "epoch 428 loss = 1.343786\n",
      "epoch 429 loss = 1.438686\n",
      "epoch 430 loss = 1.324368\n",
      "epoch 431 loss = 1.291913\n",
      "epoch 432 loss = 1.433112\n",
      "epoch 433 loss = 1.448681\n",
      "epoch 434 loss = 1.512156\n",
      "epoch 435 loss = 1.408510\n",
      "epoch 436 loss = 1.425694\n",
      "epoch 437 loss = 1.381881\n",
      "epoch 438 loss = 1.414357\n",
      "epoch 439 loss = 1.375122\n",
      "epoch 440 loss = 1.346115\n",
      "epoch 441 loss = 1.423784\n",
      "epoch 442 loss = 1.533700\n",
      "epoch 443 loss = 1.505944\n",
      "epoch 444 loss = 1.422336\n",
      "epoch 445 loss = 1.236233\n",
      "epoch 446 loss = 1.354727\n",
      "epoch 447 loss = 1.437898\n",
      "epoch 448 loss = 1.552168\n",
      "epoch 449 loss = 1.522444\n",
      "epoch 450 loss = 1.302462\n",
      "epoch 451 loss = 1.325456\n",
      "epoch 452 loss = 1.544890\n",
      "epoch 453 loss = 1.510413\n",
      "epoch 454 loss = 1.476964\n",
      "epoch 455 loss = 1.486150\n",
      "epoch 456 loss = 1.307229\n",
      "epoch 457 loss = 1.444445\n",
      "epoch 458 loss = 1.462959\n",
      "epoch 459 loss = 1.492464\n",
      "epoch 460 loss = 1.466545\n",
      "epoch 461 loss = 1.491478\n",
      "epoch 462 loss = 1.266100\n",
      "epoch 463 loss = 1.578918\n",
      "epoch 464 loss = 1.386727\n",
      "epoch 465 loss = 1.365986\n",
      "epoch 466 loss = 1.450377\n",
      "epoch 467 loss = 1.290845\n",
      "epoch 468 loss = 1.536313\n",
      "epoch 469 loss = 1.390512\n",
      "epoch 470 loss = 1.277280\n",
      "epoch 471 loss = 1.404987\n",
      "epoch 472 loss = 1.394558\n",
      "epoch 473 loss = 1.492862\n",
      "epoch 474 loss = 1.313643\n",
      "epoch 475 loss = 1.424387\n",
      "epoch 476 loss = 1.485163\n",
      "epoch 477 loss = 1.324003\n",
      "epoch 478 loss = 1.329830\n",
      "epoch 479 loss = 1.507434\n",
      "epoch 480 loss = 1.413832\n",
      "epoch 481 loss = 1.471676\n",
      "epoch 482 loss = 1.432914\n",
      "epoch 483 loss = 1.247239\n",
      "epoch 484 loss = 1.517901\n",
      "epoch 485 loss = 1.367871\n",
      "epoch 486 loss = 1.384390\n",
      "epoch 487 loss = 1.590521\n",
      "epoch 488 loss = 1.402133\n",
      "epoch 489 loss = 1.382028\n",
      "epoch 490 loss = 1.438532\n",
      "epoch 491 loss = 1.501300\n",
      "epoch 492 loss = 1.448172\n",
      "epoch 493 loss = 1.577365\n",
      "epoch 494 loss = 1.579249\n",
      "epoch 495 loss = 1.483414\n",
      "epoch 496 loss = 1.393662\n",
      "epoch 497 loss = 1.478994\n",
      "epoch 498 loss = 1.388508\n",
      "epoch 499 loss = 1.314323\n",
      "final loss = 1.314323\n",
      "accuracy_mc = tensor(0.4446, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.4521, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.6222, device='cuda:0')\n",
      "training time = 304.67344427108765 seconds\n",
      "testing time = 3.285902500152588 seconds\n",
      "\n",
      "subset 0.050000, dropout_rate 0.300000, reg_strength 0.050000\n",
      "n_epoch 10\n",
      "\n",
      "Files already downloaded and verified\n",
      "subset size = (2500, 32, 32, 3)\n",
      "training set size = 2000\n",
      "test set size = 500\n",
      "\n",
      "Training with split 0\n",
      "epoch 0 loss = 2.272101\n",
      "epoch 1 loss = 2.210046\n",
      "epoch 2 loss = 2.082906\n",
      "epoch 3 loss = 2.124542\n",
      "epoch 4 loss = 2.117086\n",
      "epoch 5 loss = 2.093739\n",
      "epoch 6 loss = 2.142990\n",
      "epoch 7 loss = 2.029237\n",
      "epoch 8 loss = 1.985675\n",
      "epoch 9 loss = 2.001804\n",
      "final loss = 2.001804\n",
      "accuracy_mc = tensor(0.2446, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2298, device='cuda:0')\n",
      "test_ll_mc = tensor(-2.0218, device='cuda:0')\n",
      "training time = 6.121519088745117 seconds\n",
      "testing time = 3.197754383087158 seconds\n",
      "\n",
      "Training with split 1\n",
      "epoch 0 loss = 2.199178\n",
      "epoch 1 loss = 2.201432\n",
      "epoch 2 loss = 2.199109\n",
      "epoch 3 loss = 2.161354\n",
      "epoch 4 loss = 2.031994\n",
      "epoch 5 loss = 2.097171\n",
      "epoch 6 loss = 1.998957\n",
      "epoch 7 loss = 2.095108\n",
      "epoch 8 loss = 2.050275\n",
      "epoch 9 loss = 2.115671\n",
      "final loss = 2.115671\n",
      "accuracy_mc = tensor(0.2858, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.3046, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.9154, device='cuda:0')\n",
      "training time = 6.084434270858765 seconds\n",
      "testing time = 3.200463056564331 seconds\n",
      "\n",
      "Training with split 2\n",
      "epoch 0 loss = 2.241118\n",
      "epoch 1 loss = 2.127359\n",
      "epoch 2 loss = 2.107241\n",
      "epoch 3 loss = 2.119633\n",
      "epoch 4 loss = 2.131468\n",
      "epoch 5 loss = 2.015751\n",
      "epoch 6 loss = 1.946325\n",
      "epoch 7 loss = 2.155636\n",
      "epoch 8 loss = 2.111773\n",
      "epoch 9 loss = 1.965218\n",
      "final loss = 1.965218\n",
      "accuracy_mc = tensor(0.2607, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2888, device='cuda:0')\n",
      "test_ll_mc = tensor(-2.0413, device='cuda:0')\n",
      "training time = 6.073448181152344 seconds\n",
      "testing time = 3.167919158935547 seconds\n",
      "\n",
      "Training with split 3\n",
      "epoch 0 loss = 2.231757\n",
      "epoch 1 loss = 2.179222\n",
      "epoch 2 loss = 2.133929\n",
      "epoch 3 loss = 2.108509\n",
      "epoch 4 loss = 2.127434\n",
      "epoch 5 loss = 1.896073\n",
      "epoch 6 loss = 1.857738\n",
      "epoch 7 loss = 2.024416\n",
      "epoch 8 loss = 1.961863\n",
      "epoch 9 loss = 1.953114\n",
      "final loss = 1.953114\n",
      "accuracy_mc = tensor(0.2561, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2916, device='cuda:0')\n",
      "test_ll_mc = tensor(-2.0621, device='cuda:0')\n",
      "training time = 6.119627237319946 seconds\n",
      "testing time = 3.141462564468384 seconds\n",
      "\n",
      "Training with split 4\n",
      "epoch 0 loss = 2.139950\n",
      "epoch 1 loss = 2.134352\n",
      "epoch 2 loss = 2.092497\n",
      "epoch 3 loss = 2.032722\n",
      "epoch 4 loss = 2.025885\n",
      "epoch 5 loss = 2.019209\n",
      "epoch 6 loss = 1.948115\n",
      "epoch 7 loss = 1.977285\n",
      "epoch 8 loss = 1.884996\n",
      "epoch 9 loss = 1.802734\n",
      "final loss = 1.802734\n",
      "accuracy_mc = tensor(0.3245, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.3348, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.9240, device='cuda:0')\n",
      "training time = 6.074620723724365 seconds\n",
      "testing time = 3.084806203842163 seconds\n",
      "\n",
      "Training with split 5\n",
      "epoch 0 loss = 2.274042\n",
      "epoch 1 loss = 2.206171\n",
      "epoch 2 loss = 2.130338\n",
      "epoch 3 loss = 2.164093\n",
      "epoch 4 loss = 2.270989\n",
      "epoch 5 loss = 2.211150\n",
      "epoch 6 loss = 2.143459\n",
      "epoch 7 loss = 2.150179\n",
      "epoch 8 loss = 2.092754\n",
      "epoch 9 loss = 2.173556\n",
      "final loss = 2.173556\n",
      "accuracy_mc = tensor(0.2997, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.3145, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.9844, device='cuda:0')\n",
      "training time = 6.2247443199157715 seconds\n",
      "testing time = 3.235172748565674 seconds\n",
      "\n",
      "Training with split 6\n",
      "epoch 0 loss = 2.235933\n",
      "epoch 1 loss = 2.242602\n",
      "epoch 2 loss = 2.206500\n",
      "epoch 3 loss = 2.108919\n",
      "epoch 4 loss = 2.121076\n",
      "epoch 5 loss = 2.226936\n",
      "epoch 6 loss = 2.259893\n",
      "epoch 7 loss = 2.077012\n",
      "epoch 8 loss = 2.062213\n",
      "epoch 9 loss = 2.120634\n",
      "final loss = 2.120634\n",
      "accuracy_mc = tensor(0.2598, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2509, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.9558, device='cuda:0')\n",
      "training time = 6.178112268447876 seconds\n",
      "testing time = 3.171642780303955 seconds\n",
      "\n",
      "Training with split 7\n",
      "epoch 0 loss = 2.180546\n",
      "epoch 1 loss = 2.163925\n",
      "epoch 2 loss = 1.989608\n",
      "epoch 3 loss = 2.067055\n",
      "epoch 4 loss = 2.054409\n",
      "epoch 5 loss = 2.083820\n",
      "epoch 6 loss = 1.989875\n",
      "epoch 7 loss = 2.080132\n",
      "epoch 8 loss = 1.916608\n",
      "epoch 9 loss = 2.103394\n",
      "final loss = 2.103394\n",
      "accuracy_mc = tensor(0.2968, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2942, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.9749, device='cuda:0')\n",
      "training time = 6.0695250034332275 seconds\n",
      "testing time = 3.2141518592834473 seconds\n",
      "\n",
      "Training with split 8\n",
      "epoch 0 loss = 2.218706\n",
      "epoch 1 loss = 2.153522\n",
      "epoch 2 loss = 2.313219\n",
      "epoch 3 loss = 2.047192\n",
      "epoch 4 loss = 2.034654\n",
      "epoch 5 loss = 2.125370\n",
      "epoch 6 loss = 1.987391\n",
      "epoch 7 loss = 2.082201\n",
      "epoch 8 loss = 2.038868\n",
      "epoch 9 loss = 1.898650\n",
      "final loss = 1.898650\n",
      "accuracy_mc = tensor(0.2966, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2879, device='cuda:0')\n",
      "test_ll_mc = tensor(-2.0368, device='cuda:0')\n",
      "training time = 6.155651807785034 seconds\n",
      "testing time = 3.154106616973877 seconds\n",
      "\n",
      "Training with split 9\n",
      "epoch 0 loss = 2.307520\n",
      "epoch 1 loss = 2.216412\n",
      "epoch 2 loss = 2.051661\n",
      "epoch 3 loss = 2.193631\n",
      "epoch 4 loss = 2.116462\n",
      "epoch 5 loss = 2.058303\n",
      "epoch 6 loss = 2.226635\n",
      "epoch 7 loss = 2.054229\n",
      "epoch 8 loss = 1.890171\n",
      "epoch 9 loss = 2.028410\n",
      "final loss = 2.028410\n",
      "accuracy_mc = tensor(0.2878, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2792, device='cuda:0')\n",
      "test_ll_mc = tensor(-2.0248, device='cuda:0')\n",
      "training time = 6.18159294128418 seconds\n",
      "testing time = 3.1631250381469727 seconds\n",
      "\n",
      "subset 0.050000, dropout_rate 0.300000, reg_strength 0.050000\n",
      "n_epoch 100\n",
      "\n",
      "Files already downloaded and verified\n",
      "subset size = (2500, 32, 32, 3)\n",
      "training set size = 2000\n",
      "test set size = 500\n",
      "\n",
      "Training with split 0\n",
      "epoch 0 loss = 2.272101\n",
      "epoch 1 loss = 2.210046\n",
      "epoch 2 loss = 2.082906\n",
      "epoch 3 loss = 2.124542\n",
      "epoch 4 loss = 2.117086\n",
      "epoch 5 loss = 2.093739\n",
      "epoch 6 loss = 2.142990\n",
      "epoch 7 loss = 2.029237\n",
      "epoch 8 loss = 1.985675\n",
      "epoch 9 loss = 2.001804\n",
      "epoch 10 loss = 2.189731\n",
      "epoch 11 loss = 1.928363\n",
      "epoch 12 loss = 2.127447\n",
      "epoch 13 loss = 2.001741\n",
      "epoch 14 loss = 2.061622\n",
      "epoch 15 loss = 1.868242\n",
      "epoch 16 loss = 2.125101\n",
      "epoch 17 loss = 2.211401\n",
      "epoch 18 loss = 1.816199\n",
      "epoch 19 loss = 1.954219\n",
      "epoch 20 loss = 2.044205\n",
      "epoch 21 loss = 2.027961\n",
      "epoch 22 loss = 1.880994\n",
      "epoch 23 loss = 2.002453\n",
      "epoch 24 loss = 1.908395\n",
      "epoch 25 loss = 1.854994\n",
      "epoch 26 loss = 1.717154\n",
      "epoch 27 loss = 1.955989\n",
      "epoch 28 loss = 2.061297\n",
      "epoch 29 loss = 1.968164\n",
      "epoch 30 loss = 1.826833\n",
      "epoch 31 loss = 1.924188\n",
      "epoch 32 loss = 2.051707\n",
      "epoch 33 loss = 2.084294\n",
      "epoch 34 loss = 1.735162\n",
      "epoch 35 loss = 1.928107\n",
      "epoch 36 loss = 2.010673\n",
      "epoch 37 loss = 1.716434\n",
      "epoch 38 loss = 1.824827\n",
      "epoch 39 loss = 2.142500\n",
      "epoch 40 loss = 1.848287\n",
      "epoch 41 loss = 1.892653\n",
      "epoch 42 loss = 1.954499\n",
      "epoch 43 loss = 1.947648\n",
      "epoch 44 loss = 1.812148\n",
      "epoch 45 loss = 1.924581\n",
      "epoch 46 loss = 1.877573\n",
      "epoch 47 loss = 1.715330\n",
      "epoch 48 loss = 1.883789\n",
      "epoch 49 loss = 1.931157\n",
      "epoch 50 loss = 1.874478\n",
      "epoch 51 loss = 1.872086\n",
      "epoch 52 loss = 1.748873\n",
      "epoch 53 loss = 1.711919\n",
      "epoch 54 loss = 1.881948\n",
      "epoch 55 loss = 1.843917\n",
      "epoch 56 loss = 1.979796\n",
      "epoch 57 loss = 2.089822\n",
      "epoch 58 loss = 2.093104\n",
      "epoch 59 loss = 1.890170\n",
      "epoch 60 loss = 1.714958\n",
      "epoch 61 loss = 1.865886\n",
      "epoch 62 loss = 2.014517\n",
      "epoch 63 loss = 1.846741\n",
      "epoch 64 loss = 2.003099\n",
      "epoch 65 loss = 1.569684\n",
      "epoch 66 loss = 1.838377\n",
      "epoch 67 loss = 1.861932\n",
      "epoch 68 loss = 1.707635\n",
      "epoch 69 loss = 1.571220\n",
      "epoch 70 loss = 2.006869\n",
      "epoch 71 loss = 2.115240\n",
      "epoch 72 loss = 1.796949\n",
      "epoch 73 loss = 1.813446\n",
      "epoch 74 loss = 1.943631\n",
      "epoch 75 loss = 1.647555\n",
      "epoch 76 loss = 1.776891\n",
      "epoch 77 loss = 1.674241\n",
      "epoch 78 loss = 1.690368\n",
      "epoch 79 loss = 1.982112\n",
      "epoch 80 loss = 1.728215\n",
      "epoch 81 loss = 1.749147\n",
      "epoch 82 loss = 1.583256\n",
      "epoch 83 loss = 1.590566\n",
      "epoch 84 loss = 1.725714\n",
      "epoch 85 loss = 1.783261\n",
      "epoch 86 loss = 1.810202\n",
      "epoch 87 loss = 1.758010\n",
      "epoch 88 loss = 1.639456\n",
      "epoch 89 loss = 1.901850\n",
      "epoch 90 loss = 1.732337\n",
      "epoch 91 loss = 1.606547\n",
      "epoch 92 loss = 1.742441\n",
      "epoch 93 loss = 1.707504\n",
      "epoch 94 loss = 2.014341\n",
      "epoch 95 loss = 1.674543\n",
      "epoch 96 loss = 1.880917\n",
      "epoch 97 loss = 1.771115\n",
      "epoch 98 loss = 1.789944\n",
      "epoch 99 loss = 1.651291\n",
      "final loss = 1.651291\n",
      "accuracy_mc = tensor(0.3360, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.3732, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.8558, device='cuda:0')\n",
      "training time = 61.36664915084839 seconds\n",
      "testing time = 3.2195231914520264 seconds\n",
      "\n",
      "Training with split 1\n",
      "epoch 0 loss = 2.225346\n",
      "epoch 1 loss = 2.246437\n",
      "epoch 2 loss = 2.113596\n",
      "epoch 3 loss = 1.989701\n",
      "epoch 4 loss = 1.979354\n",
      "epoch 5 loss = 1.982876\n",
      "epoch 6 loss = 1.902710\n",
      "epoch 7 loss = 2.050525\n",
      "epoch 8 loss = 2.105483\n",
      "epoch 9 loss = 1.909798\n",
      "epoch 10 loss = 1.858592\n",
      "epoch 11 loss = 1.991391\n",
      "epoch 12 loss = 1.960694\n",
      "epoch 13 loss = 1.873042\n",
      "epoch 14 loss = 1.712006\n",
      "epoch 15 loss = 1.847043\n",
      "epoch 16 loss = 1.589134\n",
      "epoch 17 loss = 1.994814\n",
      "epoch 18 loss = 2.013763\n",
      "epoch 19 loss = 1.680399\n",
      "epoch 20 loss = 1.808136\n",
      "epoch 21 loss = 1.934221\n",
      "epoch 22 loss = 2.048230\n",
      "epoch 23 loss = 1.832315\n",
      "epoch 24 loss = 1.900116\n",
      "epoch 25 loss = 1.963466\n",
      "epoch 26 loss = 1.987417\n",
      "epoch 27 loss = 1.957167\n",
      "epoch 28 loss = 1.981077\n",
      "epoch 29 loss = 1.975046\n",
      "epoch 30 loss = 1.767663\n",
      "epoch 31 loss = 1.705720\n",
      "epoch 32 loss = 1.748549\n",
      "epoch 33 loss = 1.777745\n",
      "epoch 34 loss = 2.040319\n",
      "epoch 35 loss = 1.846422\n",
      "epoch 36 loss = 1.749973\n",
      "epoch 37 loss = 2.076990\n",
      "epoch 38 loss = 1.939683\n",
      "epoch 39 loss = 1.723488\n",
      "epoch 40 loss = 1.774630\n",
      "epoch 41 loss = 1.837234\n",
      "epoch 42 loss = 1.936976\n",
      "epoch 43 loss = 1.907986\n",
      "epoch 44 loss = 1.862844\n",
      "epoch 45 loss = 1.749865\n",
      "epoch 46 loss = 1.804948\n",
      "epoch 47 loss = 1.937814\n",
      "epoch 48 loss = 1.969689\n",
      "epoch 49 loss = 1.688408\n",
      "epoch 50 loss = 1.917783\n",
      "epoch 51 loss = 1.683154\n",
      "epoch 52 loss = 1.743234\n",
      "epoch 53 loss = 1.785670\n",
      "epoch 54 loss = 1.691777\n",
      "epoch 55 loss = 1.767376\n",
      "epoch 56 loss = 1.738180\n",
      "epoch 57 loss = 1.687140\n",
      "epoch 58 loss = 2.024299\n",
      "epoch 59 loss = 1.764936\n",
      "epoch 60 loss = 1.739687\n",
      "epoch 61 loss = 1.630065\n",
      "epoch 62 loss = 1.822009\n",
      "epoch 63 loss = 1.672322\n",
      "epoch 64 loss = 1.871096\n",
      "epoch 65 loss = 1.821113\n",
      "epoch 66 loss = 1.738373\n",
      "epoch 67 loss = 1.823434\n",
      "epoch 68 loss = 1.791829\n",
      "epoch 69 loss = 1.816818\n",
      "epoch 70 loss = 1.985913\n",
      "epoch 71 loss = 1.807900\n",
      "epoch 72 loss = 1.755227\n",
      "epoch 73 loss = 1.834704\n",
      "epoch 74 loss = 1.971187\n",
      "epoch 75 loss = 1.701587\n",
      "epoch 76 loss = 1.682652\n",
      "epoch 77 loss = 1.584656\n",
      "epoch 78 loss = 1.790542\n",
      "epoch 79 loss = 1.508094\n",
      "epoch 80 loss = 1.750850\n",
      "epoch 81 loss = 1.970038\n",
      "epoch 82 loss = 1.676233\n",
      "epoch 83 loss = 1.758624\n",
      "epoch 84 loss = 1.830048\n",
      "epoch 85 loss = 1.927777\n",
      "epoch 86 loss = 1.697557\n",
      "epoch 87 loss = 1.773982\n",
      "epoch 88 loss = 1.736730\n",
      "epoch 89 loss = 1.721774\n",
      "epoch 90 loss = 1.724036\n",
      "epoch 91 loss = 1.974690\n",
      "epoch 92 loss = 1.703320\n",
      "epoch 93 loss = 1.457939\n",
      "epoch 94 loss = 1.613481\n",
      "epoch 95 loss = 1.570457\n",
      "epoch 96 loss = 1.765081\n",
      "epoch 97 loss = 1.642890\n",
      "epoch 98 loss = 1.651501\n",
      "epoch 99 loss = 1.833765\n",
      "final loss = 1.833765\n",
      "accuracy_mc = tensor(0.3765, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.3345, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.7627, device='cuda:0')\n",
      "training time = 61.605701208114624 seconds\n",
      "testing time = 3.2203662395477295 seconds\n",
      "\n",
      "Training with split 2\n",
      "epoch 0 loss = 2.315445\n",
      "epoch 1 loss = 2.095809\n",
      "epoch 2 loss = 2.094661\n",
      "epoch 3 loss = 2.018515\n",
      "epoch 4 loss = 1.905317\n",
      "epoch 5 loss = 2.024801\n",
      "epoch 6 loss = 1.934092\n",
      "epoch 7 loss = 2.040051\n",
      "epoch 8 loss = 2.022577\n",
      "epoch 9 loss = 2.022845\n",
      "epoch 10 loss = 2.040549\n",
      "epoch 11 loss = 1.842843\n",
      "epoch 12 loss = 1.977460\n",
      "epoch 13 loss = 2.078014\n",
      "epoch 14 loss = 1.990507\n",
      "epoch 15 loss = 1.780721\n",
      "epoch 16 loss = 2.060541\n",
      "epoch 17 loss = 1.855701\n",
      "epoch 18 loss = 2.039847\n",
      "epoch 19 loss = 1.886195\n",
      "epoch 20 loss = 2.013420\n",
      "epoch 21 loss = 1.869476\n",
      "epoch 22 loss = 1.998774\n",
      "epoch 23 loss = 1.892467\n",
      "epoch 24 loss = 1.963640\n",
      "epoch 25 loss = 1.856757\n",
      "epoch 26 loss = 1.829484\n",
      "epoch 27 loss = 1.858182\n",
      "epoch 28 loss = 1.978812\n",
      "epoch 29 loss = 1.833230\n",
      "epoch 30 loss = 1.992692\n",
      "epoch 31 loss = 1.815140\n",
      "epoch 32 loss = 1.862758\n",
      "epoch 33 loss = 2.058911\n",
      "epoch 34 loss = 1.599699\n",
      "epoch 35 loss = 1.936310\n",
      "epoch 36 loss = 1.910154\n",
      "epoch 37 loss = 2.027018\n",
      "epoch 38 loss = 2.035201\n",
      "epoch 39 loss = 1.832365\n",
      "epoch 40 loss = 1.790331\n",
      "epoch 41 loss = 1.816982\n",
      "epoch 42 loss = 1.751974\n",
      "epoch 43 loss = 1.816698\n",
      "epoch 44 loss = 1.954391\n",
      "epoch 45 loss = 2.161132\n",
      "epoch 46 loss = 1.836760\n",
      "epoch 47 loss = 1.949899\n",
      "epoch 48 loss = 1.954238\n",
      "epoch 49 loss = 1.974677\n",
      "epoch 50 loss = 1.893305\n",
      "epoch 51 loss = 1.820600\n",
      "epoch 52 loss = 1.865634\n",
      "epoch 53 loss = 1.874518\n",
      "epoch 54 loss = 1.862967\n",
      "epoch 55 loss = 1.942599\n",
      "epoch 56 loss = 1.848814\n",
      "epoch 57 loss = 1.951146\n",
      "epoch 58 loss = 1.763411\n",
      "epoch 59 loss = 1.914387\n",
      "epoch 60 loss = 1.954440\n",
      "epoch 61 loss = 1.888494\n",
      "epoch 62 loss = 2.024978\n",
      "epoch 63 loss = 2.082487\n",
      "epoch 64 loss = 1.849105\n",
      "epoch 65 loss = 1.887245\n",
      "epoch 66 loss = 2.082244\n",
      "epoch 67 loss = 2.052681\n",
      "epoch 68 loss = 1.827496\n",
      "epoch 69 loss = 1.776118\n",
      "epoch 70 loss = 1.799052\n",
      "epoch 71 loss = 2.021992\n",
      "epoch 72 loss = 1.586582\n",
      "epoch 73 loss = 1.682910\n",
      "epoch 74 loss = 1.775636\n",
      "epoch 75 loss = 1.944920\n",
      "epoch 76 loss = 1.836630\n",
      "epoch 77 loss = 2.025965\n",
      "epoch 78 loss = 1.719017\n",
      "epoch 79 loss = 1.751771\n",
      "epoch 80 loss = 1.757290\n",
      "epoch 81 loss = 1.782153\n",
      "epoch 82 loss = 1.689922\n",
      "epoch 83 loss = 1.876529\n",
      "epoch 84 loss = 2.037148\n",
      "epoch 85 loss = 1.902146\n",
      "epoch 86 loss = 1.977160\n",
      "epoch 87 loss = 1.774517\n",
      "epoch 88 loss = 1.939522\n",
      "epoch 89 loss = 1.700487\n",
      "epoch 90 loss = 1.859386\n",
      "epoch 91 loss = 1.869992\n",
      "epoch 92 loss = 1.803297\n",
      "epoch 93 loss = 1.855308\n",
      "epoch 94 loss = 1.730222\n",
      "epoch 95 loss = 1.849041\n",
      "epoch 96 loss = 1.893806\n",
      "epoch 97 loss = 1.902995\n",
      "epoch 98 loss = 1.704035\n",
      "epoch 99 loss = 1.659830\n",
      "final loss = 1.659830\n",
      "accuracy_mc = tensor(0.3253, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.3276, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.8470, device='cuda:0')\n",
      "training time = 61.21267127990723 seconds\n",
      "testing time = 3.1559512615203857 seconds\n",
      "\n",
      "Training with split 3\n",
      "epoch 0 loss = 2.174344\n",
      "epoch 1 loss = 2.111384\n",
      "epoch 2 loss = 2.065097\n",
      "epoch 3 loss = 2.006503\n",
      "epoch 4 loss = 1.949313\n",
      "epoch 5 loss = 1.929946\n",
      "epoch 6 loss = 1.928686\n",
      "epoch 7 loss = 1.967280\n",
      "epoch 8 loss = 1.899356\n",
      "epoch 9 loss = 1.875967\n",
      "epoch 10 loss = 2.022892\n",
      "epoch 11 loss = 1.864135\n",
      "epoch 12 loss = 1.920029\n",
      "epoch 13 loss = 1.908533\n",
      "epoch 14 loss = 1.907302\n",
      "epoch 15 loss = 1.814347\n",
      "epoch 16 loss = 1.884317\n",
      "epoch 17 loss = 1.809680\n",
      "epoch 18 loss = 1.912261\n",
      "epoch 19 loss = 1.720149\n",
      "epoch 20 loss = 1.970969\n",
      "epoch 21 loss = 1.820978\n",
      "epoch 22 loss = 1.856017\n",
      "epoch 23 loss = 1.890706\n",
      "epoch 24 loss = 2.010508\n",
      "epoch 25 loss = 1.739397\n",
      "epoch 26 loss = 1.703766\n",
      "epoch 27 loss = 1.936543\n",
      "epoch 28 loss = 1.761981\n",
      "epoch 29 loss = 1.957618\n",
      "epoch 30 loss = 1.793651\n",
      "epoch 31 loss = 1.952520\n",
      "epoch 32 loss = 1.777920\n",
      "epoch 33 loss = 1.839313\n",
      "epoch 34 loss = 1.658723\n",
      "epoch 35 loss = 1.536958\n",
      "epoch 36 loss = 1.736110\n",
      "epoch 37 loss = 1.699470\n",
      "epoch 38 loss = 1.797685\n",
      "epoch 39 loss = 1.842279\n",
      "epoch 40 loss = 1.894855\n",
      "epoch 41 loss = 1.924951\n",
      "epoch 42 loss = 1.631129\n",
      "epoch 43 loss = 1.929758\n",
      "epoch 44 loss = 1.858094\n",
      "epoch 45 loss = 1.635485\n",
      "epoch 46 loss = 1.851178\n",
      "epoch 47 loss = 1.767476\n",
      "epoch 48 loss = 1.684667\n",
      "epoch 49 loss = 1.752669\n",
      "epoch 50 loss = 1.755749\n",
      "epoch 51 loss = 1.765843\n",
      "epoch 52 loss = 1.918304\n",
      "epoch 53 loss = 1.731415\n",
      "epoch 54 loss = 1.910507\n",
      "epoch 55 loss = 1.613281\n",
      "epoch 56 loss = 1.518160\n",
      "epoch 57 loss = 1.652860\n",
      "epoch 58 loss = 1.682925\n",
      "epoch 59 loss = 1.676723\n",
      "epoch 60 loss = 1.654004\n",
      "epoch 61 loss = 1.670598\n",
      "epoch 62 loss = 1.787533\n",
      "epoch 63 loss = 1.870194\n",
      "epoch 64 loss = 1.832091\n",
      "epoch 65 loss = 1.825888\n",
      "epoch 66 loss = 1.858780\n",
      "epoch 67 loss = 1.930313\n",
      "epoch 68 loss = 1.818401\n",
      "epoch 69 loss = 1.553657\n",
      "epoch 70 loss = 1.652221\n",
      "epoch 71 loss = 1.716085\n",
      "epoch 72 loss = 1.765040\n",
      "epoch 73 loss = 1.742073\n",
      "epoch 74 loss = 1.843556\n",
      "epoch 75 loss = 1.757698\n",
      "epoch 76 loss = 1.745921\n",
      "epoch 77 loss = 1.544420\n",
      "epoch 78 loss = 1.850942\n",
      "epoch 79 loss = 1.982448\n",
      "epoch 80 loss = 1.851860\n",
      "epoch 81 loss = 1.865319\n",
      "epoch 82 loss = 1.759075\n",
      "epoch 83 loss = 1.636739\n",
      "epoch 84 loss = 1.956663\n",
      "epoch 85 loss = 1.763615\n",
      "epoch 86 loss = 1.541713\n",
      "epoch 87 loss = 1.830441\n",
      "epoch 88 loss = 1.662959\n",
      "epoch 89 loss = 1.867396\n",
      "epoch 90 loss = 1.818071\n",
      "epoch 91 loss = 1.744817\n",
      "epoch 92 loss = 1.644232\n",
      "epoch 93 loss = 1.852822\n",
      "epoch 94 loss = 1.790840\n",
      "epoch 95 loss = 1.686247\n",
      "epoch 96 loss = 1.598283\n",
      "epoch 97 loss = 1.649454\n",
      "epoch 98 loss = 1.759027\n",
      "epoch 99 loss = 1.675871\n",
      "final loss = 1.675871\n",
      "accuracy_mc = tensor(0.2902, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2928, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.8689, device='cuda:0')\n",
      "training time = 61.12280035018921 seconds\n",
      "testing time = 3.2041828632354736 seconds\n",
      "\n",
      "Training with split 4\n",
      "epoch 0 loss = 2.225726\n",
      "epoch 1 loss = 2.040996\n",
      "epoch 2 loss = 2.103999\n",
      "epoch 3 loss = 1.975139\n",
      "epoch 4 loss = 2.012111\n",
      "epoch 5 loss = 2.028027\n",
      "epoch 6 loss = 1.956259\n",
      "epoch 7 loss = 1.992239\n",
      "epoch 8 loss = 2.033822\n",
      "epoch 9 loss = 1.887558\n",
      "epoch 10 loss = 1.875260\n",
      "epoch 11 loss = 2.043462\n",
      "epoch 12 loss = 1.880428\n",
      "epoch 13 loss = 1.687747\n",
      "epoch 14 loss = 1.882797\n",
      "epoch 15 loss = 2.034018\n",
      "epoch 16 loss = 1.784565\n",
      "epoch 17 loss = 1.981977\n",
      "epoch 18 loss = 1.939740\n",
      "epoch 19 loss = 2.049644\n",
      "epoch 20 loss = 1.902511\n",
      "epoch 21 loss = 1.759362\n",
      "epoch 22 loss = 1.957166\n",
      "epoch 23 loss = 1.826489\n",
      "epoch 24 loss = 2.036271\n",
      "epoch 25 loss = 1.972769\n",
      "epoch 26 loss = 2.043844\n",
      "epoch 27 loss = 2.099210\n",
      "epoch 28 loss = 1.849362\n",
      "epoch 29 loss = 1.911598\n",
      "epoch 30 loss = 2.024091\n",
      "epoch 31 loss = 1.953852\n",
      "epoch 32 loss = 1.877810\n",
      "epoch 33 loss = 1.641122\n",
      "epoch 34 loss = 1.737493\n",
      "epoch 35 loss = 1.895915\n",
      "epoch 36 loss = 1.944823\n",
      "epoch 37 loss = 2.007059\n",
      "epoch 38 loss = 1.745011\n",
      "epoch 39 loss = 1.993378\n",
      "epoch 40 loss = 1.903553\n",
      "epoch 41 loss = 1.821192\n",
      "epoch 42 loss = 1.776602\n",
      "epoch 43 loss = 1.947544\n",
      "epoch 44 loss = 1.692825\n",
      "epoch 45 loss = 1.872392\n",
      "epoch 46 loss = 1.882809\n",
      "epoch 47 loss = 1.869853\n",
      "epoch 48 loss = 2.113627\n",
      "epoch 49 loss = 1.999286\n",
      "epoch 50 loss = 1.716131\n",
      "epoch 51 loss = 2.048877\n",
      "epoch 52 loss = 1.767140\n",
      "epoch 53 loss = 1.742333\n",
      "epoch 54 loss = 1.737324\n",
      "epoch 55 loss = 1.762318\n",
      "epoch 56 loss = 1.896423\n",
      "epoch 57 loss = 1.903813\n",
      "epoch 58 loss = 1.802242\n",
      "epoch 59 loss = 1.985930\n",
      "epoch 60 loss = 1.935694\n",
      "epoch 61 loss = 1.911013\n",
      "epoch 62 loss = 1.901744\n",
      "epoch 63 loss = 1.582373\n",
      "epoch 64 loss = 1.855517\n",
      "epoch 65 loss = 1.720675\n",
      "epoch 66 loss = 2.044722\n",
      "epoch 67 loss = 1.987981\n",
      "epoch 68 loss = 1.914298\n",
      "epoch 69 loss = 1.696430\n",
      "epoch 70 loss = 1.751840\n",
      "epoch 71 loss = 1.770226\n",
      "epoch 72 loss = 2.021978\n",
      "epoch 73 loss = 2.072313\n",
      "epoch 74 loss = 1.820505\n",
      "epoch 75 loss = 1.741213\n",
      "epoch 76 loss = 1.892455\n",
      "epoch 77 loss = 1.911546\n",
      "epoch 78 loss = 1.767525\n",
      "epoch 79 loss = 1.970944\n",
      "epoch 80 loss = 1.820554\n",
      "epoch 81 loss = 1.904427\n",
      "epoch 82 loss = 1.683686\n",
      "epoch 83 loss = 1.946746\n",
      "epoch 84 loss = 2.010944\n",
      "epoch 85 loss = 1.902646\n",
      "epoch 86 loss = 1.901962\n",
      "epoch 87 loss = 1.623195\n",
      "epoch 88 loss = 1.760570\n",
      "epoch 89 loss = 1.807610\n",
      "epoch 90 loss = 1.861153\n",
      "epoch 91 loss = 1.528236\n",
      "epoch 92 loss = 1.933611\n",
      "epoch 93 loss = 1.934904\n",
      "epoch 94 loss = 1.785787\n",
      "epoch 95 loss = 2.070865\n",
      "epoch 96 loss = 1.727068\n",
      "epoch 97 loss = 1.986759\n",
      "epoch 98 loss = 1.830948\n",
      "epoch 99 loss = 1.683579\n",
      "final loss = 1.683579\n",
      "accuracy_mc = tensor(0.3925, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.3857, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.7734, device='cuda:0')\n",
      "training time = 61.04745364189148 seconds\n",
      "testing time = 3.173396348953247 seconds\n",
      "\n",
      "Training with split 5\n",
      "epoch 0 loss = 2.274733\n",
      "epoch 1 loss = 2.283510\n",
      "epoch 2 loss = 2.217466\n",
      "epoch 3 loss = 2.183049\n",
      "epoch 4 loss = 2.158473\n",
      "epoch 5 loss = 2.192181\n",
      "epoch 6 loss = 2.314245\n",
      "epoch 7 loss = 2.128086\n",
      "epoch 8 loss = 2.289025\n",
      "epoch 9 loss = 2.351584\n",
      "epoch 10 loss = 2.295326\n",
      "epoch 11 loss = 2.181951\n",
      "epoch 12 loss = 2.179765\n",
      "epoch 13 loss = 2.051904\n",
      "epoch 14 loss = 2.280976\n",
      "epoch 15 loss = 2.086298\n",
      "epoch 16 loss = 2.187193\n",
      "epoch 17 loss = 2.209077\n",
      "epoch 18 loss = 2.300618\n",
      "epoch 19 loss = 2.296170\n",
      "epoch 20 loss = 2.043949\n",
      "epoch 21 loss = 2.053267\n",
      "epoch 22 loss = 2.234030\n",
      "epoch 23 loss = 2.254762\n",
      "epoch 24 loss = 2.106293\n",
      "epoch 25 loss = 2.085173\n",
      "epoch 26 loss = 1.998777\n",
      "epoch 27 loss = 2.170668\n",
      "epoch 28 loss = 2.130687\n",
      "epoch 29 loss = 2.111404\n",
      "epoch 30 loss = 2.178895\n",
      "epoch 31 loss = 2.157289\n",
      "epoch 32 loss = 1.916560\n",
      "epoch 33 loss = 2.000761\n",
      "epoch 34 loss = 2.175191\n",
      "epoch 35 loss = 1.843671\n",
      "epoch 36 loss = 2.357120\n",
      "epoch 37 loss = 1.970726\n",
      "epoch 38 loss = 2.332775\n",
      "epoch 39 loss = 1.947343\n",
      "epoch 40 loss = 1.995318\n",
      "epoch 41 loss = 2.143044\n",
      "epoch 42 loss = 2.049432\n",
      "epoch 43 loss = 1.970171\n",
      "epoch 44 loss = 1.964174\n",
      "epoch 45 loss = 2.159740\n",
      "epoch 46 loss = 2.070452\n",
      "epoch 47 loss = 2.084660\n",
      "epoch 48 loss = 2.044242\n",
      "epoch 49 loss = 1.968973\n",
      "epoch 50 loss = 1.929549\n",
      "epoch 51 loss = 2.037536\n",
      "epoch 52 loss = 1.816232\n",
      "epoch 53 loss = 2.121113\n",
      "epoch 54 loss = 2.335581\n",
      "epoch 55 loss = 1.994954\n",
      "epoch 56 loss = 1.981447\n",
      "epoch 57 loss = 1.964963\n",
      "epoch 58 loss = 1.884801\n",
      "epoch 59 loss = 2.074406\n",
      "epoch 60 loss = 2.168094\n",
      "epoch 61 loss = 2.086420\n",
      "epoch 62 loss = 2.137598\n",
      "epoch 63 loss = 2.130404\n",
      "epoch 64 loss = 1.955151\n",
      "epoch 65 loss = 1.876422\n",
      "epoch 66 loss = 1.921518\n",
      "epoch 67 loss = 1.923336\n",
      "epoch 68 loss = 1.896378\n",
      "epoch 69 loss = 1.962950\n",
      "epoch 70 loss = 1.936409\n",
      "epoch 71 loss = 2.022131\n",
      "epoch 72 loss = 1.977189\n",
      "epoch 73 loss = 2.205109\n",
      "epoch 74 loss = 2.041112\n",
      "epoch 75 loss = 1.807018\n",
      "epoch 76 loss = 2.108444\n",
      "epoch 77 loss = 1.880335\n",
      "epoch 78 loss = 1.920142\n",
      "epoch 79 loss = 2.057926\n",
      "epoch 80 loss = 2.180482\n",
      "epoch 81 loss = 2.107042\n",
      "epoch 82 loss = 1.919135\n",
      "epoch 83 loss = 1.871754\n",
      "epoch 84 loss = 2.081781\n",
      "epoch 85 loss = 1.927046\n",
      "epoch 86 loss = 1.862466\n",
      "epoch 87 loss = 1.931798\n",
      "epoch 88 loss = 1.776097\n",
      "epoch 89 loss = 1.808015\n",
      "epoch 90 loss = 1.926839\n",
      "epoch 91 loss = 2.040992\n",
      "epoch 92 loss = 1.905676\n",
      "epoch 93 loss = 2.082873\n",
      "epoch 94 loss = 2.036396\n",
      "epoch 95 loss = 2.029305\n",
      "epoch 96 loss = 1.865945\n",
      "epoch 97 loss = 2.019497\n",
      "epoch 98 loss = 2.056500\n",
      "epoch 99 loss = 2.040642\n",
      "final loss = 2.040642\n",
      "accuracy_mc = tensor(0.3296, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.3159, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.8825, device='cuda:0')\n",
      "training time = 61.04037809371948 seconds\n",
      "testing time = 3.234025001525879 seconds\n",
      "\n",
      "Training with split 6\n",
      "epoch 0 loss = 2.307060\n",
      "epoch 1 loss = 2.386120\n",
      "epoch 2 loss = 2.260475\n",
      "epoch 3 loss = 2.138808\n",
      "epoch 4 loss = 2.247710\n",
      "epoch 5 loss = 2.290960\n",
      "epoch 6 loss = 2.261983\n",
      "epoch 7 loss = 2.284137\n",
      "epoch 8 loss = 2.245069\n",
      "epoch 9 loss = 2.352115\n",
      "epoch 10 loss = 2.204968\n",
      "epoch 11 loss = 2.227931\n",
      "epoch 12 loss = 2.200726\n",
      "epoch 13 loss = 2.128537\n",
      "epoch 14 loss = 2.220723\n",
      "epoch 15 loss = 2.288612\n",
      "epoch 16 loss = 2.238717\n",
      "epoch 17 loss = 2.201294\n",
      "epoch 18 loss = 2.147065\n",
      "epoch 19 loss = 2.183642\n",
      "epoch 20 loss = 2.206694\n",
      "epoch 21 loss = 2.220123\n",
      "epoch 22 loss = 2.380342\n",
      "epoch 23 loss = 1.982387\n",
      "epoch 24 loss = 2.156183\n",
      "epoch 25 loss = 2.255982\n",
      "epoch 26 loss = 2.209277\n",
      "epoch 27 loss = 2.239532\n",
      "epoch 28 loss = 2.177150\n",
      "epoch 29 loss = 2.161368\n",
      "epoch 30 loss = 2.142326\n",
      "epoch 31 loss = 2.059310\n",
      "epoch 32 loss = 2.037857\n",
      "epoch 33 loss = 2.280349\n",
      "epoch 34 loss = 2.412306\n",
      "epoch 35 loss = 1.947371\n",
      "epoch 36 loss = 2.118264\n",
      "epoch 37 loss = 2.103763\n",
      "epoch 38 loss = 2.061081\n",
      "epoch 39 loss = 1.857119\n",
      "epoch 40 loss = 2.116819\n",
      "epoch 41 loss = 1.893706\n",
      "epoch 42 loss = 1.970226\n",
      "epoch 43 loss = 1.920807\n",
      "epoch 44 loss = 2.028705\n",
      "epoch 45 loss = 1.886549\n",
      "epoch 46 loss = 2.281399\n",
      "epoch 47 loss = 1.888746\n",
      "epoch 48 loss = 1.874106\n",
      "epoch 49 loss = 1.835995\n",
      "epoch 50 loss = 1.996091\n",
      "epoch 51 loss = 2.149640\n",
      "epoch 52 loss = 2.065254\n",
      "epoch 53 loss = 2.055113\n",
      "epoch 54 loss = 1.795586\n",
      "epoch 55 loss = 1.788422\n",
      "epoch 56 loss = 2.352455\n",
      "epoch 57 loss = 2.101823\n",
      "epoch 58 loss = 1.976552\n",
      "epoch 59 loss = 2.174889\n",
      "epoch 60 loss = 1.974289\n",
      "epoch 61 loss = 2.082804\n",
      "epoch 62 loss = 2.010188\n",
      "epoch 63 loss = 2.054971\n",
      "epoch 64 loss = 2.002552\n",
      "epoch 65 loss = 2.156288\n",
      "epoch 66 loss = 1.937089\n",
      "epoch 67 loss = 2.258822\n",
      "epoch 68 loss = 2.090496\n",
      "epoch 69 loss = 1.828135\n",
      "epoch 70 loss = 2.047557\n",
      "epoch 71 loss = 1.936646\n",
      "epoch 72 loss = 1.881323\n",
      "epoch 73 loss = 1.882733\n",
      "epoch 74 loss = 1.998077\n",
      "epoch 75 loss = 2.195950\n",
      "epoch 76 loss = 1.983835\n",
      "epoch 77 loss = 2.037322\n",
      "epoch 78 loss = 1.980035\n",
      "epoch 79 loss = 1.699802\n",
      "epoch 80 loss = 1.776078\n",
      "epoch 81 loss = 1.944766\n",
      "epoch 82 loss = 2.177047\n",
      "epoch 83 loss = 2.158932\n",
      "epoch 84 loss = 1.764219\n",
      "epoch 85 loss = 1.892706\n",
      "epoch 86 loss = 1.984344\n",
      "epoch 87 loss = 2.124930\n",
      "epoch 88 loss = 1.993585\n",
      "epoch 89 loss = 1.941190\n",
      "epoch 90 loss = 1.990246\n",
      "epoch 91 loss = 1.759096\n",
      "epoch 92 loss = 1.781972\n",
      "epoch 93 loss = 2.096202\n",
      "epoch 94 loss = 1.913900\n",
      "epoch 95 loss = 1.856363\n",
      "epoch 96 loss = 1.915236\n",
      "epoch 97 loss = 1.874309\n",
      "epoch 98 loss = 1.952996\n",
      "epoch 99 loss = 1.743060\n",
      "final loss = 1.743060\n",
      "accuracy_mc = tensor(0.3934, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.4087, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.7549, device='cuda:0')\n",
      "training time = 61.37321901321411 seconds\n",
      "testing time = 3.2069883346557617 seconds\n",
      "\n",
      "Training with split 7\n",
      "epoch 0 loss = 2.237998\n",
      "epoch 1 loss = 2.241210\n",
      "epoch 2 loss = 2.142102\n",
      "epoch 3 loss = 2.135119\n",
      "epoch 4 loss = 2.044935\n",
      "epoch 5 loss = 2.191162\n",
      "epoch 6 loss = 2.023319\n",
      "epoch 7 loss = 1.881285\n",
      "epoch 8 loss = 1.959004\n",
      "epoch 9 loss = 1.923704\n",
      "epoch 10 loss = 2.096366\n",
      "epoch 11 loss = 2.109163\n",
      "epoch 12 loss = 2.064434\n",
      "epoch 13 loss = 2.090636\n",
      "epoch 14 loss = 1.979949\n",
      "epoch 15 loss = 1.879669\n",
      "epoch 16 loss = 2.075718\n",
      "epoch 17 loss = 1.943711\n",
      "epoch 18 loss = 2.009475\n",
      "epoch 19 loss = 1.966447\n",
      "epoch 20 loss = 1.910349\n",
      "epoch 21 loss = 2.010239\n",
      "epoch 22 loss = 1.874981\n",
      "epoch 23 loss = 1.878493\n",
      "epoch 24 loss = 2.113244\n",
      "epoch 25 loss = 2.159214\n",
      "epoch 26 loss = 2.108892\n",
      "epoch 27 loss = 1.953395\n",
      "epoch 28 loss = 1.875414\n",
      "epoch 29 loss = 2.263674\n",
      "epoch 30 loss = 2.005395\n",
      "epoch 31 loss = 1.958294\n",
      "epoch 32 loss = 1.972693\n",
      "epoch 33 loss = 2.068802\n",
      "epoch 34 loss = 2.046574\n",
      "epoch 35 loss = 2.027311\n",
      "epoch 36 loss = 1.985233\n",
      "epoch 37 loss = 1.978569\n",
      "epoch 38 loss = 1.926865\n",
      "epoch 39 loss = 1.950312\n",
      "epoch 40 loss = 1.878276\n",
      "epoch 41 loss = 1.940179\n",
      "epoch 42 loss = 1.770354\n",
      "epoch 43 loss = 2.025501\n",
      "epoch 44 loss = 2.143806\n",
      "epoch 45 loss = 1.994060\n",
      "epoch 46 loss = 1.948516\n",
      "epoch 47 loss = 2.087005\n",
      "epoch 48 loss = 1.894350\n",
      "epoch 49 loss = 1.892081\n",
      "epoch 50 loss = 1.968211\n",
      "epoch 51 loss = 1.869899\n",
      "epoch 52 loss = 1.915386\n",
      "epoch 53 loss = 1.851722\n",
      "epoch 54 loss = 1.935592\n",
      "epoch 55 loss = 1.909339\n",
      "epoch 56 loss = 1.902050\n",
      "epoch 57 loss = 1.883566\n",
      "epoch 58 loss = 2.119440\n",
      "epoch 59 loss = 1.923385\n",
      "epoch 60 loss = 2.124235\n",
      "epoch 61 loss = 1.997153\n",
      "epoch 62 loss = 1.973646\n",
      "epoch 63 loss = 1.839068\n",
      "epoch 64 loss = 1.941349\n",
      "epoch 65 loss = 1.904924\n",
      "epoch 66 loss = 1.803735\n",
      "epoch 67 loss = 1.998181\n",
      "epoch 68 loss = 2.013511\n",
      "epoch 69 loss = 1.865320\n",
      "epoch 70 loss = 1.924757\n",
      "epoch 71 loss = 1.853418\n",
      "epoch 72 loss = 1.765876\n",
      "epoch 73 loss = 1.916864\n",
      "epoch 74 loss = 1.858390\n",
      "epoch 75 loss = 1.817774\n",
      "epoch 76 loss = 1.922631\n",
      "epoch 77 loss = 1.974666\n",
      "epoch 78 loss = 1.863488\n",
      "epoch 79 loss = 1.900645\n",
      "epoch 80 loss = 1.869262\n",
      "epoch 81 loss = 1.766146\n",
      "epoch 82 loss = 1.876720\n",
      "epoch 83 loss = 2.054148\n",
      "epoch 84 loss = 1.939356\n",
      "epoch 85 loss = 1.875654\n",
      "epoch 86 loss = 1.774698\n",
      "epoch 87 loss = 2.040561\n",
      "epoch 88 loss = 1.774595\n",
      "epoch 89 loss = 1.873899\n",
      "epoch 90 loss = 1.957798\n",
      "epoch 91 loss = 1.862053\n",
      "epoch 92 loss = 1.838201\n",
      "epoch 93 loss = 1.861396\n",
      "epoch 94 loss = 1.988386\n",
      "epoch 95 loss = 1.968297\n",
      "epoch 96 loss = 1.768085\n",
      "epoch 97 loss = 2.014890\n",
      "epoch 98 loss = 1.869829\n",
      "epoch 99 loss = 1.825056\n",
      "final loss = 1.825056\n",
      "accuracy_mc = tensor(0.3022, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.3020, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.8729, device='cuda:0')\n",
      "training time = 61.17468595504761 seconds\n",
      "testing time = 3.1757729053497314 seconds\n",
      "\n",
      "Training with split 8\n",
      "epoch 0 loss = 2.239006\n",
      "epoch 1 loss = 2.184875\n",
      "epoch 2 loss = 1.934965\n",
      "epoch 3 loss = 2.195536\n",
      "epoch 4 loss = 2.100975\n",
      "epoch 5 loss = 2.039853\n",
      "epoch 6 loss = 2.157214\n",
      "epoch 7 loss = 1.927450\n",
      "epoch 8 loss = 2.004858\n",
      "epoch 9 loss = 2.017466\n",
      "epoch 10 loss = 1.987029\n",
      "epoch 11 loss = 1.990665\n",
      "epoch 12 loss = 1.954474\n",
      "epoch 13 loss = 2.037225\n",
      "epoch 14 loss = 1.983811\n",
      "epoch 15 loss = 2.009549\n",
      "epoch 16 loss = 2.140633\n",
      "epoch 17 loss = 2.071852\n",
      "epoch 18 loss = 1.892763\n",
      "epoch 19 loss = 1.891537\n",
      "epoch 20 loss = 1.805961\n",
      "epoch 21 loss = 1.898211\n",
      "epoch 22 loss = 1.865079\n",
      "epoch 23 loss = 2.046210\n",
      "epoch 24 loss = 1.936480\n",
      "epoch 25 loss = 2.075082\n",
      "epoch 26 loss = 2.085282\n",
      "epoch 27 loss = 2.053546\n",
      "epoch 28 loss = 1.954617\n",
      "epoch 29 loss = 1.926379\n",
      "epoch 30 loss = 2.057306\n",
      "epoch 31 loss = 1.964634\n",
      "epoch 32 loss = 1.932575\n",
      "epoch 33 loss = 1.956046\n",
      "epoch 34 loss = 1.972420\n",
      "epoch 35 loss = 1.869111\n",
      "epoch 36 loss = 2.171385\n",
      "epoch 37 loss = 1.820824\n",
      "epoch 38 loss = 1.973953\n",
      "epoch 39 loss = 1.983520\n",
      "epoch 40 loss = 1.928240\n",
      "epoch 41 loss = 2.067432\n",
      "epoch 42 loss = 2.005450\n",
      "epoch 43 loss = 2.044116\n",
      "epoch 44 loss = 1.925317\n",
      "epoch 45 loss = 1.968979\n",
      "epoch 46 loss = 1.863789\n",
      "epoch 47 loss = 1.889089\n",
      "epoch 48 loss = 1.795010\n",
      "epoch 49 loss = 1.862201\n",
      "epoch 50 loss = 1.795785\n",
      "epoch 51 loss = 2.045337\n",
      "epoch 52 loss = 1.977599\n",
      "epoch 53 loss = 2.086994\n",
      "epoch 54 loss = 1.996419\n",
      "epoch 55 loss = 2.102511\n",
      "epoch 56 loss = 2.089941\n",
      "epoch 57 loss = 2.009436\n",
      "epoch 58 loss = 1.937001\n",
      "epoch 59 loss = 2.085969\n",
      "epoch 60 loss = 2.016483\n",
      "epoch 61 loss = 2.046461\n",
      "epoch 62 loss = 2.004682\n",
      "epoch 63 loss = 1.839413\n",
      "epoch 64 loss = 1.994139\n",
      "epoch 65 loss = 1.876148\n",
      "epoch 66 loss = 1.900727\n",
      "epoch 67 loss = 1.924608\n",
      "epoch 68 loss = 1.858109\n",
      "epoch 69 loss = 1.980743\n",
      "epoch 70 loss = 1.844289\n",
      "epoch 71 loss = 1.923766\n",
      "epoch 72 loss = 1.908606\n",
      "epoch 73 loss = 1.872892\n",
      "epoch 74 loss = 2.004176\n",
      "epoch 75 loss = 1.845639\n",
      "epoch 76 loss = 1.896432\n",
      "epoch 77 loss = 1.887515\n",
      "epoch 78 loss = 1.869090\n",
      "epoch 79 loss = 1.783067\n",
      "epoch 80 loss = 1.906797\n",
      "epoch 81 loss = 1.876114\n",
      "epoch 82 loss = 1.718673\n",
      "epoch 83 loss = 1.953813\n",
      "epoch 84 loss = 2.061112\n",
      "epoch 85 loss = 1.876570\n",
      "epoch 86 loss = 1.892067\n",
      "epoch 87 loss = 2.201422\n",
      "epoch 88 loss = 1.784384\n",
      "epoch 89 loss = 1.836032\n",
      "epoch 90 loss = 1.990641\n",
      "epoch 91 loss = 1.834632\n",
      "epoch 92 loss = 1.904277\n",
      "epoch 93 loss = 1.875837\n",
      "epoch 94 loss = 1.940518\n",
      "epoch 95 loss = 2.062021\n",
      "epoch 96 loss = 1.994066\n",
      "epoch 97 loss = 2.007827\n",
      "epoch 98 loss = 1.976900\n",
      "epoch 99 loss = 1.888107\n",
      "final loss = 1.888107\n",
      "accuracy_mc = tensor(0.3033, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2788, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.9043, device='cuda:0')\n",
      "training time = 61.15721774101257 seconds\n",
      "testing time = 3.179722785949707 seconds\n",
      "\n",
      "Training with split 9\n",
      "epoch 0 loss = 2.316541\n",
      "epoch 1 loss = 2.305227\n",
      "epoch 2 loss = 2.230484\n",
      "epoch 3 loss = 2.106373\n",
      "epoch 4 loss = 2.221057\n",
      "epoch 5 loss = 2.025348\n",
      "epoch 6 loss = 2.019426\n",
      "epoch 7 loss = 2.137414\n",
      "epoch 8 loss = 2.048978\n",
      "epoch 9 loss = 2.010383\n",
      "epoch 10 loss = 2.135226\n",
      "epoch 11 loss = 2.002940\n",
      "epoch 12 loss = 2.016080\n",
      "epoch 13 loss = 2.060369\n",
      "epoch 14 loss = 1.905593\n",
      "epoch 15 loss = 1.833792\n",
      "epoch 16 loss = 2.007666\n",
      "epoch 17 loss = 1.964967\n",
      "epoch 18 loss = 2.016329\n",
      "epoch 19 loss = 1.840884\n",
      "epoch 20 loss = 1.929013\n",
      "epoch 21 loss = 1.996880\n",
      "epoch 22 loss = 1.941781\n",
      "epoch 23 loss = 1.955906\n",
      "epoch 24 loss = 2.029231\n",
      "epoch 25 loss = 2.070225\n",
      "epoch 26 loss = 1.920120\n",
      "epoch 27 loss = 1.887397\n",
      "epoch 28 loss = 1.763465\n",
      "epoch 29 loss = 2.140478\n",
      "epoch 30 loss = 1.812681\n",
      "epoch 31 loss = 2.020508\n",
      "epoch 32 loss = 2.108472\n",
      "epoch 33 loss = 1.716525\n",
      "epoch 34 loss = 1.879614\n",
      "epoch 35 loss = 1.869479\n",
      "epoch 36 loss = 1.961816\n",
      "epoch 37 loss = 2.027540\n",
      "epoch 38 loss = 1.901544\n",
      "epoch 39 loss = 2.048073\n",
      "epoch 40 loss = 1.985891\n",
      "epoch 41 loss = 1.815376\n",
      "epoch 42 loss = 2.040171\n",
      "epoch 43 loss = 1.924457\n",
      "epoch 44 loss = 1.928202\n",
      "epoch 45 loss = 1.802596\n",
      "epoch 46 loss = 1.860801\n",
      "epoch 47 loss = 2.016261\n",
      "epoch 48 loss = 1.967136\n",
      "epoch 49 loss = 1.725204\n",
      "epoch 50 loss = 2.157028\n",
      "epoch 51 loss = 1.860332\n",
      "epoch 52 loss = 1.897336\n",
      "epoch 53 loss = 2.015452\n",
      "epoch 54 loss = 1.838327\n",
      "epoch 55 loss = 1.901649\n",
      "epoch 56 loss = 1.990862\n",
      "epoch 57 loss = 1.937012\n",
      "epoch 58 loss = 1.881094\n",
      "epoch 59 loss = 1.950547\n",
      "epoch 60 loss = 1.697561\n",
      "epoch 61 loss = 1.931549\n",
      "epoch 62 loss = 1.874328\n",
      "epoch 63 loss = 1.733133\n",
      "epoch 64 loss = 1.791076\n",
      "epoch 65 loss = 1.843944\n",
      "epoch 66 loss = 1.950766\n",
      "epoch 67 loss = 1.856115\n",
      "epoch 68 loss = 1.986963\n",
      "epoch 69 loss = 1.829540\n",
      "epoch 70 loss = 1.726905\n",
      "epoch 71 loss = 1.869229\n",
      "epoch 72 loss = 1.816503\n",
      "epoch 73 loss = 1.853838\n",
      "epoch 74 loss = 1.795399\n",
      "epoch 75 loss = 2.000686\n",
      "epoch 76 loss = 1.940917\n",
      "epoch 77 loss = 1.624232\n",
      "epoch 78 loss = 2.082047\n",
      "epoch 79 loss = 1.850961\n",
      "epoch 80 loss = 2.048790\n",
      "epoch 81 loss = 1.858807\n",
      "epoch 82 loss = 1.694533\n",
      "epoch 83 loss = 2.059653\n",
      "epoch 84 loss = 1.921890\n",
      "epoch 85 loss = 2.020924\n",
      "epoch 86 loss = 1.884739\n",
      "epoch 87 loss = 1.711584\n",
      "epoch 88 loss = 1.915565\n",
      "epoch 89 loss = 1.699782\n",
      "epoch 90 loss = 1.679362\n",
      "epoch 91 loss = 1.918325\n",
      "epoch 92 loss = 1.692307\n",
      "epoch 93 loss = 1.843022\n",
      "epoch 94 loss = 2.010845\n",
      "epoch 95 loss = 1.824835\n",
      "epoch 96 loss = 1.691906\n",
      "epoch 97 loss = 1.720622\n",
      "epoch 98 loss = 1.970734\n",
      "epoch 99 loss = 1.896870\n",
      "final loss = 1.896870\n",
      "accuracy_mc = tensor(0.4347, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.4083, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.7524, device='cuda:0')\n",
      "training time = 61.01236033439636 seconds\n",
      "testing time = 3.2267239093780518 seconds\n",
      "\n",
      "subset 0.050000, dropout_rate 0.300000, reg_strength 0.050000\n",
      "n_epoch 500\n",
      "\n",
      "Files already downloaded and verified\n",
      "subset size = (2500, 32, 32, 3)\n",
      "training set size = 2000\n",
      "test set size = 500\n",
      "\n",
      "Training with split 0\n",
      "epoch 0 loss = 2.272101\n",
      "epoch 1 loss = 2.210046\n",
      "epoch 2 loss = 2.082906\n",
      "epoch 3 loss = 2.124542\n",
      "epoch 4 loss = 2.117086\n",
      "epoch 5 loss = 2.093739\n",
      "epoch 6 loss = 2.142990\n",
      "epoch 7 loss = 2.029237\n",
      "epoch 8 loss = 1.985675\n",
      "epoch 9 loss = 2.001804\n",
      "epoch 10 loss = 2.189731\n",
      "epoch 11 loss = 1.928363\n",
      "epoch 12 loss = 2.127447\n",
      "epoch 13 loss = 2.001741\n",
      "epoch 14 loss = 2.061622\n",
      "epoch 15 loss = 1.868242\n",
      "epoch 16 loss = 2.125101\n",
      "epoch 17 loss = 2.211401\n",
      "epoch 18 loss = 1.816199\n",
      "epoch 19 loss = 1.954219\n",
      "epoch 20 loss = 2.044205\n",
      "epoch 21 loss = 2.027961\n",
      "epoch 22 loss = 1.880994\n",
      "epoch 23 loss = 2.002453\n",
      "epoch 24 loss = 1.908395\n",
      "epoch 25 loss = 1.854994\n",
      "epoch 26 loss = 1.717154\n",
      "epoch 27 loss = 1.955989\n",
      "epoch 28 loss = 2.061297\n",
      "epoch 29 loss = 1.968164\n",
      "epoch 30 loss = 1.826833\n",
      "epoch 31 loss = 1.924188\n",
      "epoch 32 loss = 2.051707\n",
      "epoch 33 loss = 2.084294\n",
      "epoch 34 loss = 1.735162\n",
      "epoch 35 loss = 1.928107\n",
      "epoch 36 loss = 2.010673\n",
      "epoch 37 loss = 1.716434\n",
      "epoch 38 loss = 1.824827\n",
      "epoch 39 loss = 2.142500\n",
      "epoch 40 loss = 1.848287\n",
      "epoch 41 loss = 1.892653\n",
      "epoch 42 loss = 1.954499\n",
      "epoch 43 loss = 1.947648\n",
      "epoch 44 loss = 1.812148\n",
      "epoch 45 loss = 1.924581\n",
      "epoch 46 loss = 1.877573\n",
      "epoch 47 loss = 1.715330\n",
      "epoch 48 loss = 1.883789\n",
      "epoch 49 loss = 1.931157\n",
      "epoch 50 loss = 1.874478\n",
      "epoch 51 loss = 1.872086\n",
      "epoch 52 loss = 1.748873\n",
      "epoch 53 loss = 1.711919\n",
      "epoch 54 loss = 1.881948\n",
      "epoch 55 loss = 1.843917\n",
      "epoch 56 loss = 1.979796\n",
      "epoch 57 loss = 2.089822\n",
      "epoch 58 loss = 2.093104\n",
      "epoch 59 loss = 1.890170\n",
      "epoch 60 loss = 1.714958\n",
      "epoch 61 loss = 1.865886\n",
      "epoch 62 loss = 2.014517\n",
      "epoch 63 loss = 1.846741\n",
      "epoch 64 loss = 2.003099\n",
      "epoch 65 loss = 1.569684\n",
      "epoch 66 loss = 1.838377\n",
      "epoch 67 loss = 1.861932\n",
      "epoch 68 loss = 1.707635\n",
      "epoch 69 loss = 1.571220\n",
      "epoch 70 loss = 2.006869\n",
      "epoch 71 loss = 2.115240\n",
      "epoch 72 loss = 1.796949\n",
      "epoch 73 loss = 1.813446\n",
      "epoch 74 loss = 1.943631\n",
      "epoch 75 loss = 1.647555\n",
      "epoch 76 loss = 1.776891\n",
      "epoch 77 loss = 1.674241\n",
      "epoch 78 loss = 1.690368\n",
      "epoch 79 loss = 1.982112\n",
      "epoch 80 loss = 1.728215\n",
      "epoch 81 loss = 1.749147\n",
      "epoch 82 loss = 1.583256\n",
      "epoch 83 loss = 1.590566\n",
      "epoch 84 loss = 1.725714\n",
      "epoch 85 loss = 1.783261\n",
      "epoch 86 loss = 1.810202\n",
      "epoch 87 loss = 1.758010\n",
      "epoch 88 loss = 1.639456\n",
      "epoch 89 loss = 1.901850\n",
      "epoch 90 loss = 1.732337\n",
      "epoch 91 loss = 1.606547\n",
      "epoch 92 loss = 1.742441\n",
      "epoch 93 loss = 1.707504\n",
      "epoch 94 loss = 2.014341\n",
      "epoch 95 loss = 1.674543\n",
      "epoch 96 loss = 1.880917\n",
      "epoch 97 loss = 1.771115\n",
      "epoch 98 loss = 1.789944\n",
      "epoch 99 loss = 1.651291\n",
      "epoch 100 loss = 1.642854\n",
      "epoch 101 loss = 1.694394\n",
      "epoch 102 loss = 1.713512\n",
      "epoch 103 loss = 1.783984\n",
      "epoch 104 loss = 1.755814\n",
      "epoch 105 loss = 1.773731\n",
      "epoch 106 loss = 1.711184\n",
      "epoch 107 loss = 1.746500\n",
      "epoch 108 loss = 1.615740\n",
      "epoch 109 loss = 1.808204\n",
      "epoch 110 loss = 1.798702\n",
      "epoch 111 loss = 1.723981\n",
      "epoch 112 loss = 1.863910\n",
      "epoch 113 loss = 1.629600\n",
      "epoch 114 loss = 1.791479\n",
      "epoch 115 loss = 1.717079\n",
      "epoch 116 loss = 1.770217\n",
      "epoch 117 loss = 1.640799\n",
      "epoch 118 loss = 1.867183\n",
      "epoch 119 loss = 1.740496\n",
      "epoch 120 loss = 1.635682\n",
      "epoch 121 loss = 1.571580\n",
      "epoch 122 loss = 1.594576\n",
      "epoch 123 loss = 1.586986\n",
      "epoch 124 loss = 1.751083\n",
      "epoch 125 loss = 1.711859\n",
      "epoch 126 loss = 1.826405\n",
      "epoch 127 loss = 1.809600\n",
      "epoch 128 loss = 1.658692\n",
      "epoch 129 loss = 1.852541\n",
      "epoch 130 loss = 1.726025\n",
      "epoch 131 loss = 1.817669\n",
      "epoch 132 loss = 1.401621\n",
      "epoch 133 loss = 1.823889\n",
      "epoch 134 loss = 1.797384\n",
      "epoch 135 loss = 1.552073\n",
      "epoch 136 loss = 1.496998\n",
      "epoch 137 loss = 1.777615\n",
      "epoch 138 loss = 1.762631\n",
      "epoch 139 loss = 1.658018\n",
      "epoch 140 loss = 1.702212\n",
      "epoch 141 loss = 1.628023\n",
      "epoch 142 loss = 1.618187\n",
      "epoch 143 loss = 1.743334\n",
      "epoch 144 loss = 1.529375\n",
      "epoch 145 loss = 1.572421\n",
      "epoch 146 loss = 1.668452\n",
      "epoch 147 loss = 1.649897\n",
      "epoch 148 loss = 1.536246\n",
      "epoch 149 loss = 1.363442\n",
      "epoch 150 loss = 1.543400\n",
      "epoch 151 loss = 1.562224\n",
      "epoch 152 loss = 1.549049\n",
      "epoch 153 loss = 1.775818\n",
      "epoch 154 loss = 1.873480\n",
      "epoch 155 loss = 1.886348\n",
      "epoch 156 loss = 1.839883\n",
      "epoch 157 loss = 1.682724\n",
      "epoch 158 loss = 1.517313\n",
      "epoch 159 loss = 1.678717\n",
      "epoch 160 loss = 1.660678\n",
      "epoch 161 loss = 1.791550\n",
      "epoch 162 loss = 1.875833\n",
      "epoch 163 loss = 1.754175\n",
      "epoch 164 loss = 1.589018\n",
      "epoch 165 loss = 1.708372\n",
      "epoch 166 loss = 1.961455\n",
      "epoch 167 loss = 1.563731\n",
      "epoch 168 loss = 1.923429\n",
      "epoch 169 loss = 1.689509\n",
      "epoch 170 loss = 1.600079\n",
      "epoch 171 loss = 1.438789\n",
      "epoch 172 loss = 1.441106\n",
      "epoch 173 loss = 1.591999\n",
      "epoch 174 loss = 1.852758\n",
      "epoch 175 loss = 1.718416\n",
      "epoch 176 loss = 1.408720\n",
      "epoch 177 loss = 1.735334\n",
      "epoch 178 loss = 1.790955\n",
      "epoch 179 loss = 1.669149\n",
      "epoch 180 loss = 1.665361\n",
      "epoch 181 loss = 1.787431\n",
      "epoch 182 loss = 1.755308\n",
      "epoch 183 loss = 1.720009\n",
      "epoch 184 loss = 1.890407\n",
      "epoch 185 loss = 1.685538\n",
      "epoch 186 loss = 1.746922\n",
      "epoch 187 loss = 1.741067\n",
      "epoch 188 loss = 1.655248\n",
      "epoch 189 loss = 1.618888\n",
      "epoch 190 loss = 1.664456\n",
      "epoch 191 loss = 1.797855\n",
      "epoch 192 loss = 1.600032\n",
      "epoch 193 loss = 1.613472\n",
      "epoch 194 loss = 1.743216\n",
      "epoch 195 loss = 1.761458\n",
      "epoch 196 loss = 1.724127\n",
      "epoch 197 loss = 1.833220\n",
      "epoch 198 loss = 1.605791\n",
      "epoch 199 loss = 1.566140\n",
      "epoch 200 loss = 1.638331\n",
      "epoch 201 loss = 1.577223\n",
      "epoch 202 loss = 1.472743\n",
      "epoch 203 loss = 1.667251\n",
      "epoch 204 loss = 1.533925\n",
      "epoch 205 loss = 1.917285\n",
      "epoch 206 loss = 1.584558\n",
      "epoch 207 loss = 1.715375\n",
      "epoch 208 loss = 1.982177\n",
      "epoch 209 loss = 1.818085\n",
      "epoch 210 loss = 1.648293\n",
      "epoch 211 loss = 1.691061\n",
      "epoch 212 loss = 1.725160\n",
      "epoch 213 loss = 1.628644\n",
      "epoch 214 loss = 1.531995\n",
      "epoch 215 loss = 1.516869\n",
      "epoch 216 loss = 1.817851\n",
      "epoch 217 loss = 1.667952\n",
      "epoch 218 loss = 1.756243\n",
      "epoch 219 loss = 1.915741\n",
      "epoch 220 loss = 1.536416\n",
      "epoch 221 loss = 1.721412\n",
      "epoch 222 loss = 1.590047\n",
      "epoch 223 loss = 1.828188\n",
      "epoch 224 loss = 1.617468\n",
      "epoch 225 loss = 1.617963\n",
      "epoch 226 loss = 1.502749\n",
      "epoch 227 loss = 1.813670\n",
      "epoch 228 loss = 1.837208\n",
      "epoch 229 loss = 1.730238\n",
      "epoch 230 loss = 1.771089\n",
      "epoch 231 loss = 1.519918\n",
      "epoch 232 loss = 1.918218\n",
      "epoch 233 loss = 1.630913\n",
      "epoch 234 loss = 1.750388\n",
      "epoch 235 loss = 1.722302\n",
      "epoch 236 loss = 1.438468\n",
      "epoch 237 loss = 1.631193\n",
      "epoch 238 loss = 1.478334\n",
      "epoch 239 loss = 1.517381\n",
      "epoch 240 loss = 1.733372\n",
      "epoch 241 loss = 1.481430\n",
      "epoch 242 loss = 1.674043\n",
      "epoch 243 loss = 1.770472\n",
      "epoch 244 loss = 1.925463\n",
      "epoch 245 loss = 1.766374\n",
      "epoch 246 loss = 1.574938\n",
      "epoch 247 loss = 1.574359\n",
      "epoch 248 loss = 1.547079\n",
      "epoch 249 loss = 1.740124\n",
      "epoch 250 loss = 1.631470\n",
      "epoch 251 loss = 1.484610\n",
      "epoch 252 loss = 1.641046\n",
      "epoch 253 loss = 1.694269\n",
      "epoch 254 loss = 1.697181\n",
      "epoch 255 loss = 1.515482\n",
      "epoch 256 loss = 1.679839\n",
      "epoch 257 loss = 1.784112\n",
      "epoch 258 loss = 1.810025\n",
      "epoch 259 loss = 1.770819\n",
      "epoch 260 loss = 1.718476\n",
      "epoch 261 loss = 1.520993\n",
      "epoch 262 loss = 1.595151\n",
      "epoch 263 loss = 1.826030\n",
      "epoch 264 loss = 1.696674\n",
      "epoch 265 loss = 1.857580\n",
      "epoch 266 loss = 1.618819\n",
      "epoch 267 loss = 1.797547\n",
      "epoch 268 loss = 1.628999\n",
      "epoch 269 loss = 2.056283\n",
      "epoch 270 loss = 1.788957\n",
      "epoch 271 loss = 1.434174\n",
      "epoch 272 loss = 1.564274\n",
      "epoch 273 loss = 1.656611\n",
      "epoch 274 loss = 1.751271\n",
      "epoch 275 loss = 1.669562\n",
      "epoch 276 loss = 1.650207\n",
      "epoch 277 loss = 1.875424\n",
      "epoch 278 loss = 1.614152\n",
      "epoch 279 loss = 1.780806\n",
      "epoch 280 loss = 1.576878\n",
      "epoch 281 loss = 1.765004\n",
      "epoch 282 loss = 1.612107\n",
      "epoch 283 loss = 1.423967\n",
      "epoch 284 loss = 1.628268\n",
      "epoch 285 loss = 1.749763\n",
      "epoch 286 loss = 1.751584\n",
      "epoch 287 loss = 1.653193\n",
      "epoch 288 loss = 1.859629\n",
      "epoch 289 loss = 1.927684\n",
      "epoch 290 loss = 1.476592\n",
      "epoch 291 loss = 1.377694\n",
      "epoch 292 loss = 1.673728\n",
      "epoch 293 loss = 1.772844\n",
      "epoch 294 loss = 1.575942\n",
      "epoch 295 loss = 1.756780\n",
      "epoch 296 loss = 1.772717\n",
      "epoch 297 loss = 1.614220\n",
      "epoch 298 loss = 1.706527\n",
      "epoch 299 loss = 1.877012\n",
      "epoch 300 loss = 1.861294\n",
      "epoch 301 loss = 1.705492\n",
      "epoch 302 loss = 1.900090\n",
      "epoch 303 loss = 1.495364\n",
      "epoch 304 loss = 1.837463\n",
      "epoch 305 loss = 1.863920\n",
      "epoch 306 loss = 1.472070\n",
      "epoch 307 loss = 1.730774\n",
      "epoch 308 loss = 1.725238\n",
      "epoch 309 loss = 1.865208\n",
      "epoch 310 loss = 1.646008\n",
      "epoch 311 loss = 1.561317\n",
      "epoch 312 loss = 1.632533\n",
      "epoch 313 loss = 1.365329\n",
      "epoch 314 loss = 1.634198\n",
      "epoch 315 loss = 1.844970\n",
      "epoch 316 loss = 1.676796\n",
      "epoch 317 loss = 1.821443\n",
      "epoch 318 loss = 1.661147\n",
      "epoch 319 loss = 1.600316\n",
      "epoch 320 loss = 1.449924\n",
      "epoch 321 loss = 1.692084\n",
      "epoch 322 loss = 1.827667\n",
      "epoch 323 loss = 1.682519\n",
      "epoch 324 loss = 1.683319\n",
      "epoch 325 loss = 1.341732\n",
      "epoch 326 loss = 1.626776\n",
      "epoch 327 loss = 1.503564\n",
      "epoch 328 loss = 1.786498\n",
      "epoch 329 loss = 1.657489\n",
      "epoch 330 loss = 1.884969\n",
      "epoch 331 loss = 1.547718\n",
      "epoch 332 loss = 1.605797\n",
      "epoch 333 loss = 1.426778\n",
      "epoch 334 loss = 1.671011\n",
      "epoch 335 loss = 1.540577\n",
      "epoch 336 loss = 1.955713\n",
      "epoch 337 loss = 1.805193\n",
      "epoch 338 loss = 1.539465\n",
      "epoch 339 loss = 1.501878\n",
      "epoch 340 loss = 1.738974\n",
      "epoch 341 loss = 1.614359\n",
      "epoch 342 loss = 1.594275\n",
      "epoch 343 loss = 1.627760\n",
      "epoch 344 loss = 1.850259\n",
      "epoch 345 loss = 1.720506\n",
      "epoch 346 loss = 1.722383\n",
      "epoch 347 loss = 1.988129\n",
      "epoch 348 loss = 1.664931\n",
      "epoch 349 loss = 1.657855\n",
      "epoch 350 loss = 1.575887\n",
      "epoch 351 loss = 1.735683\n",
      "epoch 352 loss = 1.653521\n",
      "epoch 353 loss = 1.799103\n",
      "epoch 354 loss = 1.679109\n",
      "epoch 355 loss = 1.601093\n",
      "epoch 356 loss = 1.797849\n",
      "epoch 357 loss = 1.763218\n",
      "epoch 358 loss = 1.699724\n",
      "epoch 359 loss = 1.698349\n",
      "epoch 360 loss = 1.752977\n",
      "epoch 361 loss = 1.828464\n",
      "epoch 362 loss = 1.592332\n",
      "epoch 363 loss = 1.456053\n",
      "epoch 364 loss = 1.516496\n",
      "epoch 365 loss = 1.558645\n",
      "epoch 366 loss = 1.718629\n",
      "epoch 367 loss = 1.382069\n",
      "epoch 368 loss = 1.597685\n",
      "epoch 369 loss = 1.480281\n",
      "epoch 370 loss = 1.661867\n",
      "epoch 371 loss = 1.595238\n",
      "epoch 372 loss = 1.896098\n",
      "epoch 373 loss = 1.751619\n",
      "epoch 374 loss = 1.471979\n",
      "epoch 375 loss = 1.553635\n",
      "epoch 376 loss = 1.937243\n",
      "epoch 377 loss = 1.627187\n",
      "epoch 378 loss = 1.479330\n",
      "epoch 379 loss = 1.607847\n",
      "epoch 380 loss = 1.873024\n",
      "epoch 381 loss = 1.570240\n",
      "epoch 382 loss = 1.535164\n",
      "epoch 383 loss = 1.646245\n",
      "epoch 384 loss = 1.484312\n",
      "epoch 385 loss = 1.688944\n",
      "epoch 386 loss = 1.709471\n",
      "epoch 387 loss = 1.651800\n",
      "epoch 388 loss = 1.709666\n",
      "epoch 389 loss = 1.578009\n",
      "epoch 390 loss = 1.607103\n",
      "epoch 391 loss = 1.570346\n",
      "epoch 392 loss = 1.784638\n",
      "epoch 393 loss = 1.600572\n",
      "epoch 394 loss = 1.733048\n",
      "epoch 395 loss = 1.670307\n",
      "epoch 396 loss = 1.874649\n",
      "epoch 397 loss = 1.764772\n",
      "epoch 398 loss = 1.848452\n",
      "epoch 399 loss = 1.636554\n",
      "epoch 400 loss = 1.627708\n",
      "epoch 401 loss = 1.753462\n",
      "epoch 402 loss = 1.863420\n",
      "epoch 403 loss = 1.870352\n",
      "epoch 404 loss = 1.513238\n",
      "epoch 405 loss = 1.778567\n",
      "epoch 406 loss = 1.542408\n",
      "epoch 407 loss = 1.845181\n",
      "epoch 408 loss = 1.715174\n",
      "epoch 409 loss = 1.634127\n",
      "epoch 410 loss = 1.708297\n",
      "epoch 411 loss = 1.492030\n",
      "epoch 412 loss = 1.492988\n",
      "epoch 413 loss = 1.697431\n",
      "epoch 414 loss = 1.658542\n",
      "epoch 415 loss = 1.454460\n",
      "epoch 416 loss = 1.496378\n",
      "epoch 417 loss = 1.922412\n",
      "epoch 418 loss = 1.635319\n",
      "epoch 419 loss = 1.682604\n",
      "epoch 420 loss = 1.545094\n",
      "epoch 421 loss = 1.623100\n",
      "epoch 422 loss = 1.746786\n",
      "epoch 423 loss = 1.478306\n",
      "epoch 424 loss = 1.897458\n",
      "epoch 425 loss = 1.504833\n",
      "epoch 426 loss = 1.476737\n",
      "epoch 427 loss = 1.320643\n",
      "epoch 428 loss = 1.649963\n",
      "epoch 429 loss = 1.566941\n",
      "epoch 430 loss = 1.717136\n",
      "epoch 431 loss = 1.565677\n",
      "epoch 432 loss = 1.544254\n",
      "epoch 433 loss = 1.529237\n",
      "epoch 434 loss = 1.720439\n",
      "epoch 435 loss = 1.694370\n",
      "epoch 436 loss = 1.796853\n",
      "epoch 437 loss = 1.552534\n",
      "epoch 438 loss = 1.526634\n",
      "epoch 439 loss = 1.568043\n",
      "epoch 440 loss = 1.662338\n",
      "epoch 441 loss = 1.430187\n",
      "epoch 442 loss = 1.575505\n",
      "epoch 443 loss = 1.620956\n",
      "epoch 444 loss = 1.798472\n",
      "epoch 445 loss = 1.547999\n",
      "epoch 446 loss = 1.482051\n",
      "epoch 447 loss = 1.662484\n",
      "epoch 448 loss = 2.045895\n",
      "epoch 449 loss = 1.816405\n",
      "epoch 450 loss = 1.671443\n",
      "epoch 451 loss = 1.547673\n",
      "epoch 452 loss = 1.558075\n",
      "epoch 453 loss = 1.704487\n",
      "epoch 454 loss = 1.714573\n",
      "epoch 455 loss = 1.535055\n",
      "epoch 456 loss = 1.638491\n",
      "epoch 457 loss = 1.549391\n",
      "epoch 458 loss = 1.599825\n",
      "epoch 459 loss = 1.525715\n",
      "epoch 460 loss = 1.775405\n",
      "epoch 461 loss = 1.766733\n",
      "epoch 462 loss = 1.734282\n",
      "epoch 463 loss = 1.611915\n",
      "epoch 464 loss = 1.710178\n",
      "epoch 465 loss = 1.380680\n",
      "epoch 466 loss = 1.695660\n",
      "epoch 467 loss = 1.704176\n",
      "epoch 468 loss = 1.363821\n",
      "epoch 469 loss = 1.604802\n",
      "epoch 470 loss = 1.413481\n",
      "epoch 471 loss = 1.640716\n",
      "epoch 472 loss = 1.607781\n",
      "epoch 473 loss = 1.328095\n",
      "epoch 474 loss = 1.476398\n",
      "epoch 475 loss = 1.844906\n",
      "epoch 476 loss = 1.600215\n",
      "epoch 477 loss = 1.700242\n",
      "epoch 478 loss = 1.755286\n",
      "epoch 479 loss = 1.576747\n",
      "epoch 480 loss = 1.663796\n",
      "epoch 481 loss = 1.663491\n",
      "epoch 482 loss = 1.543550\n",
      "epoch 483 loss = 1.822562\n",
      "epoch 484 loss = 1.512548\n",
      "epoch 485 loss = 1.615713\n",
      "epoch 486 loss = 1.691046\n",
      "epoch 487 loss = 1.327299\n",
      "epoch 488 loss = 1.437510\n",
      "epoch 489 loss = 1.778841\n",
      "epoch 490 loss = 1.663353\n",
      "epoch 491 loss = 1.428730\n",
      "epoch 492 loss = 1.740130\n",
      "epoch 493 loss = 1.582911\n",
      "epoch 494 loss = 1.451762\n",
      "epoch 495 loss = 1.683807\n",
      "epoch 496 loss = 1.783505\n",
      "epoch 497 loss = 1.909719\n",
      "epoch 498 loss = 1.705963\n",
      "epoch 499 loss = 1.836884\n",
      "final loss = 1.836884\n",
      "accuracy_mc = tensor(0.3539, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.3244, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.8288, device='cuda:0')\n",
      "training time = 305.4474081993103 seconds\n",
      "testing time = 3.268876314163208 seconds\n",
      "\n",
      "Training with split 1\n",
      "epoch 0 loss = 2.274534\n",
      "epoch 1 loss = 2.078852\n",
      "epoch 2 loss = 2.214270\n",
      "epoch 3 loss = 2.036765\n",
      "epoch 4 loss = 2.173492\n",
      "epoch 5 loss = 2.021035\n",
      "epoch 6 loss = 1.979636\n",
      "epoch 7 loss = 2.035789\n",
      "epoch 8 loss = 2.276239\n",
      "epoch 9 loss = 2.042680\n",
      "epoch 10 loss = 2.124681\n",
      "epoch 11 loss = 1.925037\n",
      "epoch 12 loss = 1.909770\n",
      "epoch 13 loss = 2.138180\n",
      "epoch 14 loss = 1.987028\n",
      "epoch 15 loss = 2.188095\n",
      "epoch 16 loss = 2.024985\n",
      "epoch 17 loss = 1.964976\n",
      "epoch 18 loss = 1.910835\n",
      "epoch 19 loss = 2.091194\n",
      "epoch 20 loss = 1.989081\n",
      "epoch 21 loss = 2.005159\n",
      "epoch 22 loss = 1.808359\n",
      "epoch 23 loss = 2.006819\n",
      "epoch 24 loss = 2.118716\n",
      "epoch 25 loss = 1.791713\n",
      "epoch 26 loss = 1.730367\n",
      "epoch 27 loss = 1.862050\n",
      "epoch 28 loss = 1.800088\n",
      "epoch 29 loss = 2.073501\n",
      "epoch 30 loss = 1.833882\n",
      "epoch 31 loss = 1.761414\n",
      "epoch 32 loss = 1.861115\n",
      "epoch 33 loss = 2.020595\n",
      "epoch 34 loss = 1.889896\n",
      "epoch 35 loss = 1.748852\n",
      "epoch 36 loss = 1.818574\n",
      "epoch 37 loss = 1.968561\n",
      "epoch 38 loss = 1.892514\n",
      "epoch 39 loss = 2.002851\n",
      "epoch 40 loss = 1.861143\n",
      "epoch 41 loss = 1.890842\n",
      "epoch 42 loss = 1.782399\n",
      "epoch 43 loss = 1.863769\n",
      "epoch 44 loss = 1.679936\n",
      "epoch 45 loss = 1.979676\n",
      "epoch 46 loss = 1.963706\n",
      "epoch 47 loss = 1.902464\n",
      "epoch 48 loss = 1.979393\n",
      "epoch 49 loss = 1.933064\n",
      "epoch 50 loss = 1.802561\n",
      "epoch 51 loss = 1.811499\n",
      "epoch 52 loss = 1.604478\n",
      "epoch 53 loss = 1.887493\n",
      "epoch 54 loss = 1.898260\n",
      "epoch 55 loss = 1.737773\n",
      "epoch 56 loss = 1.662083\n",
      "epoch 57 loss = 1.772152\n",
      "epoch 58 loss = 1.939463\n",
      "epoch 59 loss = 1.739757\n",
      "epoch 60 loss = 1.615950\n",
      "epoch 61 loss = 1.933946\n",
      "epoch 62 loss = 1.920781\n",
      "epoch 63 loss = 1.665147\n",
      "epoch 64 loss = 1.955739\n",
      "epoch 65 loss = 1.921783\n",
      "epoch 66 loss = 1.996199\n",
      "epoch 67 loss = 1.908805\n",
      "epoch 68 loss = 1.535689\n",
      "epoch 69 loss = 1.989710\n",
      "epoch 70 loss = 1.737352\n",
      "epoch 71 loss = 1.809571\n",
      "epoch 72 loss = 1.671283\n",
      "epoch 73 loss = 1.861890\n",
      "epoch 74 loss = 1.569870\n",
      "epoch 75 loss = 1.925818\n",
      "epoch 76 loss = 1.736997\n",
      "epoch 77 loss = 2.080497\n",
      "epoch 78 loss = 1.546085\n",
      "epoch 79 loss = 1.807026\n",
      "epoch 80 loss = 1.595417\n",
      "epoch 81 loss = 1.729725\n",
      "epoch 82 loss = 1.647196\n",
      "epoch 83 loss = 1.726293\n",
      "epoch 84 loss = 1.595768\n",
      "epoch 85 loss = 1.903453\n",
      "epoch 86 loss = 1.635634\n",
      "epoch 87 loss = 1.641826\n",
      "epoch 88 loss = 1.524850\n",
      "epoch 89 loss = 1.756094\n",
      "epoch 90 loss = 1.689302\n",
      "epoch 91 loss = 1.542715\n",
      "epoch 92 loss = 2.053229\n",
      "epoch 93 loss = 1.613891\n",
      "epoch 94 loss = 1.467145\n",
      "epoch 95 loss = 1.684750\n",
      "epoch 96 loss = 1.761539\n",
      "epoch 97 loss = 1.862334\n",
      "epoch 98 loss = 1.636607\n",
      "epoch 99 loss = 1.699022\n",
      "epoch 100 loss = 1.859522\n",
      "epoch 101 loss = 1.831723\n",
      "epoch 102 loss = 1.844798\n",
      "epoch 103 loss = 1.686134\n",
      "epoch 104 loss = 1.662726\n",
      "epoch 105 loss = 1.695792\n",
      "epoch 106 loss = 1.725053\n",
      "epoch 107 loss = 1.979831\n",
      "epoch 108 loss = 1.651902\n",
      "epoch 109 loss = 1.832899\n",
      "epoch 110 loss = 1.580737\n",
      "epoch 111 loss = 1.815958\n",
      "epoch 112 loss = 1.818144\n",
      "epoch 113 loss = 1.662332\n",
      "epoch 114 loss = 1.773914\n",
      "epoch 115 loss = 1.739992\n",
      "epoch 116 loss = 1.953822\n",
      "epoch 117 loss = 1.742710\n",
      "epoch 118 loss = 1.665183\n",
      "epoch 119 loss = 1.674191\n",
      "epoch 120 loss = 1.502140\n",
      "epoch 121 loss = 1.551028\n",
      "epoch 122 loss = 1.645218\n",
      "epoch 123 loss = 1.712813\n",
      "epoch 124 loss = 1.529733\n",
      "epoch 125 loss = 1.802018\n",
      "epoch 126 loss = 1.789944\n",
      "epoch 127 loss = 1.752316\n",
      "epoch 128 loss = 1.777905\n",
      "epoch 129 loss = 1.675918\n",
      "epoch 130 loss = 1.762806\n",
      "epoch 131 loss = 1.531969\n",
      "epoch 132 loss = 1.903138\n",
      "epoch 133 loss = 1.558262\n",
      "epoch 134 loss = 1.731611\n",
      "epoch 135 loss = 1.598690\n",
      "epoch 136 loss = 1.619756\n",
      "epoch 137 loss = 1.688990\n",
      "epoch 138 loss = 1.811701\n",
      "epoch 139 loss = 1.567889\n",
      "epoch 140 loss = 1.689153\n",
      "epoch 141 loss = 1.760986\n",
      "epoch 142 loss = 1.675231\n",
      "epoch 143 loss = 1.812579\n",
      "epoch 144 loss = 1.754604\n",
      "epoch 145 loss = 1.674289\n",
      "epoch 146 loss = 1.808925\n",
      "epoch 147 loss = 1.735962\n",
      "epoch 148 loss = 1.591723\n",
      "epoch 149 loss = 1.745093\n",
      "epoch 150 loss = 1.704579\n",
      "epoch 151 loss = 1.713085\n",
      "epoch 152 loss = 1.598209\n",
      "epoch 153 loss = 1.741721\n",
      "epoch 154 loss = 1.802727\n",
      "epoch 155 loss = 1.488037\n",
      "epoch 156 loss = 1.834471\n",
      "epoch 157 loss = 1.734905\n",
      "epoch 158 loss = 1.694618\n",
      "epoch 159 loss = 1.806790\n",
      "epoch 160 loss = 1.752380\n",
      "epoch 161 loss = 1.683892\n",
      "epoch 162 loss = 1.913610\n",
      "epoch 163 loss = 1.791190\n",
      "epoch 164 loss = 1.604569\n",
      "epoch 165 loss = 1.747501\n",
      "epoch 166 loss = 1.736034\n",
      "epoch 167 loss = 1.840697\n",
      "epoch 168 loss = 1.779438\n",
      "epoch 169 loss = 1.592963\n",
      "epoch 170 loss = 1.550880\n",
      "epoch 171 loss = 2.014811\n",
      "epoch 172 loss = 1.805661\n",
      "epoch 173 loss = 1.677562\n",
      "epoch 174 loss = 1.738037\n",
      "epoch 175 loss = 1.548911\n",
      "epoch 176 loss = 1.470697\n",
      "epoch 177 loss = 1.647980\n",
      "epoch 178 loss = 1.787383\n",
      "epoch 179 loss = 1.509455\n",
      "epoch 180 loss = 1.768602\n",
      "epoch 181 loss = 1.893487\n",
      "epoch 182 loss = 1.834719\n",
      "epoch 183 loss = 1.901918\n",
      "epoch 184 loss = 1.662677\n",
      "epoch 185 loss = 1.522487\n",
      "epoch 186 loss = 1.541513\n",
      "epoch 187 loss = 1.764234\n",
      "epoch 188 loss = 1.564960\n",
      "epoch 189 loss = 1.622441\n",
      "epoch 190 loss = 1.602149\n",
      "epoch 191 loss = 1.780971\n",
      "epoch 192 loss = 1.486578\n",
      "epoch 193 loss = 1.595552\n",
      "epoch 194 loss = 1.582224\n",
      "epoch 195 loss = 1.572182\n",
      "epoch 196 loss = 1.936516\n",
      "epoch 197 loss = 1.795471\n",
      "epoch 198 loss = 1.633847\n",
      "epoch 199 loss = 1.681559\n",
      "epoch 200 loss = 1.957389\n",
      "epoch 201 loss = 1.760811\n",
      "epoch 202 loss = 1.700762\n",
      "epoch 203 loss = 1.609489\n",
      "epoch 204 loss = 1.781784\n",
      "epoch 205 loss = 1.839184\n",
      "epoch 206 loss = 1.798231\n",
      "epoch 207 loss = 1.687606\n",
      "epoch 208 loss = 1.923804\n",
      "epoch 209 loss = 1.860998\n",
      "epoch 210 loss = 1.623917\n",
      "epoch 211 loss = 1.626616\n",
      "epoch 212 loss = 1.670188\n",
      "epoch 213 loss = 1.685237\n",
      "epoch 214 loss = 1.615489\n",
      "epoch 215 loss = 2.122100\n",
      "epoch 216 loss = 1.786559\n",
      "epoch 217 loss = 1.682015\n",
      "epoch 218 loss = 1.851194\n",
      "epoch 219 loss = 1.920984\n",
      "epoch 220 loss = 1.783458\n",
      "epoch 221 loss = 1.598660\n",
      "epoch 222 loss = 1.564101\n",
      "epoch 223 loss = 1.635181\n",
      "epoch 224 loss = 1.783883\n",
      "epoch 225 loss = 1.653412\n",
      "epoch 226 loss = 1.504165\n",
      "epoch 227 loss = 1.758854\n",
      "epoch 228 loss = 1.808235\n",
      "epoch 229 loss = 1.715476\n",
      "epoch 230 loss = 1.799381\n",
      "epoch 231 loss = 1.930877\n",
      "epoch 232 loss = 1.819245\n",
      "epoch 233 loss = 1.569280\n",
      "epoch 234 loss = 1.606763\n",
      "epoch 235 loss = 1.560476\n",
      "epoch 236 loss = 1.569769\n",
      "epoch 237 loss = 1.652897\n",
      "epoch 238 loss = 1.699110\n",
      "epoch 239 loss = 1.810360\n",
      "epoch 240 loss = 1.754579\n",
      "epoch 241 loss = 1.718743\n",
      "epoch 242 loss = 1.577668\n",
      "epoch 243 loss = 1.657163\n",
      "epoch 244 loss = 1.798094\n",
      "epoch 245 loss = 1.730398\n",
      "epoch 246 loss = 1.476453\n",
      "epoch 247 loss = 2.022330\n",
      "epoch 248 loss = 1.666868\n",
      "epoch 249 loss = 1.646910\n",
      "epoch 250 loss = 1.769632\n",
      "epoch 251 loss = 1.544891\n",
      "epoch 252 loss = 1.646565\n",
      "epoch 253 loss = 1.735341\n",
      "epoch 254 loss = 1.878368\n",
      "epoch 255 loss = 1.708633\n",
      "epoch 256 loss = 1.574468\n",
      "epoch 257 loss = 1.564493\n",
      "epoch 258 loss = 1.793992\n",
      "epoch 259 loss = 1.718400\n",
      "epoch 260 loss = 1.854596\n",
      "epoch 261 loss = 1.848242\n",
      "epoch 262 loss = 1.760715\n",
      "epoch 263 loss = 1.662519\n",
      "epoch 264 loss = 1.694085\n",
      "epoch 265 loss = 1.800935\n",
      "epoch 266 loss = 1.713383\n",
      "epoch 267 loss = 1.829434\n",
      "epoch 268 loss = 1.521482\n",
      "epoch 269 loss = 1.781208\n",
      "epoch 270 loss = 1.608492\n",
      "epoch 271 loss = 1.373303\n",
      "epoch 272 loss = 1.575478\n",
      "epoch 273 loss = 1.750334\n",
      "epoch 274 loss = 1.701880\n",
      "epoch 275 loss = 1.758042\n",
      "epoch 276 loss = 1.506194\n",
      "epoch 277 loss = 1.687611\n",
      "epoch 278 loss = 1.786160\n",
      "epoch 279 loss = 1.514765\n",
      "epoch 280 loss = 1.783383\n",
      "epoch 281 loss = 1.408633\n",
      "epoch 282 loss = 1.739991\n",
      "epoch 283 loss = 1.557173\n",
      "epoch 284 loss = 1.833631\n",
      "epoch 285 loss = 1.629585\n",
      "epoch 286 loss = 1.597045\n",
      "epoch 287 loss = 1.439314\n",
      "epoch 288 loss = 1.898388\n",
      "epoch 289 loss = 1.669335\n",
      "epoch 290 loss = 1.662098\n",
      "epoch 291 loss = 1.925149\n",
      "epoch 292 loss = 1.786450\n",
      "epoch 293 loss = 1.489633\n",
      "epoch 294 loss = 1.891125\n",
      "epoch 295 loss = 1.730398\n",
      "epoch 296 loss = 1.322278\n",
      "epoch 297 loss = 1.661124\n",
      "epoch 298 loss = 1.530229\n",
      "epoch 299 loss = 1.829519\n",
      "epoch 300 loss = 1.725181\n",
      "epoch 301 loss = 1.489325\n",
      "epoch 302 loss = 1.577154\n",
      "epoch 303 loss = 2.042348\n",
      "epoch 304 loss = 1.674379\n",
      "epoch 305 loss = 1.766255\n",
      "epoch 306 loss = 1.964091\n",
      "epoch 307 loss = 1.738742\n",
      "epoch 308 loss = 1.538725\n",
      "epoch 309 loss = 1.716457\n",
      "epoch 310 loss = 1.650657\n",
      "epoch 311 loss = 1.526504\n",
      "epoch 312 loss = 1.783172\n",
      "epoch 313 loss = 1.568793\n",
      "epoch 314 loss = 1.529173\n",
      "epoch 315 loss = 1.559033\n",
      "epoch 316 loss = 1.664751\n",
      "epoch 317 loss = 1.545118\n",
      "epoch 318 loss = 1.707145\n",
      "epoch 319 loss = 1.779583\n",
      "epoch 320 loss = 1.708904\n",
      "epoch 321 loss = 1.590177\n",
      "epoch 322 loss = 1.902647\n",
      "epoch 323 loss = 1.510863\n",
      "epoch 324 loss = 1.626483\n",
      "epoch 325 loss = 1.626061\n",
      "epoch 326 loss = 1.514317\n",
      "epoch 327 loss = 1.520829\n",
      "epoch 328 loss = 1.961212\n",
      "epoch 329 loss = 1.742106\n",
      "epoch 330 loss = 1.539495\n",
      "epoch 331 loss = 1.541449\n",
      "epoch 332 loss = 1.531779\n",
      "epoch 333 loss = 1.708668\n",
      "epoch 334 loss = 1.848039\n",
      "epoch 335 loss = 1.732759\n",
      "epoch 336 loss = 1.708143\n",
      "epoch 337 loss = 1.621348\n",
      "epoch 338 loss = 1.819270\n",
      "epoch 339 loss = 1.547736\n",
      "epoch 340 loss = 1.652546\n",
      "epoch 341 loss = 1.609923\n",
      "epoch 342 loss = 1.482997\n",
      "epoch 343 loss = 1.550137\n",
      "epoch 344 loss = 1.631284\n",
      "epoch 345 loss = 1.606400\n",
      "epoch 346 loss = 1.678163\n",
      "epoch 347 loss = 1.596975\n",
      "epoch 348 loss = 1.889559\n",
      "epoch 349 loss = 1.424097\n",
      "epoch 350 loss = 1.625201\n",
      "epoch 351 loss = 1.605230\n",
      "epoch 352 loss = 1.644895\n",
      "epoch 353 loss = 1.386407\n",
      "epoch 354 loss = 1.531107\n",
      "epoch 355 loss = 1.834180\n",
      "epoch 356 loss = 1.971065\n",
      "epoch 357 loss = 1.763754\n",
      "epoch 358 loss = 1.667703\n",
      "epoch 359 loss = 1.485327\n",
      "epoch 360 loss = 1.449252\n",
      "epoch 361 loss = 1.754727\n",
      "epoch 362 loss = 1.616934\n",
      "epoch 363 loss = 1.746244\n",
      "epoch 364 loss = 1.711786\n",
      "epoch 365 loss = 1.703931\n",
      "epoch 366 loss = 1.510588\n",
      "epoch 367 loss = 1.673553\n",
      "epoch 368 loss = 1.842682\n",
      "epoch 369 loss = 1.389878\n",
      "epoch 370 loss = 1.881481\n",
      "epoch 371 loss = 1.525448\n",
      "epoch 372 loss = 1.526737\n",
      "epoch 373 loss = 1.583156\n",
      "epoch 374 loss = 1.718520\n",
      "epoch 375 loss = 1.654729\n",
      "epoch 376 loss = 1.467753\n",
      "epoch 377 loss = 1.504189\n",
      "epoch 378 loss = 1.564214\n",
      "epoch 379 loss = 1.591074\n",
      "epoch 380 loss = 1.418863\n",
      "epoch 381 loss = 1.348640\n",
      "epoch 382 loss = 1.574484\n",
      "epoch 383 loss = 1.704974\n",
      "epoch 384 loss = 1.654526\n",
      "epoch 385 loss = 1.689799\n",
      "epoch 386 loss = 1.798147\n",
      "epoch 387 loss = 1.900540\n",
      "epoch 388 loss = 1.911541\n",
      "epoch 389 loss = 1.622746\n",
      "epoch 390 loss = 1.906295\n",
      "epoch 391 loss = 1.654893\n",
      "epoch 392 loss = 1.829678\n",
      "epoch 393 loss = 1.556557\n",
      "epoch 394 loss = 1.602469\n",
      "epoch 395 loss = 1.662018\n",
      "epoch 396 loss = 1.917402\n",
      "epoch 397 loss = 1.777103\n",
      "epoch 398 loss = 1.748418\n",
      "epoch 399 loss = 1.430328\n",
      "epoch 400 loss = 1.627394\n",
      "epoch 401 loss = 1.529068\n",
      "epoch 402 loss = 1.526499\n",
      "epoch 403 loss = 1.673659\n",
      "epoch 404 loss = 1.510999\n",
      "epoch 405 loss = 1.440624\n",
      "epoch 406 loss = 1.802263\n",
      "epoch 407 loss = 1.700061\n",
      "epoch 408 loss = 1.608137\n",
      "epoch 409 loss = 1.522393\n",
      "epoch 410 loss = 1.679767\n",
      "epoch 411 loss = 1.722670\n",
      "epoch 412 loss = 1.749323\n",
      "epoch 413 loss = 1.740817\n",
      "epoch 414 loss = 1.498536\n",
      "epoch 415 loss = 1.756061\n",
      "epoch 416 loss = 1.682657\n",
      "epoch 417 loss = 1.696401\n",
      "epoch 418 loss = 1.644714\n",
      "epoch 419 loss = 1.778370\n",
      "epoch 420 loss = 1.829182\n",
      "epoch 421 loss = 1.689636\n",
      "epoch 422 loss = 1.525162\n",
      "epoch 423 loss = 1.683470\n",
      "epoch 424 loss = 1.568770\n",
      "epoch 425 loss = 1.667319\n",
      "epoch 426 loss = 1.589082\n",
      "epoch 427 loss = 1.552471\n",
      "epoch 428 loss = 1.804720\n",
      "epoch 429 loss = 1.497500\n",
      "epoch 430 loss = 1.685440\n",
      "epoch 431 loss = 1.636872\n",
      "epoch 432 loss = 1.546840\n",
      "epoch 433 loss = 1.758704\n",
      "epoch 434 loss = 1.686991\n",
      "epoch 435 loss = 1.513295\n",
      "epoch 436 loss = 1.409066\n",
      "epoch 437 loss = 1.653341\n",
      "epoch 438 loss = 1.676481\n",
      "epoch 439 loss = 1.518642\n",
      "epoch 440 loss = 1.669133\n",
      "epoch 441 loss = 1.640495\n",
      "epoch 442 loss = 1.623070\n",
      "epoch 443 loss = 1.654930\n",
      "epoch 444 loss = 1.660334\n",
      "epoch 445 loss = 1.995257\n",
      "epoch 446 loss = 1.467315\n",
      "epoch 447 loss = 1.672317\n",
      "epoch 448 loss = 1.913061\n",
      "epoch 449 loss = 1.716764\n",
      "epoch 450 loss = 1.859251\n",
      "epoch 451 loss = 1.737438\n",
      "epoch 452 loss = 1.719331\n",
      "epoch 453 loss = 1.923636\n",
      "epoch 454 loss = 1.510578\n",
      "epoch 455 loss = 1.644885\n",
      "epoch 456 loss = 1.632544\n",
      "epoch 457 loss = 1.613089\n",
      "epoch 458 loss = 1.595855\n",
      "epoch 459 loss = 1.835317\n",
      "epoch 460 loss = 1.536691\n",
      "epoch 461 loss = 1.712028\n",
      "epoch 462 loss = 1.791156\n",
      "epoch 463 loss = 1.666622\n",
      "epoch 464 loss = 1.433059\n",
      "epoch 465 loss = 1.634843\n",
      "epoch 466 loss = 1.423600\n",
      "epoch 467 loss = 1.803254\n",
      "epoch 468 loss = 1.611343\n",
      "epoch 469 loss = 1.690794\n",
      "epoch 470 loss = 1.680941\n",
      "epoch 471 loss = 1.704628\n",
      "epoch 472 loss = 1.750630\n",
      "epoch 473 loss = 1.654204\n",
      "epoch 474 loss = 1.603795\n",
      "epoch 475 loss = 1.556662\n",
      "epoch 476 loss = 1.571211\n",
      "epoch 477 loss = 1.722355\n",
      "epoch 478 loss = 1.654266\n",
      "epoch 479 loss = 1.659641\n",
      "epoch 480 loss = 1.410412\n",
      "epoch 481 loss = 1.873627\n",
      "epoch 482 loss = 1.553771\n",
      "epoch 483 loss = 1.648277\n",
      "epoch 484 loss = 1.710823\n",
      "epoch 485 loss = 1.603220\n",
      "epoch 486 loss = 1.977468\n",
      "epoch 487 loss = 1.785524\n",
      "epoch 488 loss = 1.744537\n",
      "epoch 489 loss = 1.587288\n",
      "epoch 490 loss = 1.628343\n",
      "epoch 491 loss = 1.643069\n",
      "epoch 492 loss = 1.467535\n",
      "epoch 493 loss = 1.589947\n",
      "epoch 494 loss = 1.683966\n",
      "epoch 495 loss = 1.515392\n",
      "epoch 496 loss = 1.571306\n",
      "epoch 497 loss = 1.558657\n",
      "epoch 498 loss = 1.564334\n",
      "epoch 499 loss = 1.369591\n",
      "final loss = 1.369591\n",
      "accuracy_mc = tensor(0.3724, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.3629, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.7492, device='cuda:0')\n",
      "training time = 305.93630623817444 seconds\n",
      "testing time = 3.207557439804077 seconds\n",
      "\n",
      "Training with split 2\n",
      "epoch 0 loss = 2.267319\n",
      "epoch 1 loss = 2.131224\n",
      "epoch 2 loss = 2.084084\n",
      "epoch 3 loss = 2.161952\n",
      "epoch 4 loss = 2.113919\n",
      "epoch 5 loss = 2.087002\n",
      "epoch 6 loss = 2.058775\n",
      "epoch 7 loss = 2.026273\n",
      "epoch 8 loss = 2.108905\n",
      "epoch 9 loss = 2.101061\n",
      "epoch 10 loss = 1.926615\n",
      "epoch 11 loss = 2.048565\n",
      "epoch 12 loss = 1.978083\n",
      "epoch 13 loss = 2.099622\n",
      "epoch 14 loss = 1.905173\n",
      "epoch 15 loss = 1.987046\n",
      "epoch 16 loss = 1.981959\n",
      "epoch 17 loss = 2.023653\n",
      "epoch 18 loss = 2.018145\n",
      "epoch 19 loss = 1.876578\n",
      "epoch 20 loss = 1.925300\n",
      "epoch 21 loss = 2.061690\n",
      "epoch 22 loss = 2.085757\n",
      "epoch 23 loss = 1.807399\n",
      "epoch 24 loss = 1.943274\n",
      "epoch 25 loss = 1.907474\n",
      "epoch 26 loss = 2.008291\n",
      "epoch 27 loss = 1.861369\n",
      "epoch 28 loss = 2.121550\n",
      "epoch 29 loss = 1.875042\n",
      "epoch 30 loss = 1.893965\n",
      "epoch 31 loss = 1.896150\n",
      "epoch 32 loss = 1.841501\n",
      "epoch 33 loss = 1.957681\n",
      "epoch 34 loss = 2.080934\n",
      "epoch 35 loss = 2.013605\n",
      "epoch 36 loss = 2.012299\n",
      "epoch 37 loss = 1.878538\n",
      "epoch 38 loss = 1.803858\n",
      "epoch 39 loss = 2.187854\n",
      "epoch 40 loss = 1.946306\n",
      "epoch 41 loss = 1.777436\n",
      "epoch 42 loss = 1.909567\n",
      "epoch 43 loss = 1.848988\n",
      "epoch 44 loss = 1.832677\n",
      "epoch 45 loss = 1.766194\n",
      "epoch 46 loss = 1.792984\n",
      "epoch 47 loss = 1.846619\n",
      "epoch 48 loss = 1.919639\n",
      "epoch 49 loss = 1.776259\n",
      "epoch 50 loss = 1.895373\n",
      "epoch 51 loss = 1.880372\n",
      "epoch 52 loss = 1.792629\n",
      "epoch 53 loss = 1.823619\n",
      "epoch 54 loss = 1.773261\n",
      "epoch 55 loss = 1.918492\n",
      "epoch 56 loss = 1.983175\n",
      "epoch 57 loss = 1.768561\n",
      "epoch 58 loss = 1.694420\n",
      "epoch 59 loss = 1.899552\n",
      "epoch 60 loss = 1.829055\n",
      "epoch 61 loss = 1.660899\n",
      "epoch 62 loss = 1.896941\n",
      "epoch 63 loss = 1.963450\n",
      "epoch 64 loss = 1.695631\n",
      "epoch 65 loss = 1.836512\n",
      "epoch 66 loss = 1.813342\n",
      "epoch 67 loss = 1.757262\n",
      "epoch 68 loss = 1.727149\n",
      "epoch 69 loss = 1.778052\n",
      "epoch 70 loss = 1.780623\n",
      "epoch 71 loss = 1.733037\n",
      "epoch 72 loss = 1.625939\n",
      "epoch 73 loss = 1.660290\n",
      "epoch 74 loss = 1.899260\n",
      "epoch 75 loss = 1.663102\n",
      "epoch 76 loss = 1.824049\n",
      "epoch 77 loss = 1.766610\n",
      "epoch 78 loss = 1.724651\n",
      "epoch 79 loss = 1.801550\n",
      "epoch 80 loss = 1.884402\n",
      "epoch 81 loss = 1.699962\n",
      "epoch 82 loss = 1.625394\n",
      "epoch 83 loss = 1.829660\n",
      "epoch 84 loss = 1.960682\n",
      "epoch 85 loss = 1.812834\n",
      "epoch 86 loss = 1.879780\n",
      "epoch 87 loss = 1.697588\n",
      "epoch 88 loss = 1.914944\n",
      "epoch 89 loss = 1.765421\n",
      "epoch 90 loss = 1.694374\n",
      "epoch 91 loss = 1.698237\n",
      "epoch 92 loss = 1.727427\n",
      "epoch 93 loss = 1.772844\n",
      "epoch 94 loss = 1.812709\n",
      "epoch 95 loss = 1.739606\n",
      "epoch 96 loss = 1.795623\n",
      "epoch 97 loss = 1.915233\n",
      "epoch 98 loss = 1.826311\n",
      "epoch 99 loss = 1.807866\n",
      "epoch 100 loss = 1.628996\n",
      "epoch 101 loss = 1.860577\n",
      "epoch 102 loss = 1.642276\n",
      "epoch 103 loss = 1.837858\n",
      "epoch 104 loss = 1.802836\n",
      "epoch 105 loss = 1.727294\n",
      "epoch 106 loss = 1.847726\n",
      "epoch 107 loss = 1.931652\n",
      "epoch 108 loss = 2.068081\n",
      "epoch 109 loss = 1.823246\n",
      "epoch 110 loss = 1.827701\n",
      "epoch 111 loss = 1.700774\n",
      "epoch 112 loss = 1.783606\n",
      "epoch 113 loss = 1.815831\n",
      "epoch 114 loss = 1.695609\n",
      "epoch 115 loss = 1.822019\n",
      "epoch 116 loss = 1.506316\n",
      "epoch 117 loss = 1.741324\n",
      "epoch 118 loss = 1.839680\n",
      "epoch 119 loss = 1.688169\n",
      "epoch 120 loss = 1.680470\n",
      "epoch 121 loss = 1.630821\n",
      "epoch 122 loss = 1.872868\n",
      "epoch 123 loss = 1.797531\n",
      "epoch 124 loss = 1.581870\n",
      "epoch 125 loss = 1.860943\n",
      "epoch 126 loss = 1.665839\n",
      "epoch 127 loss = 1.931005\n",
      "epoch 128 loss = 1.791149\n",
      "epoch 129 loss = 1.730308\n",
      "epoch 130 loss = 1.664947\n",
      "epoch 131 loss = 1.673752\n",
      "epoch 132 loss = 1.742302\n",
      "epoch 133 loss = 1.643940\n",
      "epoch 134 loss = 1.732012\n",
      "epoch 135 loss = 1.624284\n",
      "epoch 136 loss = 1.818642\n",
      "epoch 137 loss = 1.691196\n",
      "epoch 138 loss = 1.778814\n",
      "epoch 139 loss = 1.636234\n",
      "epoch 140 loss = 1.745098\n",
      "epoch 141 loss = 1.810633\n",
      "epoch 142 loss = 1.630077\n",
      "epoch 143 loss = 2.004025\n",
      "epoch 144 loss = 1.933252\n",
      "epoch 145 loss = 1.794457\n",
      "epoch 146 loss = 1.785766\n",
      "epoch 147 loss = 1.735787\n",
      "epoch 148 loss = 1.536138\n",
      "epoch 149 loss = 1.732200\n",
      "epoch 150 loss = 2.015585\n",
      "epoch 151 loss = 1.815389\n",
      "epoch 152 loss = 1.672473\n",
      "epoch 153 loss = 1.709022\n",
      "epoch 154 loss = 1.804359\n",
      "epoch 155 loss = 1.706220\n",
      "epoch 156 loss = 1.583052\n",
      "epoch 157 loss = 1.687920\n",
      "epoch 158 loss = 1.676952\n",
      "epoch 159 loss = 1.680806\n",
      "epoch 160 loss = 1.614038\n",
      "epoch 161 loss = 1.750063\n",
      "epoch 162 loss = 1.609571\n",
      "epoch 163 loss = 1.705296\n",
      "epoch 164 loss = 1.885355\n",
      "epoch 165 loss = 1.491907\n",
      "epoch 166 loss = 1.864096\n",
      "epoch 167 loss = 1.609171\n",
      "epoch 168 loss = 1.780664\n",
      "epoch 169 loss = 1.726439\n",
      "epoch 170 loss = 1.730623\n",
      "epoch 171 loss = 1.660216\n",
      "epoch 172 loss = 1.680864\n",
      "epoch 173 loss = 1.866137\n",
      "epoch 174 loss = 1.621780\n",
      "epoch 175 loss = 1.628618\n",
      "epoch 176 loss = 1.570852\n",
      "epoch 177 loss = 1.754470\n",
      "epoch 178 loss = 1.693841\n",
      "epoch 179 loss = 1.643737\n",
      "epoch 180 loss = 1.768526\n",
      "epoch 181 loss = 1.647807\n",
      "epoch 182 loss = 1.755386\n",
      "epoch 183 loss = 1.860712\n",
      "epoch 184 loss = 1.873771\n",
      "epoch 185 loss = 1.796023\n",
      "epoch 186 loss = 1.794182\n",
      "epoch 187 loss = 1.549292\n",
      "epoch 188 loss = 1.639175\n",
      "epoch 189 loss = 1.761414\n",
      "epoch 190 loss = 1.715127\n",
      "epoch 191 loss = 1.697674\n",
      "epoch 192 loss = 1.710319\n",
      "epoch 193 loss = 1.725971\n",
      "epoch 194 loss = 1.856455\n",
      "epoch 195 loss = 1.790762\n",
      "epoch 196 loss = 1.726143\n",
      "epoch 197 loss = 1.650974\n",
      "epoch 198 loss = 1.705088\n",
      "epoch 199 loss = 1.629173\n",
      "epoch 200 loss = 1.674344\n",
      "epoch 201 loss = 1.660240\n",
      "epoch 202 loss = 1.776911\n",
      "epoch 203 loss = 1.816274\n",
      "epoch 204 loss = 1.882627\n",
      "epoch 205 loss = 1.675158\n",
      "epoch 206 loss = 1.858356\n",
      "epoch 207 loss = 1.592077\n",
      "epoch 208 loss = 1.571643\n",
      "epoch 209 loss = 1.769973\n",
      "epoch 210 loss = 1.846777\n",
      "epoch 211 loss = 1.733878\n",
      "epoch 212 loss = 1.659643\n",
      "epoch 213 loss = 1.794668\n",
      "epoch 214 loss = 1.735224\n",
      "epoch 215 loss = 1.735313\n",
      "epoch 216 loss = 1.492614\n",
      "epoch 217 loss = 1.814805\n",
      "epoch 218 loss = 1.646793\n",
      "epoch 219 loss = 1.695440\n",
      "epoch 220 loss = 1.693518\n",
      "epoch 221 loss = 1.532348\n",
      "epoch 222 loss = 1.630979\n",
      "epoch 223 loss = 1.786865\n",
      "epoch 224 loss = 1.770388\n",
      "epoch 225 loss = 1.795659\n",
      "epoch 226 loss = 1.723508\n",
      "epoch 227 loss = 1.716303\n",
      "epoch 228 loss = 1.714294\n",
      "epoch 229 loss = 1.535417\n",
      "epoch 230 loss = 1.740698\n",
      "epoch 231 loss = 1.600112\n",
      "epoch 232 loss = 1.592398\n",
      "epoch 233 loss = 1.735394\n",
      "epoch 234 loss = 1.735963\n",
      "epoch 235 loss = 1.707783\n",
      "epoch 236 loss = 1.563806\n",
      "epoch 237 loss = 1.790754\n",
      "epoch 238 loss = 1.746195\n",
      "epoch 239 loss = 1.776641\n",
      "epoch 240 loss = 1.801036\n",
      "epoch 241 loss = 1.476304\n",
      "epoch 242 loss = 1.815690\n",
      "epoch 243 loss = 1.350522\n",
      "epoch 244 loss = 1.730369\n",
      "epoch 245 loss = 1.608073\n",
      "epoch 246 loss = 1.695927\n",
      "epoch 247 loss = 1.575863\n",
      "epoch 248 loss = 1.648962\n",
      "epoch 249 loss = 1.646066\n",
      "epoch 250 loss = 1.399218\n",
      "epoch 251 loss = 1.755310\n",
      "epoch 252 loss = 1.490391\n",
      "epoch 253 loss = 1.684532\n",
      "epoch 254 loss = 1.690703\n",
      "epoch 255 loss = 1.501410\n",
      "epoch 256 loss = 1.545087\n",
      "epoch 257 loss = 1.591845\n",
      "epoch 258 loss = 1.695281\n",
      "epoch 259 loss = 1.547204\n",
      "epoch 260 loss = 1.871232\n",
      "epoch 261 loss = 2.002527\n",
      "epoch 262 loss = 2.043492\n",
      "epoch 263 loss = 1.694957\n",
      "epoch 264 loss = 1.857220\n",
      "epoch 265 loss = 2.109836\n",
      "epoch 266 loss = 1.627128\n",
      "epoch 267 loss = 1.801318\n",
      "epoch 268 loss = 1.810909\n",
      "epoch 269 loss = 1.801317\n",
      "epoch 270 loss = 1.583763\n",
      "epoch 271 loss = 1.739530\n",
      "epoch 272 loss = 1.778893\n",
      "epoch 273 loss = 1.576744\n",
      "epoch 274 loss = 1.599268\n",
      "epoch 275 loss = 1.475318\n",
      "epoch 276 loss = 1.511509\n",
      "epoch 277 loss = 1.832159\n",
      "epoch 278 loss = 1.994342\n",
      "epoch 279 loss = 1.713046\n",
      "epoch 280 loss = 1.418559\n",
      "epoch 281 loss = 1.568559\n",
      "epoch 282 loss = 1.673171\n",
      "epoch 283 loss = 1.815765\n",
      "epoch 284 loss = 1.490740\n",
      "epoch 285 loss = 1.405691\n",
      "epoch 286 loss = 1.696207\n",
      "epoch 287 loss = 1.761656\n",
      "epoch 288 loss = 1.547155\n",
      "epoch 289 loss = 1.590827\n",
      "epoch 290 loss = 1.453189\n",
      "epoch 291 loss = 1.764292\n",
      "epoch 292 loss = 2.004015\n",
      "epoch 293 loss = 1.752317\n",
      "epoch 294 loss = 1.720741\n",
      "epoch 295 loss = 1.959737\n",
      "epoch 296 loss = 1.505957\n",
      "epoch 297 loss = 1.782376\n",
      "epoch 298 loss = 1.774152\n",
      "epoch 299 loss = 1.795432\n",
      "epoch 300 loss = 1.821374\n",
      "epoch 301 loss = 1.677835\n",
      "epoch 302 loss = 1.571541\n",
      "epoch 303 loss = 1.897498\n",
      "epoch 304 loss = 1.364960\n",
      "epoch 305 loss = 1.796309\n",
      "epoch 306 loss = 1.577530\n",
      "epoch 307 loss = 1.618880\n",
      "epoch 308 loss = 1.918864\n",
      "epoch 309 loss = 1.469828\n",
      "epoch 310 loss = 1.934766\n",
      "epoch 311 loss = 1.651009\n",
      "epoch 312 loss = 1.524102\n",
      "epoch 313 loss = 1.634596\n",
      "epoch 314 loss = 1.653948\n",
      "epoch 315 loss = 2.052478\n",
      "epoch 316 loss = 1.761750\n",
      "epoch 317 loss = 1.747147\n",
      "epoch 318 loss = 1.647877\n",
      "epoch 319 loss = 1.906608\n",
      "epoch 320 loss = 1.720867\n",
      "epoch 321 loss = 1.763922\n",
      "epoch 322 loss = 1.618310\n",
      "epoch 323 loss = 1.681222\n",
      "epoch 324 loss = 1.818310\n",
      "epoch 325 loss = 1.718140\n",
      "epoch 326 loss = 1.642393\n",
      "epoch 327 loss = 1.860268\n",
      "epoch 328 loss = 1.595766\n",
      "epoch 329 loss = 1.920428\n",
      "epoch 330 loss = 1.496650\n",
      "epoch 331 loss = 1.458905\n",
      "epoch 332 loss = 1.966753\n",
      "epoch 333 loss = 1.416736\n",
      "epoch 334 loss = 1.416375\n",
      "epoch 335 loss = 1.771527\n",
      "epoch 336 loss = 1.723776\n",
      "epoch 337 loss = 1.679133\n",
      "epoch 338 loss = 1.585647\n",
      "epoch 339 loss = 1.856325\n",
      "epoch 340 loss = 1.474753\n",
      "epoch 341 loss = 1.746878\n",
      "epoch 342 loss = 1.671853\n",
      "epoch 343 loss = 1.843044\n",
      "epoch 344 loss = 1.441661\n",
      "epoch 345 loss = 1.476869\n",
      "epoch 346 loss = 1.742551\n",
      "epoch 347 loss = 1.694985\n",
      "epoch 348 loss = 1.547864\n",
      "epoch 349 loss = 1.846470\n",
      "epoch 350 loss = 1.512130\n",
      "epoch 351 loss = 1.567604\n",
      "epoch 352 loss = 1.573761\n",
      "epoch 353 loss = 1.490787\n",
      "epoch 354 loss = 1.651401\n",
      "epoch 355 loss = 1.443382\n",
      "epoch 356 loss = 1.479686\n",
      "epoch 357 loss = 1.731709\n",
      "epoch 358 loss = 1.843618\n",
      "epoch 359 loss = 1.508116\n",
      "epoch 360 loss = 1.614275\n",
      "epoch 361 loss = 1.545083\n",
      "epoch 362 loss = 1.452804\n",
      "epoch 363 loss = 1.575008\n",
      "epoch 364 loss = 1.712528\n",
      "epoch 365 loss = 1.488762\n",
      "epoch 366 loss = 1.520442\n",
      "epoch 367 loss = 1.488405\n",
      "epoch 368 loss = 1.853734\n",
      "epoch 369 loss = 1.719203\n",
      "epoch 370 loss = 1.811066\n",
      "epoch 371 loss = 1.726118\n",
      "epoch 372 loss = 1.553468\n",
      "epoch 373 loss = 1.494320\n",
      "epoch 374 loss = 1.545070\n",
      "epoch 375 loss = 1.576980\n",
      "epoch 376 loss = 1.572949\n",
      "epoch 377 loss = 1.675458\n",
      "epoch 378 loss = 1.766052\n",
      "epoch 379 loss = 1.626777\n",
      "epoch 380 loss = 1.662953\n",
      "epoch 381 loss = 1.793882\n",
      "epoch 382 loss = 1.504751\n",
      "epoch 383 loss = 1.662096\n",
      "epoch 384 loss = 1.667689\n",
      "epoch 385 loss = 1.600680\n",
      "epoch 386 loss = 1.723849\n",
      "epoch 387 loss = 1.708523\n",
      "epoch 388 loss = 1.467403\n",
      "epoch 389 loss = 1.896332\n",
      "epoch 390 loss = 1.595043\n",
      "epoch 391 loss = 1.745082\n",
      "epoch 392 loss = 1.651249\n",
      "epoch 393 loss = 1.952850\n",
      "epoch 394 loss = 1.718162\n",
      "epoch 395 loss = 1.642576\n",
      "epoch 396 loss = 1.749854\n",
      "epoch 397 loss = 1.824676\n",
      "epoch 398 loss = 1.709790\n",
      "epoch 399 loss = 1.795428\n",
      "epoch 400 loss = 1.438351\n",
      "epoch 401 loss = 1.703712\n",
      "epoch 402 loss = 1.650211\n",
      "epoch 403 loss = 1.553683\n",
      "epoch 404 loss = 1.830227\n",
      "epoch 405 loss = 1.712048\n",
      "epoch 406 loss = 1.758716\n",
      "epoch 407 loss = 1.558975\n",
      "epoch 408 loss = 1.761389\n",
      "epoch 409 loss = 1.698352\n",
      "epoch 410 loss = 1.759545\n",
      "epoch 411 loss = 1.681579\n",
      "epoch 412 loss = 1.616216\n",
      "epoch 413 loss = 1.708270\n",
      "epoch 414 loss = 1.701965\n",
      "epoch 415 loss = 1.623780\n",
      "epoch 416 loss = 1.683084\n",
      "epoch 417 loss = 1.472025\n",
      "epoch 418 loss = 1.811588\n",
      "epoch 419 loss = 1.607939\n",
      "epoch 420 loss = 1.500618\n",
      "epoch 421 loss = 1.548643\n",
      "epoch 422 loss = 1.725215\n",
      "epoch 423 loss = 1.564741\n",
      "epoch 424 loss = 1.535538\n",
      "epoch 425 loss = 1.767810\n",
      "epoch 426 loss = 1.719781\n",
      "epoch 427 loss = 1.646437\n",
      "epoch 428 loss = 1.849749\n",
      "epoch 429 loss = 1.631519\n",
      "epoch 430 loss = 1.710073\n",
      "epoch 431 loss = 1.556644\n",
      "epoch 432 loss = 1.602415\n",
      "epoch 433 loss = 1.868493\n",
      "epoch 434 loss = 1.780145\n",
      "epoch 435 loss = 1.497843\n",
      "epoch 436 loss = 1.706758\n",
      "epoch 437 loss = 1.513122\n",
      "epoch 438 loss = 1.616014\n",
      "epoch 439 loss = 1.602522\n",
      "epoch 440 loss = 1.636254\n",
      "epoch 441 loss = 1.804822\n",
      "epoch 442 loss = 1.569206\n",
      "epoch 443 loss = 1.391407\n",
      "epoch 444 loss = 1.792906\n",
      "epoch 445 loss = 1.498814\n",
      "epoch 446 loss = 1.747133\n",
      "epoch 447 loss = 1.857348\n",
      "epoch 448 loss = 1.499134\n",
      "epoch 449 loss = 1.793812\n",
      "epoch 450 loss = 1.609845\n",
      "epoch 451 loss = 1.551472\n",
      "epoch 452 loss = 1.737659\n",
      "epoch 453 loss = 1.632301\n",
      "epoch 454 loss = 1.651285\n",
      "epoch 455 loss = 1.661340\n",
      "epoch 456 loss = 1.682735\n",
      "epoch 457 loss = 1.777958\n",
      "epoch 458 loss = 1.564759\n",
      "epoch 459 loss = 1.826188\n",
      "epoch 460 loss = 1.672391\n",
      "epoch 461 loss = 1.732589\n",
      "epoch 462 loss = 1.605193\n",
      "epoch 463 loss = 1.435115\n",
      "epoch 464 loss = 1.555368\n",
      "epoch 465 loss = 1.757637\n",
      "epoch 466 loss = 1.756772\n",
      "epoch 467 loss = 1.697878\n",
      "epoch 468 loss = 1.805651\n",
      "epoch 469 loss = 2.036962\n",
      "epoch 470 loss = 1.713862\n",
      "epoch 471 loss = 1.567454\n",
      "epoch 472 loss = 1.582396\n",
      "epoch 473 loss = 1.655060\n",
      "epoch 474 loss = 1.718682\n",
      "epoch 475 loss = 1.667509\n",
      "epoch 476 loss = 1.559404\n",
      "epoch 477 loss = 1.617327\n",
      "epoch 478 loss = 1.610418\n",
      "epoch 479 loss = 1.501743\n",
      "epoch 480 loss = 1.839480\n",
      "epoch 481 loss = 1.540778\n",
      "epoch 482 loss = 1.669871\n",
      "epoch 483 loss = 1.744623\n",
      "epoch 484 loss = 1.824854\n",
      "epoch 485 loss = 1.629526\n",
      "epoch 486 loss = 1.705063\n",
      "epoch 487 loss = 1.974658\n",
      "epoch 488 loss = 1.526124\n",
      "epoch 489 loss = 1.699453\n",
      "epoch 490 loss = 1.484471\n",
      "epoch 491 loss = 1.521639\n",
      "epoch 492 loss = 1.812238\n",
      "epoch 493 loss = 1.612000\n",
      "epoch 494 loss = 1.507965\n",
      "epoch 495 loss = 1.452743\n",
      "epoch 496 loss = 1.906987\n",
      "epoch 497 loss = 1.344433\n",
      "epoch 498 loss = 1.655150\n",
      "epoch 499 loss = 1.763131\n",
      "final loss = 1.763131\n",
      "accuracy_mc = tensor(0.3455, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.3656, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.7577, device='cuda:0')\n",
      "training time = 306.00513076782227 seconds\n",
      "testing time = 3.2057387828826904 seconds\n",
      "\n",
      "Training with split 3\n",
      "epoch 0 loss = 2.217232\n",
      "epoch 1 loss = 2.240124\n",
      "epoch 2 loss = 1.941667\n",
      "epoch 3 loss = 1.981928\n",
      "epoch 4 loss = 1.935462\n",
      "epoch 5 loss = 1.870969\n",
      "epoch 6 loss = 2.137712\n",
      "epoch 7 loss = 1.991522\n",
      "epoch 8 loss = 2.024139\n",
      "epoch 9 loss = 1.899860\n",
      "epoch 10 loss = 1.994239\n",
      "epoch 11 loss = 1.999444\n",
      "epoch 12 loss = 1.964157\n",
      "epoch 13 loss = 1.924964\n",
      "epoch 14 loss = 2.015870\n",
      "epoch 15 loss = 1.906919\n",
      "epoch 16 loss = 1.882471\n",
      "epoch 17 loss = 1.849776\n",
      "epoch 18 loss = 1.774706\n",
      "epoch 19 loss = 1.987877\n",
      "epoch 20 loss = 1.631563\n",
      "epoch 21 loss = 1.700397\n",
      "epoch 22 loss = 1.751785\n",
      "epoch 23 loss = 1.889887\n",
      "epoch 24 loss = 1.978877\n",
      "epoch 25 loss = 1.869157\n",
      "epoch 26 loss = 1.836027\n",
      "epoch 27 loss = 1.723229\n",
      "epoch 28 loss = 1.921745\n",
      "epoch 29 loss = 1.864335\n",
      "epoch 30 loss = 2.012014\n",
      "epoch 31 loss = 1.700817\n",
      "epoch 32 loss = 1.737731\n",
      "epoch 33 loss = 1.748887\n",
      "epoch 34 loss = 1.852530\n",
      "epoch 35 loss = 1.863471\n",
      "epoch 36 loss = 1.893207\n",
      "epoch 37 loss = 1.719309\n",
      "epoch 38 loss = 1.947066\n",
      "epoch 39 loss = 1.812765\n",
      "epoch 40 loss = 1.940907\n",
      "epoch 41 loss = 1.747544\n",
      "epoch 42 loss = 1.685042\n",
      "epoch 43 loss = 1.850733\n",
      "epoch 44 loss = 1.744248\n",
      "epoch 45 loss = 1.761720\n",
      "epoch 46 loss = 1.774747\n",
      "epoch 47 loss = 1.822312\n",
      "epoch 48 loss = 1.822464\n",
      "epoch 49 loss = 1.755148\n",
      "epoch 50 loss = 1.834864\n",
      "epoch 51 loss = 1.751421\n",
      "epoch 52 loss = 1.881286\n",
      "epoch 53 loss = 2.006013\n",
      "epoch 54 loss = 1.833672\n",
      "epoch 55 loss = 1.741351\n",
      "epoch 56 loss = 1.754218\n",
      "epoch 57 loss = 1.939265\n",
      "epoch 58 loss = 1.731144\n",
      "epoch 59 loss = 1.564842\n",
      "epoch 60 loss = 1.573772\n",
      "epoch 61 loss = 1.669455\n",
      "epoch 62 loss = 1.857843\n",
      "epoch 63 loss = 1.706235\n",
      "epoch 64 loss = 1.496721\n",
      "epoch 65 loss = 1.834262\n",
      "epoch 66 loss = 1.761657\n",
      "epoch 67 loss = 1.818449\n",
      "epoch 68 loss = 1.680713\n",
      "epoch 69 loss = 1.805789\n",
      "epoch 70 loss = 1.763574\n",
      "epoch 71 loss = 1.725380\n",
      "epoch 72 loss = 1.564285\n",
      "epoch 73 loss = 1.623428\n",
      "epoch 74 loss = 1.746650\n",
      "epoch 75 loss = 1.612388\n",
      "epoch 76 loss = 1.710760\n",
      "epoch 77 loss = 1.876743\n",
      "epoch 78 loss = 1.758549\n",
      "epoch 79 loss = 1.752710\n",
      "epoch 80 loss = 1.709220\n",
      "epoch 81 loss = 1.791997\n",
      "epoch 82 loss = 1.845918\n",
      "epoch 83 loss = 1.565481\n",
      "epoch 84 loss = 1.643313\n",
      "epoch 85 loss = 1.735407\n",
      "epoch 86 loss = 1.617019\n",
      "epoch 87 loss = 1.679039\n",
      "epoch 88 loss = 1.639844\n",
      "epoch 89 loss = 1.656153\n",
      "epoch 90 loss = 1.612254\n",
      "epoch 91 loss = 1.787585\n",
      "epoch 92 loss = 1.761479\n",
      "epoch 93 loss = 1.784792\n",
      "epoch 94 loss = 1.934178\n",
      "epoch 95 loss = 1.843138\n",
      "epoch 96 loss = 1.667588\n",
      "epoch 97 loss = 1.474662\n",
      "epoch 98 loss = 1.669912\n",
      "epoch 99 loss = 1.524277\n",
      "epoch 100 loss = 1.620454\n",
      "epoch 101 loss = 1.576947\n",
      "epoch 102 loss = 1.875072\n",
      "epoch 103 loss = 1.763145\n",
      "epoch 104 loss = 1.653065\n",
      "epoch 105 loss = 1.662042\n",
      "epoch 106 loss = 1.674303\n",
      "epoch 107 loss = 1.643273\n",
      "epoch 108 loss = 1.594635\n",
      "epoch 109 loss = 1.573876\n",
      "epoch 110 loss = 1.638965\n",
      "epoch 111 loss = 1.758696\n",
      "epoch 112 loss = 1.574967\n",
      "epoch 113 loss = 1.637579\n",
      "epoch 114 loss = 1.573029\n",
      "epoch 115 loss = 1.752232\n",
      "epoch 116 loss = 1.635212\n",
      "epoch 117 loss = 1.746394\n",
      "epoch 118 loss = 1.709727\n",
      "epoch 119 loss = 1.654634\n",
      "epoch 120 loss = 1.567127\n",
      "epoch 121 loss = 1.759591\n",
      "epoch 122 loss = 1.471423\n",
      "epoch 123 loss = 1.519448\n",
      "epoch 124 loss = 1.602278\n",
      "epoch 125 loss = 1.776977\n",
      "epoch 126 loss = 1.760388\n",
      "epoch 127 loss = 1.530989\n",
      "epoch 128 loss = 1.738268\n",
      "epoch 129 loss = 1.716532\n",
      "epoch 130 loss = 1.503553\n",
      "epoch 131 loss = 1.811234\n",
      "epoch 132 loss = 1.561905\n",
      "epoch 133 loss = 1.637390\n",
      "epoch 134 loss = 1.658336\n",
      "epoch 135 loss = 1.702223\n",
      "epoch 136 loss = 1.604770\n",
      "epoch 137 loss = 1.800978\n",
      "epoch 138 loss = 1.803737\n",
      "epoch 139 loss = 1.570184\n",
      "epoch 140 loss = 1.844169\n",
      "epoch 141 loss = 1.572865\n",
      "epoch 142 loss = 1.487963\n",
      "epoch 143 loss = 1.704216\n",
      "epoch 144 loss = 1.579160\n",
      "epoch 145 loss = 1.593791\n",
      "epoch 146 loss = 1.629068\n",
      "epoch 147 loss = 1.698490\n",
      "epoch 148 loss = 1.739686\n",
      "epoch 149 loss = 1.892611\n",
      "epoch 150 loss = 1.621541\n",
      "epoch 151 loss = 1.859311\n",
      "epoch 152 loss = 1.701834\n",
      "epoch 153 loss = 1.825835\n",
      "epoch 154 loss = 1.874975\n",
      "epoch 155 loss = 1.664019\n",
      "epoch 156 loss = 1.667628\n",
      "epoch 157 loss = 1.605933\n",
      "epoch 158 loss = 1.884215\n",
      "epoch 159 loss = 1.751112\n",
      "epoch 160 loss = 1.591715\n",
      "epoch 161 loss = 1.611386\n",
      "epoch 162 loss = 1.568547\n",
      "epoch 163 loss = 1.633750\n",
      "epoch 164 loss = 1.526563\n",
      "epoch 165 loss = 1.519687\n",
      "epoch 166 loss = 1.869169\n",
      "epoch 167 loss = 1.848082\n",
      "epoch 168 loss = 1.814100\n",
      "epoch 169 loss = 1.637119\n",
      "epoch 170 loss = 1.696389\n",
      "epoch 171 loss = 1.815638\n",
      "epoch 172 loss = 1.818062\n",
      "epoch 173 loss = 1.640686\n",
      "epoch 174 loss = 1.751867\n",
      "epoch 175 loss = 1.711383\n",
      "epoch 176 loss = 1.645733\n",
      "epoch 177 loss = 1.732937\n",
      "epoch 178 loss = 1.749308\n",
      "epoch 179 loss = 1.656493\n",
      "epoch 180 loss = 1.647576\n",
      "epoch 181 loss = 1.661335\n",
      "epoch 182 loss = 1.457593\n",
      "epoch 183 loss = 1.622258\n",
      "epoch 184 loss = 1.545773\n",
      "epoch 185 loss = 1.638308\n",
      "epoch 186 loss = 1.848110\n",
      "epoch 187 loss = 1.894709\n",
      "epoch 188 loss = 1.719511\n",
      "epoch 189 loss = 1.797575\n",
      "epoch 190 loss = 1.761721\n",
      "epoch 191 loss = 1.669625\n",
      "epoch 192 loss = 1.486968\n",
      "epoch 193 loss = 1.703541\n",
      "epoch 194 loss = 1.436595\n",
      "epoch 195 loss = 1.639853\n",
      "epoch 196 loss = 1.836085\n",
      "epoch 197 loss = 1.781477\n",
      "epoch 198 loss = 1.669557\n",
      "epoch 199 loss = 1.588017\n",
      "epoch 200 loss = 1.606313\n",
      "epoch 201 loss = 1.566629\n",
      "epoch 202 loss = 1.767797\n",
      "epoch 203 loss = 1.628986\n",
      "epoch 204 loss = 1.500790\n",
      "epoch 205 loss = 1.568402\n",
      "epoch 206 loss = 1.667823\n",
      "epoch 207 loss = 1.907984\n",
      "epoch 208 loss = 1.428364\n",
      "epoch 209 loss = 1.536871\n",
      "epoch 210 loss = 1.777349\n",
      "epoch 211 loss = 1.696850\n",
      "epoch 212 loss = 1.612808\n",
      "epoch 213 loss = 1.520739\n",
      "epoch 214 loss = 1.665127\n",
      "epoch 215 loss = 1.642365\n",
      "epoch 216 loss = 1.679400\n",
      "epoch 217 loss = 1.729076\n",
      "epoch 218 loss = 1.628293\n",
      "epoch 219 loss = 1.764063\n",
      "epoch 220 loss = 1.673957\n",
      "epoch 221 loss = 1.435585\n",
      "epoch 222 loss = 1.549696\n",
      "epoch 223 loss = 1.584761\n",
      "epoch 224 loss = 1.737653\n",
      "epoch 225 loss = 1.484213\n",
      "epoch 226 loss = 1.619784\n",
      "epoch 227 loss = 1.511502\n",
      "epoch 228 loss = 1.573616\n",
      "epoch 229 loss = 1.683513\n",
      "epoch 230 loss = 1.619187\n",
      "epoch 231 loss = 1.732171\n",
      "epoch 232 loss = 1.665480\n",
      "epoch 233 loss = 1.570081\n",
      "epoch 234 loss = 1.703442\n",
      "epoch 235 loss = 1.812950\n",
      "epoch 236 loss = 1.773615\n",
      "epoch 237 loss = 1.504711\n",
      "epoch 238 loss = 1.688133\n",
      "epoch 239 loss = 1.572913\n",
      "epoch 240 loss = 1.564185\n",
      "epoch 241 loss = 1.499087\n",
      "epoch 242 loss = 1.843363\n",
      "epoch 243 loss = 1.597005\n",
      "epoch 244 loss = 1.639741\n",
      "epoch 245 loss = 1.845236\n",
      "epoch 246 loss = 1.583589\n",
      "epoch 247 loss = 1.631513\n",
      "epoch 248 loss = 1.492467\n",
      "epoch 249 loss = 1.492323\n",
      "epoch 250 loss = 1.418007\n",
      "epoch 251 loss = 1.523144\n",
      "epoch 252 loss = 1.617969\n",
      "epoch 253 loss = 1.586614\n",
      "epoch 254 loss = 1.644875\n",
      "epoch 255 loss = 1.635333\n",
      "epoch 256 loss = 1.621907\n",
      "epoch 257 loss = 1.785283\n",
      "epoch 258 loss = 1.651889\n",
      "epoch 259 loss = 1.554292\n",
      "epoch 260 loss = 1.708163\n",
      "epoch 261 loss = 1.639277\n",
      "epoch 262 loss = 1.720795\n",
      "epoch 263 loss = 1.826237\n",
      "epoch 264 loss = 1.615494\n",
      "epoch 265 loss = 1.733271\n",
      "epoch 266 loss = 1.777499\n",
      "epoch 267 loss = 1.680844\n",
      "epoch 268 loss = 1.656780\n",
      "epoch 269 loss = 1.757892\n",
      "epoch 270 loss = 1.650629\n",
      "epoch 271 loss = 1.551355\n",
      "epoch 272 loss = 1.581849\n",
      "epoch 273 loss = 1.760557\n",
      "epoch 274 loss = 1.636570\n",
      "epoch 275 loss = 1.642620\n",
      "epoch 276 loss = 1.591436\n",
      "epoch 277 loss = 1.587164\n",
      "epoch 278 loss = 1.728214\n",
      "epoch 279 loss = 1.602046\n",
      "epoch 280 loss = 1.803014\n",
      "epoch 281 loss = 1.632519\n",
      "epoch 282 loss = 1.558992\n",
      "epoch 283 loss = 1.758628\n",
      "epoch 284 loss = 1.782437\n",
      "epoch 285 loss = 1.630434\n",
      "epoch 286 loss = 1.534698\n",
      "epoch 287 loss = 1.712317\n",
      "epoch 288 loss = 1.580892\n",
      "epoch 289 loss = 1.757484\n",
      "epoch 290 loss = 1.659716\n",
      "epoch 291 loss = 1.644465\n",
      "epoch 292 loss = 1.736379\n",
      "epoch 293 loss = 1.473832\n",
      "epoch 294 loss = 1.736899\n",
      "epoch 295 loss = 1.502951\n",
      "epoch 296 loss = 1.557442\n",
      "epoch 297 loss = 1.900140\n",
      "epoch 298 loss = 1.527317\n",
      "epoch 299 loss = 1.504045\n",
      "epoch 300 loss = 1.488698\n",
      "epoch 301 loss = 1.593845\n",
      "epoch 302 loss = 1.459278\n",
      "epoch 303 loss = 1.540660\n",
      "epoch 304 loss = 1.703929\n",
      "epoch 305 loss = 1.885321\n",
      "epoch 306 loss = 1.668725\n",
      "epoch 307 loss = 1.781800\n",
      "epoch 308 loss = 1.761245\n",
      "epoch 309 loss = 1.472367\n",
      "epoch 310 loss = 1.968165\n",
      "epoch 311 loss = 1.745887\n",
      "epoch 312 loss = 1.532893\n",
      "epoch 313 loss = 1.795228\n",
      "epoch 314 loss = 1.639743\n",
      "epoch 315 loss = 1.479902\n",
      "epoch 316 loss = 1.782139\n",
      "epoch 317 loss = 1.523358\n",
      "epoch 318 loss = 1.586559\n",
      "epoch 319 loss = 1.741088\n",
      "epoch 320 loss = 1.803982\n",
      "epoch 321 loss = 1.584271\n",
      "epoch 322 loss = 1.521130\n",
      "epoch 323 loss = 1.590832\n",
      "epoch 324 loss = 1.539428\n",
      "epoch 325 loss = 1.581638\n",
      "epoch 326 loss = 1.675911\n",
      "epoch 327 loss = 1.553582\n",
      "epoch 328 loss = 1.832168\n",
      "epoch 329 loss = 1.511358\n",
      "epoch 330 loss = 1.680084\n",
      "epoch 331 loss = 1.454380\n",
      "epoch 332 loss = 1.687659\n",
      "epoch 333 loss = 1.765893\n",
      "epoch 334 loss = 1.567612\n",
      "epoch 335 loss = 1.851082\n",
      "epoch 336 loss = 1.718315\n",
      "epoch 337 loss = 1.605833\n",
      "epoch 338 loss = 1.607943\n",
      "epoch 339 loss = 1.818088\n",
      "epoch 340 loss = 1.489003\n",
      "epoch 341 loss = 1.486550\n",
      "epoch 342 loss = 1.634691\n",
      "epoch 343 loss = 1.725418\n",
      "epoch 344 loss = 1.831405\n",
      "epoch 345 loss = 1.757619\n",
      "epoch 346 loss = 1.626319\n",
      "epoch 347 loss = 1.416243\n",
      "epoch 348 loss = 1.661604\n",
      "epoch 349 loss = 1.649633\n",
      "epoch 350 loss = 1.606788\n",
      "epoch 351 loss = 1.667276\n",
      "epoch 352 loss = 1.502144\n",
      "epoch 353 loss = 1.710893\n",
      "epoch 354 loss = 1.485304\n",
      "epoch 355 loss = 1.761027\n",
      "epoch 356 loss = 1.531214\n",
      "epoch 357 loss = 1.516286\n",
      "epoch 358 loss = 1.807406\n",
      "epoch 359 loss = 1.689728\n",
      "epoch 360 loss = 1.468313\n",
      "epoch 361 loss = 1.844103\n",
      "epoch 362 loss = 1.593382\n",
      "epoch 363 loss = 1.495047\n",
      "epoch 364 loss = 1.531357\n",
      "epoch 365 loss = 1.636066\n",
      "epoch 366 loss = 1.566754\n",
      "epoch 367 loss = 1.503811\n",
      "epoch 368 loss = 1.602653\n",
      "epoch 369 loss = 1.437373\n",
      "epoch 370 loss = 1.645033\n",
      "epoch 371 loss = 1.647120\n",
      "epoch 372 loss = 1.470450\n",
      "epoch 373 loss = 1.700608\n",
      "epoch 374 loss = 1.433517\n",
      "epoch 375 loss = 1.540816\n",
      "epoch 376 loss = 1.764405\n",
      "epoch 377 loss = 1.773936\n",
      "epoch 378 loss = 1.856901\n",
      "epoch 379 loss = 1.770871\n",
      "epoch 380 loss = 1.697234\n",
      "epoch 381 loss = 1.567430\n",
      "epoch 382 loss = 1.421185\n",
      "epoch 383 loss = 1.524566\n",
      "epoch 384 loss = 1.778792\n",
      "epoch 385 loss = 1.660472\n",
      "epoch 386 loss = 1.816009\n",
      "epoch 387 loss = 1.787292\n",
      "epoch 388 loss = 1.488564\n",
      "epoch 389 loss = 1.496985\n",
      "epoch 390 loss = 1.513321\n",
      "epoch 391 loss = 1.605600\n",
      "epoch 392 loss = 1.696598\n",
      "epoch 393 loss = 1.481432\n",
      "epoch 394 loss = 1.767211\n",
      "epoch 395 loss = 1.734860\n",
      "epoch 396 loss = 1.658751\n",
      "epoch 397 loss = 1.375845\n",
      "epoch 398 loss = 1.690687\n",
      "epoch 399 loss = 1.380639\n",
      "epoch 400 loss = 1.584608\n",
      "epoch 401 loss = 1.732749\n",
      "epoch 402 loss = 1.505795\n",
      "epoch 403 loss = 1.777901\n",
      "epoch 404 loss = 1.553892\n",
      "epoch 405 loss = 1.561817\n",
      "epoch 406 loss = 1.489678\n",
      "epoch 407 loss = 1.736932\n",
      "epoch 408 loss = 1.803836\n",
      "epoch 409 loss = 1.645388\n",
      "epoch 410 loss = 1.578175\n",
      "epoch 411 loss = 1.627340\n",
      "epoch 412 loss = 1.775842\n",
      "epoch 413 loss = 1.834474\n",
      "epoch 414 loss = 1.768804\n",
      "epoch 415 loss = 1.496855\n",
      "epoch 416 loss = 1.626442\n",
      "epoch 417 loss = 1.972869\n",
      "epoch 418 loss = 1.541566\n",
      "epoch 419 loss = 1.752450\n",
      "epoch 420 loss = 1.605671\n",
      "epoch 421 loss = 1.795671\n",
      "epoch 422 loss = 1.581024\n",
      "epoch 423 loss = 1.517852\n",
      "epoch 424 loss = 1.727286\n",
      "epoch 425 loss = 1.570779\n",
      "epoch 426 loss = 1.405318\n",
      "epoch 427 loss = 1.559860\n",
      "epoch 428 loss = 1.446601\n",
      "epoch 429 loss = 1.718783\n",
      "epoch 430 loss = 1.498357\n",
      "epoch 431 loss = 1.397526\n",
      "epoch 432 loss = 1.582877\n",
      "epoch 433 loss = 1.666049\n",
      "epoch 434 loss = 1.503299\n",
      "epoch 435 loss = 1.777945\n",
      "epoch 436 loss = 1.749141\n",
      "epoch 437 loss = 1.747699\n",
      "epoch 438 loss = 1.502779\n",
      "epoch 439 loss = 1.522363\n",
      "epoch 440 loss = 1.704975\n",
      "epoch 441 loss = 1.683405\n",
      "epoch 442 loss = 1.439538\n",
      "epoch 443 loss = 1.673586\n",
      "epoch 444 loss = 1.791005\n",
      "epoch 445 loss = 1.583623\n",
      "epoch 446 loss = 1.688610\n",
      "epoch 447 loss = 1.567948\n",
      "epoch 448 loss = 1.743618\n",
      "epoch 449 loss = 1.820377\n",
      "epoch 450 loss = 1.802387\n",
      "epoch 451 loss = 1.631367\n",
      "epoch 452 loss = 1.652289\n",
      "epoch 453 loss = 1.599569\n",
      "epoch 454 loss = 1.838221\n",
      "epoch 455 loss = 1.633376\n",
      "epoch 456 loss = 1.441355\n",
      "epoch 457 loss = 1.599054\n",
      "epoch 458 loss = 1.566308\n",
      "epoch 459 loss = 1.486028\n",
      "epoch 460 loss = 1.782726\n",
      "epoch 461 loss = 1.613055\n",
      "epoch 462 loss = 1.475414\n",
      "epoch 463 loss = 1.751140\n",
      "epoch 464 loss = 1.563097\n",
      "epoch 465 loss = 1.644204\n",
      "epoch 466 loss = 1.609210\n",
      "epoch 467 loss = 1.664008\n",
      "epoch 468 loss = 1.842023\n",
      "epoch 469 loss = 1.688282\n",
      "epoch 470 loss = 1.780232\n",
      "epoch 471 loss = 1.612887\n",
      "epoch 472 loss = 1.754856\n",
      "epoch 473 loss = 1.669050\n",
      "epoch 474 loss = 1.744377\n",
      "epoch 475 loss = 1.639349\n",
      "epoch 476 loss = 1.755888\n",
      "epoch 477 loss = 1.497383\n",
      "epoch 478 loss = 1.688894\n",
      "epoch 479 loss = 1.452335\n",
      "epoch 480 loss = 1.447278\n",
      "epoch 481 loss = 1.941677\n",
      "epoch 482 loss = 1.645536\n",
      "epoch 483 loss = 1.552516\n",
      "epoch 484 loss = 1.596667\n",
      "epoch 485 loss = 1.771278\n",
      "epoch 486 loss = 1.591608\n",
      "epoch 487 loss = 1.686368\n",
      "epoch 488 loss = 1.556303\n",
      "epoch 489 loss = 1.631356\n",
      "epoch 490 loss = 1.459012\n",
      "epoch 491 loss = 1.719770\n",
      "epoch 492 loss = 1.465774\n",
      "epoch 493 loss = 1.642582\n",
      "epoch 494 loss = 1.483446\n",
      "epoch 495 loss = 1.502467\n",
      "epoch 496 loss = 1.561962\n",
      "epoch 497 loss = 1.514329\n",
      "epoch 498 loss = 1.463644\n",
      "epoch 499 loss = 1.323171\n",
      "final loss = 1.323171\n",
      "accuracy_mc = tensor(0.2972, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2848, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.8461, device='cuda:0')\n",
      "training time = 306.4221429824829 seconds\n",
      "testing time = 3.2280216217041016 seconds\n",
      "\n",
      "Training with split 4\n",
      "epoch 0 loss = 2.231445\n",
      "epoch 1 loss = 1.970860\n",
      "epoch 2 loss = 2.018411\n",
      "epoch 3 loss = 2.031010\n",
      "epoch 4 loss = 1.950063\n",
      "epoch 5 loss = 1.974462\n",
      "epoch 6 loss = 1.951595\n",
      "epoch 7 loss = 2.059706\n",
      "epoch 8 loss = 1.841597\n",
      "epoch 9 loss = 2.009757\n",
      "epoch 10 loss = 1.928852\n",
      "epoch 11 loss = 2.118601\n",
      "epoch 12 loss = 1.991166\n",
      "epoch 13 loss = 1.872590\n",
      "epoch 14 loss = 1.880416\n",
      "epoch 15 loss = 1.972787\n",
      "epoch 16 loss = 1.909014\n",
      "epoch 17 loss = 1.903786\n",
      "epoch 18 loss = 2.139861\n",
      "epoch 19 loss = 1.796526\n",
      "epoch 20 loss = 1.955586\n",
      "epoch 21 loss = 1.917248\n",
      "epoch 22 loss = 1.984720\n",
      "epoch 23 loss = 1.826460\n",
      "epoch 24 loss = 1.937273\n",
      "epoch 25 loss = 1.720248\n",
      "epoch 26 loss = 1.938013\n",
      "epoch 27 loss = 1.880966\n",
      "epoch 28 loss = 1.808752\n",
      "epoch 29 loss = 1.979508\n",
      "epoch 30 loss = 1.797965\n",
      "epoch 31 loss = 1.787662\n",
      "epoch 32 loss = 1.688961\n",
      "epoch 33 loss = 1.977010\n",
      "epoch 34 loss = 2.108538\n",
      "epoch 35 loss = 1.946224\n",
      "epoch 36 loss = 2.100527\n",
      "epoch 37 loss = 2.122434\n",
      "epoch 38 loss = 1.614794\n",
      "epoch 39 loss = 1.918182\n",
      "epoch 40 loss = 1.719698\n",
      "epoch 41 loss = 1.671851\n",
      "epoch 42 loss = 1.727667\n",
      "epoch 43 loss = 1.790901\n",
      "epoch 44 loss = 1.999201\n",
      "epoch 45 loss = 1.603986\n",
      "epoch 46 loss = 1.907583\n",
      "epoch 47 loss = 2.002860\n",
      "epoch 48 loss = 1.776899\n",
      "epoch 49 loss = 1.651433\n",
      "epoch 50 loss = 1.699575\n",
      "epoch 51 loss = 1.848320\n",
      "epoch 52 loss = 1.843718\n",
      "epoch 53 loss = 1.760873\n",
      "epoch 54 loss = 2.119493\n",
      "epoch 55 loss = 1.560954\n",
      "epoch 56 loss = 1.810720\n",
      "epoch 57 loss = 1.808444\n",
      "epoch 58 loss = 1.869973\n",
      "epoch 59 loss = 1.585344\n",
      "epoch 60 loss = 1.749361\n",
      "epoch 61 loss = 1.847012\n",
      "epoch 62 loss = 1.759936\n",
      "epoch 63 loss = 1.797676\n",
      "epoch 64 loss = 1.682170\n",
      "epoch 65 loss = 1.698609\n",
      "epoch 66 loss = 1.581474\n",
      "epoch 67 loss = 1.946372\n",
      "epoch 68 loss = 1.830714\n",
      "epoch 69 loss = 1.988355\n",
      "epoch 70 loss = 1.691902\n",
      "epoch 71 loss = 1.854828\n",
      "epoch 72 loss = 1.827524\n",
      "epoch 73 loss = 1.754600\n",
      "epoch 74 loss = 1.936179\n",
      "epoch 75 loss = 1.697680\n",
      "epoch 76 loss = 1.624361\n",
      "epoch 77 loss = 1.625394\n",
      "epoch 78 loss = 1.672618\n",
      "epoch 79 loss = 1.753221\n",
      "epoch 80 loss = 1.730501\n",
      "epoch 81 loss = 1.932694\n",
      "epoch 82 loss = 1.844727\n",
      "epoch 83 loss = 1.684253\n",
      "epoch 84 loss = 1.597393\n",
      "epoch 85 loss = 1.492073\n",
      "epoch 86 loss = 1.539628\n",
      "epoch 87 loss = 1.753141\n",
      "epoch 88 loss = 1.833422\n",
      "epoch 89 loss = 1.667224\n",
      "epoch 90 loss = 1.808319\n",
      "epoch 91 loss = 1.570035\n",
      "epoch 92 loss = 1.733748\n",
      "epoch 93 loss = 2.073583\n",
      "epoch 94 loss = 1.674737\n",
      "epoch 95 loss = 1.726930\n",
      "epoch 96 loss = 1.622434\n",
      "epoch 97 loss = 1.743968\n",
      "epoch 98 loss = 1.870191\n",
      "epoch 99 loss = 1.618417\n",
      "epoch 100 loss = 1.606987\n",
      "epoch 101 loss = 1.852343\n",
      "epoch 102 loss = 1.557646\n",
      "epoch 103 loss = 1.794655\n",
      "epoch 104 loss = 1.335775\n",
      "epoch 105 loss = 1.678110\n",
      "epoch 106 loss = 1.699078\n",
      "epoch 107 loss = 1.600218\n",
      "epoch 108 loss = 1.633110\n",
      "epoch 109 loss = 1.867675\n",
      "epoch 110 loss = 1.599101\n",
      "epoch 111 loss = 1.742681\n",
      "epoch 112 loss = 1.714608\n",
      "epoch 113 loss = 1.922232\n",
      "epoch 114 loss = 1.600882\n",
      "epoch 115 loss = 1.702089\n",
      "epoch 116 loss = 1.601601\n",
      "epoch 117 loss = 1.578098\n",
      "epoch 118 loss = 1.475884\n",
      "epoch 119 loss = 1.506221\n",
      "epoch 120 loss = 1.849854\n",
      "epoch 121 loss = 1.857976\n",
      "epoch 122 loss = 1.795061\n",
      "epoch 123 loss = 1.659517\n",
      "epoch 124 loss = 1.749297\n",
      "epoch 125 loss = 1.364987\n",
      "epoch 126 loss = 1.817117\n",
      "epoch 127 loss = 1.667034\n",
      "epoch 128 loss = 1.656744\n",
      "epoch 129 loss = 1.669233\n",
      "epoch 130 loss = 1.597201\n",
      "epoch 131 loss = 1.608451\n",
      "epoch 132 loss = 1.663620\n",
      "epoch 133 loss = 1.757222\n",
      "epoch 134 loss = 1.721483\n",
      "epoch 135 loss = 1.725024\n",
      "epoch 136 loss = 1.730727\n",
      "epoch 137 loss = 1.603509\n",
      "epoch 138 loss = 1.897424\n",
      "epoch 139 loss = 1.586303\n",
      "epoch 140 loss = 1.496672\n",
      "epoch 141 loss = 1.702212\n",
      "epoch 142 loss = 1.660752\n",
      "epoch 143 loss = 1.739424\n",
      "epoch 144 loss = 1.637313\n",
      "epoch 145 loss = 1.544070\n",
      "epoch 146 loss = 1.631971\n",
      "epoch 147 loss = 1.721896\n",
      "epoch 148 loss = 1.593858\n",
      "epoch 149 loss = 1.782368\n",
      "epoch 150 loss = 1.385979\n",
      "epoch 151 loss = 1.783458\n",
      "epoch 152 loss = 1.594113\n",
      "epoch 153 loss = 1.468550\n",
      "epoch 154 loss = 1.776390\n",
      "epoch 155 loss = 1.697121\n",
      "epoch 156 loss = 1.896719\n",
      "epoch 157 loss = 1.589202\n",
      "epoch 158 loss = 1.673361\n",
      "epoch 159 loss = 1.646563\n",
      "epoch 160 loss = 1.488079\n",
      "epoch 161 loss = 1.461812\n",
      "epoch 162 loss = 1.584459\n",
      "epoch 163 loss = 1.638516\n",
      "epoch 164 loss = 1.739053\n",
      "epoch 165 loss = 1.613572\n",
      "epoch 166 loss = 1.764928\n",
      "epoch 167 loss = 1.756352\n",
      "epoch 168 loss = 1.597273\n",
      "epoch 169 loss = 1.761843\n",
      "epoch 170 loss = 1.672112\n",
      "epoch 171 loss = 1.631939\n",
      "epoch 172 loss = 1.563446\n",
      "epoch 173 loss = 1.512493\n",
      "epoch 174 loss = 1.599211\n",
      "epoch 175 loss = 1.813847\n",
      "epoch 176 loss = 1.655737\n",
      "epoch 177 loss = 1.538356\n",
      "epoch 178 loss = 1.619882\n",
      "epoch 179 loss = 1.577749\n",
      "epoch 180 loss = 1.662549\n",
      "epoch 181 loss = 1.870147\n",
      "epoch 182 loss = 1.623467\n",
      "epoch 183 loss = 1.597265\n",
      "epoch 184 loss = 1.702762\n",
      "epoch 185 loss = 1.607308\n",
      "epoch 186 loss = 1.564364\n",
      "epoch 187 loss = 1.579983\n",
      "epoch 188 loss = 1.658409\n",
      "epoch 189 loss = 1.551594\n",
      "epoch 190 loss = 1.801946\n",
      "epoch 191 loss = 1.544273\n",
      "epoch 192 loss = 1.673069\n",
      "epoch 193 loss = 1.765681\n",
      "epoch 194 loss = 1.515220\n",
      "epoch 195 loss = 1.706558\n",
      "epoch 196 loss = 1.578257\n",
      "epoch 197 loss = 1.499782\n",
      "epoch 198 loss = 1.508741\n",
      "epoch 199 loss = 1.566116\n",
      "epoch 200 loss = 1.349205\n",
      "epoch 201 loss = 1.567930\n",
      "epoch 202 loss = 1.578180\n",
      "epoch 203 loss = 2.032693\n",
      "epoch 204 loss = 1.693649\n",
      "epoch 205 loss = 1.859621\n",
      "epoch 206 loss = 1.684347\n",
      "epoch 207 loss = 1.757707\n",
      "epoch 208 loss = 1.729596\n",
      "epoch 209 loss = 1.601396\n",
      "epoch 210 loss = 1.777159\n",
      "epoch 211 loss = 1.360584\n",
      "epoch 212 loss = 1.626379\n",
      "epoch 213 loss = 1.642958\n",
      "epoch 214 loss = 1.748482\n",
      "epoch 215 loss = 1.852188\n",
      "epoch 216 loss = 1.522899\n",
      "epoch 217 loss = 1.649660\n",
      "epoch 218 loss = 1.438025\n",
      "epoch 219 loss = 1.844507\n",
      "epoch 220 loss = 1.664224\n",
      "epoch 221 loss = 1.538060\n",
      "epoch 222 loss = 1.665161\n",
      "epoch 223 loss = 1.650148\n",
      "epoch 224 loss = 1.407240\n",
      "epoch 225 loss = 1.576057\n",
      "epoch 226 loss = 1.637023\n",
      "epoch 227 loss = 1.509376\n",
      "epoch 228 loss = 1.615265\n",
      "epoch 229 loss = 1.672042\n",
      "epoch 230 loss = 1.402377\n",
      "epoch 231 loss = 1.828317\n",
      "epoch 232 loss = 1.586386\n",
      "epoch 233 loss = 1.602677\n",
      "epoch 234 loss = 1.458379\n",
      "epoch 235 loss = 1.859162\n",
      "epoch 236 loss = 1.666086\n",
      "epoch 237 loss = 1.685050\n",
      "epoch 238 loss = 1.753203\n",
      "epoch 239 loss = 1.745416\n",
      "epoch 240 loss = 1.817294\n",
      "epoch 241 loss = 1.509137\n",
      "epoch 242 loss = 1.735244\n",
      "epoch 243 loss = 1.717863\n",
      "epoch 244 loss = 1.651466\n",
      "epoch 245 loss = 1.585215\n",
      "epoch 246 loss = 1.625569\n",
      "epoch 247 loss = 1.648253\n",
      "epoch 248 loss = 1.543529\n",
      "epoch 249 loss = 1.914211\n",
      "epoch 250 loss = 1.625674\n",
      "epoch 251 loss = 1.834779\n",
      "epoch 252 loss = 1.611951\n",
      "epoch 253 loss = 1.636068\n",
      "epoch 254 loss = 1.568215\n",
      "epoch 255 loss = 1.814104\n",
      "epoch 256 loss = 1.639390\n",
      "epoch 257 loss = 1.706774\n",
      "epoch 258 loss = 1.719009\n",
      "epoch 259 loss = 1.677893\n",
      "epoch 260 loss = 1.701817\n",
      "epoch 261 loss = 1.592000\n",
      "epoch 262 loss = 1.503210\n",
      "epoch 263 loss = 1.629112\n",
      "epoch 264 loss = 1.651614\n",
      "epoch 265 loss = 1.691255\n",
      "epoch 266 loss = 1.756796\n",
      "epoch 267 loss = 1.752630\n",
      "epoch 268 loss = 1.558570\n",
      "epoch 269 loss = 1.738839\n",
      "epoch 270 loss = 1.563472\n",
      "epoch 271 loss = 1.643126\n",
      "epoch 272 loss = 1.541560\n",
      "epoch 273 loss = 1.697943\n",
      "epoch 274 loss = 1.855336\n",
      "epoch 275 loss = 1.606961\n",
      "epoch 276 loss = 1.702391\n",
      "epoch 277 loss = 1.572905\n",
      "epoch 278 loss = 1.688798\n",
      "epoch 279 loss = 1.805479\n",
      "epoch 280 loss = 1.335077\n",
      "epoch 281 loss = 1.756256\n",
      "epoch 282 loss = 1.621157\n",
      "epoch 283 loss = 1.630797\n",
      "epoch 284 loss = 1.744577\n",
      "epoch 285 loss = 1.747460\n",
      "epoch 286 loss = 1.424767\n",
      "epoch 287 loss = 1.526121\n",
      "epoch 288 loss = 1.660950\n",
      "epoch 289 loss = 1.723943\n",
      "epoch 290 loss = 1.520692\n",
      "epoch 291 loss = 1.551409\n",
      "epoch 292 loss = 1.609985\n",
      "epoch 293 loss = 1.703627\n",
      "epoch 294 loss = 1.619964\n",
      "epoch 295 loss = 1.723826\n",
      "epoch 296 loss = 1.786766\n",
      "epoch 297 loss = 1.680466\n",
      "epoch 298 loss = 1.653029\n",
      "epoch 299 loss = 1.538572\n",
      "epoch 300 loss = 1.624197\n",
      "epoch 301 loss = 1.857865\n",
      "epoch 302 loss = 1.865127\n",
      "epoch 303 loss = 1.636425\n",
      "epoch 304 loss = 1.418773\n",
      "epoch 305 loss = 1.714131\n",
      "epoch 306 loss = 1.539993\n",
      "epoch 307 loss = 1.546415\n",
      "epoch 308 loss = 1.720042\n",
      "epoch 309 loss = 1.853459\n",
      "epoch 310 loss = 1.777589\n",
      "epoch 311 loss = 1.528395\n",
      "epoch 312 loss = 1.802958\n",
      "epoch 313 loss = 1.820859\n",
      "epoch 314 loss = 1.823142\n",
      "epoch 315 loss = 1.812901\n",
      "epoch 316 loss = 1.710956\n",
      "epoch 317 loss = 1.657354\n",
      "epoch 318 loss = 1.604981\n",
      "epoch 319 loss = 1.409656\n",
      "epoch 320 loss = 1.597620\n",
      "epoch 321 loss = 1.890607\n",
      "epoch 322 loss = 1.680039\n",
      "epoch 323 loss = 1.963432\n",
      "epoch 324 loss = 1.782419\n",
      "epoch 325 loss = 1.647252\n",
      "epoch 326 loss = 1.522257\n",
      "epoch 327 loss = 1.614044\n",
      "epoch 328 loss = 1.517906\n",
      "epoch 329 loss = 1.867303\n",
      "epoch 330 loss = 1.700514\n",
      "epoch 331 loss = 1.601822\n",
      "epoch 332 loss = 1.646147\n",
      "epoch 333 loss = 1.601246\n",
      "epoch 334 loss = 1.694384\n",
      "epoch 335 loss = 1.496766\n",
      "epoch 336 loss = 1.755955\n",
      "epoch 337 loss = 1.848877\n",
      "epoch 338 loss = 1.607285\n",
      "epoch 339 loss = 1.647285\n",
      "epoch 340 loss = 1.826890\n",
      "epoch 341 loss = 1.699265\n",
      "epoch 342 loss = 1.561271\n",
      "epoch 343 loss = 1.663867\n",
      "epoch 344 loss = 1.902094\n",
      "epoch 345 loss = 1.643152\n",
      "epoch 346 loss = 1.665556\n",
      "epoch 347 loss = 1.635698\n",
      "epoch 348 loss = 1.520943\n",
      "epoch 349 loss = 1.711731\n",
      "epoch 350 loss = 1.624203\n",
      "epoch 351 loss = 1.585516\n",
      "epoch 352 loss = 1.659477\n",
      "epoch 353 loss = 1.669587\n",
      "epoch 354 loss = 1.755725\n",
      "epoch 355 loss = 1.877765\n",
      "epoch 356 loss = 1.744385\n",
      "epoch 357 loss = 1.449224\n",
      "epoch 358 loss = 1.680747\n",
      "epoch 359 loss = 1.492047\n",
      "epoch 360 loss = 1.542338\n",
      "epoch 361 loss = 1.616675\n",
      "epoch 362 loss = 1.405544\n",
      "epoch 363 loss = 1.766569\n",
      "epoch 364 loss = 1.824861\n",
      "epoch 365 loss = 1.803738\n",
      "epoch 366 loss = 1.508752\n",
      "epoch 367 loss = 1.880219\n",
      "epoch 368 loss = 1.701580\n",
      "epoch 369 loss = 1.515193\n",
      "epoch 370 loss = 1.689467\n",
      "epoch 371 loss = 1.670417\n",
      "epoch 372 loss = 1.725745\n",
      "epoch 373 loss = 1.651406\n",
      "epoch 374 loss = 1.768433\n",
      "epoch 375 loss = 1.812299\n",
      "epoch 376 loss = 1.668980\n",
      "epoch 377 loss = 1.815448\n",
      "epoch 378 loss = 1.801344\n",
      "epoch 379 loss = 1.805902\n",
      "epoch 380 loss = 1.716850\n",
      "epoch 381 loss = 1.451466\n",
      "epoch 382 loss = 1.996183\n",
      "epoch 383 loss = 1.646560\n",
      "epoch 384 loss = 1.531253\n",
      "epoch 385 loss = 1.527557\n",
      "epoch 386 loss = 1.493217\n",
      "epoch 387 loss = 1.726741\n",
      "epoch 388 loss = 1.317945\n",
      "epoch 389 loss = 1.632594\n",
      "epoch 390 loss = 1.882415\n",
      "epoch 391 loss = 1.645254\n",
      "epoch 392 loss = 1.768964\n",
      "epoch 393 loss = 1.608955\n",
      "epoch 394 loss = 1.623123\n",
      "epoch 395 loss = 1.678828\n",
      "epoch 396 loss = 1.741514\n",
      "epoch 397 loss = 1.765661\n",
      "epoch 398 loss = 1.593704\n",
      "epoch 399 loss = 1.478528\n",
      "epoch 400 loss = 1.977879\n",
      "epoch 401 loss = 1.803513\n",
      "epoch 402 loss = 1.741277\n",
      "epoch 403 loss = 1.428999\n",
      "epoch 404 loss = 1.967956\n",
      "epoch 405 loss = 1.782510\n",
      "epoch 406 loss = 1.449265\n",
      "epoch 407 loss = 1.745380\n",
      "epoch 408 loss = 1.613535\n",
      "epoch 409 loss = 1.537360\n",
      "epoch 410 loss = 1.767324\n",
      "epoch 411 loss = 1.791387\n",
      "epoch 412 loss = 1.533094\n",
      "epoch 413 loss = 1.468789\n",
      "epoch 414 loss = 1.629246\n",
      "epoch 415 loss = 1.660159\n",
      "epoch 416 loss = 1.481529\n",
      "epoch 417 loss = 1.570058\n",
      "epoch 418 loss = 1.603725\n",
      "epoch 419 loss = 1.725687\n",
      "epoch 420 loss = 1.633130\n",
      "epoch 421 loss = 1.650234\n",
      "epoch 422 loss = 1.497361\n",
      "epoch 423 loss = 1.500477\n",
      "epoch 424 loss = 1.509467\n",
      "epoch 425 loss = 1.514478\n",
      "epoch 426 loss = 1.704086\n",
      "epoch 427 loss = 1.506282\n",
      "epoch 428 loss = 1.513185\n",
      "epoch 429 loss = 1.691122\n",
      "epoch 430 loss = 1.640978\n",
      "epoch 431 loss = 1.486879\n",
      "epoch 432 loss = 1.668606\n",
      "epoch 433 loss = 1.948709\n",
      "epoch 434 loss = 1.778082\n",
      "epoch 435 loss = 1.896102\n",
      "epoch 436 loss = 1.802230\n",
      "epoch 437 loss = 1.742772\n",
      "epoch 438 loss = 1.710100\n",
      "epoch 439 loss = 1.383818\n",
      "epoch 440 loss = 1.946711\n",
      "epoch 441 loss = 2.052721\n",
      "epoch 442 loss = 1.678772\n",
      "epoch 443 loss = 1.481687\n",
      "epoch 444 loss = 1.811642\n",
      "epoch 445 loss = 1.683877\n",
      "epoch 446 loss = 1.738037\n",
      "epoch 447 loss = 1.724282\n",
      "epoch 448 loss = 1.672018\n",
      "epoch 449 loss = 1.643380\n",
      "epoch 450 loss = 1.382868\n",
      "epoch 451 loss = 1.591387\n",
      "epoch 452 loss = 1.540146\n",
      "epoch 453 loss = 1.717103\n",
      "epoch 454 loss = 1.438301\n",
      "epoch 455 loss = 1.566042\n",
      "epoch 456 loss = 1.517899\n",
      "epoch 457 loss = 1.737391\n",
      "epoch 458 loss = 1.584034\n",
      "epoch 459 loss = 1.799785\n",
      "epoch 460 loss = 1.677125\n",
      "epoch 461 loss = 1.629102\n",
      "epoch 462 loss = 1.473026\n",
      "epoch 463 loss = 1.385364\n",
      "epoch 464 loss = 1.910940\n",
      "epoch 465 loss = 1.734806\n",
      "epoch 466 loss = 1.516858\n",
      "epoch 467 loss = 1.842365\n",
      "epoch 468 loss = 1.706269\n",
      "epoch 469 loss = 1.825431\n",
      "epoch 470 loss = 1.827850\n",
      "epoch 471 loss = 1.896181\n",
      "epoch 472 loss = 1.536068\n",
      "epoch 473 loss = 1.439549\n",
      "epoch 474 loss = 1.754781\n",
      "epoch 475 loss = 1.777958\n",
      "epoch 476 loss = 1.606470\n",
      "epoch 477 loss = 1.535501\n",
      "epoch 478 loss = 1.707898\n",
      "epoch 479 loss = 1.420820\n",
      "epoch 480 loss = 1.540990\n",
      "epoch 481 loss = 1.697132\n",
      "epoch 482 loss = 1.943702\n",
      "epoch 483 loss = 1.789799\n",
      "epoch 484 loss = 1.586242\n",
      "epoch 485 loss = 1.564227\n",
      "epoch 486 loss = 1.527951\n",
      "epoch 487 loss = 1.477517\n",
      "epoch 488 loss = 1.655183\n",
      "epoch 489 loss = 1.835252\n",
      "epoch 490 loss = 1.582190\n",
      "epoch 491 loss = 1.658237\n",
      "epoch 492 loss = 1.690633\n",
      "epoch 493 loss = 1.475448\n",
      "epoch 494 loss = 1.734065\n",
      "epoch 495 loss = 1.674846\n",
      "epoch 496 loss = 1.374670\n",
      "epoch 497 loss = 1.666403\n",
      "epoch 498 loss = 1.412767\n",
      "epoch 499 loss = 1.738088\n",
      "final loss = 1.738088\n",
      "accuracy_mc = tensor(0.4101, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.4187, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.7032, device='cuda:0')\n",
      "training time = 305.5250198841095 seconds\n",
      "testing time = 3.2642171382904053 seconds\n",
      "\n",
      "Training with split 5\n",
      "epoch 0 loss = 2.290285\n",
      "epoch 1 loss = 2.150913\n",
      "epoch 2 loss = 2.174683\n",
      "epoch 3 loss = 2.212096\n",
      "epoch 4 loss = 2.071778\n",
      "epoch 5 loss = 2.207070\n",
      "epoch 6 loss = 2.203781\n",
      "epoch 7 loss = 2.122574\n",
      "epoch 8 loss = 2.104724\n",
      "epoch 9 loss = 1.926449\n",
      "epoch 10 loss = 2.119802\n",
      "epoch 11 loss = 2.054675\n",
      "epoch 12 loss = 2.197213\n",
      "epoch 13 loss = 2.285094\n",
      "epoch 14 loss = 2.037354\n",
      "epoch 15 loss = 1.999731\n",
      "epoch 16 loss = 1.953623\n",
      "epoch 17 loss = 2.137059\n",
      "epoch 18 loss = 2.023218\n",
      "epoch 19 loss = 1.964997\n",
      "epoch 20 loss = 2.000496\n",
      "epoch 21 loss = 1.942018\n",
      "epoch 22 loss = 2.219641\n",
      "epoch 23 loss = 2.046122\n",
      "epoch 24 loss = 2.138855\n",
      "epoch 25 loss = 2.045883\n",
      "epoch 26 loss = 2.194350\n",
      "epoch 27 loss = 1.928338\n",
      "epoch 28 loss = 2.026485\n",
      "epoch 29 loss = 1.900224\n",
      "epoch 30 loss = 1.921123\n",
      "epoch 31 loss = 1.990834\n",
      "epoch 32 loss = 2.070781\n",
      "epoch 33 loss = 2.022407\n",
      "epoch 34 loss = 2.074606\n",
      "epoch 35 loss = 1.834990\n",
      "epoch 36 loss = 1.958996\n",
      "epoch 37 loss = 1.827718\n",
      "epoch 38 loss = 2.303372\n",
      "epoch 39 loss = 2.082225\n",
      "epoch 40 loss = 2.071018\n",
      "epoch 41 loss = 2.017038\n",
      "epoch 42 loss = 2.050021\n",
      "epoch 43 loss = 2.024128\n",
      "epoch 44 loss = 2.279923\n",
      "epoch 45 loss = 1.916632\n",
      "epoch 46 loss = 1.778596\n",
      "epoch 47 loss = 2.076023\n",
      "epoch 48 loss = 1.950569\n",
      "epoch 49 loss = 1.908121\n",
      "epoch 50 loss = 2.102013\n",
      "epoch 51 loss = 2.112646\n",
      "epoch 52 loss = 2.029760\n",
      "epoch 53 loss = 1.999325\n",
      "epoch 54 loss = 1.831523\n",
      "epoch 55 loss = 1.990433\n",
      "epoch 56 loss = 2.022926\n",
      "epoch 57 loss = 1.878369\n",
      "epoch 58 loss = 1.885055\n",
      "epoch 59 loss = 2.162813\n",
      "epoch 60 loss = 1.976622\n",
      "epoch 61 loss = 2.148358\n",
      "epoch 62 loss = 2.069049\n",
      "epoch 63 loss = 2.031659\n",
      "epoch 64 loss = 2.319471\n",
      "epoch 65 loss = 1.990469\n",
      "epoch 66 loss = 2.080425\n",
      "epoch 67 loss = 1.916675\n",
      "epoch 68 loss = 1.994594\n",
      "epoch 69 loss = 2.062555\n",
      "epoch 70 loss = 1.973058\n",
      "epoch 71 loss = 2.014407\n",
      "epoch 72 loss = 2.217192\n",
      "epoch 73 loss = 1.986327\n",
      "epoch 74 loss = 1.880407\n",
      "epoch 75 loss = 2.043366\n",
      "epoch 76 loss = 2.002329\n",
      "epoch 77 loss = 2.099165\n",
      "epoch 78 loss = 2.012407\n",
      "epoch 79 loss = 1.898849\n",
      "epoch 80 loss = 1.930993\n",
      "epoch 81 loss = 2.153664\n",
      "epoch 82 loss = 1.888072\n",
      "epoch 83 loss = 2.098844\n",
      "epoch 84 loss = 1.842963\n",
      "epoch 85 loss = 1.934383\n",
      "epoch 86 loss = 1.785519\n",
      "epoch 87 loss = 1.798448\n",
      "epoch 88 loss = 1.965721\n",
      "epoch 89 loss = 1.947996\n",
      "epoch 90 loss = 1.939539\n",
      "epoch 91 loss = 1.844740\n",
      "epoch 92 loss = 2.048348\n",
      "epoch 93 loss = 1.912366\n",
      "epoch 94 loss = 1.928041\n",
      "epoch 95 loss = 2.021843\n",
      "epoch 96 loss = 1.931664\n",
      "epoch 97 loss = 1.669140\n",
      "epoch 98 loss = 1.863450\n",
      "epoch 99 loss = 1.861562\n",
      "epoch 100 loss = 2.001146\n",
      "epoch 101 loss = 2.070104\n",
      "epoch 102 loss = 1.683687\n",
      "epoch 103 loss = 1.894161\n",
      "epoch 104 loss = 2.059244\n",
      "epoch 105 loss = 1.798712\n",
      "epoch 106 loss = 2.014009\n",
      "epoch 107 loss = 1.834235\n",
      "epoch 108 loss = 1.802563\n",
      "epoch 109 loss = 1.869916\n",
      "epoch 110 loss = 1.807103\n",
      "epoch 111 loss = 2.071254\n",
      "epoch 112 loss = 1.731759\n",
      "epoch 113 loss = 1.659201\n",
      "epoch 114 loss = 1.824748\n",
      "epoch 115 loss = 1.744874\n",
      "epoch 116 loss = 2.025480\n",
      "epoch 117 loss = 1.972101\n",
      "epoch 118 loss = 1.818992\n",
      "epoch 119 loss = 1.781937\n",
      "epoch 120 loss = 1.856607\n",
      "epoch 121 loss = 2.041258\n",
      "epoch 122 loss = 1.954665\n",
      "epoch 123 loss = 1.868757\n",
      "epoch 124 loss = 1.928398\n",
      "epoch 125 loss = 1.862270\n",
      "epoch 126 loss = 1.897624\n",
      "epoch 127 loss = 1.940872\n",
      "epoch 128 loss = 1.745602\n",
      "epoch 129 loss = 1.894357\n",
      "epoch 130 loss = 2.049145\n",
      "epoch 131 loss = 1.829488\n",
      "epoch 132 loss = 2.014103\n",
      "epoch 133 loss = 1.943186\n",
      "epoch 134 loss = 2.116740\n",
      "epoch 135 loss = 1.810882\n",
      "epoch 136 loss = 1.817284\n",
      "epoch 137 loss = 2.004314\n",
      "epoch 138 loss = 1.672251\n",
      "epoch 139 loss = 1.952021\n",
      "epoch 140 loss = 1.682968\n",
      "epoch 141 loss = 1.966153\n",
      "epoch 142 loss = 1.783214\n",
      "epoch 143 loss = 2.127413\n",
      "epoch 144 loss = 2.070801\n",
      "epoch 145 loss = 1.890212\n",
      "epoch 146 loss = 1.860403\n",
      "epoch 147 loss = 1.800079\n",
      "epoch 148 loss = 2.021355\n",
      "epoch 149 loss = 1.976645\n",
      "epoch 150 loss = 1.808635\n",
      "epoch 151 loss = 1.946446\n",
      "epoch 152 loss = 1.820865\n",
      "epoch 153 loss = 1.924739\n",
      "epoch 154 loss = 1.739662\n",
      "epoch 155 loss = 2.034227\n",
      "epoch 156 loss = 1.778957\n",
      "epoch 157 loss = 1.664539\n",
      "epoch 158 loss = 1.699129\n",
      "epoch 159 loss = 2.109147\n",
      "epoch 160 loss = 2.072312\n",
      "epoch 161 loss = 1.812132\n",
      "epoch 162 loss = 1.919797\n",
      "epoch 163 loss = 1.966708\n",
      "epoch 164 loss = 1.902826\n",
      "epoch 165 loss = 1.949008\n",
      "epoch 166 loss = 2.020442\n",
      "epoch 167 loss = 1.993691\n",
      "epoch 168 loss = 1.838044\n",
      "epoch 169 loss = 1.744703\n",
      "epoch 170 loss = 1.988686\n",
      "epoch 171 loss = 1.561226\n",
      "epoch 172 loss = 1.932439\n",
      "epoch 173 loss = 1.722068\n",
      "epoch 174 loss = 2.200071\n",
      "epoch 175 loss = 1.788146\n",
      "epoch 176 loss = 1.669859\n",
      "epoch 177 loss = 1.856295\n",
      "epoch 178 loss = 1.944335\n",
      "epoch 179 loss = 1.973829\n",
      "epoch 180 loss = 1.993078\n",
      "epoch 181 loss = 1.775665\n",
      "epoch 182 loss = 1.846628\n",
      "epoch 183 loss = 1.952704\n",
      "epoch 184 loss = 1.834501\n",
      "epoch 185 loss = 1.879542\n",
      "epoch 186 loss = 1.846257\n",
      "epoch 187 loss = 1.963896\n",
      "epoch 188 loss = 2.127644\n",
      "epoch 189 loss = 1.827017\n",
      "epoch 190 loss = 1.814262\n",
      "epoch 191 loss = 1.757880\n",
      "epoch 192 loss = 1.905421\n",
      "epoch 193 loss = 1.901787\n",
      "epoch 194 loss = 1.759641\n",
      "epoch 195 loss = 1.701983\n",
      "epoch 196 loss = 1.978014\n",
      "epoch 197 loss = 1.961208\n",
      "epoch 198 loss = 2.100816\n",
      "epoch 199 loss = 2.259026\n",
      "epoch 200 loss = 2.053821\n",
      "epoch 201 loss = 1.937985\n",
      "epoch 202 loss = 1.715961\n",
      "epoch 203 loss = 1.728954\n",
      "epoch 204 loss = 1.769478\n",
      "epoch 205 loss = 1.743692\n",
      "epoch 206 loss = 1.798714\n",
      "epoch 207 loss = 1.937268\n",
      "epoch 208 loss = 1.639674\n",
      "epoch 209 loss = 2.256480\n",
      "epoch 210 loss = 2.095257\n",
      "epoch 211 loss = 1.821573\n",
      "epoch 212 loss = 1.941956\n",
      "epoch 213 loss = 1.898421\n",
      "epoch 214 loss = 2.013081\n",
      "epoch 215 loss = 1.832057\n",
      "epoch 216 loss = 1.666360\n",
      "epoch 217 loss = 1.887555\n",
      "epoch 218 loss = 1.801179\n",
      "epoch 219 loss = 1.828821\n",
      "epoch 220 loss = 2.073958\n",
      "epoch 221 loss = 2.137601\n",
      "epoch 222 loss = 2.113221\n",
      "epoch 223 loss = 2.020180\n",
      "epoch 224 loss = 2.016411\n",
      "epoch 225 loss = 1.878060\n",
      "epoch 226 loss = 1.993674\n",
      "epoch 227 loss = 1.750726\n",
      "epoch 228 loss = 1.800135\n",
      "epoch 229 loss = 1.964035\n",
      "epoch 230 loss = 2.093500\n",
      "epoch 231 loss = 1.737437\n",
      "epoch 232 loss = 1.550475\n",
      "epoch 233 loss = 1.910182\n",
      "epoch 234 loss = 1.831432\n",
      "epoch 235 loss = 2.089386\n",
      "epoch 236 loss = 2.155638\n",
      "epoch 237 loss = 1.871103\n",
      "epoch 238 loss = 1.893349\n",
      "epoch 239 loss = 1.742332\n",
      "epoch 240 loss = 1.850909\n",
      "epoch 241 loss = 2.030306\n",
      "epoch 242 loss = 2.101523\n",
      "epoch 243 loss = 1.748182\n",
      "epoch 244 loss = 2.086118\n",
      "epoch 245 loss = 1.875070\n",
      "epoch 246 loss = 1.862270\n",
      "epoch 247 loss = 2.053166\n",
      "epoch 248 loss = 1.969654\n",
      "epoch 249 loss = 1.846979\n",
      "epoch 250 loss = 1.862466\n",
      "epoch 251 loss = 1.934008\n",
      "epoch 252 loss = 2.109191\n",
      "epoch 253 loss = 1.835982\n",
      "epoch 254 loss = 1.904143\n",
      "epoch 255 loss = 1.833045\n",
      "epoch 256 loss = 1.996776\n",
      "epoch 257 loss = 1.717730\n",
      "epoch 258 loss = 1.787941\n",
      "epoch 259 loss = 1.864683\n",
      "epoch 260 loss = 2.157727\n",
      "epoch 261 loss = 1.875550\n",
      "epoch 262 loss = 1.959513\n",
      "epoch 263 loss = 2.126002\n",
      "epoch 264 loss = 1.848391\n",
      "epoch 265 loss = 1.799535\n",
      "epoch 266 loss = 1.934576\n",
      "epoch 267 loss = 1.941258\n",
      "epoch 268 loss = 1.791235\n",
      "epoch 269 loss = 1.984621\n",
      "epoch 270 loss = 1.914196\n",
      "epoch 271 loss = 1.875330\n",
      "epoch 272 loss = 1.779634\n",
      "epoch 273 loss = 1.800075\n",
      "epoch 274 loss = 1.627315\n",
      "epoch 275 loss = 1.705284\n",
      "epoch 276 loss = 2.128553\n",
      "epoch 277 loss = 1.975724\n",
      "epoch 278 loss = 1.922166\n",
      "epoch 279 loss = 1.837583\n",
      "epoch 280 loss = 2.146397\n",
      "epoch 281 loss = 1.924732\n",
      "epoch 282 loss = 1.923735\n",
      "epoch 283 loss = 1.760787\n",
      "epoch 284 loss = 1.948235\n",
      "epoch 285 loss = 1.857496\n",
      "epoch 286 loss = 1.894789\n",
      "epoch 287 loss = 1.699175\n",
      "epoch 288 loss = 1.672423\n",
      "epoch 289 loss = 1.849672\n",
      "epoch 290 loss = 1.782826\n",
      "epoch 291 loss = 1.747285\n",
      "epoch 292 loss = 1.792260\n",
      "epoch 293 loss = 1.949828\n",
      "epoch 294 loss = 1.820096\n",
      "epoch 295 loss = 1.897058\n",
      "epoch 296 loss = 1.884278\n",
      "epoch 297 loss = 1.612266\n",
      "epoch 298 loss = 2.002766\n",
      "epoch 299 loss = 1.856655\n",
      "epoch 300 loss = 2.121992\n",
      "epoch 301 loss = 1.769883\n",
      "epoch 302 loss = 1.833489\n",
      "epoch 303 loss = 1.699337\n",
      "epoch 304 loss = 1.885603\n",
      "epoch 305 loss = 1.934268\n",
      "epoch 306 loss = 1.995131\n",
      "epoch 307 loss = 2.076877\n",
      "epoch 308 loss = 1.985421\n",
      "epoch 309 loss = 2.077683\n",
      "epoch 310 loss = 1.663879\n",
      "epoch 311 loss = 1.608923\n",
      "epoch 312 loss = 2.055934\n",
      "epoch 313 loss = 1.843445\n",
      "epoch 314 loss = 1.743341\n",
      "epoch 315 loss = 2.125713\n",
      "epoch 316 loss = 1.829331\n",
      "epoch 317 loss = 1.889125\n",
      "epoch 318 loss = 1.906896\n",
      "epoch 319 loss = 1.749215\n",
      "epoch 320 loss = 2.137043\n",
      "epoch 321 loss = 1.794085\n",
      "epoch 322 loss = 1.967797\n",
      "epoch 323 loss = 1.702768\n",
      "epoch 324 loss = 2.107702\n",
      "epoch 325 loss = 1.770093\n",
      "epoch 326 loss = 1.797637\n",
      "epoch 327 loss = 1.915850\n",
      "epoch 328 loss = 1.787276\n",
      "epoch 329 loss = 2.054080\n",
      "epoch 330 loss = 1.978178\n",
      "epoch 331 loss = 1.875685\n",
      "epoch 332 loss = 1.881346\n",
      "epoch 333 loss = 2.040587\n",
      "epoch 334 loss = 1.814144\n",
      "epoch 335 loss = 1.921397\n",
      "epoch 336 loss = 1.911735\n",
      "epoch 337 loss = 2.002647\n",
      "epoch 338 loss = 1.830977\n",
      "epoch 339 loss = 1.743506\n",
      "epoch 340 loss = 1.807370\n",
      "epoch 341 loss = 1.960815\n",
      "epoch 342 loss = 1.982663\n",
      "epoch 343 loss = 1.859111\n",
      "epoch 344 loss = 1.924910\n",
      "epoch 345 loss = 1.859135\n",
      "epoch 346 loss = 1.692736\n",
      "epoch 347 loss = 1.959593\n",
      "epoch 348 loss = 1.810502\n",
      "epoch 349 loss = 1.693836\n",
      "epoch 350 loss = 1.716590\n",
      "epoch 351 loss = 2.008621\n",
      "epoch 352 loss = 1.954346\n",
      "epoch 353 loss = 1.881557\n",
      "epoch 354 loss = 1.947283\n",
      "epoch 355 loss = 1.855744\n",
      "epoch 356 loss = 1.875662\n",
      "epoch 357 loss = 1.869126\n",
      "epoch 358 loss = 1.895190\n",
      "epoch 359 loss = 1.870582\n",
      "epoch 360 loss = 2.164672\n",
      "epoch 361 loss = 1.947835\n",
      "epoch 362 loss = 1.985981\n",
      "epoch 363 loss = 1.763740\n",
      "epoch 364 loss = 1.981870\n",
      "epoch 365 loss = 1.808154\n",
      "epoch 366 loss = 1.734388\n",
      "epoch 367 loss = 1.876120\n",
      "epoch 368 loss = 2.026304\n",
      "epoch 369 loss = 1.951907\n",
      "epoch 370 loss = 1.858087\n",
      "epoch 371 loss = 1.862240\n",
      "epoch 372 loss = 1.964607\n",
      "epoch 373 loss = 1.831262\n",
      "epoch 374 loss = 1.774714\n",
      "epoch 375 loss = 2.016352\n",
      "epoch 376 loss = 1.833635\n",
      "epoch 377 loss = 1.941457\n",
      "epoch 378 loss = 1.850327\n",
      "epoch 379 loss = 1.857573\n",
      "epoch 380 loss = 1.961292\n",
      "epoch 381 loss = 1.866030\n",
      "epoch 382 loss = 1.991483\n",
      "epoch 383 loss = 1.828993\n",
      "epoch 384 loss = 1.840269\n",
      "epoch 385 loss = 1.783960\n",
      "epoch 386 loss = 2.064110\n",
      "epoch 387 loss = 1.796767\n",
      "epoch 388 loss = 1.798670\n",
      "epoch 389 loss = 1.985260\n",
      "epoch 390 loss = 1.690417\n",
      "epoch 391 loss = 1.820644\n",
      "epoch 392 loss = 1.884907\n",
      "epoch 393 loss = 2.192876\n",
      "epoch 394 loss = 1.934503\n",
      "epoch 395 loss = 1.837850\n",
      "epoch 396 loss = 2.140363\n",
      "epoch 397 loss = 2.297377\n",
      "epoch 398 loss = 1.799613\n",
      "epoch 399 loss = 1.983094\n",
      "epoch 400 loss = 2.001574\n",
      "epoch 401 loss = 1.748541\n",
      "epoch 402 loss = 1.826684\n",
      "epoch 403 loss = 1.643851\n",
      "epoch 404 loss = 2.027088\n",
      "epoch 405 loss = 2.026855\n",
      "epoch 406 loss = 1.749040\n",
      "epoch 407 loss = 1.698672\n",
      "epoch 408 loss = 1.980006\n",
      "epoch 409 loss = 1.845711\n",
      "epoch 410 loss = 2.065047\n",
      "epoch 411 loss = 1.997138\n",
      "epoch 412 loss = 2.118625\n",
      "epoch 413 loss = 1.784668\n",
      "epoch 414 loss = 1.671468\n",
      "epoch 415 loss = 1.898657\n",
      "epoch 416 loss = 1.841882\n",
      "epoch 417 loss = 1.994929\n",
      "epoch 418 loss = 1.860351\n",
      "epoch 419 loss = 1.641743\n",
      "epoch 420 loss = 1.853168\n",
      "epoch 421 loss = 2.178840\n",
      "epoch 422 loss = 2.087790\n",
      "epoch 423 loss = 1.834574\n",
      "epoch 424 loss = 1.863128\n",
      "epoch 425 loss = 1.955614\n",
      "epoch 426 loss = 2.016813\n",
      "epoch 427 loss = 2.224410\n",
      "epoch 428 loss = 1.989602\n",
      "epoch 429 loss = 1.857814\n",
      "epoch 430 loss = 1.886055\n",
      "epoch 431 loss = 1.940827\n",
      "epoch 432 loss = 1.802742\n",
      "epoch 433 loss = 1.734232\n",
      "epoch 434 loss = 1.915473\n",
      "epoch 435 loss = 1.886162\n",
      "epoch 436 loss = 1.872530\n",
      "epoch 437 loss = 1.787936\n",
      "epoch 438 loss = 2.000214\n",
      "epoch 439 loss = 1.941740\n",
      "epoch 440 loss = 2.211631\n",
      "epoch 441 loss = 1.881248\n",
      "epoch 442 loss = 1.668626\n",
      "epoch 443 loss = 1.862021\n",
      "epoch 444 loss = 1.947256\n",
      "epoch 445 loss = 1.939712\n",
      "epoch 446 loss = 1.782580\n",
      "epoch 447 loss = 1.748163\n",
      "epoch 448 loss = 1.915661\n",
      "epoch 449 loss = 1.964379\n",
      "epoch 450 loss = 1.930418\n",
      "epoch 451 loss = 1.610829\n",
      "epoch 452 loss = 1.615286\n",
      "epoch 453 loss = 1.792735\n",
      "epoch 454 loss = 1.899848\n",
      "epoch 455 loss = 1.983021\n",
      "epoch 456 loss = 1.878279\n",
      "epoch 457 loss = 1.901420\n",
      "epoch 458 loss = 1.574217\n",
      "epoch 459 loss = 1.863199\n",
      "epoch 460 loss = 2.086493\n",
      "epoch 461 loss = 2.223976\n",
      "epoch 462 loss = 1.991878\n",
      "epoch 463 loss = 1.748623\n",
      "epoch 464 loss = 1.858173\n",
      "epoch 465 loss = 1.972714\n",
      "epoch 466 loss = 1.644671\n",
      "epoch 467 loss = 1.754581\n",
      "epoch 468 loss = 2.074320\n",
      "epoch 469 loss = 1.802667\n",
      "epoch 470 loss = 1.666186\n",
      "epoch 471 loss = 2.039442\n",
      "epoch 472 loss = 1.698088\n",
      "epoch 473 loss = 1.641018\n",
      "epoch 474 loss = 1.682505\n",
      "epoch 475 loss = 1.889716\n",
      "epoch 476 loss = 1.824334\n",
      "epoch 477 loss = 2.032246\n",
      "epoch 478 loss = 1.837304\n",
      "epoch 479 loss = 1.880937\n",
      "epoch 480 loss = 1.730836\n",
      "epoch 481 loss = 1.815019\n",
      "epoch 482 loss = 1.801640\n",
      "epoch 483 loss = 1.607051\n",
      "epoch 484 loss = 1.943429\n",
      "epoch 485 loss = 1.831988\n",
      "epoch 486 loss = 1.946290\n",
      "epoch 487 loss = 1.846195\n",
      "epoch 488 loss = 1.837920\n",
      "epoch 489 loss = 1.848603\n",
      "epoch 490 loss = 1.738777\n",
      "epoch 491 loss = 1.830572\n",
      "epoch 492 loss = 1.879491\n",
      "epoch 493 loss = 2.070131\n",
      "epoch 494 loss = 1.834911\n",
      "epoch 495 loss = 1.804852\n",
      "epoch 496 loss = 2.018295\n",
      "epoch 497 loss = 1.712335\n",
      "epoch 498 loss = 1.526467\n",
      "epoch 499 loss = 1.888800\n",
      "final loss = 1.888800\n",
      "accuracy_mc = tensor(0.3063, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.3039, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.8571, device='cuda:0')\n",
      "training time = 306.1543171405792 seconds\n",
      "testing time = 3.2385873794555664 seconds\n",
      "\n",
      "Training with split 6\n",
      "epoch 0 loss = 2.279150\n",
      "epoch 1 loss = 2.366536\n",
      "epoch 2 loss = 2.318632\n",
      "epoch 3 loss = 2.510020\n",
      "epoch 4 loss = 2.225910\n",
      "epoch 5 loss = 2.407941\n",
      "epoch 6 loss = 2.292308\n",
      "epoch 7 loss = 2.297240\n",
      "epoch 8 loss = 2.191586\n",
      "epoch 9 loss = 2.110430\n",
      "epoch 10 loss = 2.443314\n",
      "epoch 11 loss = 2.226828\n",
      "epoch 12 loss = 2.267670\n",
      "epoch 13 loss = 2.157628\n",
      "epoch 14 loss = 2.102085\n",
      "epoch 15 loss = 2.124369\n",
      "epoch 16 loss = 2.436640\n",
      "epoch 17 loss = 2.260755\n",
      "epoch 18 loss = 2.183486\n",
      "epoch 19 loss = 2.265212\n",
      "epoch 20 loss = 2.371400\n",
      "epoch 21 loss = 2.103991\n",
      "epoch 22 loss = 2.026366\n",
      "epoch 23 loss = 2.431739\n",
      "epoch 24 loss = 2.395543\n",
      "epoch 25 loss = 1.910333\n",
      "epoch 26 loss = 2.111689\n",
      "epoch 27 loss = 2.258836\n",
      "epoch 28 loss = 2.109642\n",
      "epoch 29 loss = 2.186819\n",
      "epoch 30 loss = 2.222280\n",
      "epoch 31 loss = 2.166198\n",
      "epoch 32 loss = 2.172518\n",
      "epoch 33 loss = 1.971253\n",
      "epoch 34 loss = 2.070498\n",
      "epoch 35 loss = 2.303473\n",
      "epoch 36 loss = 2.132545\n",
      "epoch 37 loss = 2.039643\n",
      "epoch 38 loss = 1.938900\n",
      "epoch 39 loss = 2.202306\n",
      "epoch 40 loss = 1.999998\n",
      "epoch 41 loss = 1.881978\n",
      "epoch 42 loss = 1.903736\n",
      "epoch 43 loss = 2.060231\n",
      "epoch 44 loss = 2.157135\n",
      "epoch 45 loss = 2.043084\n",
      "epoch 46 loss = 1.952741\n",
      "epoch 47 loss = 2.067168\n",
      "epoch 48 loss = 1.858234\n",
      "epoch 49 loss = 2.045276\n",
      "epoch 50 loss = 2.036566\n",
      "epoch 51 loss = 2.074702\n",
      "epoch 52 loss = 2.110722\n",
      "epoch 53 loss = 2.002259\n",
      "epoch 54 loss = 1.664798\n",
      "epoch 55 loss = 2.150311\n",
      "epoch 56 loss = 2.114338\n",
      "epoch 57 loss = 2.203053\n",
      "epoch 58 loss = 1.954729\n",
      "epoch 59 loss = 1.760142\n",
      "epoch 60 loss = 2.140628\n",
      "epoch 61 loss = 1.856269\n",
      "epoch 62 loss = 2.113329\n",
      "epoch 63 loss = 1.791916\n",
      "epoch 64 loss = 1.911536\n",
      "epoch 65 loss = 1.994694\n",
      "epoch 66 loss = 2.211144\n",
      "epoch 67 loss = 2.333108\n",
      "epoch 68 loss = 2.338039\n",
      "epoch 69 loss = 2.106404\n",
      "epoch 70 loss = 1.926335\n",
      "epoch 71 loss = 1.844479\n",
      "epoch 72 loss = 2.020209\n",
      "epoch 73 loss = 2.075447\n",
      "epoch 74 loss = 1.737180\n",
      "epoch 75 loss = 1.813238\n",
      "epoch 76 loss = 2.082082\n",
      "epoch 77 loss = 1.638855\n",
      "epoch 78 loss = 2.250746\n",
      "epoch 79 loss = 2.081541\n",
      "epoch 80 loss = 1.757033\n",
      "epoch 81 loss = 1.848892\n",
      "epoch 82 loss = 1.782489\n",
      "epoch 83 loss = 1.759522\n",
      "epoch 84 loss = 1.831878\n",
      "epoch 85 loss = 2.034379\n",
      "epoch 86 loss = 2.024934\n",
      "epoch 87 loss = 1.936153\n",
      "epoch 88 loss = 1.829694\n",
      "epoch 89 loss = 1.951700\n",
      "epoch 90 loss = 1.639482\n",
      "epoch 91 loss = 1.809772\n",
      "epoch 92 loss = 2.004083\n",
      "epoch 93 loss = 2.001115\n",
      "epoch 94 loss = 1.540408\n",
      "epoch 95 loss = 1.838146\n",
      "epoch 96 loss = 1.776809\n",
      "epoch 97 loss = 2.106723\n",
      "epoch 98 loss = 1.793730\n",
      "epoch 99 loss = 2.030684\n",
      "epoch 100 loss = 1.802965\n",
      "epoch 101 loss = 1.842313\n",
      "epoch 102 loss = 1.758312\n",
      "epoch 103 loss = 1.734763\n",
      "epoch 104 loss = 1.808258\n",
      "epoch 105 loss = 1.910481\n",
      "epoch 106 loss = 1.839599\n",
      "epoch 107 loss = 1.824531\n",
      "epoch 108 loss = 1.695762\n",
      "epoch 109 loss = 1.901119\n",
      "epoch 110 loss = 1.902911\n",
      "epoch 111 loss = 1.729970\n",
      "epoch 112 loss = 1.811515\n",
      "epoch 113 loss = 2.049196\n",
      "epoch 114 loss = 1.800686\n",
      "epoch 115 loss = 1.902938\n",
      "epoch 116 loss = 1.891450\n",
      "epoch 117 loss = 1.783887\n",
      "epoch 118 loss = 1.703636\n",
      "epoch 119 loss = 1.681423\n",
      "epoch 120 loss = 1.830873\n",
      "epoch 121 loss = 1.723786\n",
      "epoch 122 loss = 2.081462\n",
      "epoch 123 loss = 1.798273\n",
      "epoch 124 loss = 1.764852\n",
      "epoch 125 loss = 2.045725\n",
      "epoch 126 loss = 2.049376\n",
      "epoch 127 loss = 1.990484\n",
      "epoch 128 loss = 1.999943\n",
      "epoch 129 loss = 1.909119\n",
      "epoch 130 loss = 1.726350\n",
      "epoch 131 loss = 1.910894\n",
      "epoch 132 loss = 1.896248\n",
      "epoch 133 loss = 1.915723\n",
      "epoch 134 loss = 2.006154\n",
      "epoch 135 loss = 1.822305\n",
      "epoch 136 loss = 1.892668\n",
      "epoch 137 loss = 1.830219\n",
      "epoch 138 loss = 1.899962\n",
      "epoch 139 loss = 1.737871\n",
      "epoch 140 loss = 1.779966\n",
      "epoch 141 loss = 1.521068\n",
      "epoch 142 loss = 1.777644\n",
      "epoch 143 loss = 1.780775\n",
      "epoch 144 loss = 1.902638\n",
      "epoch 145 loss = 1.823374\n",
      "epoch 146 loss = 1.732332\n",
      "epoch 147 loss = 1.785675\n",
      "epoch 148 loss = 1.857427\n",
      "epoch 149 loss = 1.822157\n",
      "epoch 150 loss = 1.812329\n",
      "epoch 151 loss = 1.876765\n",
      "epoch 152 loss = 1.815223\n",
      "epoch 153 loss = 1.637018\n",
      "epoch 154 loss = 1.993667\n",
      "epoch 155 loss = 1.562910\n",
      "epoch 156 loss = 1.941538\n",
      "epoch 157 loss = 1.692520\n",
      "epoch 158 loss = 1.827091\n",
      "epoch 159 loss = 1.857690\n",
      "epoch 160 loss = 1.658371\n",
      "epoch 161 loss = 1.947657\n",
      "epoch 162 loss = 1.764753\n",
      "epoch 163 loss = 1.678417\n",
      "epoch 164 loss = 1.869138\n",
      "epoch 165 loss = 1.448056\n",
      "epoch 166 loss = 1.934345\n",
      "epoch 167 loss = 1.708725\n",
      "epoch 168 loss = 1.798769\n",
      "epoch 169 loss = 1.724490\n",
      "epoch 170 loss = 1.875014\n",
      "epoch 171 loss = 1.958967\n",
      "epoch 172 loss = 1.711136\n",
      "epoch 173 loss = 1.680609\n",
      "epoch 174 loss = 1.735036\n",
      "epoch 175 loss = 1.856617\n",
      "epoch 176 loss = 1.667284\n",
      "epoch 177 loss = 1.830782\n",
      "epoch 178 loss = 1.704066\n",
      "epoch 179 loss = 1.938292\n",
      "epoch 180 loss = 1.898590\n",
      "epoch 181 loss = 1.718208\n",
      "epoch 182 loss = 2.053597\n",
      "epoch 183 loss = 1.890290\n",
      "epoch 184 loss = 1.629999\n",
      "epoch 185 loss = 1.653585\n",
      "epoch 186 loss = 1.924222\n",
      "epoch 187 loss = 1.979834\n",
      "epoch 188 loss = 1.891133\n",
      "epoch 189 loss = 1.904729\n",
      "epoch 190 loss = 1.651070\n",
      "epoch 191 loss = 1.659918\n",
      "epoch 192 loss = 1.790985\n",
      "epoch 193 loss = 1.773965\n",
      "epoch 194 loss = 1.589891\n",
      "epoch 195 loss = 2.015091\n",
      "epoch 196 loss = 1.953293\n",
      "epoch 197 loss = 1.708239\n",
      "epoch 198 loss = 1.763244\n",
      "epoch 199 loss = 1.763462\n",
      "epoch 200 loss = 1.995427\n",
      "epoch 201 loss = 1.927513\n",
      "epoch 202 loss = 1.981170\n",
      "epoch 203 loss = 1.908775\n",
      "epoch 204 loss = 1.603553\n",
      "epoch 205 loss = 2.119094\n",
      "epoch 206 loss = 1.597213\n",
      "epoch 207 loss = 1.807005\n",
      "epoch 208 loss = 1.819091\n",
      "epoch 209 loss = 1.716591\n",
      "epoch 210 loss = 1.832325\n",
      "epoch 211 loss = 1.651377\n",
      "epoch 212 loss = 1.947498\n",
      "epoch 213 loss = 1.699373\n",
      "epoch 214 loss = 1.702018\n",
      "epoch 215 loss = 1.851354\n",
      "epoch 216 loss = 1.787818\n",
      "epoch 217 loss = 1.839167\n",
      "epoch 218 loss = 1.994071\n",
      "epoch 219 loss = 1.826473\n",
      "epoch 220 loss = 1.657838\n",
      "epoch 221 loss = 2.034448\n",
      "epoch 222 loss = 1.996721\n",
      "epoch 223 loss = 1.947737\n",
      "epoch 224 loss = 1.567677\n",
      "epoch 225 loss = 1.542488\n",
      "epoch 226 loss = 1.784729\n",
      "epoch 227 loss = 1.859158\n",
      "epoch 228 loss = 1.671521\n",
      "epoch 229 loss = 1.596186\n",
      "epoch 230 loss = 1.681242\n",
      "epoch 231 loss = 1.813882\n",
      "epoch 232 loss = 1.661348\n",
      "epoch 233 loss = 1.835694\n",
      "epoch 234 loss = 1.920687\n",
      "epoch 235 loss = 1.867475\n",
      "epoch 236 loss = 1.847191\n",
      "epoch 237 loss = 1.636221\n",
      "epoch 238 loss = 1.880485\n",
      "epoch 239 loss = 1.965913\n",
      "epoch 240 loss = 1.746802\n",
      "epoch 241 loss = 1.924553\n",
      "epoch 242 loss = 1.984389\n",
      "epoch 243 loss = 2.213085\n",
      "epoch 244 loss = 1.892420\n",
      "epoch 245 loss = 1.813713\n",
      "epoch 246 loss = 1.986688\n",
      "epoch 247 loss = 1.883996\n",
      "epoch 248 loss = 1.827334\n",
      "epoch 249 loss = 1.765111\n",
      "epoch 250 loss = 1.789666\n",
      "epoch 251 loss = 1.720021\n",
      "epoch 252 loss = 2.056401\n",
      "epoch 253 loss = 1.894358\n",
      "epoch 254 loss = 1.735924\n",
      "epoch 255 loss = 1.786308\n",
      "epoch 256 loss = 2.002881\n",
      "epoch 257 loss = 1.632915\n",
      "epoch 258 loss = 1.936613\n",
      "epoch 259 loss = 1.834798\n",
      "epoch 260 loss = 1.785486\n",
      "epoch 261 loss = 1.938151\n",
      "epoch 262 loss = 1.873542\n",
      "epoch 263 loss = 1.987370\n",
      "epoch 264 loss = 1.807230\n",
      "epoch 265 loss = 1.648836\n",
      "epoch 266 loss = 1.824724\n",
      "epoch 267 loss = 1.959955\n",
      "epoch 268 loss = 1.552935\n",
      "epoch 269 loss = 1.787040\n",
      "epoch 270 loss = 1.823506\n",
      "epoch 271 loss = 1.656159\n",
      "epoch 272 loss = 1.886802\n",
      "epoch 273 loss = 1.873304\n",
      "epoch 274 loss = 2.003792\n",
      "epoch 275 loss = 1.735705\n",
      "epoch 276 loss = 1.798718\n",
      "epoch 277 loss = 1.658540\n",
      "epoch 278 loss = 1.925887\n",
      "epoch 279 loss = 1.823829\n",
      "epoch 280 loss = 1.711455\n",
      "epoch 281 loss = 2.022614\n",
      "epoch 282 loss = 1.860355\n",
      "epoch 283 loss = 1.821939\n",
      "epoch 284 loss = 1.754355\n",
      "epoch 285 loss = 1.748007\n",
      "epoch 286 loss = 1.856220\n",
      "epoch 287 loss = 1.872112\n",
      "epoch 288 loss = 1.659518\n",
      "epoch 289 loss = 1.967239\n",
      "epoch 290 loss = 1.871704\n",
      "epoch 291 loss = 1.665076\n",
      "epoch 292 loss = 1.697832\n",
      "epoch 293 loss = 1.757344\n",
      "epoch 294 loss = 1.697381\n",
      "epoch 295 loss = 1.657235\n",
      "epoch 296 loss = 1.780168\n",
      "epoch 297 loss = 1.874851\n",
      "epoch 298 loss = 1.793165\n",
      "epoch 299 loss = 1.690695\n",
      "epoch 300 loss = 1.748114\n",
      "epoch 301 loss = 1.484533\n",
      "epoch 302 loss = 1.837706\n",
      "epoch 303 loss = 1.859157\n",
      "epoch 304 loss = 2.008392\n",
      "epoch 305 loss = 1.668053\n",
      "epoch 306 loss = 1.807052\n",
      "epoch 307 loss = 1.617033\n",
      "epoch 308 loss = 1.791953\n",
      "epoch 309 loss = 1.708848\n",
      "epoch 310 loss = 1.805233\n",
      "epoch 311 loss = 1.943786\n",
      "epoch 312 loss = 1.733423\n",
      "epoch 313 loss = 1.766773\n",
      "epoch 314 loss = 1.597917\n",
      "epoch 315 loss = 1.739563\n",
      "epoch 316 loss = 1.873369\n",
      "epoch 317 loss = 1.724979\n",
      "epoch 318 loss = 1.666528\n",
      "epoch 319 loss = 1.489595\n",
      "epoch 320 loss = 1.955496\n",
      "epoch 321 loss = 1.879254\n",
      "epoch 322 loss = 1.633462\n",
      "epoch 323 loss = 1.985434\n",
      "epoch 324 loss = 1.781251\n",
      "epoch 325 loss = 1.615292\n",
      "epoch 326 loss = 1.835359\n",
      "epoch 327 loss = 1.673411\n",
      "epoch 328 loss = 1.775380\n",
      "epoch 329 loss = 1.746804\n",
      "epoch 330 loss = 1.677293\n",
      "epoch 331 loss = 2.152750\n",
      "epoch 332 loss = 1.763220\n",
      "epoch 333 loss = 1.695158\n",
      "epoch 334 loss = 1.695135\n",
      "epoch 335 loss = 1.832701\n",
      "epoch 336 loss = 1.797236\n",
      "epoch 337 loss = 2.184196\n",
      "epoch 338 loss = 1.796468\n",
      "epoch 339 loss = 1.690687\n",
      "epoch 340 loss = 1.653147\n",
      "epoch 341 loss = 1.958191\n",
      "epoch 342 loss = 1.829230\n",
      "epoch 343 loss = 1.816955\n",
      "epoch 344 loss = 1.721115\n",
      "epoch 345 loss = 1.931539\n",
      "epoch 346 loss = 2.032299\n",
      "epoch 347 loss = 1.842103\n",
      "epoch 348 loss = 1.860332\n",
      "epoch 349 loss = 1.798702\n",
      "epoch 350 loss = 1.855682\n",
      "epoch 351 loss = 1.742709\n",
      "epoch 352 loss = 1.718799\n",
      "epoch 353 loss = 1.899000\n",
      "epoch 354 loss = 1.877483\n",
      "epoch 355 loss = 1.756871\n",
      "epoch 356 loss = 1.532005\n",
      "epoch 357 loss = 2.013954\n",
      "epoch 358 loss = 1.616766\n",
      "epoch 359 loss = 1.651218\n",
      "epoch 360 loss = 1.972220\n",
      "epoch 361 loss = 1.618168\n",
      "epoch 362 loss = 1.736297\n",
      "epoch 363 loss = 1.557613\n",
      "epoch 364 loss = 1.948236\n",
      "epoch 365 loss = 1.594158\n",
      "epoch 366 loss = 1.766372\n",
      "epoch 367 loss = 1.882192\n",
      "epoch 368 loss = 1.644288\n",
      "epoch 369 loss = 1.812978\n",
      "epoch 370 loss = 1.627628\n",
      "epoch 371 loss = 1.916721\n",
      "epoch 372 loss = 1.685386\n",
      "epoch 373 loss = 1.899986\n",
      "epoch 374 loss = 1.762316\n",
      "epoch 375 loss = 1.680088\n",
      "epoch 376 loss = 1.989594\n",
      "epoch 377 loss = 1.733232\n",
      "epoch 378 loss = 1.700917\n",
      "epoch 379 loss = 1.844578\n",
      "epoch 380 loss = 2.124656\n",
      "epoch 381 loss = 1.778493\n",
      "epoch 382 loss = 1.639711\n",
      "epoch 383 loss = 1.705497\n",
      "epoch 384 loss = 1.598019\n",
      "epoch 385 loss = 1.671294\n",
      "epoch 386 loss = 1.955770\n",
      "epoch 387 loss = 1.816405\n",
      "epoch 388 loss = 1.499443\n",
      "epoch 389 loss = 1.893450\n",
      "epoch 390 loss = 1.768513\n",
      "epoch 391 loss = 1.797986\n",
      "epoch 392 loss = 1.699755\n",
      "epoch 393 loss = 1.808951\n",
      "epoch 394 loss = 1.805490\n",
      "epoch 395 loss = 1.752412\n",
      "epoch 396 loss = 1.759446\n",
      "epoch 397 loss = 1.769490\n",
      "epoch 398 loss = 1.645429\n",
      "epoch 399 loss = 1.855516\n",
      "epoch 400 loss = 1.792330\n",
      "epoch 401 loss = 1.890265\n",
      "epoch 402 loss = 1.856636\n",
      "epoch 403 loss = 2.037401\n",
      "epoch 404 loss = 1.833262\n",
      "epoch 405 loss = 1.521827\n",
      "epoch 406 loss = 1.880363\n",
      "epoch 407 loss = 2.019809\n",
      "epoch 408 loss = 1.755349\n",
      "epoch 409 loss = 1.928823\n",
      "epoch 410 loss = 1.732006\n",
      "epoch 411 loss = 1.614611\n",
      "epoch 412 loss = 1.891269\n",
      "epoch 413 loss = 1.717139\n",
      "epoch 414 loss = 1.923891\n",
      "epoch 415 loss = 1.620033\n",
      "epoch 416 loss = 1.992333\n",
      "epoch 417 loss = 2.000787\n",
      "epoch 418 loss = 1.807869\n",
      "epoch 419 loss = 1.986907\n",
      "epoch 420 loss = 1.882644\n",
      "epoch 421 loss = 1.821402\n",
      "epoch 422 loss = 1.794129\n",
      "epoch 423 loss = 1.973012\n",
      "epoch 424 loss = 1.836070\n",
      "epoch 425 loss = 1.818755\n",
      "epoch 426 loss = 2.130908\n",
      "epoch 427 loss = 1.775869\n",
      "epoch 428 loss = 1.968451\n",
      "epoch 429 loss = 1.721172\n",
      "epoch 430 loss = 1.837143\n",
      "epoch 431 loss = 1.584493\n",
      "epoch 432 loss = 1.895395\n",
      "epoch 433 loss = 1.697010\n",
      "epoch 434 loss = 1.835692\n",
      "epoch 435 loss = 1.981717\n",
      "epoch 436 loss = 1.871579\n",
      "epoch 437 loss = 1.697641\n",
      "epoch 438 loss = 1.751079\n",
      "epoch 439 loss = 1.782566\n",
      "epoch 440 loss = 1.764794\n",
      "epoch 441 loss = 2.025112\n",
      "epoch 442 loss = 1.664114\n",
      "epoch 443 loss = 1.510754\n",
      "epoch 444 loss = 1.653393\n",
      "epoch 445 loss = 1.984547\n",
      "epoch 446 loss = 1.835674\n",
      "epoch 447 loss = 1.705463\n",
      "epoch 448 loss = 1.989551\n",
      "epoch 449 loss = 1.939603\n",
      "epoch 450 loss = 1.897204\n",
      "epoch 451 loss = 1.814107\n",
      "epoch 452 loss = 1.581895\n",
      "epoch 453 loss = 1.743062\n",
      "epoch 454 loss = 1.588917\n",
      "epoch 455 loss = 1.850512\n",
      "epoch 456 loss = 1.753670\n",
      "epoch 457 loss = 1.551427\n",
      "epoch 458 loss = 1.752973\n",
      "epoch 459 loss = 1.943415\n",
      "epoch 460 loss = 1.742479\n",
      "epoch 461 loss = 1.843121\n",
      "epoch 462 loss = 1.611148\n",
      "epoch 463 loss = 1.935643\n",
      "epoch 464 loss = 1.774410\n",
      "epoch 465 loss = 1.466534\n",
      "epoch 466 loss = 1.763236\n",
      "epoch 467 loss = 1.851362\n",
      "epoch 468 loss = 1.883195\n",
      "epoch 469 loss = 1.708563\n",
      "epoch 470 loss = 1.554342\n",
      "epoch 471 loss = 1.649495\n",
      "epoch 472 loss = 1.886006\n",
      "epoch 473 loss = 1.896950\n",
      "epoch 474 loss = 2.081108\n",
      "epoch 475 loss = 1.595639\n",
      "epoch 476 loss = 1.849420\n",
      "epoch 477 loss = 1.719432\n",
      "epoch 478 loss = 1.661141\n",
      "epoch 479 loss = 1.777285\n",
      "epoch 480 loss = 1.975003\n",
      "epoch 481 loss = 1.719980\n",
      "epoch 482 loss = 1.902179\n",
      "epoch 483 loss = 1.651110\n",
      "epoch 484 loss = 1.963848\n",
      "epoch 485 loss = 1.960179\n",
      "epoch 486 loss = 1.708556\n",
      "epoch 487 loss = 1.774192\n",
      "epoch 488 loss = 1.577176\n",
      "epoch 489 loss = 1.709810\n",
      "epoch 490 loss = 2.056894\n",
      "epoch 491 loss = 1.950455\n",
      "epoch 492 loss = 1.820500\n",
      "epoch 493 loss = 1.717280\n",
      "epoch 494 loss = 1.552238\n",
      "epoch 495 loss = 1.736857\n",
      "epoch 496 loss = 1.969307\n",
      "epoch 497 loss = 1.816796\n",
      "epoch 498 loss = 1.552574\n",
      "epoch 499 loss = 1.868312\n",
      "final loss = 1.868312\n",
      "accuracy_mc = tensor(0.4190, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.3718, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.7003, device='cuda:0')\n",
      "training time = 305.1993622779846 seconds\n",
      "testing time = 3.1577672958374023 seconds\n",
      "\n",
      "Training with split 7\n",
      "epoch 0 loss = 2.202537\n",
      "epoch 1 loss = 2.140564\n",
      "epoch 2 loss = 2.215002\n",
      "epoch 3 loss = 2.232232\n",
      "epoch 4 loss = 2.094933\n",
      "epoch 5 loss = 2.118559\n",
      "epoch 6 loss = 1.990863\n",
      "epoch 7 loss = 2.011194\n",
      "epoch 8 loss = 1.946396\n",
      "epoch 9 loss = 1.943161\n",
      "epoch 10 loss = 1.929982\n",
      "epoch 11 loss = 2.027266\n",
      "epoch 12 loss = 2.064383\n",
      "epoch 13 loss = 1.951461\n",
      "epoch 14 loss = 2.028229\n",
      "epoch 15 loss = 2.054301\n",
      "epoch 16 loss = 1.962765\n",
      "epoch 17 loss = 1.850812\n",
      "epoch 18 loss = 1.967502\n",
      "epoch 19 loss = 2.036439\n",
      "epoch 20 loss = 2.031984\n",
      "epoch 21 loss = 1.818913\n",
      "epoch 22 loss = 2.034081\n",
      "epoch 23 loss = 2.005706\n",
      "epoch 24 loss = 1.994135\n",
      "epoch 25 loss = 1.938551\n",
      "epoch 26 loss = 1.947152\n",
      "epoch 27 loss = 2.001630\n",
      "epoch 28 loss = 2.077495\n",
      "epoch 29 loss = 2.063598\n",
      "epoch 30 loss = 1.910989\n",
      "epoch 31 loss = 1.981315\n",
      "epoch 32 loss = 1.947209\n",
      "epoch 33 loss = 1.822865\n",
      "epoch 34 loss = 1.839139\n",
      "epoch 35 loss = 1.838089\n",
      "epoch 36 loss = 1.777290\n",
      "epoch 37 loss = 1.816544\n",
      "epoch 38 loss = 1.878892\n",
      "epoch 39 loss = 1.910360\n",
      "epoch 40 loss = 1.814935\n",
      "epoch 41 loss = 1.772205\n",
      "epoch 42 loss = 1.835174\n",
      "epoch 43 loss = 1.767555\n",
      "epoch 44 loss = 1.795814\n",
      "epoch 45 loss = 1.758018\n",
      "epoch 46 loss = 2.026423\n",
      "epoch 47 loss = 1.664805\n",
      "epoch 48 loss = 1.822878\n",
      "epoch 49 loss = 1.822551\n",
      "epoch 50 loss = 1.746736\n",
      "epoch 51 loss = 1.904032\n",
      "epoch 52 loss = 1.988353\n",
      "epoch 53 loss = 1.962953\n",
      "epoch 54 loss = 2.017059\n",
      "epoch 55 loss = 1.815015\n",
      "epoch 56 loss = 1.916095\n",
      "epoch 57 loss = 1.607439\n",
      "epoch 58 loss = 2.039343\n",
      "epoch 59 loss = 1.984040\n",
      "epoch 60 loss = 1.968708\n",
      "epoch 61 loss = 1.780046\n",
      "epoch 62 loss = 1.757679\n",
      "epoch 63 loss = 1.861795\n",
      "epoch 64 loss = 1.914078\n",
      "epoch 65 loss = 1.831976\n",
      "epoch 66 loss = 1.791089\n",
      "epoch 67 loss = 1.746784\n",
      "epoch 68 loss = 1.765805\n",
      "epoch 69 loss = 1.689087\n",
      "epoch 70 loss = 1.837136\n",
      "epoch 71 loss = 1.683965\n",
      "epoch 72 loss = 1.752782\n",
      "epoch 73 loss = 1.782480\n",
      "epoch 74 loss = 1.844048\n",
      "epoch 75 loss = 1.613217\n",
      "epoch 76 loss = 1.716282\n",
      "epoch 77 loss = 1.796778\n",
      "epoch 78 loss = 1.618348\n",
      "epoch 79 loss = 1.828514\n",
      "epoch 80 loss = 1.947963\n",
      "epoch 81 loss = 1.804643\n",
      "epoch 82 loss = 1.694228\n",
      "epoch 83 loss = 1.883153\n",
      "epoch 84 loss = 1.658122\n",
      "epoch 85 loss = 1.639696\n",
      "epoch 86 loss = 1.629535\n",
      "epoch 87 loss = 1.737941\n",
      "epoch 88 loss = 1.711425\n",
      "epoch 89 loss = 1.788792\n",
      "epoch 90 loss = 1.839566\n",
      "epoch 91 loss = 1.649119\n",
      "epoch 92 loss = 1.782863\n",
      "epoch 93 loss = 1.749332\n",
      "epoch 94 loss = 1.697275\n",
      "epoch 95 loss = 1.579504\n",
      "epoch 96 loss = 1.680600\n",
      "epoch 97 loss = 1.527563\n",
      "epoch 98 loss = 1.819052\n",
      "epoch 99 loss = 1.856467\n",
      "epoch 100 loss = 1.783092\n",
      "epoch 101 loss = 1.773642\n",
      "epoch 102 loss = 1.682222\n",
      "epoch 103 loss = 1.805317\n",
      "epoch 104 loss = 1.579575\n",
      "epoch 105 loss = 1.750562\n",
      "epoch 106 loss = 1.765831\n",
      "epoch 107 loss = 1.775437\n",
      "epoch 108 loss = 1.675473\n",
      "epoch 109 loss = 1.750533\n",
      "epoch 110 loss = 1.959876\n",
      "epoch 111 loss = 1.675736\n",
      "epoch 112 loss = 1.851765\n",
      "epoch 113 loss = 1.772386\n",
      "epoch 114 loss = 1.821154\n",
      "epoch 115 loss = 1.717092\n",
      "epoch 116 loss = 1.696343\n",
      "epoch 117 loss = 1.747800\n",
      "epoch 118 loss = 1.698827\n",
      "epoch 119 loss = 1.738036\n",
      "epoch 120 loss = 1.744728\n",
      "epoch 121 loss = 1.696617\n",
      "epoch 122 loss = 1.720834\n",
      "epoch 123 loss = 1.849080\n",
      "epoch 124 loss = 1.796491\n",
      "epoch 125 loss = 1.637409\n",
      "epoch 126 loss = 1.909153\n",
      "epoch 127 loss = 1.607078\n",
      "epoch 128 loss = 1.707552\n",
      "epoch 129 loss = 1.657633\n",
      "epoch 130 loss = 1.688497\n",
      "epoch 131 loss = 1.631365\n",
      "epoch 132 loss = 1.773357\n",
      "epoch 133 loss = 1.731204\n",
      "epoch 134 loss = 1.954785\n",
      "epoch 135 loss = 1.838871\n",
      "epoch 136 loss = 1.648282\n",
      "epoch 137 loss = 1.731519\n",
      "epoch 138 loss = 1.796380\n",
      "epoch 139 loss = 1.759259\n",
      "epoch 140 loss = 1.817180\n",
      "epoch 141 loss = 1.779362\n",
      "epoch 142 loss = 1.685136\n",
      "epoch 143 loss = 1.621734\n",
      "epoch 144 loss = 1.856576\n",
      "epoch 145 loss = 1.665479\n",
      "epoch 146 loss = 1.799296\n",
      "epoch 147 loss = 1.833653\n",
      "epoch 148 loss = 1.621815\n",
      "epoch 149 loss = 1.852728\n",
      "epoch 150 loss = 1.728804\n",
      "epoch 151 loss = 1.753117\n",
      "epoch 152 loss = 1.825441\n",
      "epoch 153 loss = 1.810949\n",
      "epoch 154 loss = 1.640530\n",
      "epoch 155 loss = 1.905018\n",
      "epoch 156 loss = 1.851968\n",
      "epoch 157 loss = 1.644044\n",
      "epoch 158 loss = 1.686460\n",
      "epoch 159 loss = 1.841981\n",
      "epoch 160 loss = 1.928956\n",
      "epoch 161 loss = 1.777675\n",
      "epoch 162 loss = 1.775000\n",
      "epoch 163 loss = 1.899551\n",
      "epoch 164 loss = 1.997964\n",
      "epoch 165 loss = 1.608087\n",
      "epoch 166 loss = 1.864651\n",
      "epoch 167 loss = 1.622546\n",
      "epoch 168 loss = 1.526101\n",
      "epoch 169 loss = 1.717324\n",
      "epoch 170 loss = 1.667296\n",
      "epoch 171 loss = 1.682035\n",
      "epoch 172 loss = 1.812605\n",
      "epoch 173 loss = 1.776643\n",
      "epoch 174 loss = 1.930923\n",
      "epoch 175 loss = 1.665157\n",
      "epoch 176 loss = 1.746032\n",
      "epoch 177 loss = 1.765538\n",
      "epoch 178 loss = 1.795548\n",
      "epoch 179 loss = 1.768780\n",
      "epoch 180 loss = 1.766418\n",
      "epoch 181 loss = 1.663138\n",
      "epoch 182 loss = 1.893604\n",
      "epoch 183 loss = 1.829777\n",
      "epoch 184 loss = 1.747061\n",
      "epoch 185 loss = 1.692343\n",
      "epoch 186 loss = 1.586709\n",
      "epoch 187 loss = 1.839309\n",
      "epoch 188 loss = 1.803324\n",
      "epoch 189 loss = 1.777019\n",
      "epoch 190 loss = 1.745402\n",
      "epoch 191 loss = 1.665744\n",
      "epoch 192 loss = 1.754211\n",
      "epoch 193 loss = 1.584649\n",
      "epoch 194 loss = 1.866980\n",
      "epoch 195 loss = 1.964229\n",
      "epoch 196 loss = 1.892407\n",
      "epoch 197 loss = 1.580557\n",
      "epoch 198 loss = 1.716504\n",
      "epoch 199 loss = 1.774293\n",
      "epoch 200 loss = 1.737471\n",
      "epoch 201 loss = 1.773832\n",
      "epoch 202 loss = 1.685059\n",
      "epoch 203 loss = 1.768435\n",
      "epoch 204 loss = 1.858340\n",
      "epoch 205 loss = 1.713820\n",
      "epoch 206 loss = 1.760941\n",
      "epoch 207 loss = 1.844007\n",
      "epoch 208 loss = 1.648204\n",
      "epoch 209 loss = 1.930519\n",
      "epoch 210 loss = 1.758767\n",
      "epoch 211 loss = 1.736697\n",
      "epoch 212 loss = 1.680963\n",
      "epoch 213 loss = 1.743137\n",
      "epoch 214 loss = 1.636794\n",
      "epoch 215 loss = 1.921753\n",
      "epoch 216 loss = 1.676672\n",
      "epoch 217 loss = 1.779897\n",
      "epoch 218 loss = 1.603141\n",
      "epoch 219 loss = 1.608510\n",
      "epoch 220 loss = 1.682853\n",
      "epoch 221 loss = 1.570861\n",
      "epoch 222 loss = 1.702431\n",
      "epoch 223 loss = 1.803154\n",
      "epoch 224 loss = 1.733770\n",
      "epoch 225 loss = 1.721103\n",
      "epoch 226 loss = 1.747741\n",
      "epoch 227 loss = 1.706443\n",
      "epoch 228 loss = 1.589468\n",
      "epoch 229 loss = 1.920276\n",
      "epoch 230 loss = 1.917018\n",
      "epoch 231 loss = 1.609761\n",
      "epoch 232 loss = 1.713389\n",
      "epoch 233 loss = 1.876571\n",
      "epoch 234 loss = 1.815917\n",
      "epoch 235 loss = 1.860053\n",
      "epoch 236 loss = 1.913804\n",
      "epoch 237 loss = 1.793537\n",
      "epoch 238 loss = 1.861515\n",
      "epoch 239 loss = 1.812973\n",
      "epoch 240 loss = 1.666647\n",
      "epoch 241 loss = 1.661801\n",
      "epoch 242 loss = 1.898268\n",
      "epoch 243 loss = 1.833889\n",
      "epoch 244 loss = 1.853227\n",
      "epoch 245 loss = 1.907054\n",
      "epoch 246 loss = 1.896729\n",
      "epoch 247 loss = 1.758527\n",
      "epoch 248 loss = 1.674538\n",
      "epoch 249 loss = 1.701381\n",
      "epoch 250 loss = 1.924272\n",
      "epoch 251 loss = 1.753446\n",
      "epoch 252 loss = 1.826324\n",
      "epoch 253 loss = 1.795399\n",
      "epoch 254 loss = 1.817493\n",
      "epoch 255 loss = 1.725822\n",
      "epoch 256 loss = 1.666951\n",
      "epoch 257 loss = 1.542858\n",
      "epoch 258 loss = 1.697384\n",
      "epoch 259 loss = 1.685737\n",
      "epoch 260 loss = 1.763927\n",
      "epoch 261 loss = 1.886467\n",
      "epoch 262 loss = 1.607235\n",
      "epoch 263 loss = 1.721475\n",
      "epoch 264 loss = 1.749672\n",
      "epoch 265 loss = 1.660800\n",
      "epoch 266 loss = 1.649533\n",
      "epoch 267 loss = 1.779729\n",
      "epoch 268 loss = 1.749077\n",
      "epoch 269 loss = 1.932402\n",
      "epoch 270 loss = 1.587354\n",
      "epoch 271 loss = 1.652067\n",
      "epoch 272 loss = 1.552895\n",
      "epoch 273 loss = 1.809584\n",
      "epoch 274 loss = 1.816857\n",
      "epoch 275 loss = 1.720559\n",
      "epoch 276 loss = 1.877081\n",
      "epoch 277 loss = 1.865556\n",
      "epoch 278 loss = 1.716500\n",
      "epoch 279 loss = 1.912986\n",
      "epoch 280 loss = 1.860966\n",
      "epoch 281 loss = 1.934255\n",
      "epoch 282 loss = 1.661312\n",
      "epoch 283 loss = 1.828458\n",
      "epoch 284 loss = 1.859484\n",
      "epoch 285 loss = 1.795856\n",
      "epoch 286 loss = 1.804401\n",
      "epoch 287 loss = 1.808329\n",
      "epoch 288 loss = 1.571089\n",
      "epoch 289 loss = 1.969085\n",
      "epoch 290 loss = 1.838743\n",
      "epoch 291 loss = 1.641664\n",
      "epoch 292 loss = 1.870936\n",
      "epoch 293 loss = 1.965964\n",
      "epoch 294 loss = 1.761165\n",
      "epoch 295 loss = 1.897687\n",
      "epoch 296 loss = 1.703851\n",
      "epoch 297 loss = 1.550330\n",
      "epoch 298 loss = 1.639807\n",
      "epoch 299 loss = 1.813341\n",
      "epoch 300 loss = 1.714182\n",
      "epoch 301 loss = 1.827225\n",
      "epoch 302 loss = 1.919736\n",
      "epoch 303 loss = 1.638696\n",
      "epoch 304 loss = 1.614378\n",
      "epoch 305 loss = 1.666107\n",
      "epoch 306 loss = 1.883830\n",
      "epoch 307 loss = 1.811648\n",
      "epoch 308 loss = 1.805856\n",
      "epoch 309 loss = 1.763424\n",
      "epoch 310 loss = 1.730993\n",
      "epoch 311 loss = 1.893680\n",
      "epoch 312 loss = 1.889517\n",
      "epoch 313 loss = 1.770560\n",
      "epoch 314 loss = 1.926048\n",
      "epoch 315 loss = 1.710782\n",
      "epoch 316 loss = 1.522016\n",
      "epoch 317 loss = 1.689479\n",
      "epoch 318 loss = 1.681440\n",
      "epoch 319 loss = 1.717034\n",
      "epoch 320 loss = 1.710432\n",
      "epoch 321 loss = 1.729829\n",
      "epoch 322 loss = 1.733879\n",
      "epoch 323 loss = 1.716111\n",
      "epoch 324 loss = 1.681365\n",
      "epoch 325 loss = 1.841437\n",
      "epoch 326 loss = 1.622760\n",
      "epoch 327 loss = 2.116506\n",
      "epoch 328 loss = 1.683515\n",
      "epoch 329 loss = 1.714941\n",
      "epoch 330 loss = 1.715803\n",
      "epoch 331 loss = 1.801266\n",
      "epoch 332 loss = 1.770849\n",
      "epoch 333 loss = 1.632308\n",
      "epoch 334 loss = 1.546665\n",
      "epoch 335 loss = 1.641657\n",
      "epoch 336 loss = 1.663886\n",
      "epoch 337 loss = 1.658450\n",
      "epoch 338 loss = 1.975878\n",
      "epoch 339 loss = 1.469995\n",
      "epoch 340 loss = 1.849054\n",
      "epoch 341 loss = 1.737941\n",
      "epoch 342 loss = 1.762772\n",
      "epoch 343 loss = 1.833310\n",
      "epoch 344 loss = 1.756426\n",
      "epoch 345 loss = 1.626778\n",
      "epoch 346 loss = 1.856313\n",
      "epoch 347 loss = 1.719243\n",
      "epoch 348 loss = 1.627938\n",
      "epoch 349 loss = 1.789395\n",
      "epoch 350 loss = 1.869205\n",
      "epoch 351 loss = 1.721625\n",
      "epoch 352 loss = 1.763069\n",
      "epoch 353 loss = 1.760960\n",
      "epoch 354 loss = 1.802849\n",
      "epoch 355 loss = 1.897945\n",
      "epoch 356 loss = 2.142275\n",
      "epoch 357 loss = 1.740370\n",
      "epoch 358 loss = 1.608602\n",
      "epoch 359 loss = 1.804210\n",
      "epoch 360 loss = 1.828021\n",
      "epoch 361 loss = 1.826960\n",
      "epoch 362 loss = 1.845311\n",
      "epoch 363 loss = 1.717632\n",
      "epoch 364 loss = 1.852098\n",
      "epoch 365 loss = 1.687495\n",
      "epoch 366 loss = 1.960482\n",
      "epoch 367 loss = 1.484912\n",
      "epoch 368 loss = 1.757494\n",
      "epoch 369 loss = 1.753237\n",
      "epoch 370 loss = 1.901542\n",
      "epoch 371 loss = 1.976640\n",
      "epoch 372 loss = 1.976429\n",
      "epoch 373 loss = 1.886368\n",
      "epoch 374 loss = 1.670299\n",
      "epoch 375 loss = 1.619790\n",
      "epoch 376 loss = 1.866316\n",
      "epoch 377 loss = 1.983157\n",
      "epoch 378 loss = 1.951143\n",
      "epoch 379 loss = 1.939703\n",
      "epoch 380 loss = 1.784570\n",
      "epoch 381 loss = 1.936344\n",
      "epoch 382 loss = 1.659624\n",
      "epoch 383 loss = 1.708212\n",
      "epoch 384 loss = 1.681747\n",
      "epoch 385 loss = 1.776212\n",
      "epoch 386 loss = 2.013436\n",
      "epoch 387 loss = 1.769400\n",
      "epoch 388 loss = 1.891042\n",
      "epoch 389 loss = 1.769127\n",
      "epoch 390 loss = 1.881935\n",
      "epoch 391 loss = 1.884648\n",
      "epoch 392 loss = 1.694547\n",
      "epoch 393 loss = 1.819194\n",
      "epoch 394 loss = 1.743593\n",
      "epoch 395 loss = 1.925238\n",
      "epoch 396 loss = 1.787703\n",
      "epoch 397 loss = 1.597502\n",
      "epoch 398 loss = 2.008182\n",
      "epoch 399 loss = 1.779369\n",
      "epoch 400 loss = 1.908133\n",
      "epoch 401 loss = 1.425639\n",
      "epoch 402 loss = 1.504691\n",
      "epoch 403 loss = 1.647934\n",
      "epoch 404 loss = 1.881205\n",
      "epoch 405 loss = 1.956087\n",
      "epoch 406 loss = 1.535097\n",
      "epoch 407 loss = 1.484426\n",
      "epoch 408 loss = 1.956383\n",
      "epoch 409 loss = 1.819182\n",
      "epoch 410 loss = 1.866877\n",
      "epoch 411 loss = 1.730810\n",
      "epoch 412 loss = 1.893028\n",
      "epoch 413 loss = 1.756612\n",
      "epoch 414 loss = 1.651875\n",
      "epoch 415 loss = 1.607973\n",
      "epoch 416 loss = 1.852726\n",
      "epoch 417 loss = 1.716294\n",
      "epoch 418 loss = 1.833454\n",
      "epoch 419 loss = 1.855227\n",
      "epoch 420 loss = 1.599232\n",
      "epoch 421 loss = 1.764019\n",
      "epoch 422 loss = 1.730857\n",
      "epoch 423 loss = 1.670253\n",
      "epoch 424 loss = 1.822516\n",
      "epoch 425 loss = 1.654629\n",
      "epoch 426 loss = 1.710087\n",
      "epoch 427 loss = 1.439240\n",
      "epoch 428 loss = 1.703902\n",
      "epoch 429 loss = 1.585254\n",
      "epoch 430 loss = 1.715460\n",
      "epoch 431 loss = 1.926573\n",
      "epoch 432 loss = 1.765221\n",
      "epoch 433 loss = 1.653084\n",
      "epoch 434 loss = 1.758113\n",
      "epoch 435 loss = 1.705737\n",
      "epoch 436 loss = 1.713215\n",
      "epoch 437 loss = 2.039807\n",
      "epoch 438 loss = 1.639706\n",
      "epoch 439 loss = 1.767918\n",
      "epoch 440 loss = 1.755865\n",
      "epoch 441 loss = 1.918173\n",
      "epoch 442 loss = 1.867195\n",
      "epoch 443 loss = 1.851598\n",
      "epoch 444 loss = 1.568187\n",
      "epoch 445 loss = 1.627712\n",
      "epoch 446 loss = 1.811440\n",
      "epoch 447 loss = 1.729359\n",
      "epoch 448 loss = 1.581396\n",
      "epoch 449 loss = 1.706756\n",
      "epoch 450 loss = 1.787859\n",
      "epoch 451 loss = 1.902793\n",
      "epoch 452 loss = 1.667817\n",
      "epoch 453 loss = 1.758918\n",
      "epoch 454 loss = 1.633694\n",
      "epoch 455 loss = 1.699489\n",
      "epoch 456 loss = 1.599815\n",
      "epoch 457 loss = 1.969317\n",
      "epoch 458 loss = 1.700833\n",
      "epoch 459 loss = 1.703471\n",
      "epoch 460 loss = 1.740542\n",
      "epoch 461 loss = 1.674617\n",
      "epoch 462 loss = 1.684258\n",
      "epoch 463 loss = 1.592060\n",
      "epoch 464 loss = 1.707072\n",
      "epoch 465 loss = 1.791579\n",
      "epoch 466 loss = 1.967870\n",
      "epoch 467 loss = 1.575094\n",
      "epoch 468 loss = 1.795625\n",
      "epoch 469 loss = 1.688161\n",
      "epoch 470 loss = 1.813005\n",
      "epoch 471 loss = 1.736120\n",
      "epoch 472 loss = 1.776813\n",
      "epoch 473 loss = 1.806820\n",
      "epoch 474 loss = 1.784149\n",
      "epoch 475 loss = 1.792015\n",
      "epoch 476 loss = 1.596538\n",
      "epoch 477 loss = 1.640170\n",
      "epoch 478 loss = 1.848455\n",
      "epoch 479 loss = 1.832359\n",
      "epoch 480 loss = 1.550403\n",
      "epoch 481 loss = 1.752464\n",
      "epoch 482 loss = 1.691332\n",
      "epoch 483 loss = 1.648435\n",
      "epoch 484 loss = 1.723394\n",
      "epoch 485 loss = 1.551475\n",
      "epoch 486 loss = 1.867363\n",
      "epoch 487 loss = 1.762316\n",
      "epoch 488 loss = 1.597286\n",
      "epoch 489 loss = 1.792493\n",
      "epoch 490 loss = 1.791213\n",
      "epoch 491 loss = 1.650213\n",
      "epoch 492 loss = 1.705191\n",
      "epoch 493 loss = 1.958558\n",
      "epoch 494 loss = 1.823316\n",
      "epoch 495 loss = 1.627738\n",
      "epoch 496 loss = 1.687747\n",
      "epoch 497 loss = 2.031740\n",
      "epoch 498 loss = 1.701557\n",
      "epoch 499 loss = 1.703339\n",
      "final loss = 1.703339\n",
      "accuracy_mc = tensor(0.3474, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.3674, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.8270, device='cuda:0')\n",
      "training time = 305.4996061325073 seconds\n",
      "testing time = 3.2122700214385986 seconds\n",
      "\n",
      "Training with split 8\n",
      "epoch 0 loss = 2.266470\n",
      "epoch 1 loss = 2.010536\n",
      "epoch 2 loss = 2.103636\n",
      "epoch 3 loss = 2.189291\n",
      "epoch 4 loss = 2.113654\n",
      "epoch 5 loss = 2.114675\n",
      "epoch 6 loss = 2.010316\n",
      "epoch 7 loss = 2.122049\n",
      "epoch 8 loss = 2.054194\n",
      "epoch 9 loss = 1.943934\n",
      "epoch 10 loss = 2.053811\n",
      "epoch 11 loss = 1.981690\n",
      "epoch 12 loss = 1.924976\n",
      "epoch 13 loss = 2.053826\n",
      "epoch 14 loss = 2.140358\n",
      "epoch 15 loss = 1.959202\n",
      "epoch 16 loss = 1.989377\n",
      "epoch 17 loss = 1.901238\n",
      "epoch 18 loss = 1.868651\n",
      "epoch 19 loss = 1.964595\n",
      "epoch 20 loss = 2.046943\n",
      "epoch 21 loss = 1.853332\n",
      "epoch 22 loss = 1.919962\n",
      "epoch 23 loss = 1.950544\n",
      "epoch 24 loss = 1.708562\n",
      "epoch 25 loss = 2.044467\n",
      "epoch 26 loss = 2.144556\n",
      "epoch 27 loss = 1.777158\n",
      "epoch 28 loss = 2.221056\n",
      "epoch 29 loss = 1.951526\n",
      "epoch 30 loss = 1.951215\n",
      "epoch 31 loss = 1.836925\n",
      "epoch 32 loss = 1.797060\n",
      "epoch 33 loss = 1.898601\n",
      "epoch 34 loss = 1.808517\n",
      "epoch 35 loss = 1.859324\n",
      "epoch 36 loss = 1.939807\n",
      "epoch 37 loss = 1.827089\n",
      "epoch 38 loss = 1.937174\n",
      "epoch 39 loss = 1.766399\n",
      "epoch 40 loss = 1.919145\n",
      "epoch 41 loss = 1.802203\n",
      "epoch 42 loss = 1.746226\n",
      "epoch 43 loss = 2.038322\n",
      "epoch 44 loss = 1.872671\n",
      "epoch 45 loss = 1.743849\n",
      "epoch 46 loss = 1.946578\n",
      "epoch 47 loss = 1.870278\n",
      "epoch 48 loss = 1.831794\n",
      "epoch 49 loss = 1.835927\n",
      "epoch 50 loss = 1.999024\n",
      "epoch 51 loss = 1.785452\n",
      "epoch 52 loss = 1.744463\n",
      "epoch 53 loss = 1.786864\n",
      "epoch 54 loss = 1.732386\n",
      "epoch 55 loss = 1.905437\n",
      "epoch 56 loss = 1.893752\n",
      "epoch 57 loss = 1.711889\n",
      "epoch 58 loss = 1.879028\n",
      "epoch 59 loss = 1.914452\n",
      "epoch 60 loss = 1.839827\n",
      "epoch 61 loss = 1.881486\n",
      "epoch 62 loss = 1.767934\n",
      "epoch 63 loss = 1.633481\n",
      "epoch 64 loss = 1.697245\n",
      "epoch 65 loss = 1.925213\n",
      "epoch 66 loss = 1.832781\n",
      "epoch 67 loss = 1.819232\n",
      "epoch 68 loss = 1.967495\n",
      "epoch 69 loss = 1.773282\n",
      "epoch 70 loss = 1.879462\n",
      "epoch 71 loss = 1.941132\n",
      "epoch 72 loss = 1.834162\n",
      "epoch 73 loss = 1.870452\n",
      "epoch 74 loss = 1.838561\n",
      "epoch 75 loss = 2.040646\n",
      "epoch 76 loss = 1.712080\n",
      "epoch 77 loss = 1.873977\n",
      "epoch 78 loss = 1.880473\n",
      "epoch 79 loss = 1.736232\n",
      "epoch 80 loss = 2.041785\n",
      "epoch 81 loss = 1.848755\n",
      "epoch 82 loss = 1.726654\n",
      "epoch 83 loss = 1.787255\n",
      "epoch 84 loss = 1.663445\n",
      "epoch 85 loss = 1.853438\n",
      "epoch 86 loss = 1.872145\n",
      "epoch 87 loss = 1.766281\n",
      "epoch 88 loss = 1.906116\n",
      "epoch 89 loss = 1.988530\n",
      "epoch 90 loss = 1.777899\n",
      "epoch 91 loss = 1.762658\n",
      "epoch 92 loss = 1.881439\n",
      "epoch 93 loss = 1.839035\n",
      "epoch 94 loss = 1.805586\n",
      "epoch 95 loss = 1.843904\n",
      "epoch 96 loss = 2.008431\n",
      "epoch 97 loss = 1.933352\n",
      "epoch 98 loss = 1.688461\n",
      "epoch 99 loss = 1.619933\n",
      "epoch 100 loss = 1.808949\n",
      "epoch 101 loss = 1.796383\n",
      "epoch 102 loss = 1.923639\n",
      "epoch 103 loss = 1.943228\n",
      "epoch 104 loss = 1.678437\n",
      "epoch 105 loss = 1.782030\n",
      "epoch 106 loss = 1.852146\n",
      "epoch 107 loss = 1.853478\n",
      "epoch 108 loss = 1.876041\n",
      "epoch 109 loss = 1.921784\n",
      "epoch 110 loss = 1.766346\n",
      "epoch 111 loss = 2.004245\n",
      "epoch 112 loss = 1.749969\n",
      "epoch 113 loss = 1.691326\n",
      "epoch 114 loss = 1.674098\n",
      "epoch 115 loss = 1.939145\n",
      "epoch 116 loss = 1.737584\n",
      "epoch 117 loss = 1.659605\n",
      "epoch 118 loss = 1.808152\n",
      "epoch 119 loss = 1.881314\n",
      "epoch 120 loss = 1.838506\n",
      "epoch 121 loss = 1.817475\n",
      "epoch 122 loss = 1.837898\n",
      "epoch 123 loss = 1.715962\n",
      "epoch 124 loss = 1.909404\n",
      "epoch 125 loss = 1.848804\n",
      "epoch 126 loss = 1.809248\n",
      "epoch 127 loss = 1.786707\n",
      "epoch 128 loss = 1.657163\n",
      "epoch 129 loss = 1.789619\n",
      "epoch 130 loss = 1.712054\n",
      "epoch 131 loss = 1.922200\n",
      "epoch 132 loss = 1.725659\n",
      "epoch 133 loss = 1.813313\n",
      "epoch 134 loss = 1.896607\n",
      "epoch 135 loss = 1.847856\n",
      "epoch 136 loss = 1.973803\n",
      "epoch 137 loss = 1.856682\n",
      "epoch 138 loss = 1.976992\n",
      "epoch 139 loss = 1.815536\n",
      "epoch 140 loss = 1.856514\n",
      "epoch 141 loss = 1.862251\n",
      "epoch 142 loss = 1.837269\n",
      "epoch 143 loss = 1.844961\n",
      "epoch 144 loss = 1.840708\n",
      "epoch 145 loss = 1.793591\n",
      "epoch 146 loss = 1.827533\n",
      "epoch 147 loss = 1.969505\n",
      "epoch 148 loss = 1.787587\n",
      "epoch 149 loss = 1.672636\n",
      "epoch 150 loss = 1.860382\n",
      "epoch 151 loss = 1.766231\n",
      "epoch 152 loss = 1.762630\n",
      "epoch 153 loss = 1.816335\n",
      "epoch 154 loss = 1.706320\n",
      "epoch 155 loss = 1.760381\n",
      "epoch 156 loss = 1.784082\n",
      "epoch 157 loss = 1.786794\n",
      "epoch 158 loss = 1.805491\n",
      "epoch 159 loss = 1.761927\n",
      "epoch 160 loss = 1.763690\n",
      "epoch 161 loss = 1.821188\n",
      "epoch 162 loss = 1.632275\n",
      "epoch 163 loss = 1.762251\n",
      "epoch 164 loss = 1.821651\n",
      "epoch 165 loss = 1.715468\n",
      "epoch 166 loss = 1.834584\n",
      "epoch 167 loss = 1.766514\n",
      "epoch 168 loss = 1.879223\n",
      "epoch 169 loss = 1.836955\n",
      "epoch 170 loss = 1.870504\n",
      "epoch 171 loss = 1.846689\n",
      "epoch 172 loss = 1.893183\n",
      "epoch 173 loss = 1.741173\n",
      "epoch 174 loss = 1.749119\n",
      "epoch 175 loss = 1.848546\n",
      "epoch 176 loss = 1.867870\n",
      "epoch 177 loss = 1.800426\n",
      "epoch 178 loss = 1.797251\n",
      "epoch 179 loss = 1.663917\n",
      "epoch 180 loss = 1.744559\n",
      "epoch 181 loss = 2.011032\n",
      "epoch 182 loss = 1.955058\n",
      "epoch 183 loss = 1.727983\n",
      "epoch 184 loss = 1.831767\n",
      "epoch 185 loss = 1.731740\n",
      "epoch 186 loss = 1.734634\n",
      "epoch 187 loss = 1.679642\n",
      "epoch 188 loss = 1.581606\n",
      "epoch 189 loss = 1.792834\n",
      "epoch 190 loss = 1.655773\n",
      "epoch 191 loss = 1.794561\n",
      "epoch 192 loss = 1.820488\n",
      "epoch 193 loss = 1.855467\n",
      "epoch 194 loss = 1.658975\n",
      "epoch 195 loss = 1.815155\n",
      "epoch 196 loss = 1.828843\n",
      "epoch 197 loss = 1.706784\n",
      "epoch 198 loss = 1.687884\n",
      "epoch 199 loss = 1.611124\n",
      "epoch 200 loss = 1.921229\n",
      "epoch 201 loss = 1.722008\n",
      "epoch 202 loss = 1.625360\n",
      "epoch 203 loss = 1.790714\n",
      "epoch 204 loss = 1.719871\n",
      "epoch 205 loss = 1.624749\n",
      "epoch 206 loss = 2.070382\n",
      "epoch 207 loss = 1.638710\n",
      "epoch 208 loss = 1.626718\n",
      "epoch 209 loss = 1.959372\n",
      "epoch 210 loss = 1.882381\n",
      "epoch 211 loss = 1.931275\n",
      "epoch 212 loss = 1.694147\n",
      "epoch 213 loss = 1.784078\n",
      "epoch 214 loss = 1.742008\n",
      "epoch 215 loss = 1.699574\n",
      "epoch 216 loss = 1.927404\n",
      "epoch 217 loss = 1.743781\n",
      "epoch 218 loss = 1.864683\n",
      "epoch 219 loss = 1.996434\n",
      "epoch 220 loss = 1.818294\n",
      "epoch 221 loss = 1.778585\n",
      "epoch 222 loss = 1.882831\n",
      "epoch 223 loss = 1.710099\n",
      "epoch 224 loss = 1.612535\n",
      "epoch 225 loss = 1.808262\n",
      "epoch 226 loss = 1.587274\n",
      "epoch 227 loss = 1.621591\n",
      "epoch 228 loss = 1.926444\n",
      "epoch 229 loss = 1.805881\n",
      "epoch 230 loss = 1.722353\n",
      "epoch 231 loss = 1.733976\n",
      "epoch 232 loss = 1.801989\n",
      "epoch 233 loss = 1.797552\n",
      "epoch 234 loss = 1.525807\n",
      "epoch 235 loss = 1.721315\n",
      "epoch 236 loss = 2.022119\n",
      "epoch 237 loss = 1.680291\n",
      "epoch 238 loss = 2.079303\n",
      "epoch 239 loss = 1.641289\n",
      "epoch 240 loss = 1.722311\n",
      "epoch 241 loss = 1.746680\n",
      "epoch 242 loss = 1.917048\n",
      "epoch 243 loss = 1.821219\n",
      "epoch 244 loss = 1.810631\n",
      "epoch 245 loss = 1.910119\n",
      "epoch 246 loss = 1.794260\n",
      "epoch 247 loss = 1.592597\n",
      "epoch 248 loss = 2.010959\n",
      "epoch 249 loss = 1.862375\n",
      "epoch 250 loss = 1.880205\n",
      "epoch 251 loss = 1.865741\n",
      "epoch 252 loss = 1.675098\n",
      "epoch 253 loss = 1.706331\n",
      "epoch 254 loss = 1.817879\n",
      "epoch 255 loss = 1.672324\n",
      "epoch 256 loss = 1.779088\n",
      "epoch 257 loss = 1.850014\n",
      "epoch 258 loss = 1.598222\n",
      "epoch 259 loss = 1.743804\n",
      "epoch 260 loss = 1.582723\n",
      "epoch 261 loss = 1.633471\n",
      "epoch 262 loss = 1.872121\n",
      "epoch 263 loss = 1.677277\n",
      "epoch 264 loss = 1.826848\n",
      "epoch 265 loss = 1.764052\n",
      "epoch 266 loss = 1.720590\n",
      "epoch 267 loss = 1.723027\n",
      "epoch 268 loss = 1.901337\n",
      "epoch 269 loss = 1.497443\n",
      "epoch 270 loss = 1.769491\n",
      "epoch 271 loss = 1.801638\n",
      "epoch 272 loss = 1.825084\n",
      "epoch 273 loss = 1.796216\n",
      "epoch 274 loss = 1.938476\n",
      "epoch 275 loss = 1.616270\n",
      "epoch 276 loss = 1.470737\n",
      "epoch 277 loss = 1.538493\n",
      "epoch 278 loss = 1.569367\n",
      "epoch 279 loss = 1.588994\n",
      "epoch 280 loss = 1.643405\n",
      "epoch 281 loss = 1.736574\n",
      "epoch 282 loss = 1.708966\n",
      "epoch 283 loss = 1.546360\n",
      "epoch 284 loss = 1.566950\n",
      "epoch 285 loss = 1.845483\n",
      "epoch 286 loss = 1.444131\n",
      "epoch 287 loss = 1.600977\n",
      "epoch 288 loss = 1.666668\n",
      "epoch 289 loss = 1.983937\n",
      "epoch 290 loss = 1.705543\n",
      "epoch 291 loss = 1.862882\n",
      "epoch 292 loss = 1.922259\n",
      "epoch 293 loss = 1.557922\n",
      "epoch 294 loss = 1.780044\n",
      "epoch 295 loss = 1.790356\n",
      "epoch 296 loss = 1.652484\n",
      "epoch 297 loss = 1.518709\n",
      "epoch 298 loss = 1.764866\n",
      "epoch 299 loss = 1.778755\n",
      "epoch 300 loss = 1.760901\n",
      "epoch 301 loss = 1.599455\n",
      "epoch 302 loss = 1.782599\n",
      "epoch 303 loss = 1.602902\n",
      "epoch 304 loss = 1.929018\n",
      "epoch 305 loss = 1.692885\n",
      "epoch 306 loss = 1.741921\n",
      "epoch 307 loss = 1.818265\n",
      "epoch 308 loss = 1.956830\n",
      "epoch 309 loss = 1.636906\n",
      "epoch 310 loss = 1.682083\n",
      "epoch 311 loss = 1.648780\n",
      "epoch 312 loss = 1.718961\n",
      "epoch 313 loss = 1.617670\n",
      "epoch 314 loss = 1.803133\n",
      "epoch 315 loss = 1.741490\n",
      "epoch 316 loss = 1.780255\n",
      "epoch 317 loss = 1.671689\n",
      "epoch 318 loss = 1.857864\n",
      "epoch 319 loss = 1.707050\n",
      "epoch 320 loss = 1.556090\n",
      "epoch 321 loss = 1.676810\n",
      "epoch 322 loss = 1.642756\n",
      "epoch 323 loss = 1.784912\n",
      "epoch 324 loss = 1.646979\n",
      "epoch 325 loss = 1.885162\n",
      "epoch 326 loss = 1.677809\n",
      "epoch 327 loss = 1.686488\n",
      "epoch 328 loss = 1.631467\n",
      "epoch 329 loss = 1.711328\n",
      "epoch 330 loss = 1.969707\n",
      "epoch 331 loss = 1.616725\n",
      "epoch 332 loss = 1.872316\n",
      "epoch 333 loss = 1.747333\n",
      "epoch 334 loss = 2.009240\n",
      "epoch 335 loss = 1.775451\n",
      "epoch 336 loss = 1.784957\n",
      "epoch 337 loss = 1.631332\n",
      "epoch 338 loss = 1.733724\n",
      "epoch 339 loss = 1.978514\n",
      "epoch 340 loss = 1.789796\n",
      "epoch 341 loss = 1.667231\n",
      "epoch 342 loss = 1.866144\n",
      "epoch 343 loss = 1.699905\n",
      "epoch 344 loss = 1.708556\n",
      "epoch 345 loss = 1.977613\n",
      "epoch 346 loss = 1.796167\n",
      "epoch 347 loss = 1.882920\n",
      "epoch 348 loss = 1.803420\n",
      "epoch 349 loss = 1.729148\n",
      "epoch 350 loss = 1.788718\n",
      "epoch 351 loss = 1.811851\n",
      "epoch 352 loss = 1.676489\n",
      "epoch 353 loss = 1.620559\n",
      "epoch 354 loss = 1.606029\n",
      "epoch 355 loss = 1.787463\n",
      "epoch 356 loss = 1.761318\n",
      "epoch 357 loss = 1.847356\n",
      "epoch 358 loss = 1.696702\n",
      "epoch 359 loss = 1.566717\n",
      "epoch 360 loss = 1.507465\n",
      "epoch 361 loss = 1.815476\n",
      "epoch 362 loss = 1.852041\n",
      "epoch 363 loss = 1.926491\n",
      "epoch 364 loss = 1.799472\n",
      "epoch 365 loss = 1.850712\n",
      "epoch 366 loss = 1.831019\n",
      "epoch 367 loss = 1.985722\n",
      "epoch 368 loss = 1.740035\n",
      "epoch 369 loss = 1.652110\n",
      "epoch 370 loss = 1.756926\n",
      "epoch 371 loss = 1.775838\n",
      "epoch 372 loss = 1.596473\n",
      "epoch 373 loss = 1.604389\n",
      "epoch 374 loss = 1.668318\n",
      "epoch 375 loss = 1.609468\n",
      "epoch 376 loss = 1.611556\n",
      "epoch 377 loss = 1.648224\n",
      "epoch 378 loss = 1.483037\n",
      "epoch 379 loss = 1.606135\n",
      "epoch 380 loss = 1.758466\n",
      "epoch 381 loss = 1.664108\n",
      "epoch 382 loss = 1.823991\n",
      "epoch 383 loss = 1.641083\n",
      "epoch 384 loss = 1.938604\n",
      "epoch 385 loss = 1.758008\n",
      "epoch 386 loss = 1.857873\n",
      "epoch 387 loss = 1.638776\n",
      "epoch 388 loss = 1.835267\n",
      "epoch 389 loss = 1.857238\n",
      "epoch 390 loss = 1.959220\n",
      "epoch 391 loss = 1.680933\n",
      "epoch 392 loss = 1.775560\n",
      "epoch 393 loss = 1.804974\n",
      "epoch 394 loss = 1.685460\n",
      "epoch 395 loss = 1.507360\n",
      "epoch 396 loss = 1.720567\n",
      "epoch 397 loss = 1.680272\n",
      "epoch 398 loss = 1.822360\n",
      "epoch 399 loss = 1.705377\n",
      "epoch 400 loss = 1.801295\n",
      "epoch 401 loss = 1.918977\n",
      "epoch 402 loss = 1.633959\n",
      "epoch 403 loss = 1.698043\n",
      "epoch 404 loss = 1.720218\n",
      "epoch 405 loss = 1.535732\n",
      "epoch 406 loss = 1.880160\n",
      "epoch 407 loss = 1.794203\n",
      "epoch 408 loss = 1.808502\n",
      "epoch 409 loss = 1.680618\n",
      "epoch 410 loss = 1.630909\n",
      "epoch 411 loss = 1.883772\n",
      "epoch 412 loss = 1.814046\n",
      "epoch 413 loss = 1.870763\n",
      "epoch 414 loss = 1.763536\n",
      "epoch 415 loss = 1.618443\n",
      "epoch 416 loss = 1.733251\n",
      "epoch 417 loss = 1.896596\n",
      "epoch 418 loss = 1.765020\n",
      "epoch 419 loss = 1.941366\n",
      "epoch 420 loss = 1.695433\n",
      "epoch 421 loss = 1.563434\n",
      "epoch 422 loss = 1.708818\n",
      "epoch 423 loss = 1.817441\n",
      "epoch 424 loss = 1.888625\n",
      "epoch 425 loss = 1.771499\n",
      "epoch 426 loss = 1.655539\n",
      "epoch 427 loss = 1.799216\n",
      "epoch 428 loss = 1.655888\n",
      "epoch 429 loss = 1.724291\n",
      "epoch 430 loss = 1.534717\n",
      "epoch 431 loss = 1.626703\n",
      "epoch 432 loss = 1.824034\n",
      "epoch 433 loss = 1.819759\n",
      "epoch 434 loss = 1.577423\n",
      "epoch 435 loss = 1.857607\n",
      "epoch 436 loss = 1.706515\n",
      "epoch 437 loss = 1.811404\n",
      "epoch 438 loss = 1.934164\n",
      "epoch 439 loss = 1.720732\n",
      "epoch 440 loss = 1.782583\n",
      "epoch 441 loss = 1.678378\n",
      "epoch 442 loss = 1.811493\n",
      "epoch 443 loss = 1.654294\n",
      "epoch 444 loss = 1.849719\n",
      "epoch 445 loss = 1.732078\n",
      "epoch 446 loss = 1.645606\n",
      "epoch 447 loss = 1.672775\n",
      "epoch 448 loss = 1.765581\n",
      "epoch 449 loss = 1.738786\n",
      "epoch 450 loss = 1.646203\n",
      "epoch 451 loss = 1.637119\n",
      "epoch 452 loss = 1.604277\n",
      "epoch 453 loss = 1.695813\n",
      "epoch 454 loss = 1.819821\n",
      "epoch 455 loss = 1.672887\n",
      "epoch 456 loss = 1.954739\n",
      "epoch 457 loss = 1.659315\n",
      "epoch 458 loss = 1.583413\n",
      "epoch 459 loss = 1.697906\n",
      "epoch 460 loss = 1.586365\n",
      "epoch 461 loss = 1.768341\n",
      "epoch 462 loss = 1.926794\n",
      "epoch 463 loss = 1.859816\n",
      "epoch 464 loss = 1.734346\n",
      "epoch 465 loss = 1.677066\n",
      "epoch 466 loss = 1.924819\n",
      "epoch 467 loss = 1.770740\n",
      "epoch 468 loss = 1.493575\n",
      "epoch 469 loss = 1.690628\n",
      "epoch 470 loss = 1.804907\n",
      "epoch 471 loss = 1.742895\n",
      "epoch 472 loss = 1.856905\n",
      "epoch 473 loss = 1.684302\n",
      "epoch 474 loss = 1.700638\n",
      "epoch 475 loss = 1.584283\n",
      "epoch 476 loss = 1.766695\n",
      "epoch 477 loss = 1.723990\n",
      "epoch 478 loss = 1.688862\n",
      "epoch 479 loss = 1.717647\n",
      "epoch 480 loss = 1.917565\n",
      "epoch 481 loss = 1.851901\n",
      "epoch 482 loss = 1.842819\n",
      "epoch 483 loss = 1.670518\n",
      "epoch 484 loss = 1.814384\n",
      "epoch 485 loss = 1.731574\n",
      "epoch 486 loss = 1.750841\n",
      "epoch 487 loss = 1.631685\n",
      "epoch 488 loss = 1.854188\n",
      "epoch 489 loss = 1.610027\n",
      "epoch 490 loss = 1.792384\n",
      "epoch 491 loss = 1.902342\n",
      "epoch 492 loss = 1.752792\n",
      "epoch 493 loss = 1.828515\n",
      "epoch 494 loss = 1.734750\n",
      "epoch 495 loss = 1.848992\n",
      "epoch 496 loss = 1.803639\n",
      "epoch 497 loss = 1.708618\n",
      "epoch 498 loss = 1.730863\n",
      "epoch 499 loss = 1.632550\n",
      "final loss = 1.632550\n",
      "accuracy_mc = tensor(0.3782, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.3717, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.7921, device='cuda:0')\n",
      "training time = 305.0277795791626 seconds\n",
      "testing time = 3.203744888305664 seconds\n",
      "\n",
      "Training with split 9\n",
      "epoch 0 loss = 2.239862\n",
      "epoch 1 loss = 2.190938\n",
      "epoch 2 loss = 2.139170\n",
      "epoch 3 loss = 2.017598\n",
      "epoch 4 loss = 2.118948\n",
      "epoch 5 loss = 2.061509\n",
      "epoch 6 loss = 1.958008\n",
      "epoch 7 loss = 2.159313\n",
      "epoch 8 loss = 2.032115\n",
      "epoch 9 loss = 1.986238\n",
      "epoch 10 loss = 2.058104\n",
      "epoch 11 loss = 2.038524\n",
      "epoch 12 loss = 2.009382\n",
      "epoch 13 loss = 1.940782\n",
      "epoch 14 loss = 2.304950\n",
      "epoch 15 loss = 2.047410\n",
      "epoch 16 loss = 2.104734\n",
      "epoch 17 loss = 1.979807\n",
      "epoch 18 loss = 2.087072\n",
      "epoch 19 loss = 2.049056\n",
      "epoch 20 loss = 1.966922\n",
      "epoch 21 loss = 1.883525\n",
      "epoch 22 loss = 1.883224\n",
      "epoch 23 loss = 2.119867\n",
      "epoch 24 loss = 2.001980\n",
      "epoch 25 loss = 2.128834\n",
      "epoch 26 loss = 1.873756\n",
      "epoch 27 loss = 1.959474\n",
      "epoch 28 loss = 1.909252\n",
      "epoch 29 loss = 2.000164\n",
      "epoch 30 loss = 2.042151\n",
      "epoch 31 loss = 1.939518\n",
      "epoch 32 loss = 1.964835\n",
      "epoch 33 loss = 1.953735\n",
      "epoch 34 loss = 1.921708\n",
      "epoch 35 loss = 1.947643\n",
      "epoch 36 loss = 1.920114\n",
      "epoch 37 loss = 1.945047\n",
      "epoch 38 loss = 2.013221\n",
      "epoch 39 loss = 1.873993\n",
      "epoch 40 loss = 1.737341\n",
      "epoch 41 loss = 1.884729\n",
      "epoch 42 loss = 1.934787\n",
      "epoch 43 loss = 2.066558\n",
      "epoch 44 loss = 1.770706\n",
      "epoch 45 loss = 1.886634\n",
      "epoch 46 loss = 2.011761\n",
      "epoch 47 loss = 1.992576\n",
      "epoch 48 loss = 1.909623\n",
      "epoch 49 loss = 1.997946\n",
      "epoch 50 loss = 1.832443\n",
      "epoch 51 loss = 2.018250\n",
      "epoch 52 loss = 1.935974\n",
      "epoch 53 loss = 1.899678\n",
      "epoch 54 loss = 1.874083\n",
      "epoch 55 loss = 1.832837\n",
      "epoch 56 loss = 1.964520\n",
      "epoch 57 loss = 1.772762\n",
      "epoch 58 loss = 1.928754\n",
      "epoch 59 loss = 2.010230\n",
      "epoch 60 loss = 1.938170\n",
      "epoch 61 loss = 1.853211\n",
      "epoch 62 loss = 2.050337\n",
      "epoch 63 loss = 1.721597\n",
      "epoch 64 loss = 1.829578\n",
      "epoch 65 loss = 1.830700\n",
      "epoch 66 loss = 1.792128\n",
      "epoch 67 loss = 1.922760\n",
      "epoch 68 loss = 1.881138\n",
      "epoch 69 loss = 2.009559\n",
      "epoch 70 loss = 1.982317\n",
      "epoch 71 loss = 1.811441\n",
      "epoch 72 loss = 1.732768\n",
      "epoch 73 loss = 1.778383\n",
      "epoch 74 loss = 1.913121\n",
      "epoch 75 loss = 1.789741\n",
      "epoch 76 loss = 1.673921\n",
      "epoch 77 loss = 1.869757\n",
      "epoch 78 loss = 1.825714\n",
      "epoch 79 loss = 1.633370\n",
      "epoch 80 loss = 1.716376\n",
      "epoch 81 loss = 1.922771\n",
      "epoch 82 loss = 1.829845\n",
      "epoch 83 loss = 1.703195\n",
      "epoch 84 loss = 1.748452\n",
      "epoch 85 loss = 1.954467\n",
      "epoch 86 loss = 1.808817\n",
      "epoch 87 loss = 1.799736\n",
      "epoch 88 loss = 1.849816\n",
      "epoch 89 loss = 1.810809\n",
      "epoch 90 loss = 1.827126\n",
      "epoch 91 loss = 1.792631\n",
      "epoch 92 loss = 1.976660\n",
      "epoch 93 loss = 1.800108\n",
      "epoch 94 loss = 1.829479\n",
      "epoch 95 loss = 1.720434\n",
      "epoch 96 loss = 1.731912\n",
      "epoch 97 loss = 1.825727\n",
      "epoch 98 loss = 1.700189\n",
      "epoch 99 loss = 1.688292\n",
      "epoch 100 loss = 1.660140\n",
      "epoch 101 loss = 1.691639\n",
      "epoch 102 loss = 1.802767\n",
      "epoch 103 loss = 1.789031\n",
      "epoch 104 loss = 1.930749\n",
      "epoch 105 loss = 1.760781\n",
      "epoch 106 loss = 1.909695\n",
      "epoch 107 loss = 1.677996\n",
      "epoch 108 loss = 1.836164\n",
      "epoch 109 loss = 1.735217\n",
      "epoch 110 loss = 1.808419\n",
      "epoch 111 loss = 1.720608\n",
      "epoch 112 loss = 1.765329\n",
      "epoch 113 loss = 1.706720\n",
      "epoch 114 loss = 1.896906\n",
      "epoch 115 loss = 1.913954\n",
      "epoch 116 loss = 1.826209\n",
      "epoch 117 loss = 1.875075\n",
      "epoch 118 loss = 1.686024\n",
      "epoch 119 loss = 1.643257\n",
      "epoch 120 loss = 1.796164\n",
      "epoch 121 loss = 1.695590\n",
      "epoch 122 loss = 1.556472\n",
      "epoch 123 loss = 1.859397\n",
      "epoch 124 loss = 1.859130\n",
      "epoch 125 loss = 1.885310\n",
      "epoch 126 loss = 1.643105\n",
      "epoch 127 loss = 1.668002\n",
      "epoch 128 loss = 1.864042\n",
      "epoch 129 loss = 1.720540\n",
      "epoch 130 loss = 1.765728\n",
      "epoch 131 loss = 1.682480\n",
      "epoch 132 loss = 1.831661\n",
      "epoch 133 loss = 1.788507\n",
      "epoch 134 loss = 1.820169\n",
      "epoch 135 loss = 1.724686\n",
      "epoch 136 loss = 1.781590\n",
      "epoch 137 loss = 1.754845\n",
      "epoch 138 loss = 1.634953\n",
      "epoch 139 loss = 1.784709\n",
      "epoch 140 loss = 1.774735\n",
      "epoch 141 loss = 1.868972\n",
      "epoch 142 loss = 1.714710\n",
      "epoch 143 loss = 1.844387\n",
      "epoch 144 loss = 1.733305\n",
      "epoch 145 loss = 1.753947\n",
      "epoch 146 loss = 2.089268\n",
      "epoch 147 loss = 1.751029\n",
      "epoch 148 loss = 1.680764\n",
      "epoch 149 loss = 1.888148\n",
      "epoch 150 loss = 1.781842\n",
      "epoch 151 loss = 1.927437\n",
      "epoch 152 loss = 1.974213\n",
      "epoch 153 loss = 1.732112\n",
      "epoch 154 loss = 1.794063\n",
      "epoch 155 loss = 1.892639\n",
      "epoch 156 loss = 1.609340\n",
      "epoch 157 loss = 1.813388\n",
      "epoch 158 loss = 1.858656\n",
      "epoch 159 loss = 1.628062\n",
      "epoch 160 loss = 1.745600\n",
      "epoch 161 loss = 1.770083\n",
      "epoch 162 loss = 1.827478\n",
      "epoch 163 loss = 1.793966\n",
      "epoch 164 loss = 1.762694\n",
      "epoch 165 loss = 1.840205\n",
      "epoch 166 loss = 1.737410\n",
      "epoch 167 loss = 1.730783\n",
      "epoch 168 loss = 1.794671\n",
      "epoch 169 loss = 1.953736\n",
      "epoch 170 loss = 1.752516\n",
      "epoch 171 loss = 1.773734\n",
      "epoch 172 loss = 1.932522\n",
      "epoch 173 loss = 1.662838\n",
      "epoch 174 loss = 1.781174\n",
      "epoch 175 loss = 1.691216\n",
      "epoch 176 loss = 1.574396\n",
      "epoch 177 loss = 1.788590\n",
      "epoch 178 loss = 1.771995\n",
      "epoch 179 loss = 1.579066\n",
      "epoch 180 loss = 1.959894\n",
      "epoch 181 loss = 1.596218\n",
      "epoch 182 loss = 1.729222\n",
      "epoch 183 loss = 1.671692\n",
      "epoch 184 loss = 1.780908\n",
      "epoch 185 loss = 1.648727\n",
      "epoch 186 loss = 1.584429\n",
      "epoch 187 loss = 1.665468\n",
      "epoch 188 loss = 1.940038\n",
      "epoch 189 loss = 1.636860\n",
      "epoch 190 loss = 1.819361\n",
      "epoch 191 loss = 1.811907\n",
      "epoch 192 loss = 1.721566\n",
      "epoch 193 loss = 1.967713\n",
      "epoch 194 loss = 1.889399\n",
      "epoch 195 loss = 1.840165\n",
      "epoch 196 loss = 1.819247\n",
      "epoch 197 loss = 1.624724\n",
      "epoch 198 loss = 1.822276\n",
      "epoch 199 loss = 1.993909\n",
      "epoch 200 loss = 1.628742\n",
      "epoch 201 loss = 1.624202\n",
      "epoch 202 loss = 1.740850\n",
      "epoch 203 loss = 1.749682\n",
      "epoch 204 loss = 1.697532\n",
      "epoch 205 loss = 1.762762\n",
      "epoch 206 loss = 1.789565\n",
      "epoch 207 loss = 1.777555\n",
      "epoch 208 loss = 1.591817\n",
      "epoch 209 loss = 1.789248\n",
      "epoch 210 loss = 1.782657\n",
      "epoch 211 loss = 1.818798\n",
      "epoch 212 loss = 1.524651\n",
      "epoch 213 loss = 1.757854\n",
      "epoch 214 loss = 1.948188\n",
      "epoch 215 loss = 1.762481\n",
      "epoch 216 loss = 1.632545\n",
      "epoch 217 loss = 1.953531\n",
      "epoch 218 loss = 1.846794\n",
      "epoch 219 loss = 1.875434\n",
      "epoch 220 loss = 1.767148\n",
      "epoch 221 loss = 1.672012\n",
      "epoch 222 loss = 1.670532\n",
      "epoch 223 loss = 1.864849\n",
      "epoch 224 loss = 1.732916\n",
      "epoch 225 loss = 1.769449\n",
      "epoch 226 loss = 1.760807\n",
      "epoch 227 loss = 1.954826\n",
      "epoch 228 loss = 1.951958\n",
      "epoch 229 loss = 1.752533\n",
      "epoch 230 loss = 1.689565\n",
      "epoch 231 loss = 1.792529\n",
      "epoch 232 loss = 1.600052\n",
      "epoch 233 loss = 1.849026\n",
      "epoch 234 loss = 1.734787\n",
      "epoch 235 loss = 1.858604\n",
      "epoch 236 loss = 1.774867\n",
      "epoch 237 loss = 1.799169\n",
      "epoch 238 loss = 1.862713\n",
      "epoch 239 loss = 1.596531\n",
      "epoch 240 loss = 1.732000\n",
      "epoch 241 loss = 1.800751\n",
      "epoch 242 loss = 1.657659\n",
      "epoch 243 loss = 1.720687\n",
      "epoch 244 loss = 1.970649\n",
      "epoch 245 loss = 1.738031\n",
      "epoch 246 loss = 1.641284\n",
      "epoch 247 loss = 1.895024\n",
      "epoch 248 loss = 1.641609\n",
      "epoch 249 loss = 1.788499\n",
      "epoch 250 loss = 1.818341\n",
      "epoch 251 loss = 1.620814\n",
      "epoch 252 loss = 1.788178\n",
      "epoch 253 loss = 1.604375\n",
      "epoch 254 loss = 1.716925\n",
      "epoch 255 loss = 1.821359\n",
      "epoch 256 loss = 1.689493\n",
      "epoch 257 loss = 1.863692\n",
      "epoch 258 loss = 1.754812\n",
      "epoch 259 loss = 1.826946\n",
      "epoch 260 loss = 1.603750\n",
      "epoch 261 loss = 1.843843\n",
      "epoch 262 loss = 1.659355\n",
      "epoch 263 loss = 1.790536\n",
      "epoch 264 loss = 1.751974\n",
      "epoch 265 loss = 1.629100\n",
      "epoch 266 loss = 1.966401\n",
      "epoch 267 loss = 2.034098\n",
      "epoch 268 loss = 1.875354\n",
      "epoch 269 loss = 1.655638\n",
      "epoch 270 loss = 1.759153\n",
      "epoch 271 loss = 1.829759\n",
      "epoch 272 loss = 1.837301\n",
      "epoch 273 loss = 1.702816\n",
      "epoch 274 loss = 1.707262\n",
      "epoch 275 loss = 1.823164\n",
      "epoch 276 loss = 1.831097\n",
      "epoch 277 loss = 1.659231\n",
      "epoch 278 loss = 1.968688\n",
      "epoch 279 loss = 1.835739\n",
      "epoch 280 loss = 1.933717\n",
      "epoch 281 loss = 1.727396\n",
      "epoch 282 loss = 1.845527\n",
      "epoch 283 loss = 1.781155\n",
      "epoch 284 loss = 1.767651\n",
      "epoch 285 loss = 1.970688\n",
      "epoch 286 loss = 1.668286\n",
      "epoch 287 loss = 1.798307\n",
      "epoch 288 loss = 1.740046\n",
      "epoch 289 loss = 1.613956\n",
      "epoch 290 loss = 1.934726\n",
      "epoch 291 loss = 1.694170\n",
      "epoch 292 loss = 1.761801\n",
      "epoch 293 loss = 1.768910\n",
      "epoch 294 loss = 1.756800\n",
      "epoch 295 loss = 1.798531\n",
      "epoch 296 loss = 1.644497\n",
      "epoch 297 loss = 1.715229\n",
      "epoch 298 loss = 1.647851\n",
      "epoch 299 loss = 1.701818\n",
      "epoch 300 loss = 1.757450\n",
      "epoch 301 loss = 1.849864\n",
      "epoch 302 loss = 1.618878\n",
      "epoch 303 loss = 1.896310\n",
      "epoch 304 loss = 1.688871\n",
      "epoch 305 loss = 1.865065\n",
      "epoch 306 loss = 1.638800\n",
      "epoch 307 loss = 1.682349\n",
      "epoch 308 loss = 1.839212\n",
      "epoch 309 loss = 1.681604\n",
      "epoch 310 loss = 1.682805\n",
      "epoch 311 loss = 2.075308\n",
      "epoch 312 loss = 1.733945\n",
      "epoch 313 loss = 1.821526\n",
      "epoch 314 loss = 1.752048\n",
      "epoch 315 loss = 1.769266\n",
      "epoch 316 loss = 1.883950\n",
      "epoch 317 loss = 1.628411\n",
      "epoch 318 loss = 1.938363\n",
      "epoch 319 loss = 1.628863\n",
      "epoch 320 loss = 1.640100\n",
      "epoch 321 loss = 1.682960\n",
      "epoch 322 loss = 1.669965\n",
      "epoch 323 loss = 1.904266\n",
      "epoch 324 loss = 1.724146\n",
      "epoch 325 loss = 1.761751\n",
      "epoch 326 loss = 1.635626\n",
      "epoch 327 loss = 1.936102\n",
      "epoch 328 loss = 1.858166\n",
      "epoch 329 loss = 1.792530\n",
      "epoch 330 loss = 1.954079\n",
      "epoch 331 loss = 1.725099\n",
      "epoch 332 loss = 1.874926\n",
      "epoch 333 loss = 1.623141\n",
      "epoch 334 loss = 1.741835\n",
      "epoch 335 loss = 1.691501\n",
      "epoch 336 loss = 1.944044\n",
      "epoch 337 loss = 1.831907\n",
      "epoch 338 loss = 2.016091\n",
      "epoch 339 loss = 1.649584\n",
      "epoch 340 loss = 1.835334\n",
      "epoch 341 loss = 1.779390\n",
      "epoch 342 loss = 1.806253\n",
      "epoch 343 loss = 1.648226\n",
      "epoch 344 loss = 1.842611\n",
      "epoch 345 loss = 1.848691\n",
      "epoch 346 loss = 1.835437\n",
      "epoch 347 loss = 1.676493\n",
      "epoch 348 loss = 1.698069\n",
      "epoch 349 loss = 1.750659\n",
      "epoch 350 loss = 1.830114\n",
      "epoch 351 loss = 1.613304\n",
      "epoch 352 loss = 1.762748\n",
      "epoch 353 loss = 1.942362\n",
      "epoch 354 loss = 1.799808\n",
      "epoch 355 loss = 1.878286\n",
      "epoch 356 loss = 1.896367\n",
      "epoch 357 loss = 1.911127\n",
      "epoch 358 loss = 1.863134\n",
      "epoch 359 loss = 1.766105\n",
      "epoch 360 loss = 1.696464\n",
      "epoch 361 loss = 1.636220\n",
      "epoch 362 loss = 1.666093\n",
      "epoch 363 loss = 1.698074\n",
      "epoch 364 loss = 1.727711\n",
      "epoch 365 loss = 1.780886\n",
      "epoch 366 loss = 1.747495\n",
      "epoch 367 loss = 1.711555\n",
      "epoch 368 loss = 1.780027\n",
      "epoch 369 loss = 1.850628\n",
      "epoch 370 loss = 1.993908\n",
      "epoch 371 loss = 1.783451\n",
      "epoch 372 loss = 1.956853\n",
      "epoch 373 loss = 1.702896\n",
      "epoch 374 loss = 1.846713\n",
      "epoch 375 loss = 1.661933\n",
      "epoch 376 loss = 1.729004\n",
      "epoch 377 loss = 1.808496\n",
      "epoch 378 loss = 1.731670\n",
      "epoch 379 loss = 1.636196\n",
      "epoch 380 loss = 1.832485\n",
      "epoch 381 loss = 1.773991\n",
      "epoch 382 loss = 1.711160\n",
      "epoch 383 loss = 1.992646\n",
      "epoch 384 loss = 1.908832\n",
      "epoch 385 loss = 1.763848\n",
      "epoch 386 loss = 1.891999\n",
      "epoch 387 loss = 1.901016\n",
      "epoch 388 loss = 1.764733\n",
      "epoch 389 loss = 1.920603\n",
      "epoch 390 loss = 1.708753\n",
      "epoch 391 loss = 1.637197\n",
      "epoch 392 loss = 1.918826\n",
      "epoch 393 loss = 1.778178\n",
      "epoch 394 loss = 1.753441\n",
      "epoch 395 loss = 1.725169\n",
      "epoch 396 loss = 1.856245\n",
      "epoch 397 loss = 1.816414\n",
      "epoch 398 loss = 1.677055\n",
      "epoch 399 loss = 1.861933\n",
      "epoch 400 loss = 1.771272\n",
      "epoch 401 loss = 1.831035\n",
      "epoch 402 loss = 1.715547\n",
      "epoch 403 loss = 1.855569\n",
      "epoch 404 loss = 1.625034\n",
      "epoch 405 loss = 1.853773\n",
      "epoch 406 loss = 1.788893\n",
      "epoch 407 loss = 2.113765\n",
      "epoch 408 loss = 1.625722\n",
      "epoch 409 loss = 1.748844\n",
      "epoch 410 loss = 2.058056\n",
      "epoch 411 loss = 1.507478\n",
      "epoch 412 loss = 1.985884\n",
      "epoch 413 loss = 1.667643\n",
      "epoch 414 loss = 1.729865\n",
      "epoch 415 loss = 1.916922\n",
      "epoch 416 loss = 1.828193\n",
      "epoch 417 loss = 1.887248\n",
      "epoch 418 loss = 1.664643\n",
      "epoch 419 loss = 1.953153\n",
      "epoch 420 loss = 1.680710\n",
      "epoch 421 loss = 1.718003\n",
      "epoch 422 loss = 1.792889\n",
      "epoch 423 loss = 1.718995\n",
      "epoch 424 loss = 1.968576\n",
      "epoch 425 loss = 1.639594\n",
      "epoch 426 loss = 1.917325\n",
      "epoch 427 loss = 1.629368\n",
      "epoch 428 loss = 1.737651\n",
      "epoch 429 loss = 1.592251\n",
      "epoch 430 loss = 1.739207\n",
      "epoch 431 loss = 1.607747\n",
      "epoch 432 loss = 1.775810\n",
      "epoch 433 loss = 1.889880\n",
      "epoch 434 loss = 1.732462\n",
      "epoch 435 loss = 1.949349\n",
      "epoch 436 loss = 1.789951\n",
      "epoch 437 loss = 1.793399\n",
      "epoch 438 loss = 1.752312\n",
      "epoch 439 loss = 1.707966\n",
      "epoch 440 loss = 1.723377\n",
      "epoch 441 loss = 1.799267\n",
      "epoch 442 loss = 1.886167\n",
      "epoch 443 loss = 1.927869\n",
      "epoch 444 loss = 1.772703\n",
      "epoch 445 loss = 1.710736\n",
      "epoch 446 loss = 1.697261\n",
      "epoch 447 loss = 1.932799\n",
      "epoch 448 loss = 2.013349\n",
      "epoch 449 loss = 1.936806\n",
      "epoch 450 loss = 1.582729\n",
      "epoch 451 loss = 1.703395\n",
      "epoch 452 loss = 1.728220\n",
      "epoch 453 loss = 1.950335\n",
      "epoch 454 loss = 1.834275\n",
      "epoch 455 loss = 1.715123\n",
      "epoch 456 loss = 1.930443\n",
      "epoch 457 loss = 1.728161\n",
      "epoch 458 loss = 1.907972\n",
      "epoch 459 loss = 1.787944\n",
      "epoch 460 loss = 1.931031\n",
      "epoch 461 loss = 1.970567\n",
      "epoch 462 loss = 1.758850\n",
      "epoch 463 loss = 1.994514\n",
      "epoch 464 loss = 1.700502\n",
      "epoch 465 loss = 1.663300\n",
      "epoch 466 loss = 1.880038\n",
      "epoch 467 loss = 1.552387\n",
      "epoch 468 loss = 1.635890\n",
      "epoch 469 loss = 1.769855\n",
      "epoch 470 loss = 1.673829\n",
      "epoch 471 loss = 1.809304\n",
      "epoch 472 loss = 1.818195\n",
      "epoch 473 loss = 1.700446\n",
      "epoch 474 loss = 1.721810\n",
      "epoch 475 loss = 1.877243\n",
      "epoch 476 loss = 1.686367\n",
      "epoch 477 loss = 1.680746\n",
      "epoch 478 loss = 1.718877\n",
      "epoch 479 loss = 1.832017\n",
      "epoch 480 loss = 1.775662\n",
      "epoch 481 loss = 1.922327\n",
      "epoch 482 loss = 1.671418\n",
      "epoch 483 loss = 1.738163\n",
      "epoch 484 loss = 1.761169\n",
      "epoch 485 loss = 1.921696\n",
      "epoch 486 loss = 1.726256\n",
      "epoch 487 loss = 1.795569\n",
      "epoch 488 loss = 1.590703\n",
      "epoch 489 loss = 1.757766\n",
      "epoch 490 loss = 1.759149\n",
      "epoch 491 loss = 1.670485\n",
      "epoch 492 loss = 1.655187\n",
      "epoch 493 loss = 1.848188\n",
      "epoch 494 loss = 1.917153\n",
      "epoch 495 loss = 1.787307\n",
      "epoch 496 loss = 1.720874\n",
      "epoch 497 loss = 1.771396\n",
      "epoch 498 loss = 1.668729\n",
      "epoch 499 loss = 1.728614\n",
      "final loss = 1.728614\n",
      "accuracy_mc = tensor(0.2772, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2566, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.8018, device='cuda:0')\n",
      "training time = 305.60508847236633 seconds\n",
      "testing time = 3.2468764781951904 seconds\n",
      "\n",
      "subset 0.050000, dropout_rate 0.500000, reg_strength 0.050000\n",
      "n_epoch 10\n",
      "\n",
      "Files already downloaded and verified\n",
      "subset size = (2500, 32, 32, 3)\n",
      "training set size = 2000\n",
      "test set size = 500\n",
      "\n",
      "Training with split 0\n",
      "epoch 0 loss = 2.291659\n",
      "epoch 1 loss = 2.316656\n",
      "epoch 2 loss = 2.256858\n",
      "epoch 3 loss = 2.167309\n",
      "epoch 4 loss = 2.213149\n",
      "epoch 5 loss = 2.210883\n",
      "epoch 6 loss = 2.276708\n",
      "epoch 7 loss = 2.190082\n",
      "epoch 8 loss = 2.149594\n",
      "epoch 9 loss = 2.238701\n",
      "final loss = 2.238701\n",
      "accuracy_mc = tensor(0.1794, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2244, device='cuda:0')\n",
      "test_ll_mc = tensor(-2.1543, device='cuda:0')\n",
      "training time = 6.136138916015625 seconds\n",
      "testing time = 3.17883038520813 seconds\n",
      "\n",
      "Training with split 1\n",
      "epoch 0 loss = 2.310110\n",
      "epoch 1 loss = 2.268350\n",
      "epoch 2 loss = 2.320267\n",
      "epoch 3 loss = 2.250813\n",
      "epoch 4 loss = 2.186116\n",
      "epoch 5 loss = 2.186073\n",
      "epoch 6 loss = 2.090075\n",
      "epoch 7 loss = 2.444979\n",
      "epoch 8 loss = 2.200774\n",
      "epoch 9 loss = 2.201157\n",
      "final loss = 2.201157\n",
      "accuracy_mc = tensor(0.2219, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.1966, device='cuda:0')\n",
      "test_ll_mc = tensor(-2.0949, device='cuda:0')\n",
      "training time = 6.070327520370483 seconds\n",
      "testing time = 3.1549673080444336 seconds\n",
      "\n",
      "Training with split 2\n",
      "epoch 0 loss = 2.270715\n",
      "epoch 1 loss = 2.229077\n",
      "epoch 2 loss = 2.198201\n",
      "epoch 3 loss = 2.225803\n",
      "epoch 4 loss = 2.242987\n",
      "epoch 5 loss = 2.191522\n",
      "epoch 6 loss = 2.128619\n",
      "epoch 7 loss = 2.187593\n",
      "epoch 8 loss = 2.253128\n",
      "epoch 9 loss = 2.164430\n",
      "final loss = 2.164430\n",
      "accuracy_mc = tensor(0.2105, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.1600, device='cuda:0')\n",
      "test_ll_mc = tensor(-2.1445, device='cuda:0')\n",
      "training time = 6.078365802764893 seconds\n",
      "testing time = 3.086091995239258 seconds\n",
      "\n",
      "Training with split 3\n",
      "epoch 0 loss = 2.258836\n",
      "epoch 1 loss = 2.249093\n",
      "epoch 2 loss = 2.300068\n",
      "epoch 3 loss = 2.231747\n",
      "epoch 4 loss = 2.254675\n",
      "epoch 5 loss = 2.055099\n",
      "epoch 6 loss = 2.105245\n",
      "epoch 7 loss = 2.212668\n",
      "epoch 8 loss = 2.125587\n",
      "epoch 9 loss = 2.135405\n",
      "final loss = 2.135405\n",
      "accuracy_mc = tensor(0.2455, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2351, device='cuda:0')\n",
      "test_ll_mc = tensor(-2.1552, device='cuda:0')\n",
      "training time = 6.077810764312744 seconds\n",
      "testing time = 3.2391200065612793 seconds\n",
      "\n",
      "Training with split 4\n",
      "epoch 0 loss = 2.257435\n",
      "epoch 1 loss = 2.216435\n",
      "epoch 2 loss = 2.142976\n",
      "epoch 3 loss = 2.098682\n",
      "epoch 4 loss = 2.074956\n",
      "epoch 5 loss = 2.202136\n",
      "epoch 6 loss = 2.154771\n",
      "epoch 7 loss = 2.079828\n",
      "epoch 8 loss = 2.139470\n",
      "epoch 9 loss = 2.073292\n",
      "final loss = 2.073292\n",
      "accuracy_mc = tensor(0.2226, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2596, device='cuda:0')\n",
      "test_ll_mc = tensor(-2.0882, device='cuda:0')\n",
      "training time = 6.118399143218994 seconds\n",
      "testing time = 3.1703574657440186 seconds\n",
      "\n",
      "Training with split 5\n",
      "epoch 0 loss = 2.290789\n",
      "epoch 1 loss = 2.257273\n",
      "epoch 2 loss = 2.229789\n",
      "epoch 3 loss = 2.243307\n",
      "epoch 4 loss = 2.266276\n",
      "epoch 5 loss = 2.298235\n",
      "epoch 6 loss = 2.160346\n",
      "epoch 7 loss = 2.252532\n",
      "epoch 8 loss = 2.033429\n",
      "epoch 9 loss = 2.162971\n",
      "final loss = 2.162971\n",
      "accuracy_mc = tensor(0.3070, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2861, device='cuda:0')\n",
      "test_ll_mc = tensor(-2.0808, device='cuda:0')\n",
      "training time = 6.145797252655029 seconds\n",
      "testing time = 3.21077561378479 seconds\n",
      "\n",
      "Training with split 6\n",
      "epoch 0 loss = 2.384463\n",
      "epoch 1 loss = 2.162555\n",
      "epoch 2 loss = 2.026555\n",
      "epoch 3 loss = 2.137305\n",
      "epoch 4 loss = 2.318155\n",
      "epoch 5 loss = 2.246791\n",
      "epoch 6 loss = 2.271729\n",
      "epoch 7 loss = 2.240907\n",
      "epoch 8 loss = 2.287516\n",
      "epoch 9 loss = 2.222051\n",
      "final loss = 2.222051\n",
      "accuracy_mc = tensor(0.2370, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2424, device='cuda:0')\n",
      "test_ll_mc = tensor(-2.0795, device='cuda:0')\n",
      "training time = 6.078826665878296 seconds\n",
      "testing time = 3.096109390258789 seconds\n",
      "\n",
      "Training with split 7\n",
      "epoch 0 loss = 2.306628\n",
      "epoch 1 loss = 2.309519\n",
      "epoch 2 loss = 2.152577\n",
      "epoch 3 loss = 2.386456\n",
      "epoch 4 loss = 2.206429\n",
      "epoch 5 loss = 2.196606\n",
      "epoch 6 loss = 2.143788\n",
      "epoch 7 loss = 2.170645\n",
      "epoch 8 loss = 2.155852\n",
      "epoch 9 loss = 2.221227\n",
      "final loss = 2.221227\n",
      "accuracy_mc = tensor(0.2136, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.1783, device='cuda:0')\n",
      "test_ll_mc = tensor(-2.1063, device='cuda:0')\n",
      "training time = 6.124981164932251 seconds\n",
      "testing time = 3.2355170249938965 seconds\n",
      "\n",
      "Training with split 8\n",
      "epoch 0 loss = 2.298476\n",
      "epoch 1 loss = 2.303773\n",
      "epoch 2 loss = 2.324660\n",
      "epoch 3 loss = 2.263990\n",
      "epoch 4 loss = 2.204815\n",
      "epoch 5 loss = 2.145160\n",
      "epoch 6 loss = 2.203107\n",
      "epoch 7 loss = 2.214727\n",
      "epoch 8 loss = 2.112389\n",
      "epoch 9 loss = 2.113438\n",
      "final loss = 2.113438\n",
      "accuracy_mc = tensor(0.2119, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.1822, device='cuda:0')\n",
      "test_ll_mc = tensor(-2.1471, device='cuda:0')\n",
      "training time = 6.0601513385772705 seconds\n",
      "testing time = 3.0979998111724854 seconds\n",
      "\n",
      "Training with split 9\n",
      "epoch 0 loss = 2.306611\n",
      "epoch 1 loss = 2.292899\n",
      "epoch 2 loss = 2.299089\n",
      "epoch 3 loss = 2.265216\n",
      "epoch 4 loss = 2.140543\n",
      "epoch 5 loss = 2.186566\n",
      "epoch 6 loss = 2.246936\n",
      "epoch 7 loss = 2.227586\n",
      "epoch 8 loss = 2.006034\n",
      "epoch 9 loss = 2.131266\n",
      "final loss = 2.131266\n",
      "accuracy_mc = tensor(0.2114, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2083, device='cuda:0')\n",
      "test_ll_mc = tensor(-2.1363, device='cuda:0')\n",
      "training time = 6.258156776428223 seconds\n",
      "testing time = 3.2444779872894287 seconds\n",
      "\n",
      "subset 0.050000, dropout_rate 0.500000, reg_strength 0.050000\n",
      "n_epoch 100\n",
      "\n",
      "Files already downloaded and verified\n",
      "subset size = (2500, 32, 32, 3)\n",
      "training set size = 2000\n",
      "test set size = 500\n",
      "\n",
      "Training with split 0\n",
      "epoch 0 loss = 2.291659\n",
      "epoch 1 loss = 2.316656\n",
      "epoch 2 loss = 2.256858\n",
      "epoch 3 loss = 2.167309\n",
      "epoch 4 loss = 2.213149\n",
      "epoch 5 loss = 2.210883\n",
      "epoch 6 loss = 2.276708\n",
      "epoch 7 loss = 2.190082\n",
      "epoch 8 loss = 2.149594\n",
      "epoch 9 loss = 2.238701\n",
      "epoch 10 loss = 2.285510\n",
      "epoch 11 loss = 2.254820\n",
      "epoch 12 loss = 2.156374\n",
      "epoch 13 loss = 2.199789\n",
      "epoch 14 loss = 2.229370\n",
      "epoch 15 loss = 2.195518\n",
      "epoch 16 loss = 2.150615\n",
      "epoch 17 loss = 2.364619\n",
      "epoch 18 loss = 2.118140\n",
      "epoch 19 loss = 2.212104\n",
      "epoch 20 loss = 2.178346\n",
      "epoch 21 loss = 2.317971\n",
      "epoch 22 loss = 2.264026\n",
      "epoch 23 loss = 2.314037\n",
      "epoch 24 loss = 2.118915\n",
      "epoch 25 loss = 2.058170\n",
      "epoch 26 loss = 2.214881\n",
      "epoch 27 loss = 2.221652\n",
      "epoch 28 loss = 2.264815\n",
      "epoch 29 loss = 2.280925\n",
      "epoch 30 loss = 2.085201\n",
      "epoch 31 loss = 2.247747\n",
      "epoch 32 loss = 2.244069\n",
      "epoch 33 loss = 2.291080\n",
      "epoch 34 loss = 2.103135\n",
      "epoch 35 loss = 2.039319\n",
      "epoch 36 loss = 2.198138\n",
      "epoch 37 loss = 2.195180\n",
      "epoch 38 loss = 2.254338\n",
      "epoch 39 loss = 2.362896\n",
      "epoch 40 loss = 1.964571\n",
      "epoch 41 loss = 2.079906\n",
      "epoch 42 loss = 2.195003\n",
      "epoch 43 loss = 2.130936\n",
      "epoch 44 loss = 2.055662\n",
      "epoch 45 loss = 2.320716\n",
      "epoch 46 loss = 2.163496\n",
      "epoch 47 loss = 2.238806\n",
      "epoch 48 loss = 2.118942\n",
      "epoch 49 loss = 2.031589\n",
      "epoch 50 loss = 2.166421\n",
      "epoch 51 loss = 2.248989\n",
      "epoch 52 loss = 2.208549\n",
      "epoch 53 loss = 2.161575\n",
      "epoch 54 loss = 2.257508\n",
      "epoch 55 loss = 2.253326\n",
      "epoch 56 loss = 2.217466\n",
      "epoch 57 loss = 2.281900\n",
      "epoch 58 loss = 2.285874\n",
      "epoch 59 loss = 2.123021\n",
      "epoch 60 loss = 2.108399\n",
      "epoch 61 loss = 2.152213\n",
      "epoch 62 loss = 2.141537\n",
      "epoch 63 loss = 1.970191\n",
      "epoch 64 loss = 2.273695\n",
      "epoch 65 loss = 2.068449\n",
      "epoch 66 loss = 2.130084\n",
      "epoch 67 loss = 2.166844\n",
      "epoch 68 loss = 2.224133\n",
      "epoch 69 loss = 2.216871\n",
      "epoch 70 loss = 2.342690\n",
      "epoch 71 loss = 2.252024\n",
      "epoch 72 loss = 2.115728\n",
      "epoch 73 loss = 2.138909\n",
      "epoch 74 loss = 2.322306\n",
      "epoch 75 loss = 2.050609\n",
      "epoch 76 loss = 2.132475\n",
      "epoch 77 loss = 2.040927\n",
      "epoch 78 loss = 2.135790\n",
      "epoch 79 loss = 2.167972\n",
      "epoch 80 loss = 2.087491\n",
      "epoch 81 loss = 2.112874\n",
      "epoch 82 loss = 2.123729\n",
      "epoch 83 loss = 2.079742\n",
      "epoch 84 loss = 2.192425\n",
      "epoch 85 loss = 2.092969\n",
      "epoch 86 loss = 2.078479\n",
      "epoch 87 loss = 2.263987\n",
      "epoch 88 loss = 2.136563\n",
      "epoch 89 loss = 2.145818\n",
      "epoch 90 loss = 2.068383\n",
      "epoch 91 loss = 2.344361\n",
      "epoch 92 loss = 2.126580\n",
      "epoch 93 loss = 2.041182\n",
      "epoch 94 loss = 2.404729\n",
      "epoch 95 loss = 2.103551\n",
      "epoch 96 loss = 2.213894\n",
      "epoch 97 loss = 2.220629\n",
      "epoch 98 loss = 2.222410\n",
      "epoch 99 loss = 2.200088\n",
      "final loss = 2.200088\n",
      "accuracy_mc = tensor(0.1847, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2252, device='cuda:0')\n",
      "test_ll_mc = tensor(-2.0869, device='cuda:0')\n",
      "training time = 61.05227828025818 seconds\n",
      "testing time = 3.2255568504333496 seconds\n",
      "\n",
      "Training with split 1\n",
      "epoch 0 loss = 2.312598\n",
      "epoch 1 loss = 2.278581\n",
      "epoch 2 loss = 2.271654\n",
      "epoch 3 loss = 2.153746\n",
      "epoch 4 loss = 2.251986\n",
      "epoch 5 loss = 2.218555\n",
      "epoch 6 loss = 2.242166\n",
      "epoch 7 loss = 2.201086\n",
      "epoch 8 loss = 2.229532\n",
      "epoch 9 loss = 2.164693\n",
      "epoch 10 loss = 2.151943\n",
      "epoch 11 loss = 2.198577\n",
      "epoch 12 loss = 2.069194\n",
      "epoch 13 loss = 2.149561\n",
      "epoch 14 loss = 2.038988\n",
      "epoch 15 loss = 2.094028\n",
      "epoch 16 loss = 1.961602\n",
      "epoch 17 loss = 2.132187\n",
      "epoch 18 loss = 2.182905\n",
      "epoch 19 loss = 2.070393\n",
      "epoch 20 loss = 2.128297\n",
      "epoch 21 loss = 2.022826\n",
      "epoch 22 loss = 2.101346\n",
      "epoch 23 loss = 2.015292\n",
      "epoch 24 loss = 2.134193\n",
      "epoch 25 loss = 2.130745\n",
      "epoch 26 loss = 2.159974\n",
      "epoch 27 loss = 2.140281\n",
      "epoch 28 loss = 1.936282\n",
      "epoch 29 loss = 2.148803\n",
      "epoch 30 loss = 1.999931\n",
      "epoch 31 loss = 1.976293\n",
      "epoch 32 loss = 1.978687\n",
      "epoch 33 loss = 2.129328\n",
      "epoch 34 loss = 2.074624\n",
      "epoch 35 loss = 1.948923\n",
      "epoch 36 loss = 1.847222\n",
      "epoch 37 loss = 2.179483\n",
      "epoch 38 loss = 2.026826\n",
      "epoch 39 loss = 1.987283\n",
      "epoch 40 loss = 2.031815\n",
      "epoch 41 loss = 2.198209\n",
      "epoch 42 loss = 2.065279\n",
      "epoch 43 loss = 2.008506\n",
      "epoch 44 loss = 1.910888\n",
      "epoch 45 loss = 1.957309\n",
      "epoch 46 loss = 2.057254\n",
      "epoch 47 loss = 2.092732\n",
      "epoch 48 loss = 2.100531\n",
      "epoch 49 loss = 2.024359\n",
      "epoch 50 loss = 1.921453\n",
      "epoch 51 loss = 1.973912\n",
      "epoch 52 loss = 1.917785\n",
      "epoch 53 loss = 1.885848\n",
      "epoch 54 loss = 1.683133\n",
      "epoch 55 loss = 1.944565\n",
      "epoch 56 loss = 2.084229\n",
      "epoch 57 loss = 1.812075\n",
      "epoch 58 loss = 2.201388\n",
      "epoch 59 loss = 1.984504\n",
      "epoch 60 loss = 1.927666\n",
      "epoch 61 loss = 1.801134\n",
      "epoch 62 loss = 2.106360\n",
      "epoch 63 loss = 1.839798\n",
      "epoch 64 loss = 2.116905\n",
      "epoch 65 loss = 1.856819\n",
      "epoch 66 loss = 1.968005\n",
      "epoch 67 loss = 2.189412\n",
      "epoch 68 loss = 2.101552\n",
      "epoch 69 loss = 2.111549\n",
      "epoch 70 loss = 2.091952\n",
      "epoch 71 loss = 1.986192\n",
      "epoch 72 loss = 1.886330\n",
      "epoch 73 loss = 1.896218\n",
      "epoch 74 loss = 1.946574\n",
      "epoch 75 loss = 1.962530\n",
      "epoch 76 loss = 2.060917\n",
      "epoch 77 loss = 2.003285\n",
      "epoch 78 loss = 1.990932\n",
      "epoch 79 loss = 1.775277\n",
      "epoch 80 loss = 2.030572\n",
      "epoch 81 loss = 2.157848\n",
      "epoch 82 loss = 1.907935\n",
      "epoch 83 loss = 2.037127\n",
      "epoch 84 loss = 2.030524\n",
      "epoch 85 loss = 1.892185\n",
      "epoch 86 loss = 1.810037\n",
      "epoch 87 loss = 2.035689\n",
      "epoch 88 loss = 2.024741\n",
      "epoch 89 loss = 2.138737\n",
      "epoch 90 loss = 1.962729\n",
      "epoch 91 loss = 2.016989\n",
      "epoch 92 loss = 2.078488\n",
      "epoch 93 loss = 1.837331\n",
      "epoch 94 loss = 1.958131\n",
      "epoch 95 loss = 1.651178\n",
      "epoch 96 loss = 1.956644\n",
      "epoch 97 loss = 1.982676\n",
      "epoch 98 loss = 1.946512\n",
      "epoch 99 loss = 2.050215\n",
      "final loss = 2.050215\n",
      "accuracy_mc = tensor(0.2780, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2891, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.9360, device='cuda:0')\n",
      "training time = 60.86615037918091 seconds\n",
      "testing time = 3.215923309326172 seconds\n",
      "\n",
      "Training with split 2\n",
      "epoch 0 loss = 2.354352\n",
      "epoch 1 loss = 2.282425\n",
      "epoch 2 loss = 2.293509\n",
      "epoch 3 loss = 2.132131\n",
      "epoch 4 loss = 2.024815\n",
      "epoch 5 loss = 2.161773\n",
      "epoch 6 loss = 2.066956\n",
      "epoch 7 loss = 2.171694\n",
      "epoch 8 loss = 2.067918\n",
      "epoch 9 loss = 2.274030\n",
      "epoch 10 loss = 2.100496\n",
      "epoch 11 loss = 2.090026\n",
      "epoch 12 loss = 2.212788\n",
      "epoch 13 loss = 2.179694\n",
      "epoch 14 loss = 2.236722\n",
      "epoch 15 loss = 1.841967\n",
      "epoch 16 loss = 2.182935\n",
      "epoch 17 loss = 2.154848\n",
      "epoch 18 loss = 2.089443\n",
      "epoch 19 loss = 2.020600\n",
      "epoch 20 loss = 2.084992\n",
      "epoch 21 loss = 1.977511\n",
      "epoch 22 loss = 2.115610\n",
      "epoch 23 loss = 2.059684\n",
      "epoch 24 loss = 2.070491\n",
      "epoch 25 loss = 1.967401\n",
      "epoch 26 loss = 2.025014\n",
      "epoch 27 loss = 2.140633\n",
      "epoch 28 loss = 2.048588\n",
      "epoch 29 loss = 2.007433\n",
      "epoch 30 loss = 2.090791\n",
      "epoch 31 loss = 1.945636\n",
      "epoch 32 loss = 2.100650\n",
      "epoch 33 loss = 2.247512\n",
      "epoch 34 loss = 2.003032\n",
      "epoch 35 loss = 2.128831\n",
      "epoch 36 loss = 2.071481\n",
      "epoch 37 loss = 2.328195\n",
      "epoch 38 loss = 2.233910\n",
      "epoch 39 loss = 1.999442\n",
      "epoch 40 loss = 1.957467\n",
      "epoch 41 loss = 2.087794\n",
      "epoch 42 loss = 1.907035\n",
      "epoch 43 loss = 2.234587\n",
      "epoch 44 loss = 2.067439\n",
      "epoch 45 loss = 2.060999\n",
      "epoch 46 loss = 1.848111\n",
      "epoch 47 loss = 2.081073\n",
      "epoch 48 loss = 2.054605\n",
      "epoch 49 loss = 2.100633\n",
      "epoch 50 loss = 2.073218\n",
      "epoch 51 loss = 2.050516\n",
      "epoch 52 loss = 2.153023\n",
      "epoch 53 loss = 2.094166\n",
      "epoch 54 loss = 2.116442\n",
      "epoch 55 loss = 2.118942\n",
      "epoch 56 loss = 1.968684\n",
      "epoch 57 loss = 2.210746\n",
      "epoch 58 loss = 2.026218\n",
      "epoch 59 loss = 2.164754\n",
      "epoch 60 loss = 2.055891\n",
      "epoch 61 loss = 2.164424\n",
      "epoch 62 loss = 2.141349\n",
      "epoch 63 loss = 2.125796\n",
      "epoch 64 loss = 2.115409\n",
      "epoch 65 loss = 2.047925\n",
      "epoch 66 loss = 2.111658\n",
      "epoch 67 loss = 2.183759\n",
      "epoch 68 loss = 2.022128\n",
      "epoch 69 loss = 2.142763\n",
      "epoch 70 loss = 1.920580\n",
      "epoch 71 loss = 2.149041\n",
      "epoch 72 loss = 1.913243\n",
      "epoch 73 loss = 2.042794\n",
      "epoch 74 loss = 1.929278\n",
      "epoch 75 loss = 2.076770\n",
      "epoch 76 loss = 1.976403\n",
      "epoch 77 loss = 2.198140\n",
      "epoch 78 loss = 2.059919\n",
      "epoch 79 loss = 1.987177\n",
      "epoch 80 loss = 2.149485\n",
      "epoch 81 loss = 1.949347\n",
      "epoch 82 loss = 1.934398\n",
      "epoch 83 loss = 2.188537\n",
      "epoch 84 loss = 2.161643\n",
      "epoch 85 loss = 2.181343\n",
      "epoch 86 loss = 2.011579\n",
      "epoch 87 loss = 1.940950\n",
      "epoch 88 loss = 2.064076\n",
      "epoch 89 loss = 2.267241\n",
      "epoch 90 loss = 2.217867\n",
      "epoch 91 loss = 2.145468\n",
      "epoch 92 loss = 2.074217\n",
      "epoch 93 loss = 2.107378\n",
      "epoch 94 loss = 1.974424\n",
      "epoch 95 loss = 2.143999\n",
      "epoch 96 loss = 2.169620\n",
      "epoch 97 loss = 2.080477\n",
      "epoch 98 loss = 2.060706\n",
      "epoch 99 loss = 2.012777\n",
      "final loss = 2.012777\n",
      "accuracy_mc = tensor(0.1745, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.1324, device='cuda:0')\n",
      "test_ll_mc = tensor(-2.0626, device='cuda:0')\n",
      "training time = 60.98060607910156 seconds\n",
      "testing time = 3.2206459045410156 seconds\n",
      "\n",
      "Training with split 3\n",
      "epoch 0 loss = 2.319447\n",
      "epoch 1 loss = 2.294102\n",
      "epoch 2 loss = 2.217524\n",
      "epoch 3 loss = 2.102841\n",
      "epoch 4 loss = 2.151650\n",
      "epoch 5 loss = 2.172305\n",
      "epoch 6 loss = 2.118389\n",
      "epoch 7 loss = 2.083815\n",
      "epoch 8 loss = 2.112739\n",
      "epoch 9 loss = 2.148914\n",
      "epoch 10 loss = 2.163857\n",
      "epoch 11 loss = 1.982539\n",
      "epoch 12 loss = 1.953943\n",
      "epoch 13 loss = 2.226777\n",
      "epoch 14 loss = 1.910895\n",
      "epoch 15 loss = 1.911971\n",
      "epoch 16 loss = 2.016006\n",
      "epoch 17 loss = 1.858308\n",
      "epoch 18 loss = 2.068470\n",
      "epoch 19 loss = 1.876736\n",
      "epoch 20 loss = 1.971903\n",
      "epoch 21 loss = 1.852472\n",
      "epoch 22 loss = 2.071644\n",
      "epoch 23 loss = 2.162191\n",
      "epoch 24 loss = 2.147642\n",
      "epoch 25 loss = 2.009214\n",
      "epoch 26 loss = 1.712479\n",
      "epoch 27 loss = 2.005413\n",
      "epoch 28 loss = 2.011011\n",
      "epoch 29 loss = 2.085494\n",
      "epoch 30 loss = 1.995461\n",
      "epoch 31 loss = 2.084496\n",
      "epoch 32 loss = 1.989330\n",
      "epoch 33 loss = 1.930980\n",
      "epoch 34 loss = 1.898723\n",
      "epoch 35 loss = 1.889493\n",
      "epoch 36 loss = 1.985293\n",
      "epoch 37 loss = 2.003708\n",
      "epoch 38 loss = 2.053415\n",
      "epoch 39 loss = 2.224794\n",
      "epoch 40 loss = 2.045077\n",
      "epoch 41 loss = 2.144309\n",
      "epoch 42 loss = 1.950623\n",
      "epoch 43 loss = 2.139759\n",
      "epoch 44 loss = 2.052825\n",
      "epoch 45 loss = 2.027860\n",
      "epoch 46 loss = 2.127560\n",
      "epoch 47 loss = 1.925474\n",
      "epoch 48 loss = 2.020607\n",
      "epoch 49 loss = 2.090435\n",
      "epoch 50 loss = 1.984361\n",
      "epoch 51 loss = 1.977676\n",
      "epoch 52 loss = 2.129529\n",
      "epoch 53 loss = 2.107937\n",
      "epoch 54 loss = 2.101656\n",
      "epoch 55 loss = 1.949241\n",
      "epoch 56 loss = 2.008540\n",
      "epoch 57 loss = 1.939625\n",
      "epoch 58 loss = 2.040060\n",
      "epoch 59 loss = 2.009770\n",
      "epoch 60 loss = 1.958182\n",
      "epoch 61 loss = 1.965295\n",
      "epoch 62 loss = 1.908853\n",
      "epoch 63 loss = 2.089739\n",
      "epoch 64 loss = 2.082912\n",
      "epoch 65 loss = 2.025540\n",
      "epoch 66 loss = 2.193292\n",
      "epoch 67 loss = 2.195754\n",
      "epoch 68 loss = 2.248169\n",
      "epoch 69 loss = 1.850288\n",
      "epoch 70 loss = 2.015303\n",
      "epoch 71 loss = 2.029024\n",
      "epoch 72 loss = 1.983378\n",
      "epoch 73 loss = 1.924650\n",
      "epoch 74 loss = 2.069251\n",
      "epoch 75 loss = 1.981904\n",
      "epoch 76 loss = 2.154274\n",
      "epoch 77 loss = 1.930519\n",
      "epoch 78 loss = 2.074075\n",
      "epoch 79 loss = 2.176915\n",
      "epoch 80 loss = 2.129708\n",
      "epoch 81 loss = 2.043484\n",
      "epoch 82 loss = 2.074611\n",
      "epoch 83 loss = 1.777443\n",
      "epoch 84 loss = 2.119169\n",
      "epoch 85 loss = 1.982601\n",
      "epoch 86 loss = 1.858639\n",
      "epoch 87 loss = 2.041368\n",
      "epoch 88 loss = 2.082811\n",
      "epoch 89 loss = 2.044182\n",
      "epoch 90 loss = 2.082204\n",
      "epoch 91 loss = 1.940118\n",
      "epoch 92 loss = 2.040755\n",
      "epoch 93 loss = 2.113489\n",
      "epoch 94 loss = 2.099937\n",
      "epoch 95 loss = 1.955573\n",
      "epoch 96 loss = 1.858585\n",
      "epoch 97 loss = 2.077612\n",
      "epoch 98 loss = 1.938814\n",
      "epoch 99 loss = 1.969788\n",
      "final loss = 1.969788\n",
      "accuracy_mc = tensor(0.2167, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.1802, device='cuda:0')\n",
      "test_ll_mc = tensor(-2.0323, device='cuda:0')\n",
      "training time = 61.19248390197754 seconds\n",
      "testing time = 3.242185592651367 seconds\n",
      "\n",
      "Training with split 4\n",
      "epoch 0 loss = 2.266641\n",
      "epoch 1 loss = 2.282849\n",
      "epoch 2 loss = 2.272552\n",
      "epoch 3 loss = 2.057240\n",
      "epoch 4 loss = 2.128837\n",
      "epoch 5 loss = 2.136901\n",
      "epoch 6 loss = 2.001621\n",
      "epoch 7 loss = 2.068929\n",
      "epoch 8 loss = 2.226093\n",
      "epoch 9 loss = 2.035430\n",
      "epoch 10 loss = 1.989590\n",
      "epoch 11 loss = 2.224440\n",
      "epoch 12 loss = 2.084977\n",
      "epoch 13 loss = 1.940304\n",
      "epoch 14 loss = 2.157677\n",
      "epoch 15 loss = 2.094401\n",
      "epoch 16 loss = 1.978057\n",
      "epoch 17 loss = 2.055997\n",
      "epoch 18 loss = 2.033674\n",
      "epoch 19 loss = 2.132847\n",
      "epoch 20 loss = 2.092136\n",
      "epoch 21 loss = 2.013275\n",
      "epoch 22 loss = 2.154636\n",
      "epoch 23 loss = 1.959185\n",
      "epoch 24 loss = 2.177401\n",
      "epoch 25 loss = 1.985020\n",
      "epoch 26 loss = 2.186290\n",
      "epoch 27 loss = 2.175581\n",
      "epoch 28 loss = 2.088338\n",
      "epoch 29 loss = 2.166703\n",
      "epoch 30 loss = 2.125196\n",
      "epoch 31 loss = 2.078750\n",
      "epoch 32 loss = 2.143733\n",
      "epoch 33 loss = 2.021310\n",
      "epoch 34 loss = 2.036393\n",
      "epoch 35 loss = 2.027511\n",
      "epoch 36 loss = 2.216029\n",
      "epoch 37 loss = 2.204341\n",
      "epoch 38 loss = 1.927140\n",
      "epoch 39 loss = 2.195256\n",
      "epoch 40 loss = 2.210121\n",
      "epoch 41 loss = 2.075647\n",
      "epoch 42 loss = 1.817960\n",
      "epoch 43 loss = 2.080446\n",
      "epoch 44 loss = 2.157854\n",
      "epoch 45 loss = 2.086227\n",
      "epoch 46 loss = 2.063645\n",
      "epoch 47 loss = 2.049128\n",
      "epoch 48 loss = 2.126946\n",
      "epoch 49 loss = 2.142761\n",
      "epoch 50 loss = 1.993696\n",
      "epoch 51 loss = 2.037301\n",
      "epoch 52 loss = 2.032026\n",
      "epoch 53 loss = 2.065719\n",
      "epoch 54 loss = 1.844440\n",
      "epoch 55 loss = 2.062224\n",
      "epoch 56 loss = 2.227938\n",
      "epoch 57 loss = 2.193880\n",
      "epoch 58 loss = 2.190965\n",
      "epoch 59 loss = 2.102603\n",
      "epoch 60 loss = 2.086935\n",
      "epoch 61 loss = 2.024193\n",
      "epoch 62 loss = 1.926046\n",
      "epoch 63 loss = 1.853645\n",
      "epoch 64 loss = 1.961001\n",
      "epoch 65 loss = 1.916257\n",
      "epoch 66 loss = 2.085176\n",
      "epoch 67 loss = 2.048391\n",
      "epoch 68 loss = 2.023888\n",
      "epoch 69 loss = 2.078690\n",
      "epoch 70 loss = 1.963071\n",
      "epoch 71 loss = 1.967900\n",
      "epoch 72 loss = 2.116294\n",
      "epoch 73 loss = 2.095805\n",
      "epoch 74 loss = 2.087449\n",
      "epoch 75 loss = 1.922378\n",
      "epoch 76 loss = 2.063428\n",
      "epoch 77 loss = 2.153932\n",
      "epoch 78 loss = 2.002258\n",
      "epoch 79 loss = 2.123609\n",
      "epoch 80 loss = 2.000361\n",
      "epoch 81 loss = 2.126328\n",
      "epoch 82 loss = 2.013419\n",
      "epoch 83 loss = 2.087063\n",
      "epoch 84 loss = 2.085426\n",
      "epoch 85 loss = 2.126129\n",
      "epoch 86 loss = 2.059385\n",
      "epoch 87 loss = 1.897410\n",
      "epoch 88 loss = 1.917024\n",
      "epoch 89 loss = 2.003993\n",
      "epoch 90 loss = 2.042382\n",
      "epoch 91 loss = 2.047679\n",
      "epoch 92 loss = 2.078439\n",
      "epoch 93 loss = 2.241050\n",
      "epoch 94 loss = 2.108490\n",
      "epoch 95 loss = 2.201654\n",
      "epoch 96 loss = 2.057298\n",
      "epoch 97 loss = 2.045924\n",
      "epoch 98 loss = 2.027238\n",
      "epoch 99 loss = 1.983607\n",
      "final loss = 1.983607\n",
      "accuracy_mc = tensor(0.3092, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.3137, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.9800, device='cuda:0')\n",
      "training time = 61.40557026863098 seconds\n",
      "testing time = 3.195446014404297 seconds\n",
      "\n",
      "Training with split 5\n",
      "epoch 0 loss = 2.302969\n",
      "epoch 1 loss = 2.296962\n",
      "epoch 2 loss = 2.271666\n",
      "epoch 3 loss = 2.336143\n",
      "epoch 4 loss = 2.151609\n",
      "epoch 5 loss = 2.336662\n",
      "epoch 6 loss = 2.201482\n",
      "epoch 7 loss = 2.200166\n",
      "epoch 8 loss = 2.304923\n",
      "epoch 9 loss = 2.304420\n",
      "epoch 10 loss = 2.328526\n",
      "epoch 11 loss = 2.141523\n",
      "epoch 12 loss = 2.282401\n",
      "epoch 13 loss = 2.281568\n",
      "epoch 14 loss = 2.353127\n",
      "epoch 15 loss = 2.264322\n",
      "epoch 16 loss = 2.295443\n",
      "epoch 17 loss = 2.240558\n",
      "epoch 18 loss = 2.251759\n",
      "epoch 19 loss = 2.213519\n",
      "epoch 20 loss = 2.196218\n",
      "epoch 21 loss = 2.219093\n",
      "epoch 22 loss = 2.186553\n",
      "epoch 23 loss = 2.244249\n",
      "epoch 24 loss = 2.248916\n",
      "epoch 25 loss = 2.286329\n",
      "epoch 26 loss = 2.050838\n",
      "epoch 27 loss = 2.162744\n",
      "epoch 28 loss = 2.140294\n",
      "epoch 29 loss = 2.164066\n",
      "epoch 30 loss = 2.160444\n",
      "epoch 31 loss = 2.115478\n",
      "epoch 32 loss = 2.180748\n",
      "epoch 33 loss = 2.272783\n",
      "epoch 34 loss = 2.265069\n",
      "epoch 35 loss = 2.100755\n",
      "epoch 36 loss = 2.299752\n",
      "epoch 37 loss = 1.974917\n",
      "epoch 38 loss = 2.279907\n",
      "epoch 39 loss = 2.052775\n",
      "epoch 40 loss = 2.175912\n",
      "epoch 41 loss = 2.295015\n",
      "epoch 42 loss = 2.207595\n",
      "epoch 43 loss = 2.143783\n",
      "epoch 44 loss = 2.200484\n",
      "epoch 45 loss = 2.224512\n",
      "epoch 46 loss = 2.231126\n",
      "epoch 47 loss = 2.261538\n",
      "epoch 48 loss = 2.151052\n",
      "epoch 49 loss = 2.246236\n",
      "epoch 50 loss = 2.039863\n",
      "epoch 51 loss = 2.126923\n",
      "epoch 52 loss = 2.044715\n",
      "epoch 53 loss = 2.183529\n",
      "epoch 54 loss = 2.281103\n",
      "epoch 55 loss = 2.167190\n",
      "epoch 56 loss = 2.148470\n",
      "epoch 57 loss = 2.056340\n",
      "epoch 58 loss = 2.090614\n",
      "epoch 59 loss = 2.090280\n",
      "epoch 60 loss = 2.145111\n",
      "epoch 61 loss = 2.263255\n",
      "epoch 62 loss = 2.204741\n",
      "epoch 63 loss = 2.044753\n",
      "epoch 64 loss = 2.155127\n",
      "epoch 65 loss = 2.128772\n",
      "epoch 66 loss = 2.045271\n",
      "epoch 67 loss = 2.083617\n",
      "epoch 68 loss = 2.047072\n",
      "epoch 69 loss = 2.228814\n",
      "epoch 70 loss = 2.130188\n",
      "epoch 71 loss = 2.070758\n",
      "epoch 72 loss = 2.280693\n",
      "epoch 73 loss = 2.334602\n",
      "epoch 74 loss = 2.089059\n",
      "epoch 75 loss = 1.949571\n",
      "epoch 76 loss = 2.144082\n",
      "epoch 77 loss = 2.263887\n",
      "epoch 78 loss = 2.023060\n",
      "epoch 79 loss = 2.047473\n",
      "epoch 80 loss = 2.274084\n",
      "epoch 81 loss = 2.123295\n",
      "epoch 82 loss = 2.353857\n",
      "epoch 83 loss = 2.020283\n",
      "epoch 84 loss = 2.071260\n",
      "epoch 85 loss = 2.210442\n",
      "epoch 86 loss = 2.029187\n",
      "epoch 87 loss = 2.025474\n",
      "epoch 88 loss = 2.261059\n",
      "epoch 89 loss = 2.234032\n",
      "epoch 90 loss = 2.028733\n",
      "epoch 91 loss = 2.072438\n",
      "epoch 92 loss = 2.166884\n",
      "epoch 93 loss = 2.374441\n",
      "epoch 94 loss = 2.041981\n",
      "epoch 95 loss = 2.244165\n",
      "epoch 96 loss = 2.110249\n",
      "epoch 97 loss = 2.121849\n",
      "epoch 98 loss = 2.191869\n",
      "epoch 99 loss = 2.164375\n",
      "final loss = 2.164375\n",
      "accuracy_mc = tensor(0.2755, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2326, device='cuda:0')\n",
      "test_ll_mc = tensor(-2.0229, device='cuda:0')\n",
      "training time = 61.280401945114136 seconds\n",
      "testing time = 3.2758374214172363 seconds\n",
      "\n",
      "Training with split 6\n",
      "epoch 0 loss = 2.325766\n",
      "epoch 1 loss = 2.309238\n",
      "epoch 2 loss = 2.269561\n",
      "epoch 3 loss = 2.281095\n",
      "epoch 4 loss = 2.214402\n",
      "epoch 5 loss = 2.203237\n",
      "epoch 6 loss = 2.101881\n",
      "epoch 7 loss = 2.335330\n",
      "epoch 8 loss = 2.349286\n",
      "epoch 9 loss = 2.392706\n",
      "epoch 10 loss = 2.431408\n",
      "epoch 11 loss = 2.285912\n",
      "epoch 12 loss = 2.234406\n",
      "epoch 13 loss = 2.362543\n",
      "epoch 14 loss = 2.347919\n",
      "epoch 15 loss = 2.652009\n",
      "epoch 16 loss = 2.372396\n",
      "epoch 17 loss = 2.551874\n",
      "epoch 18 loss = 2.211845\n",
      "epoch 19 loss = 2.272275\n",
      "epoch 20 loss = 2.533080\n",
      "epoch 21 loss = 2.226167\n",
      "epoch 22 loss = 2.261316\n",
      "epoch 23 loss = 2.311460\n",
      "epoch 24 loss = 2.226930\n",
      "epoch 25 loss = 2.551439\n",
      "epoch 26 loss = 2.257298\n",
      "epoch 27 loss = 2.091765\n",
      "epoch 28 loss = 2.366246\n",
      "epoch 29 loss = 2.365252\n",
      "epoch 30 loss = 2.341951\n",
      "epoch 31 loss = 2.116176\n",
      "epoch 32 loss = 2.407562\n",
      "epoch 33 loss = 2.364261\n",
      "epoch 34 loss = 2.385890\n",
      "epoch 35 loss = 2.220458\n",
      "epoch 36 loss = 2.345106\n",
      "epoch 37 loss = 2.256236\n",
      "epoch 38 loss = 2.220171\n",
      "epoch 39 loss = 2.287559\n",
      "epoch 40 loss = 2.344645\n",
      "epoch 41 loss = 2.243469\n",
      "epoch 42 loss = 2.429874\n",
      "epoch 43 loss = 2.030304\n",
      "epoch 44 loss = 2.411822\n",
      "epoch 45 loss = 2.195838\n",
      "epoch 46 loss = 2.471889\n",
      "epoch 47 loss = 2.385704\n",
      "epoch 48 loss = 2.275216\n",
      "epoch 49 loss = 2.306618\n",
      "epoch 50 loss = 2.376445\n",
      "epoch 51 loss = 2.193951\n",
      "epoch 52 loss = 2.257877\n",
      "epoch 53 loss = 2.410263\n",
      "epoch 54 loss = 2.352164\n",
      "epoch 55 loss = 2.041346\n",
      "epoch 56 loss = 2.505171\n",
      "epoch 57 loss = 2.347976\n",
      "epoch 58 loss = 2.226542\n",
      "epoch 59 loss = 2.150648\n",
      "epoch 60 loss = 2.315600\n",
      "epoch 61 loss = 2.220705\n",
      "epoch 62 loss = 2.326793\n",
      "epoch 63 loss = 2.426591\n",
      "epoch 64 loss = 2.196084\n",
      "epoch 65 loss = 2.250404\n",
      "epoch 66 loss = 2.392802\n",
      "epoch 67 loss = 2.381207\n",
      "epoch 68 loss = 2.428015\n",
      "epoch 69 loss = 2.133389\n",
      "epoch 70 loss = 2.327844\n",
      "epoch 71 loss = 2.195193\n",
      "epoch 72 loss = 2.215618\n",
      "epoch 73 loss = 2.058949\n",
      "epoch 74 loss = 2.513173\n",
      "epoch 75 loss = 2.483581\n",
      "epoch 76 loss = 2.293220\n",
      "epoch 77 loss = 2.495883\n",
      "epoch 78 loss = 2.270050\n",
      "epoch 79 loss = 2.155573\n",
      "epoch 80 loss = 2.238514\n",
      "epoch 81 loss = 2.229385\n",
      "epoch 82 loss = 2.324108\n",
      "epoch 83 loss = 2.405226\n",
      "epoch 84 loss = 2.175147\n",
      "epoch 85 loss = 2.093431\n",
      "epoch 86 loss = 2.331652\n",
      "epoch 87 loss = 2.324661\n",
      "epoch 88 loss = 2.244907\n",
      "epoch 89 loss = 2.215869\n",
      "epoch 90 loss = 2.225916\n",
      "epoch 91 loss = 2.181387\n",
      "epoch 92 loss = 2.206837\n",
      "epoch 93 loss = 2.271423\n",
      "epoch 94 loss = 2.313991\n",
      "epoch 95 loss = 2.384865\n",
      "epoch 96 loss = 2.348851\n",
      "epoch 97 loss = 2.069678\n",
      "epoch 98 loss = 2.399124\n",
      "epoch 99 loss = 2.188052\n",
      "final loss = 2.188052\n",
      "accuracy_mc = tensor(0.2494, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2509, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.9858, device='cuda:0')\n",
      "training time = 60.996349573135376 seconds\n",
      "testing time = 3.165806531906128 seconds\n",
      "\n",
      "Training with split 7\n",
      "epoch 0 loss = 2.215577\n",
      "epoch 1 loss = 2.214985\n",
      "epoch 2 loss = 2.201742\n",
      "epoch 3 loss = 2.231071\n",
      "epoch 4 loss = 2.169327\n",
      "epoch 5 loss = 2.040761\n",
      "epoch 6 loss = 2.092295\n",
      "epoch 7 loss = 1.994397\n",
      "epoch 8 loss = 2.109261\n",
      "epoch 9 loss = 2.017932\n",
      "epoch 10 loss = 2.068230\n",
      "epoch 11 loss = 2.155291\n",
      "epoch 12 loss = 2.234306\n",
      "epoch 13 loss = 2.157330\n",
      "epoch 14 loss = 2.052254\n",
      "epoch 15 loss = 2.080444\n",
      "epoch 16 loss = 2.237130\n",
      "epoch 17 loss = 2.128605\n",
      "epoch 18 loss = 2.130704\n",
      "epoch 19 loss = 2.106261\n",
      "epoch 20 loss = 2.150491\n",
      "epoch 21 loss = 2.061869\n",
      "epoch 22 loss = 2.101571\n",
      "epoch 23 loss = 2.091456\n",
      "epoch 24 loss = 2.133511\n",
      "epoch 25 loss = 2.183380\n",
      "epoch 26 loss = 2.175578\n",
      "epoch 27 loss = 2.251192\n",
      "epoch 28 loss = 2.118007\n",
      "epoch 29 loss = 2.205608\n",
      "epoch 30 loss = 2.224407\n",
      "epoch 31 loss = 2.123583\n",
      "epoch 32 loss = 2.124972\n",
      "epoch 33 loss = 2.223153\n",
      "epoch 34 loss = 2.113678\n",
      "epoch 35 loss = 2.174489\n",
      "epoch 36 loss = 2.216099\n",
      "epoch 37 loss = 2.114478\n",
      "epoch 38 loss = 2.109809\n",
      "epoch 39 loss = 2.047271\n",
      "epoch 40 loss = 2.123498\n",
      "epoch 41 loss = 2.056463\n",
      "epoch 42 loss = 2.063657\n",
      "epoch 43 loss = 2.074636\n",
      "epoch 44 loss = 2.159061\n",
      "epoch 45 loss = 2.151282\n",
      "epoch 46 loss = 2.188350\n",
      "epoch 47 loss = 2.132449\n",
      "epoch 48 loss = 2.061335\n",
      "epoch 49 loss = 2.181339\n",
      "epoch 50 loss = 1.916072\n",
      "epoch 51 loss = 2.025522\n",
      "epoch 52 loss = 2.009195\n",
      "epoch 53 loss = 2.053456\n",
      "epoch 54 loss = 2.120065\n",
      "epoch 55 loss = 2.081034\n",
      "epoch 56 loss = 2.023106\n",
      "epoch 57 loss = 2.026128\n",
      "epoch 58 loss = 2.098472\n",
      "epoch 59 loss = 2.126620\n",
      "epoch 60 loss = 2.337851\n",
      "epoch 61 loss = 2.083181\n",
      "epoch 62 loss = 2.173974\n",
      "epoch 63 loss = 1.874646\n",
      "epoch 64 loss = 2.232753\n",
      "epoch 65 loss = 2.217085\n",
      "epoch 66 loss = 2.100391\n",
      "epoch 67 loss = 2.151053\n",
      "epoch 68 loss = 2.183707\n",
      "epoch 69 loss = 2.146047\n",
      "epoch 70 loss = 2.084059\n",
      "epoch 71 loss = 2.061203\n",
      "epoch 72 loss = 2.159825\n",
      "epoch 73 loss = 2.057769\n",
      "epoch 74 loss = 2.088313\n",
      "epoch 75 loss = 1.980254\n",
      "epoch 76 loss = 2.082332\n",
      "epoch 77 loss = 2.151538\n",
      "epoch 78 loss = 2.116412\n",
      "epoch 79 loss = 2.135499\n",
      "epoch 80 loss = 2.094135\n",
      "epoch 81 loss = 1.998274\n",
      "epoch 82 loss = 1.992294\n",
      "epoch 83 loss = 2.140084\n",
      "epoch 84 loss = 2.058375\n",
      "epoch 85 loss = 2.021883\n",
      "epoch 86 loss = 1.917361\n",
      "epoch 87 loss = 2.215511\n",
      "epoch 88 loss = 2.016020\n",
      "epoch 89 loss = 2.160108\n",
      "epoch 90 loss = 2.120890\n",
      "epoch 91 loss = 2.136825\n",
      "epoch 92 loss = 2.004354\n",
      "epoch 93 loss = 1.977892\n",
      "epoch 94 loss = 2.201758\n",
      "epoch 95 loss = 2.149761\n",
      "epoch 96 loss = 1.941167\n",
      "epoch 97 loss = 2.265412\n",
      "epoch 98 loss = 2.036794\n",
      "epoch 99 loss = 2.090076\n",
      "final loss = 2.090076\n",
      "accuracy_mc = tensor(0.2724, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2389, device='cuda:0')\n",
      "test_ll_mc = tensor(-2.0332, device='cuda:0')\n",
      "training time = 60.70056104660034 seconds\n",
      "testing time = 3.1451969146728516 seconds\n",
      "\n",
      "Training with split 8\n",
      "epoch 0 loss = 2.306731\n",
      "epoch 1 loss = 2.272666\n",
      "epoch 2 loss = 2.143917\n",
      "epoch 3 loss = 2.293417\n",
      "epoch 4 loss = 2.303511\n",
      "epoch 5 loss = 2.180687\n",
      "epoch 6 loss = 2.181636\n",
      "epoch 7 loss = 2.187791\n",
      "epoch 8 loss = 2.079060\n",
      "epoch 9 loss = 2.130610\n",
      "epoch 10 loss = 2.120764\n",
      "epoch 11 loss = 2.160589\n",
      "epoch 12 loss = 2.189678\n",
      "epoch 13 loss = 2.084904\n",
      "epoch 14 loss = 2.026904\n",
      "epoch 15 loss = 2.186604\n",
      "epoch 16 loss = 2.198868\n",
      "epoch 17 loss = 2.151893\n",
      "epoch 18 loss = 2.043617\n",
      "epoch 19 loss = 2.126412\n",
      "epoch 20 loss = 1.972062\n",
      "epoch 21 loss = 2.031277\n",
      "epoch 22 loss = 1.995818\n",
      "epoch 23 loss = 2.132620\n",
      "epoch 24 loss = 2.058948\n",
      "epoch 25 loss = 2.173856\n",
      "epoch 26 loss = 2.173197\n",
      "epoch 27 loss = 2.304267\n",
      "epoch 28 loss = 2.192733\n",
      "epoch 29 loss = 2.225527\n",
      "epoch 30 loss = 2.102406\n",
      "epoch 31 loss = 2.138398\n",
      "epoch 32 loss = 2.162405\n",
      "epoch 33 loss = 2.056912\n",
      "epoch 34 loss = 2.076336\n",
      "epoch 35 loss = 2.047129\n",
      "epoch 36 loss = 2.340232\n",
      "epoch 37 loss = 2.153010\n",
      "epoch 38 loss = 2.117292\n",
      "epoch 39 loss = 2.101992\n",
      "epoch 40 loss = 2.018840\n",
      "epoch 41 loss = 2.205592\n",
      "epoch 42 loss = 2.189014\n",
      "epoch 43 loss = 2.116759\n",
      "epoch 44 loss = 2.081992\n",
      "epoch 45 loss = 2.185387\n",
      "epoch 46 loss = 1.902408\n",
      "epoch 47 loss = 2.004755\n",
      "epoch 48 loss = 1.873527\n",
      "epoch 49 loss = 2.059889\n",
      "epoch 50 loss = 2.033955\n",
      "epoch 51 loss = 2.101094\n",
      "epoch 52 loss = 2.073686\n",
      "epoch 53 loss = 2.227387\n",
      "epoch 54 loss = 2.009738\n",
      "epoch 55 loss = 2.267463\n",
      "epoch 56 loss = 2.178996\n",
      "epoch 57 loss = 2.223743\n",
      "epoch 58 loss = 2.101378\n",
      "epoch 59 loss = 2.179641\n",
      "epoch 60 loss = 2.130145\n",
      "epoch 61 loss = 2.109410\n",
      "epoch 62 loss = 2.089427\n",
      "epoch 63 loss = 2.034674\n",
      "epoch 64 loss = 2.126646\n",
      "epoch 65 loss = 1.993118\n",
      "epoch 66 loss = 2.145041\n",
      "epoch 67 loss = 2.070587\n",
      "epoch 68 loss = 2.041113\n",
      "epoch 69 loss = 2.167093\n",
      "epoch 70 loss = 2.107729\n",
      "epoch 71 loss = 2.119177\n",
      "epoch 72 loss = 2.159490\n",
      "epoch 73 loss = 2.062076\n",
      "epoch 74 loss = 1.976350\n",
      "epoch 75 loss = 1.965454\n",
      "epoch 76 loss = 2.122261\n",
      "epoch 77 loss = 2.042416\n",
      "epoch 78 loss = 2.075359\n",
      "epoch 79 loss = 2.036431\n",
      "epoch 80 loss = 2.095883\n",
      "epoch 81 loss = 2.091450\n",
      "epoch 82 loss = 1.964719\n",
      "epoch 83 loss = 2.133035\n",
      "epoch 84 loss = 2.297413\n",
      "epoch 85 loss = 2.099683\n",
      "epoch 86 loss = 2.073457\n",
      "epoch 87 loss = 2.203718\n",
      "epoch 88 loss = 2.056033\n",
      "epoch 89 loss = 2.002298\n",
      "epoch 90 loss = 2.192521\n",
      "epoch 91 loss = 2.183895\n",
      "epoch 92 loss = 2.050462\n",
      "epoch 93 loss = 2.121964\n",
      "epoch 94 loss = 2.140132\n",
      "epoch 95 loss = 2.127598\n",
      "epoch 96 loss = 2.183453\n",
      "epoch 97 loss = 2.176765\n",
      "epoch 98 loss = 2.109631\n",
      "epoch 99 loss = 2.062004\n",
      "final loss = 2.062004\n",
      "accuracy_mc = tensor(0.2701, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2512, device='cuda:0')\n",
      "test_ll_mc = tensor(-2.0037, device='cuda:0')\n",
      "training time = 61.08422493934631 seconds\n",
      "testing time = 3.1619365215301514 seconds\n",
      "\n",
      "Training with split 9\n",
      "epoch 0 loss = 2.279968\n",
      "epoch 1 loss = 2.319584\n",
      "epoch 2 loss = 2.245954\n",
      "epoch 3 loss = 2.275331\n",
      "epoch 4 loss = 2.252223\n",
      "epoch 5 loss = 2.138349\n",
      "epoch 6 loss = 2.237396\n",
      "epoch 7 loss = 2.142975\n",
      "epoch 8 loss = 2.159343\n",
      "epoch 9 loss = 2.166954\n",
      "epoch 10 loss = 2.175637\n",
      "epoch 11 loss = 2.278534\n",
      "epoch 12 loss = 2.202576\n",
      "epoch 13 loss = 2.310817\n",
      "epoch 14 loss = 2.030303\n",
      "epoch 15 loss = 2.074818\n",
      "epoch 16 loss = 2.222892\n",
      "epoch 17 loss = 2.146445\n",
      "epoch 18 loss = 2.105954\n",
      "epoch 19 loss = 2.164044\n",
      "epoch 20 loss = 2.134698\n",
      "epoch 21 loss = 2.007800\n",
      "epoch 22 loss = 2.195700\n",
      "epoch 23 loss = 2.169302\n",
      "epoch 24 loss = 2.115546\n",
      "epoch 25 loss = 2.281382\n",
      "epoch 26 loss = 2.122780\n",
      "epoch 27 loss = 2.012846\n",
      "epoch 28 loss = 2.091419\n",
      "epoch 29 loss = 2.204838\n",
      "epoch 30 loss = 2.015441\n",
      "epoch 31 loss = 2.074461\n",
      "epoch 32 loss = 2.171016\n",
      "epoch 33 loss = 2.044421\n",
      "epoch 34 loss = 2.089711\n",
      "epoch 35 loss = 2.079161\n",
      "epoch 36 loss = 2.207710\n",
      "epoch 37 loss = 2.099592\n",
      "epoch 38 loss = 2.117686\n",
      "epoch 39 loss = 2.221439\n",
      "epoch 40 loss = 2.124386\n",
      "epoch 41 loss = 2.071403\n",
      "epoch 42 loss = 2.086786\n",
      "epoch 43 loss = 2.121512\n",
      "epoch 44 loss = 2.088977\n",
      "epoch 45 loss = 1.931921\n",
      "epoch 46 loss = 1.985359\n",
      "epoch 47 loss = 2.020593\n",
      "epoch 48 loss = 2.160785\n",
      "epoch 49 loss = 1.847416\n",
      "epoch 50 loss = 2.205954\n",
      "epoch 51 loss = 2.127762\n",
      "epoch 52 loss = 2.153976\n",
      "epoch 53 loss = 2.044226\n",
      "epoch 54 loss = 2.224052\n",
      "epoch 55 loss = 2.225992\n",
      "epoch 56 loss = 1.990342\n",
      "epoch 57 loss = 2.033707\n",
      "epoch 58 loss = 2.035276\n",
      "epoch 59 loss = 2.251935\n",
      "epoch 60 loss = 2.027655\n",
      "epoch 61 loss = 2.200350\n",
      "epoch 62 loss = 2.031753\n",
      "epoch 63 loss = 1.890225\n",
      "epoch 64 loss = 1.896750\n",
      "epoch 65 loss = 2.085679\n",
      "epoch 66 loss = 2.044122\n",
      "epoch 67 loss = 2.157994\n",
      "epoch 68 loss = 2.167412\n",
      "epoch 69 loss = 1.982181\n",
      "epoch 70 loss = 2.111624\n",
      "epoch 71 loss = 2.067022\n",
      "epoch 72 loss = 2.052226\n",
      "epoch 73 loss = 2.115055\n",
      "epoch 74 loss = 1.978073\n",
      "epoch 75 loss = 2.162071\n",
      "epoch 76 loss = 2.128019\n",
      "epoch 77 loss = 1.924141\n",
      "epoch 78 loss = 2.103755\n",
      "epoch 79 loss = 2.185541\n",
      "epoch 80 loss = 2.162305\n",
      "epoch 81 loss = 2.167732\n",
      "epoch 82 loss = 2.096306\n",
      "epoch 83 loss = 2.262916\n",
      "epoch 84 loss = 2.168490\n",
      "epoch 85 loss = 2.209431\n",
      "epoch 86 loss = 2.054787\n",
      "epoch 87 loss = 2.007066\n",
      "epoch 88 loss = 2.164767\n",
      "epoch 89 loss = 1.904531\n",
      "epoch 90 loss = 1.965850\n",
      "epoch 91 loss = 2.204937\n",
      "epoch 92 loss = 2.227618\n",
      "epoch 93 loss = 2.037320\n",
      "epoch 94 loss = 2.131870\n",
      "epoch 95 loss = 2.118447\n",
      "epoch 96 loss = 2.154062\n",
      "epoch 97 loss = 1.881705\n",
      "epoch 98 loss = 2.089295\n",
      "epoch 99 loss = 2.148609\n",
      "final loss = 2.148609\n",
      "accuracy_mc = tensor(0.1863, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2045, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.9737, device='cuda:0')\n",
      "training time = 60.990599155426025 seconds\n",
      "testing time = 3.2124688625335693 seconds\n",
      "\n",
      "subset 0.050000, dropout_rate 0.500000, reg_strength 0.050000\n",
      "n_epoch 500\n",
      "\n",
      "Files already downloaded and verified\n",
      "subset size = (2500, 32, 32, 3)\n",
      "training set size = 2000\n",
      "test set size = 500\n",
      "\n",
      "Training with split 0\n",
      "epoch 0 loss = 2.291659\n",
      "epoch 1 loss = 2.316656\n",
      "epoch 2 loss = 2.256858\n",
      "epoch 3 loss = 2.167309\n",
      "epoch 4 loss = 2.213149\n",
      "epoch 5 loss = 2.210883\n",
      "epoch 6 loss = 2.276708\n",
      "epoch 7 loss = 2.190082\n",
      "epoch 8 loss = 2.149594\n",
      "epoch 9 loss = 2.238701\n",
      "epoch 10 loss = 2.285510\n",
      "epoch 11 loss = 2.254820\n",
      "epoch 12 loss = 2.156374\n",
      "epoch 13 loss = 2.199789\n",
      "epoch 14 loss = 2.229370\n",
      "epoch 15 loss = 2.195518\n",
      "epoch 16 loss = 2.150615\n",
      "epoch 17 loss = 2.364619\n",
      "epoch 18 loss = 2.118140\n",
      "epoch 19 loss = 2.212104\n",
      "epoch 20 loss = 2.178346\n",
      "epoch 21 loss = 2.317971\n",
      "epoch 22 loss = 2.264026\n",
      "epoch 23 loss = 2.314037\n",
      "epoch 24 loss = 2.118915\n",
      "epoch 25 loss = 2.058170\n",
      "epoch 26 loss = 2.214881\n",
      "epoch 27 loss = 2.221652\n",
      "epoch 28 loss = 2.264815\n",
      "epoch 29 loss = 2.280925\n",
      "epoch 30 loss = 2.085201\n",
      "epoch 31 loss = 2.247747\n",
      "epoch 32 loss = 2.244069\n",
      "epoch 33 loss = 2.291080\n",
      "epoch 34 loss = 2.103135\n",
      "epoch 35 loss = 2.039319\n",
      "epoch 36 loss = 2.198138\n",
      "epoch 37 loss = 2.195180\n",
      "epoch 38 loss = 2.254338\n",
      "epoch 39 loss = 2.362896\n",
      "epoch 40 loss = 1.964571\n",
      "epoch 41 loss = 2.079906\n",
      "epoch 42 loss = 2.195003\n",
      "epoch 43 loss = 2.130936\n",
      "epoch 44 loss = 2.055662\n",
      "epoch 45 loss = 2.320716\n",
      "epoch 46 loss = 2.163496\n",
      "epoch 47 loss = 2.238806\n",
      "epoch 48 loss = 2.118942\n",
      "epoch 49 loss = 2.031589\n",
      "epoch 50 loss = 2.166421\n",
      "epoch 51 loss = 2.248989\n",
      "epoch 52 loss = 2.208549\n",
      "epoch 53 loss = 2.161575\n",
      "epoch 54 loss = 2.257508\n",
      "epoch 55 loss = 2.253326\n",
      "epoch 56 loss = 2.217466\n",
      "epoch 57 loss = 2.281900\n",
      "epoch 58 loss = 2.285874\n",
      "epoch 59 loss = 2.123021\n",
      "epoch 60 loss = 2.108399\n",
      "epoch 61 loss = 2.152213\n",
      "epoch 62 loss = 2.141537\n",
      "epoch 63 loss = 1.970191\n",
      "epoch 64 loss = 2.273695\n",
      "epoch 65 loss = 2.068449\n",
      "epoch 66 loss = 2.130084\n",
      "epoch 67 loss = 2.166844\n",
      "epoch 68 loss = 2.224133\n",
      "epoch 69 loss = 2.216871\n",
      "epoch 70 loss = 2.342690\n",
      "epoch 71 loss = 2.252024\n",
      "epoch 72 loss = 2.115728\n",
      "epoch 73 loss = 2.138909\n",
      "epoch 74 loss = 2.322306\n",
      "epoch 75 loss = 2.050609\n",
      "epoch 76 loss = 2.132475\n",
      "epoch 77 loss = 2.040927\n",
      "epoch 78 loss = 2.135790\n",
      "epoch 79 loss = 2.167972\n",
      "epoch 80 loss = 2.087491\n",
      "epoch 81 loss = 2.112874\n",
      "epoch 82 loss = 2.123729\n",
      "epoch 83 loss = 2.079742\n",
      "epoch 84 loss = 2.192425\n",
      "epoch 85 loss = 2.092969\n",
      "epoch 86 loss = 2.078479\n",
      "epoch 87 loss = 2.263987\n",
      "epoch 88 loss = 2.136563\n",
      "epoch 89 loss = 2.145818\n",
      "epoch 90 loss = 2.068383\n",
      "epoch 91 loss = 2.344361\n",
      "epoch 92 loss = 2.126580\n",
      "epoch 93 loss = 2.041182\n",
      "epoch 94 loss = 2.404729\n",
      "epoch 95 loss = 2.103551\n",
      "epoch 96 loss = 2.213894\n",
      "epoch 97 loss = 2.220629\n",
      "epoch 98 loss = 2.222410\n",
      "epoch 99 loss = 2.200088\n",
      "epoch 100 loss = 2.146605\n",
      "epoch 101 loss = 2.078313\n",
      "epoch 102 loss = 2.090299\n",
      "epoch 103 loss = 2.124167\n",
      "epoch 104 loss = 2.172478\n",
      "epoch 105 loss = 2.186820\n",
      "epoch 106 loss = 2.168667\n",
      "epoch 107 loss = 2.141588\n",
      "epoch 108 loss = 2.185056\n",
      "epoch 109 loss = 2.154912\n",
      "epoch 110 loss = 2.273412\n",
      "epoch 111 loss = 2.116849\n",
      "epoch 112 loss = 2.244233\n",
      "epoch 113 loss = 2.124365\n",
      "epoch 114 loss = 2.078256\n",
      "epoch 115 loss = 1.966494\n",
      "epoch 116 loss = 2.038446\n",
      "epoch 117 loss = 2.244913\n",
      "epoch 118 loss = 2.230758\n",
      "epoch 119 loss = 2.247439\n",
      "epoch 120 loss = 2.236544\n",
      "epoch 121 loss = 2.175836\n",
      "epoch 122 loss = 2.216610\n",
      "epoch 123 loss = 2.118295\n",
      "epoch 124 loss = 2.085987\n",
      "epoch 125 loss = 2.261924\n",
      "epoch 126 loss = 2.222322\n",
      "epoch 127 loss = 2.315660\n",
      "epoch 128 loss = 2.133577\n",
      "epoch 129 loss = 2.238142\n",
      "epoch 130 loss = 2.046284\n",
      "epoch 131 loss = 2.286400\n",
      "epoch 132 loss = 1.961754\n",
      "epoch 133 loss = 2.312207\n",
      "epoch 134 loss = 2.251695\n",
      "epoch 135 loss = 2.156957\n",
      "epoch 136 loss = 2.073071\n",
      "epoch 137 loss = 2.056151\n",
      "epoch 138 loss = 2.125950\n",
      "epoch 139 loss = 2.082201\n",
      "epoch 140 loss = 2.133916\n",
      "epoch 141 loss = 2.216094\n",
      "epoch 142 loss = 2.267918\n",
      "epoch 143 loss = 2.066513\n",
      "epoch 144 loss = 2.016095\n",
      "epoch 145 loss = 2.232714\n",
      "epoch 146 loss = 2.152183\n",
      "epoch 147 loss = 2.055053\n",
      "epoch 148 loss = 2.248006\n",
      "epoch 149 loss = 1.953305\n",
      "epoch 150 loss = 2.064039\n",
      "epoch 151 loss = 2.021456\n",
      "epoch 152 loss = 2.137778\n",
      "epoch 153 loss = 2.287187\n",
      "epoch 154 loss = 2.258422\n",
      "epoch 155 loss = 2.153553\n",
      "epoch 156 loss = 2.214350\n",
      "epoch 157 loss = 2.067723\n",
      "epoch 158 loss = 2.278985\n",
      "epoch 159 loss = 2.288388\n",
      "epoch 160 loss = 2.119158\n",
      "epoch 161 loss = 2.363488\n",
      "epoch 162 loss = 2.231803\n",
      "epoch 163 loss = 2.179676\n",
      "epoch 164 loss = 2.174931\n",
      "epoch 165 loss = 2.333927\n",
      "epoch 166 loss = 2.184962\n",
      "epoch 167 loss = 2.145825\n",
      "epoch 168 loss = 2.258049\n",
      "epoch 169 loss = 2.079864\n",
      "epoch 170 loss = 2.031210\n",
      "epoch 171 loss = 2.048351\n",
      "epoch 172 loss = 2.058533\n",
      "epoch 173 loss = 2.003374\n",
      "epoch 174 loss = 2.146544\n",
      "epoch 175 loss = 2.277125\n",
      "epoch 176 loss = 2.120674\n",
      "epoch 177 loss = 2.390084\n",
      "epoch 178 loss = 2.084187\n",
      "epoch 179 loss = 2.001595\n",
      "epoch 180 loss = 2.118325\n",
      "epoch 181 loss = 2.234381\n",
      "epoch 182 loss = 2.370363\n",
      "epoch 183 loss = 2.271744\n",
      "epoch 184 loss = 2.135988\n",
      "epoch 185 loss = 2.117145\n",
      "epoch 186 loss = 2.189461\n",
      "epoch 187 loss = 2.294255\n",
      "epoch 188 loss = 2.302545\n",
      "epoch 189 loss = 2.113313\n",
      "epoch 190 loss = 2.049086\n",
      "epoch 191 loss = 2.207407\n",
      "epoch 192 loss = 2.066994\n",
      "epoch 193 loss = 2.040387\n",
      "epoch 194 loss = 2.178343\n",
      "epoch 195 loss = 2.165979\n",
      "epoch 196 loss = 2.149670\n",
      "epoch 197 loss = 2.297700\n",
      "epoch 198 loss = 2.070151\n",
      "epoch 199 loss = 2.053253\n",
      "epoch 200 loss = 2.140065\n",
      "epoch 201 loss = 2.247388\n",
      "epoch 202 loss = 2.187071\n",
      "epoch 203 loss = 2.024540\n",
      "epoch 204 loss = 2.164285\n",
      "epoch 205 loss = 2.287615\n",
      "epoch 206 loss = 2.245493\n",
      "epoch 207 loss = 2.240554\n",
      "epoch 208 loss = 2.248454\n",
      "epoch 209 loss = 2.081036\n",
      "epoch 210 loss = 2.118582\n",
      "epoch 211 loss = 2.094004\n",
      "epoch 212 loss = 2.210973\n",
      "epoch 213 loss = 2.456781\n",
      "epoch 214 loss = 2.130303\n",
      "epoch 215 loss = 2.005212\n",
      "epoch 216 loss = 2.062463\n",
      "epoch 217 loss = 2.173707\n",
      "epoch 218 loss = 2.226007\n",
      "epoch 219 loss = 2.206203\n",
      "epoch 220 loss = 2.201697\n",
      "epoch 221 loss = 2.115780\n",
      "epoch 222 loss = 2.185979\n",
      "epoch 223 loss = 2.413539\n",
      "epoch 224 loss = 2.150201\n",
      "epoch 225 loss = 2.037469\n",
      "epoch 226 loss = 2.045206\n",
      "epoch 227 loss = 2.215413\n",
      "epoch 228 loss = 2.180995\n",
      "epoch 229 loss = 2.207658\n",
      "epoch 230 loss = 2.127762\n",
      "epoch 231 loss = 2.123364\n",
      "epoch 232 loss = 2.218570\n",
      "epoch 233 loss = 2.100290\n",
      "epoch 234 loss = 2.182549\n",
      "epoch 235 loss = 2.262799\n",
      "epoch 236 loss = 2.071181\n",
      "epoch 237 loss = 2.142179\n",
      "epoch 238 loss = 2.080870\n",
      "epoch 239 loss = 2.099150\n",
      "epoch 240 loss = 2.150779\n",
      "epoch 241 loss = 2.042764\n",
      "epoch 242 loss = 2.046101\n",
      "epoch 243 loss = 2.310034\n",
      "epoch 244 loss = 2.165445\n",
      "epoch 245 loss = 2.206284\n",
      "epoch 246 loss = 2.077740\n",
      "epoch 247 loss = 2.007029\n",
      "epoch 248 loss = 1.942535\n",
      "epoch 249 loss = 2.101849\n",
      "epoch 250 loss = 2.243814\n",
      "epoch 251 loss = 2.054136\n",
      "epoch 252 loss = 2.268835\n",
      "epoch 253 loss = 2.050492\n",
      "epoch 254 loss = 2.231468\n",
      "epoch 255 loss = 1.864428\n",
      "epoch 256 loss = 2.172613\n",
      "epoch 257 loss = 2.212564\n",
      "epoch 258 loss = 2.186607\n",
      "epoch 259 loss = 2.082650\n",
      "epoch 260 loss = 2.078306\n",
      "epoch 261 loss = 2.093113\n",
      "epoch 262 loss = 2.397385\n",
      "epoch 263 loss = 2.201650\n",
      "epoch 264 loss = 2.208820\n",
      "epoch 265 loss = 2.218488\n",
      "epoch 266 loss = 2.176344\n",
      "epoch 267 loss = 2.213880\n",
      "epoch 268 loss = 2.053097\n",
      "epoch 269 loss = 2.395525\n",
      "epoch 270 loss = 2.259366\n",
      "epoch 271 loss = 2.128531\n",
      "epoch 272 loss = 2.150152\n",
      "epoch 273 loss = 2.221210\n",
      "epoch 274 loss = 2.046177\n",
      "epoch 275 loss = 2.206388\n",
      "epoch 276 loss = 2.186776\n",
      "epoch 277 loss = 2.293129\n",
      "epoch 278 loss = 2.051537\n",
      "epoch 279 loss = 2.239298\n",
      "epoch 280 loss = 2.190088\n",
      "epoch 281 loss = 2.141335\n",
      "epoch 282 loss = 1.979467\n",
      "epoch 283 loss = 1.983931\n",
      "epoch 284 loss = 2.270971\n",
      "epoch 285 loss = 2.230762\n",
      "epoch 286 loss = 2.219177\n",
      "epoch 287 loss = 2.124838\n",
      "epoch 288 loss = 2.249725\n",
      "epoch 289 loss = 2.136253\n",
      "epoch 290 loss = 2.094182\n",
      "epoch 291 loss = 2.165254\n",
      "epoch 292 loss = 1.969139\n",
      "epoch 293 loss = 2.177596\n",
      "epoch 294 loss = 1.973230\n",
      "epoch 295 loss = 2.091656\n",
      "epoch 296 loss = 2.151668\n",
      "epoch 297 loss = 2.106598\n",
      "epoch 298 loss = 2.147763\n",
      "epoch 299 loss = 2.056355\n",
      "epoch 300 loss = 2.212521\n",
      "epoch 301 loss = 2.173023\n",
      "epoch 302 loss = 2.336843\n",
      "epoch 303 loss = 1.976227\n",
      "epoch 304 loss = 2.175575\n",
      "epoch 305 loss = 2.267239\n",
      "epoch 306 loss = 1.939384\n",
      "epoch 307 loss = 2.186455\n",
      "epoch 308 loss = 2.270320\n",
      "epoch 309 loss = 2.157033\n",
      "epoch 310 loss = 2.123641\n",
      "epoch 311 loss = 2.157429\n",
      "epoch 312 loss = 2.246869\n",
      "epoch 313 loss = 1.988887\n",
      "epoch 314 loss = 2.130210\n",
      "epoch 315 loss = 2.081657\n",
      "epoch 316 loss = 2.215326\n",
      "epoch 317 loss = 2.165664\n",
      "epoch 318 loss = 2.194742\n",
      "epoch 319 loss = 2.199433\n",
      "epoch 320 loss = 2.103982\n",
      "epoch 321 loss = 2.232161\n",
      "epoch 322 loss = 2.245709\n",
      "epoch 323 loss = 2.093801\n",
      "epoch 324 loss = 2.097042\n",
      "epoch 325 loss = 1.966674\n",
      "epoch 326 loss = 2.150873\n",
      "epoch 327 loss = 2.034560\n",
      "epoch 328 loss = 2.165843\n",
      "epoch 329 loss = 2.229310\n",
      "epoch 330 loss = 2.331340\n",
      "epoch 331 loss = 2.040679\n",
      "epoch 332 loss = 1.921785\n",
      "epoch 333 loss = 1.957445\n",
      "epoch 334 loss = 2.050469\n",
      "epoch 335 loss = 2.007751\n",
      "epoch 336 loss = 2.205567\n",
      "epoch 337 loss = 2.282641\n",
      "epoch 338 loss = 2.212736\n",
      "epoch 339 loss = 2.273416\n",
      "epoch 340 loss = 2.086074\n",
      "epoch 341 loss = 2.210032\n",
      "epoch 342 loss = 2.199122\n",
      "epoch 343 loss = 1.986166\n",
      "epoch 344 loss = 2.149359\n",
      "epoch 345 loss = 2.165888\n",
      "epoch 346 loss = 2.244279\n",
      "epoch 347 loss = 2.253347\n",
      "epoch 348 loss = 2.071622\n",
      "epoch 349 loss = 2.269007\n",
      "epoch 350 loss = 1.977687\n",
      "epoch 351 loss = 2.273908\n",
      "epoch 352 loss = 2.059821\n",
      "epoch 353 loss = 2.157145\n",
      "epoch 354 loss = 2.136608\n",
      "epoch 355 loss = 2.043983\n",
      "epoch 356 loss = 2.155864\n",
      "epoch 357 loss = 2.254335\n",
      "epoch 358 loss = 2.195364\n",
      "epoch 359 loss = 2.107696\n",
      "epoch 360 loss = 2.151673\n",
      "epoch 361 loss = 2.175891\n",
      "epoch 362 loss = 2.055445\n",
      "epoch 363 loss = 2.149789\n",
      "epoch 364 loss = 2.148588\n",
      "epoch 365 loss = 2.214656\n",
      "epoch 366 loss = 2.094486\n",
      "epoch 367 loss = 2.047691\n",
      "epoch 368 loss = 2.206183\n",
      "epoch 369 loss = 2.234224\n",
      "epoch 370 loss = 2.159379\n",
      "epoch 371 loss = 2.106995\n",
      "epoch 372 loss = 2.113746\n",
      "epoch 373 loss = 2.159500\n",
      "epoch 374 loss = 2.098017\n",
      "epoch 375 loss = 2.068625\n",
      "epoch 376 loss = 2.113769\n",
      "epoch 377 loss = 2.186655\n",
      "epoch 378 loss = 2.200611\n",
      "epoch 379 loss = 2.066479\n",
      "epoch 380 loss = 2.118223\n",
      "epoch 381 loss = 2.195642\n",
      "epoch 382 loss = 2.213165\n",
      "epoch 383 loss = 2.083116\n",
      "epoch 384 loss = 2.092988\n",
      "epoch 385 loss = 2.192766\n",
      "epoch 386 loss = 2.200865\n",
      "epoch 387 loss = 2.076766\n",
      "epoch 388 loss = 2.350924\n",
      "epoch 389 loss = 2.101902\n",
      "epoch 390 loss = 2.083597\n",
      "epoch 391 loss = 2.073058\n",
      "epoch 392 loss = 2.109830\n",
      "epoch 393 loss = 2.108263\n",
      "epoch 394 loss = 2.237868\n",
      "epoch 395 loss = 1.974722\n",
      "epoch 396 loss = 2.091255\n",
      "epoch 397 loss = 2.301255\n",
      "epoch 398 loss = 2.139462\n",
      "epoch 399 loss = 2.144696\n",
      "epoch 400 loss = 1.925234\n",
      "epoch 401 loss = 2.066277\n",
      "epoch 402 loss = 2.238418\n",
      "epoch 403 loss = 2.271901\n",
      "epoch 404 loss = 2.292831\n",
      "epoch 405 loss = 2.224059\n",
      "epoch 406 loss = 2.120802\n",
      "epoch 407 loss = 2.206301\n",
      "epoch 408 loss = 2.135264\n",
      "epoch 409 loss = 2.012989\n",
      "epoch 410 loss = 2.290169\n",
      "epoch 411 loss = 2.159318\n",
      "epoch 412 loss = 2.061838\n",
      "epoch 413 loss = 2.025774\n",
      "epoch 414 loss = 2.135221\n",
      "epoch 415 loss = 2.090358\n",
      "epoch 416 loss = 2.075582\n",
      "epoch 417 loss = 2.246347\n",
      "epoch 418 loss = 2.240153\n",
      "epoch 419 loss = 2.174434\n",
      "epoch 420 loss = 2.155431\n",
      "epoch 421 loss = 2.156972\n",
      "epoch 422 loss = 2.257426\n",
      "epoch 423 loss = 2.128634\n",
      "epoch 424 loss = 2.073823\n",
      "epoch 425 loss = 2.074828\n",
      "epoch 426 loss = 2.239368\n",
      "epoch 427 loss = 1.889835\n",
      "epoch 428 loss = 2.206825\n",
      "epoch 429 loss = 2.180723\n",
      "epoch 430 loss = 2.251258\n",
      "epoch 431 loss = 2.074421\n",
      "epoch 432 loss = 2.158337\n",
      "epoch 433 loss = 2.023786\n",
      "epoch 434 loss = 2.125478\n",
      "epoch 435 loss = 2.069226\n",
      "epoch 436 loss = 2.273184\n",
      "epoch 437 loss = 2.135826\n",
      "epoch 438 loss = 2.025507\n",
      "epoch 439 loss = 2.148186\n",
      "epoch 440 loss = 2.107996\n",
      "epoch 441 loss = 2.044667\n",
      "epoch 442 loss = 2.068302\n",
      "epoch 443 loss = 2.050192\n",
      "epoch 444 loss = 2.177471\n",
      "epoch 445 loss = 1.965324\n",
      "epoch 446 loss = 2.088158\n",
      "epoch 447 loss = 1.997393\n",
      "epoch 448 loss = 2.262439\n",
      "epoch 449 loss = 2.107280\n",
      "epoch 450 loss = 2.184589\n",
      "epoch 451 loss = 2.160203\n",
      "epoch 452 loss = 2.041131\n",
      "epoch 453 loss = 2.172550\n",
      "epoch 454 loss = 2.184039\n",
      "epoch 455 loss = 2.126905\n",
      "epoch 456 loss = 2.113174\n",
      "epoch 457 loss = 2.119910\n",
      "epoch 458 loss = 2.141650\n",
      "epoch 459 loss = 2.106304\n",
      "epoch 460 loss = 2.208205\n",
      "epoch 461 loss = 2.164304\n",
      "epoch 462 loss = 2.256625\n",
      "epoch 463 loss = 2.230537\n",
      "epoch 464 loss = 2.138354\n",
      "epoch 465 loss = 2.066285\n",
      "epoch 466 loss = 2.199443\n",
      "epoch 467 loss = 2.157944\n",
      "epoch 468 loss = 1.907292\n",
      "epoch 469 loss = 1.962787\n",
      "epoch 470 loss = 1.977087\n",
      "epoch 471 loss = 1.980033\n",
      "epoch 472 loss = 2.122431\n",
      "epoch 473 loss = 2.101992\n",
      "epoch 474 loss = 2.109612\n",
      "epoch 475 loss = 2.078633\n",
      "epoch 476 loss = 2.197593\n",
      "epoch 477 loss = 2.178170\n",
      "epoch 478 loss = 2.073254\n",
      "epoch 479 loss = 2.011871\n",
      "epoch 480 loss = 2.135456\n",
      "epoch 481 loss = 2.027514\n",
      "epoch 482 loss = 2.111619\n",
      "epoch 483 loss = 2.172618\n",
      "epoch 484 loss = 1.985504\n",
      "epoch 485 loss = 2.098829\n",
      "epoch 486 loss = 2.268420\n",
      "epoch 487 loss = 2.062707\n",
      "epoch 488 loss = 1.964744\n",
      "epoch 489 loss = 2.199677\n",
      "epoch 490 loss = 2.133496\n",
      "epoch 491 loss = 2.070242\n",
      "epoch 492 loss = 2.084985\n",
      "epoch 493 loss = 2.123748\n",
      "epoch 494 loss = 2.135811\n",
      "epoch 495 loss = 2.068519\n",
      "epoch 496 loss = 2.129679\n",
      "epoch 497 loss = 2.221681\n",
      "epoch 498 loss = 2.156555\n",
      "epoch 499 loss = 2.088363\n",
      "final loss = 2.088363\n",
      "accuracy_mc = tensor(0.1928, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.1819, device='cuda:0')\n",
      "test_ll_mc = tensor(-2.0456, device='cuda:0')\n",
      "training time = 306.55732321739197 seconds\n",
      "testing time = 3.164510488510132 seconds\n",
      "\n",
      "Training with split 1\n",
      "epoch 0 loss = 2.288805\n",
      "epoch 1 loss = 2.309406\n",
      "epoch 2 loss = 2.267143\n",
      "epoch 3 loss = 2.263060\n",
      "epoch 4 loss = 2.276397\n",
      "epoch 5 loss = 2.265787\n",
      "epoch 6 loss = 2.007669\n",
      "epoch 7 loss = 2.275387\n",
      "epoch 8 loss = 2.376658\n",
      "epoch 9 loss = 2.192394\n",
      "epoch 10 loss = 2.220559\n",
      "epoch 11 loss = 2.082907\n",
      "epoch 12 loss = 2.261294\n",
      "epoch 13 loss = 2.134634\n",
      "epoch 14 loss = 2.285816\n",
      "epoch 15 loss = 2.203193\n",
      "epoch 16 loss = 2.124895\n",
      "epoch 17 loss = 2.131693\n",
      "epoch 18 loss = 2.018276\n",
      "epoch 19 loss = 2.339802\n",
      "epoch 20 loss = 2.212391\n",
      "epoch 21 loss = 2.119860\n",
      "epoch 22 loss = 2.011571\n",
      "epoch 23 loss = 2.276681\n",
      "epoch 24 loss = 2.389621\n",
      "epoch 25 loss = 2.100856\n",
      "epoch 26 loss = 1.946451\n",
      "epoch 27 loss = 2.047969\n",
      "epoch 28 loss = 1.999822\n",
      "epoch 29 loss = 2.266016\n",
      "epoch 30 loss = 2.267982\n",
      "epoch 31 loss = 2.211089\n",
      "epoch 32 loss = 1.945112\n",
      "epoch 33 loss = 2.206317\n",
      "epoch 34 loss = 2.142459\n",
      "epoch 35 loss = 1.966982\n",
      "epoch 36 loss = 1.976744\n",
      "epoch 37 loss = 2.308560\n",
      "epoch 38 loss = 2.073296\n",
      "epoch 39 loss = 2.172789\n",
      "epoch 40 loss = 2.057525\n",
      "epoch 41 loss = 2.147707\n",
      "epoch 42 loss = 1.943974\n",
      "epoch 43 loss = 1.942792\n",
      "epoch 44 loss = 1.967111\n",
      "epoch 45 loss = 2.138442\n",
      "epoch 46 loss = 2.260315\n",
      "epoch 47 loss = 2.242091\n",
      "epoch 48 loss = 2.052005\n",
      "epoch 49 loss = 2.167639\n",
      "epoch 50 loss = 2.115590\n",
      "epoch 51 loss = 2.112853\n",
      "epoch 52 loss = 1.916394\n",
      "epoch 53 loss = 1.956139\n",
      "epoch 54 loss = 2.081542\n",
      "epoch 55 loss = 1.928886\n",
      "epoch 56 loss = 2.215794\n",
      "epoch 57 loss = 2.163544\n",
      "epoch 58 loss = 2.017461\n",
      "epoch 59 loss = 1.956821\n",
      "epoch 60 loss = 1.870030\n",
      "epoch 61 loss = 2.216878\n",
      "epoch 62 loss = 2.031508\n",
      "epoch 63 loss = 2.045995\n",
      "epoch 64 loss = 2.026391\n",
      "epoch 65 loss = 2.235555\n",
      "epoch 66 loss = 2.117782\n",
      "epoch 67 loss = 2.057813\n",
      "epoch 68 loss = 2.013713\n",
      "epoch 69 loss = 2.096526\n",
      "epoch 70 loss = 1.924943\n",
      "epoch 71 loss = 2.149474\n",
      "epoch 72 loss = 2.098064\n",
      "epoch 73 loss = 2.151113\n",
      "epoch 74 loss = 2.024887\n",
      "epoch 75 loss = 2.257434\n",
      "epoch 76 loss = 1.994284\n",
      "epoch 77 loss = 2.157049\n",
      "epoch 78 loss = 1.829047\n",
      "epoch 79 loss = 1.933795\n",
      "epoch 80 loss = 2.149799\n",
      "epoch 81 loss = 2.081988\n",
      "epoch 82 loss = 2.059976\n",
      "epoch 83 loss = 1.981876\n",
      "epoch 84 loss = 1.947357\n",
      "epoch 85 loss = 2.100077\n",
      "epoch 86 loss = 1.987191\n",
      "epoch 87 loss = 1.892533\n",
      "epoch 88 loss = 1.955636\n",
      "epoch 89 loss = 2.243209\n",
      "epoch 90 loss = 2.140652\n",
      "epoch 91 loss = 1.899823\n",
      "epoch 92 loss = 2.167827\n",
      "epoch 93 loss = 1.871123\n",
      "epoch 94 loss = 1.900768\n",
      "epoch 95 loss = 2.000582\n",
      "epoch 96 loss = 2.095762\n",
      "epoch 97 loss = 2.179935\n",
      "epoch 98 loss = 1.788178\n",
      "epoch 99 loss = 2.074946\n",
      "epoch 100 loss = 2.065406\n",
      "epoch 101 loss = 2.094447\n",
      "epoch 102 loss = 2.083931\n",
      "epoch 103 loss = 2.037455\n",
      "epoch 104 loss = 1.870236\n",
      "epoch 105 loss = 1.883998\n",
      "epoch 106 loss = 2.132096\n",
      "epoch 107 loss = 2.058219\n",
      "epoch 108 loss = 1.695603\n",
      "epoch 109 loss = 1.926388\n",
      "epoch 110 loss = 1.954036\n",
      "epoch 111 loss = 1.987506\n",
      "epoch 112 loss = 2.113980\n",
      "epoch 113 loss = 2.110557\n",
      "epoch 114 loss = 2.076892\n",
      "epoch 115 loss = 1.900222\n",
      "epoch 116 loss = 1.978410\n",
      "epoch 117 loss = 2.029553\n",
      "epoch 118 loss = 1.802803\n",
      "epoch 119 loss = 2.107485\n",
      "epoch 120 loss = 1.905337\n",
      "epoch 121 loss = 1.903769\n",
      "epoch 122 loss = 1.955282\n",
      "epoch 123 loss = 1.803355\n",
      "epoch 124 loss = 1.988525\n",
      "epoch 125 loss = 2.114084\n",
      "epoch 126 loss = 2.038014\n",
      "epoch 127 loss = 2.068233\n",
      "epoch 128 loss = 1.961714\n",
      "epoch 129 loss = 2.108461\n",
      "epoch 130 loss = 2.026870\n",
      "epoch 131 loss = 1.917905\n",
      "epoch 132 loss = 1.885636\n",
      "epoch 133 loss = 1.830902\n",
      "epoch 134 loss = 2.198710\n",
      "epoch 135 loss = 1.880070\n",
      "epoch 136 loss = 1.834940\n",
      "epoch 137 loss = 2.018171\n",
      "epoch 138 loss = 1.970406\n",
      "epoch 139 loss = 1.691842\n",
      "epoch 140 loss = 1.856432\n",
      "epoch 141 loss = 2.076488\n",
      "epoch 142 loss = 2.102511\n",
      "epoch 143 loss = 2.235232\n",
      "epoch 144 loss = 1.946283\n",
      "epoch 145 loss = 2.006995\n",
      "epoch 146 loss = 2.246260\n",
      "epoch 147 loss = 2.001137\n",
      "epoch 148 loss = 1.948961\n",
      "epoch 149 loss = 2.063341\n",
      "epoch 150 loss = 1.865442\n",
      "epoch 151 loss = 2.124601\n",
      "epoch 152 loss = 1.703942\n",
      "epoch 153 loss = 2.260515\n",
      "epoch 154 loss = 1.879856\n",
      "epoch 155 loss = 1.837400\n",
      "epoch 156 loss = 2.031769\n",
      "epoch 157 loss = 1.960064\n",
      "epoch 158 loss = 1.945926\n",
      "epoch 159 loss = 1.857991\n",
      "epoch 160 loss = 1.860863\n",
      "epoch 161 loss = 1.946051\n",
      "epoch 162 loss = 2.103046\n",
      "epoch 163 loss = 1.933265\n",
      "epoch 164 loss = 2.034729\n",
      "epoch 165 loss = 2.011694\n",
      "epoch 166 loss = 1.800203\n",
      "epoch 167 loss = 2.082055\n",
      "epoch 168 loss = 2.100118\n",
      "epoch 169 loss = 1.770671\n",
      "epoch 170 loss = 1.967051\n",
      "epoch 171 loss = 2.089780\n",
      "epoch 172 loss = 2.078176\n",
      "epoch 173 loss = 1.868434\n",
      "epoch 174 loss = 1.894396\n",
      "epoch 175 loss = 2.078400\n",
      "epoch 176 loss = 1.916984\n",
      "epoch 177 loss = 1.594270\n",
      "epoch 178 loss = 2.096033\n",
      "epoch 179 loss = 1.973902\n",
      "epoch 180 loss = 2.060317\n",
      "epoch 181 loss = 1.883368\n",
      "epoch 182 loss = 2.191741\n",
      "epoch 183 loss = 2.000531\n",
      "epoch 184 loss = 2.004627\n",
      "epoch 185 loss = 1.974413\n",
      "epoch 186 loss = 1.788770\n",
      "epoch 187 loss = 2.032325\n",
      "epoch 188 loss = 2.154882\n",
      "epoch 189 loss = 1.844471\n",
      "epoch 190 loss = 1.876697\n",
      "epoch 191 loss = 1.973650\n",
      "epoch 192 loss = 2.011939\n",
      "epoch 193 loss = 1.903689\n",
      "epoch 194 loss = 1.766043\n",
      "epoch 195 loss = 1.823427\n",
      "epoch 196 loss = 2.026652\n",
      "epoch 197 loss = 2.110941\n",
      "epoch 198 loss = 1.989982\n",
      "epoch 199 loss = 1.981541\n",
      "epoch 200 loss = 2.245045\n",
      "epoch 201 loss = 1.979574\n",
      "epoch 202 loss = 1.931533\n",
      "epoch 203 loss = 1.747524\n",
      "epoch 204 loss = 1.905952\n",
      "epoch 205 loss = 2.013932\n",
      "epoch 206 loss = 1.980421\n",
      "epoch 207 loss = 1.870205\n",
      "epoch 208 loss = 2.076701\n",
      "epoch 209 loss = 1.988146\n",
      "epoch 210 loss = 1.874636\n",
      "epoch 211 loss = 1.862129\n",
      "epoch 212 loss = 1.867063\n",
      "epoch 213 loss = 1.867230\n",
      "epoch 214 loss = 2.142477\n",
      "epoch 215 loss = 2.084043\n",
      "epoch 216 loss = 2.068352\n",
      "epoch 217 loss = 1.994260\n",
      "epoch 218 loss = 2.026237\n",
      "epoch 219 loss = 1.909029\n",
      "epoch 220 loss = 1.968852\n",
      "epoch 221 loss = 1.612264\n",
      "epoch 222 loss = 1.866052\n",
      "epoch 223 loss = 1.812664\n",
      "epoch 224 loss = 2.102163\n",
      "epoch 225 loss = 1.774658\n",
      "epoch 226 loss = 1.920051\n",
      "epoch 227 loss = 2.004922\n",
      "epoch 228 loss = 2.187588\n",
      "epoch 229 loss = 2.016030\n",
      "epoch 230 loss = 1.878353\n",
      "epoch 231 loss = 2.059660\n",
      "epoch 232 loss = 1.943092\n",
      "epoch 233 loss = 1.642117\n",
      "epoch 234 loss = 1.932725\n",
      "epoch 235 loss = 1.749595\n",
      "epoch 236 loss = 1.701428\n",
      "epoch 237 loss = 1.851583\n",
      "epoch 238 loss = 1.949763\n",
      "epoch 239 loss = 2.156856\n",
      "epoch 240 loss = 1.958883\n",
      "epoch 241 loss = 1.891345\n",
      "epoch 242 loss = 1.960886\n",
      "epoch 243 loss = 1.981530\n",
      "epoch 244 loss = 1.906011\n",
      "epoch 245 loss = 1.876503\n",
      "epoch 246 loss = 1.877959\n",
      "epoch 247 loss = 2.258871\n",
      "epoch 248 loss = 1.967772\n",
      "epoch 249 loss = 1.903321\n",
      "epoch 250 loss = 2.041821\n",
      "epoch 251 loss = 1.803368\n",
      "epoch 252 loss = 1.959911\n",
      "epoch 253 loss = 1.914645\n",
      "epoch 254 loss = 2.088643\n",
      "epoch 255 loss = 1.963234\n",
      "epoch 256 loss = 1.831339\n",
      "epoch 257 loss = 2.232231\n",
      "epoch 258 loss = 1.938278\n",
      "epoch 259 loss = 1.878893\n",
      "epoch 260 loss = 1.941339\n",
      "epoch 261 loss = 2.098644\n",
      "epoch 262 loss = 2.126824\n",
      "epoch 263 loss = 1.852046\n",
      "epoch 264 loss = 1.851508\n",
      "epoch 265 loss = 1.903214\n",
      "epoch 266 loss = 1.810726\n",
      "epoch 267 loss = 1.951190\n",
      "epoch 268 loss = 1.704950\n",
      "epoch 269 loss = 1.912785\n",
      "epoch 270 loss = 1.873707\n",
      "epoch 271 loss = 1.673837\n",
      "epoch 272 loss = 1.896722\n",
      "epoch 273 loss = 1.921636\n",
      "epoch 274 loss = 2.104339\n",
      "epoch 275 loss = 1.975640\n",
      "epoch 276 loss = 1.749585\n",
      "epoch 277 loss = 2.015066\n",
      "epoch 278 loss = 1.972007\n",
      "epoch 279 loss = 1.868651\n",
      "epoch 280 loss = 2.111795\n",
      "epoch 281 loss = 1.921795\n",
      "epoch 282 loss = 1.890364\n",
      "epoch 283 loss = 2.004495\n",
      "epoch 284 loss = 2.163691\n",
      "epoch 285 loss = 2.011851\n",
      "epoch 286 loss = 1.849760\n",
      "epoch 287 loss = 1.840881\n",
      "epoch 288 loss = 2.062048\n",
      "epoch 289 loss = 1.974757\n",
      "epoch 290 loss = 1.786040\n",
      "epoch 291 loss = 1.978828\n",
      "epoch 292 loss = 1.948543\n",
      "epoch 293 loss = 1.857817\n",
      "epoch 294 loss = 1.970078\n",
      "epoch 295 loss = 1.873001\n",
      "epoch 296 loss = 1.807541\n",
      "epoch 297 loss = 1.775368\n",
      "epoch 298 loss = 1.788468\n",
      "epoch 299 loss = 2.182601\n",
      "epoch 300 loss = 1.923453\n",
      "epoch 301 loss = 1.703110\n",
      "epoch 302 loss = 2.052339\n",
      "epoch 303 loss = 2.141471\n",
      "epoch 304 loss = 2.073150\n",
      "epoch 305 loss = 1.832913\n",
      "epoch 306 loss = 2.026960\n",
      "epoch 307 loss = 1.999981\n",
      "epoch 308 loss = 1.875324\n",
      "epoch 309 loss = 2.079652\n",
      "epoch 310 loss = 1.854255\n",
      "epoch 311 loss = 1.881878\n",
      "epoch 312 loss = 1.913806\n",
      "epoch 313 loss = 1.729728\n",
      "epoch 314 loss = 1.777788\n",
      "epoch 315 loss = 1.734792\n",
      "epoch 316 loss = 1.870237\n",
      "epoch 317 loss = 2.002374\n",
      "epoch 318 loss = 1.950029\n",
      "epoch 319 loss = 2.029665\n",
      "epoch 320 loss = 2.053497\n",
      "epoch 321 loss = 1.919729\n",
      "epoch 322 loss = 2.100531\n",
      "epoch 323 loss = 1.711921\n",
      "epoch 324 loss = 1.929902\n",
      "epoch 325 loss = 2.020807\n",
      "epoch 326 loss = 1.923179\n",
      "epoch 327 loss = 1.817286\n",
      "epoch 328 loss = 1.987875\n",
      "epoch 329 loss = 1.905162\n",
      "epoch 330 loss = 1.924409\n",
      "epoch 331 loss = 1.976771\n",
      "epoch 332 loss = 1.727678\n",
      "epoch 333 loss = 1.983313\n",
      "epoch 334 loss = 2.152592\n",
      "epoch 335 loss = 2.055815\n",
      "epoch 336 loss = 1.968772\n",
      "epoch 337 loss = 1.843095\n",
      "epoch 338 loss = 2.080390\n",
      "epoch 339 loss = 1.849100\n",
      "epoch 340 loss = 1.834671\n",
      "epoch 341 loss = 1.914856\n",
      "epoch 342 loss = 1.854048\n",
      "epoch 343 loss = 1.819393\n",
      "epoch 344 loss = 2.006543\n",
      "epoch 345 loss = 1.975844\n",
      "epoch 346 loss = 1.967286\n",
      "epoch 347 loss = 1.821310\n",
      "epoch 348 loss = 2.124027\n",
      "epoch 349 loss = 1.544079\n",
      "epoch 350 loss = 1.919369\n",
      "epoch 351 loss = 2.036677\n",
      "epoch 352 loss = 2.002859\n",
      "epoch 353 loss = 1.659809\n",
      "epoch 354 loss = 1.842148\n",
      "epoch 355 loss = 1.982472\n",
      "epoch 356 loss = 2.229817\n",
      "epoch 357 loss = 1.946747\n",
      "epoch 358 loss = 1.946618\n",
      "epoch 359 loss = 1.886737\n",
      "epoch 360 loss = 1.697841\n",
      "epoch 361 loss = 1.802583\n",
      "epoch 362 loss = 2.021163\n",
      "epoch 363 loss = 1.989471\n",
      "epoch 364 loss = 2.036986\n",
      "epoch 365 loss = 1.829028\n",
      "epoch 366 loss = 1.805147\n",
      "epoch 367 loss = 1.921613\n",
      "epoch 368 loss = 2.066510\n",
      "epoch 369 loss = 1.817199\n",
      "epoch 370 loss = 2.152620\n",
      "epoch 371 loss = 1.890497\n",
      "epoch 372 loss = 2.024320\n",
      "epoch 373 loss = 2.125638\n",
      "epoch 374 loss = 1.989523\n",
      "epoch 375 loss = 1.755090\n",
      "epoch 376 loss = 1.868607\n",
      "epoch 377 loss = 1.903168\n",
      "epoch 378 loss = 1.779126\n",
      "epoch 379 loss = 1.883255\n",
      "epoch 380 loss = 1.724828\n",
      "epoch 381 loss = 1.756297\n",
      "epoch 382 loss = 2.089762\n",
      "epoch 383 loss = 1.935341\n",
      "epoch 384 loss = 2.040575\n",
      "epoch 385 loss = 1.756582\n",
      "epoch 386 loss = 1.935640\n",
      "epoch 387 loss = 2.096920\n",
      "epoch 388 loss = 1.943086\n",
      "epoch 389 loss = 1.857481\n",
      "epoch 390 loss = 1.993907\n",
      "epoch 391 loss = 1.787744\n",
      "epoch 392 loss = 2.088733\n",
      "epoch 393 loss = 1.827482\n",
      "epoch 394 loss = 2.054744\n",
      "epoch 395 loss = 2.003654\n",
      "epoch 396 loss = 2.041173\n",
      "epoch 397 loss = 2.021798\n",
      "epoch 398 loss = 1.997999\n",
      "epoch 399 loss = 1.736967\n",
      "epoch 400 loss = 2.109993\n",
      "epoch 401 loss = 1.853186\n",
      "epoch 402 loss = 1.696171\n",
      "epoch 403 loss = 1.880816\n",
      "epoch 404 loss = 2.022654\n",
      "epoch 405 loss = 1.864162\n",
      "epoch 406 loss = 2.099265\n",
      "epoch 407 loss = 1.845054\n",
      "epoch 408 loss = 1.794652\n",
      "epoch 409 loss = 1.818436\n",
      "epoch 410 loss = 1.883962\n",
      "epoch 411 loss = 1.888350\n",
      "epoch 412 loss = 1.955349\n",
      "epoch 413 loss = 2.256120\n",
      "epoch 414 loss = 1.749112\n",
      "epoch 415 loss = 1.905948\n",
      "epoch 416 loss = 2.021475\n",
      "epoch 417 loss = 1.804583\n",
      "epoch 418 loss = 1.950407\n",
      "epoch 419 loss = 1.883621\n",
      "epoch 420 loss = 1.964172\n",
      "epoch 421 loss = 2.004156\n",
      "epoch 422 loss = 1.633822\n",
      "epoch 423 loss = 2.122930\n",
      "epoch 424 loss = 1.907277\n",
      "epoch 425 loss = 1.811006\n",
      "epoch 426 loss = 1.827592\n",
      "epoch 427 loss = 1.918081\n",
      "epoch 428 loss = 2.040467\n",
      "epoch 429 loss = 1.853441\n",
      "epoch 430 loss = 1.976773\n",
      "epoch 431 loss = 1.826687\n",
      "epoch 432 loss = 1.851839\n",
      "epoch 433 loss = 2.065349\n",
      "epoch 434 loss = 2.012032\n",
      "epoch 435 loss = 1.884769\n",
      "epoch 436 loss = 1.817893\n",
      "epoch 437 loss = 1.903055\n",
      "epoch 438 loss = 1.917964\n",
      "epoch 439 loss = 1.863658\n",
      "epoch 440 loss = 2.091127\n",
      "epoch 441 loss = 1.785493\n",
      "epoch 442 loss = 2.100940\n",
      "epoch 443 loss = 1.841454\n",
      "epoch 444 loss = 2.034499\n",
      "epoch 445 loss = 2.284228\n",
      "epoch 446 loss = 1.838706\n",
      "epoch 447 loss = 1.867654\n",
      "epoch 448 loss = 1.982775\n",
      "epoch 449 loss = 1.972579\n",
      "epoch 450 loss = 2.037878\n",
      "epoch 451 loss = 1.889810\n",
      "epoch 452 loss = 1.895696\n",
      "epoch 453 loss = 2.119057\n",
      "epoch 454 loss = 1.887701\n",
      "epoch 455 loss = 1.944525\n",
      "epoch 456 loss = 1.947629\n",
      "epoch 457 loss = 1.892820\n",
      "epoch 458 loss = 1.935749\n",
      "epoch 459 loss = 1.896050\n",
      "epoch 460 loss = 1.846263\n",
      "epoch 461 loss = 2.021266\n",
      "epoch 462 loss = 2.140961\n",
      "epoch 463 loss = 1.966479\n",
      "epoch 464 loss = 1.759388\n",
      "epoch 465 loss = 2.145067\n",
      "epoch 466 loss = 1.716329\n",
      "epoch 467 loss = 1.993567\n",
      "epoch 468 loss = 1.893839\n",
      "epoch 469 loss = 2.071565\n",
      "epoch 470 loss = 1.997867\n",
      "epoch 471 loss = 1.926931\n",
      "epoch 472 loss = 1.920682\n",
      "epoch 473 loss = 1.860039\n",
      "epoch 474 loss = 2.033367\n",
      "epoch 475 loss = 2.009963\n",
      "epoch 476 loss = 1.988545\n",
      "epoch 477 loss = 1.863505\n",
      "epoch 478 loss = 2.223435\n",
      "epoch 479 loss = 1.881815\n",
      "epoch 480 loss = 1.857390\n",
      "epoch 481 loss = 2.108277\n",
      "epoch 482 loss = 1.990614\n",
      "epoch 483 loss = 2.003817\n",
      "epoch 484 loss = 1.866244\n",
      "epoch 485 loss = 1.933473\n",
      "epoch 486 loss = 1.995244\n",
      "epoch 487 loss = 1.922428\n",
      "epoch 488 loss = 2.052451\n",
      "epoch 489 loss = 2.184280\n",
      "epoch 490 loss = 1.960396\n",
      "epoch 491 loss = 1.715397\n",
      "epoch 492 loss = 1.779439\n",
      "epoch 493 loss = 1.957567\n",
      "epoch 494 loss = 1.705607\n",
      "epoch 495 loss = 1.742875\n",
      "epoch 496 loss = 1.957129\n",
      "epoch 497 loss = 1.723577\n",
      "epoch 498 loss = 1.761821\n",
      "epoch 499 loss = 1.924224\n",
      "final loss = 1.924224\n",
      "accuracy_mc = tensor(0.2845, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2976, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.9113, device='cuda:0')\n",
      "training time = 306.17052960395813 seconds\n",
      "testing time = 3.2076308727264404 seconds\n",
      "\n",
      "Training with split 2\n",
      "epoch 0 loss = 2.271944\n",
      "epoch 1 loss = 2.243140\n",
      "epoch 2 loss = 2.278234\n",
      "epoch 3 loss = 2.271605\n",
      "epoch 4 loss = 2.184386\n",
      "epoch 5 loss = 2.288507\n",
      "epoch 6 loss = 2.156032\n",
      "epoch 7 loss = 2.192893\n",
      "epoch 8 loss = 2.143828\n",
      "epoch 9 loss = 2.210830\n",
      "epoch 10 loss = 1.981406\n",
      "epoch 11 loss = 2.177894\n",
      "epoch 12 loss = 2.116881\n",
      "epoch 13 loss = 2.079973\n",
      "epoch 14 loss = 2.059709\n",
      "epoch 15 loss = 2.110639\n",
      "epoch 16 loss = 2.092204\n",
      "epoch 17 loss = 2.102447\n",
      "epoch 18 loss = 2.133819\n",
      "epoch 19 loss = 2.169554\n",
      "epoch 20 loss = 2.069868\n",
      "epoch 21 loss = 2.099745\n",
      "epoch 22 loss = 2.190933\n",
      "epoch 23 loss = 2.085832\n",
      "epoch 24 loss = 2.182239\n",
      "epoch 25 loss = 2.097811\n",
      "epoch 26 loss = 2.095057\n",
      "epoch 27 loss = 2.100427\n",
      "epoch 28 loss = 2.125867\n",
      "epoch 29 loss = 1.961416\n",
      "epoch 30 loss = 2.078965\n",
      "epoch 31 loss = 2.055958\n",
      "epoch 32 loss = 2.116859\n",
      "epoch 33 loss = 2.107827\n",
      "epoch 34 loss = 2.055772\n",
      "epoch 35 loss = 2.219827\n",
      "epoch 36 loss = 2.252296\n",
      "epoch 37 loss = 2.091907\n",
      "epoch 38 loss = 2.076679\n",
      "epoch 39 loss = 2.142170\n",
      "epoch 40 loss = 2.127819\n",
      "epoch 41 loss = 2.019374\n",
      "epoch 42 loss = 2.152562\n",
      "epoch 43 loss = 2.196786\n",
      "epoch 44 loss = 2.047697\n",
      "epoch 45 loss = 1.982878\n",
      "epoch 46 loss = 2.105370\n",
      "epoch 47 loss = 2.070293\n",
      "epoch 48 loss = 2.058684\n",
      "epoch 49 loss = 1.971808\n",
      "epoch 50 loss = 2.076607\n",
      "epoch 51 loss = 1.996253\n",
      "epoch 52 loss = 2.099965\n",
      "epoch 53 loss = 2.057333\n",
      "epoch 54 loss = 2.162730\n",
      "epoch 55 loss = 2.096031\n",
      "epoch 56 loss = 2.149836\n",
      "epoch 57 loss = 2.062876\n",
      "epoch 58 loss = 2.021068\n",
      "epoch 59 loss = 2.126091\n",
      "epoch 60 loss = 2.062315\n",
      "epoch 61 loss = 2.114539\n",
      "epoch 62 loss = 2.164975\n",
      "epoch 63 loss = 2.079074\n",
      "epoch 64 loss = 2.084709\n",
      "epoch 65 loss = 2.026788\n",
      "epoch 66 loss = 1.980749\n",
      "epoch 67 loss = 2.017591\n",
      "epoch 68 loss = 2.121819\n",
      "epoch 69 loss = 2.026657\n",
      "epoch 70 loss = 1.999920\n",
      "epoch 71 loss = 2.152025\n",
      "epoch 72 loss = 1.999896\n",
      "epoch 73 loss = 2.054678\n",
      "epoch 74 loss = 2.190980\n",
      "epoch 75 loss = 2.029199\n",
      "epoch 76 loss = 2.010017\n",
      "epoch 77 loss = 1.976844\n",
      "epoch 78 loss = 2.083547\n",
      "epoch 79 loss = 2.056586\n",
      "epoch 80 loss = 2.110457\n",
      "epoch 81 loss = 2.062218\n",
      "epoch 82 loss = 2.003567\n",
      "epoch 83 loss = 1.986788\n",
      "epoch 84 loss = 2.211469\n",
      "epoch 85 loss = 2.016071\n",
      "epoch 86 loss = 2.098035\n",
      "epoch 87 loss = 2.018298\n",
      "epoch 88 loss = 2.024851\n",
      "epoch 89 loss = 2.034857\n",
      "epoch 90 loss = 2.188644\n",
      "epoch 91 loss = 2.144554\n",
      "epoch 92 loss = 1.894360\n",
      "epoch 93 loss = 1.980450\n",
      "epoch 94 loss = 2.006252\n",
      "epoch 95 loss = 2.049138\n",
      "epoch 96 loss = 2.040563\n",
      "epoch 97 loss = 2.237230\n",
      "epoch 98 loss = 2.055939\n",
      "epoch 99 loss = 2.183060\n",
      "epoch 100 loss = 1.971678\n",
      "epoch 101 loss = 2.074826\n",
      "epoch 102 loss = 2.088643\n",
      "epoch 103 loss = 2.165948\n",
      "epoch 104 loss = 2.088532\n",
      "epoch 105 loss = 1.904852\n",
      "epoch 106 loss = 2.141814\n",
      "epoch 107 loss = 2.115172\n",
      "epoch 108 loss = 2.184760\n",
      "epoch 109 loss = 2.085906\n",
      "epoch 110 loss = 2.093220\n",
      "epoch 111 loss = 2.032262\n",
      "epoch 112 loss = 2.220437\n",
      "epoch 113 loss = 2.088002\n",
      "epoch 114 loss = 2.058439\n",
      "epoch 115 loss = 2.014548\n",
      "epoch 116 loss = 1.892793\n",
      "epoch 117 loss = 2.156064\n",
      "epoch 118 loss = 2.156311\n",
      "epoch 119 loss = 1.918490\n",
      "epoch 120 loss = 1.953499\n",
      "epoch 121 loss = 2.018703\n",
      "epoch 122 loss = 2.182109\n",
      "epoch 123 loss = 2.139913\n",
      "epoch 124 loss = 2.023650\n",
      "epoch 125 loss = 2.076984\n",
      "epoch 126 loss = 2.176195\n",
      "epoch 127 loss = 2.064800\n",
      "epoch 128 loss = 2.059359\n",
      "epoch 129 loss = 2.179972\n",
      "epoch 130 loss = 2.019493\n",
      "epoch 131 loss = 1.950904\n",
      "epoch 132 loss = 2.006307\n",
      "epoch 133 loss = 2.054627\n",
      "epoch 134 loss = 1.972500\n",
      "epoch 135 loss = 1.970763\n",
      "epoch 136 loss = 2.128337\n",
      "epoch 137 loss = 1.999649\n",
      "epoch 138 loss = 2.064204\n",
      "epoch 139 loss = 2.058727\n",
      "epoch 140 loss = 2.103856\n",
      "epoch 141 loss = 2.148019\n",
      "epoch 142 loss = 2.003611\n",
      "epoch 143 loss = 2.320327\n",
      "epoch 144 loss = 2.065494\n",
      "epoch 145 loss = 1.997087\n",
      "epoch 146 loss = 2.115772\n",
      "epoch 147 loss = 2.188137\n",
      "epoch 148 loss = 2.089275\n",
      "epoch 149 loss = 2.112027\n",
      "epoch 150 loss = 2.276809\n",
      "epoch 151 loss = 2.148409\n",
      "epoch 152 loss = 2.010782\n",
      "epoch 153 loss = 2.016520\n",
      "epoch 154 loss = 2.053643\n",
      "epoch 155 loss = 2.061167\n",
      "epoch 156 loss = 2.107490\n",
      "epoch 157 loss = 1.920551\n",
      "epoch 158 loss = 2.015052\n",
      "epoch 159 loss = 2.089292\n",
      "epoch 160 loss = 1.914119\n",
      "epoch 161 loss = 2.134247\n",
      "epoch 162 loss = 1.960250\n",
      "epoch 163 loss = 2.165277\n",
      "epoch 164 loss = 2.142385\n",
      "epoch 165 loss = 1.945011\n",
      "epoch 166 loss = 2.085856\n",
      "epoch 167 loss = 2.034901\n",
      "epoch 168 loss = 2.139191\n",
      "epoch 169 loss = 2.185099\n",
      "epoch 170 loss = 2.053822\n",
      "epoch 171 loss = 2.084823\n",
      "epoch 172 loss = 2.016469\n",
      "epoch 173 loss = 2.018117\n",
      "epoch 174 loss = 2.164091\n",
      "epoch 175 loss = 2.015467\n",
      "epoch 176 loss = 2.131599\n",
      "epoch 177 loss = 2.105648\n",
      "epoch 178 loss = 1.896624\n",
      "epoch 179 loss = 1.944388\n",
      "epoch 180 loss = 2.022676\n",
      "epoch 181 loss = 2.024494\n",
      "epoch 182 loss = 2.081652\n",
      "epoch 183 loss = 2.026291\n",
      "epoch 184 loss = 2.139571\n",
      "epoch 185 loss = 2.153637\n",
      "epoch 186 loss = 1.968513\n",
      "epoch 187 loss = 1.969451\n",
      "epoch 188 loss = 2.017925\n",
      "epoch 189 loss = 2.047647\n",
      "epoch 190 loss = 2.071651\n",
      "epoch 191 loss = 2.130605\n",
      "epoch 192 loss = 2.037368\n",
      "epoch 193 loss = 2.016748\n",
      "epoch 194 loss = 2.115197\n",
      "epoch 195 loss = 2.084446\n",
      "epoch 196 loss = 2.058436\n",
      "epoch 197 loss = 2.076959\n",
      "epoch 198 loss = 2.073179\n",
      "epoch 199 loss = 2.085945\n",
      "epoch 200 loss = 1.983955\n",
      "epoch 201 loss = 1.863879\n",
      "epoch 202 loss = 2.059742\n",
      "epoch 203 loss = 2.163529\n",
      "epoch 204 loss = 2.122902\n",
      "epoch 205 loss = 2.112580\n",
      "epoch 206 loss = 2.187659\n",
      "epoch 207 loss = 1.959849\n",
      "epoch 208 loss = 2.044010\n",
      "epoch 209 loss = 2.024545\n",
      "epoch 210 loss = 2.116888\n",
      "epoch 211 loss = 2.067211\n",
      "epoch 212 loss = 2.119053\n",
      "epoch 213 loss = 2.019029\n",
      "epoch 214 loss = 1.972191\n",
      "epoch 215 loss = 2.132880\n",
      "epoch 216 loss = 1.928971\n",
      "epoch 217 loss = 1.948644\n",
      "epoch 218 loss = 2.106695\n",
      "epoch 219 loss = 2.090329\n",
      "epoch 220 loss = 2.122196\n",
      "epoch 221 loss = 1.997225\n",
      "epoch 222 loss = 1.957447\n",
      "epoch 223 loss = 2.116952\n",
      "epoch 224 loss = 2.005891\n",
      "epoch 225 loss = 2.049429\n",
      "epoch 226 loss = 2.045674\n",
      "epoch 227 loss = 2.050775\n",
      "epoch 228 loss = 2.112809\n",
      "epoch 229 loss = 1.996619\n",
      "epoch 230 loss = 2.089656\n",
      "epoch 231 loss = 2.127904\n",
      "epoch 232 loss = 2.146668\n",
      "epoch 233 loss = 2.207056\n",
      "epoch 234 loss = 2.070095\n",
      "epoch 235 loss = 2.202760\n",
      "epoch 236 loss = 2.097774\n",
      "epoch 237 loss = 2.161760\n",
      "epoch 238 loss = 1.993994\n",
      "epoch 239 loss = 2.032086\n",
      "epoch 240 loss = 2.139711\n",
      "epoch 241 loss = 1.968930\n",
      "epoch 242 loss = 2.106611\n",
      "epoch 243 loss = 1.951396\n",
      "epoch 244 loss = 2.129801\n",
      "epoch 245 loss = 2.073037\n",
      "epoch 246 loss = 1.952742\n",
      "epoch 247 loss = 2.004845\n",
      "epoch 248 loss = 2.167324\n",
      "epoch 249 loss = 2.116228\n",
      "epoch 250 loss = 2.119270\n",
      "epoch 251 loss = 2.126640\n",
      "epoch 252 loss = 1.899873\n",
      "epoch 253 loss = 2.045635\n",
      "epoch 254 loss = 1.922580\n",
      "epoch 255 loss = 2.186248\n",
      "epoch 256 loss = 2.077389\n",
      "epoch 257 loss = 1.945232\n",
      "epoch 258 loss = 2.186224\n",
      "epoch 259 loss = 2.085283\n",
      "epoch 260 loss = 2.140460\n",
      "epoch 261 loss = 2.208184\n",
      "epoch 262 loss = 2.221073\n",
      "epoch 263 loss = 2.169081\n",
      "epoch 264 loss = 2.192619\n",
      "epoch 265 loss = 2.268187\n",
      "epoch 266 loss = 1.954842\n",
      "epoch 267 loss = 2.030193\n",
      "epoch 268 loss = 2.203212\n",
      "epoch 269 loss = 2.107672\n",
      "epoch 270 loss = 2.003021\n",
      "epoch 271 loss = 2.139684\n",
      "epoch 272 loss = 2.080409\n",
      "epoch 273 loss = 2.035799\n",
      "epoch 274 loss = 2.079602\n",
      "epoch 275 loss = 2.088872\n",
      "epoch 276 loss = 2.005397\n",
      "epoch 277 loss = 2.019288\n",
      "epoch 278 loss = 2.169064\n",
      "epoch 279 loss = 2.040573\n",
      "epoch 280 loss = 2.043142\n",
      "epoch 281 loss = 2.013292\n",
      "epoch 282 loss = 1.976460\n",
      "epoch 283 loss = 2.093965\n",
      "epoch 284 loss = 1.957221\n",
      "epoch 285 loss = 1.943528\n",
      "epoch 286 loss = 2.010503\n",
      "epoch 287 loss = 2.081393\n",
      "epoch 288 loss = 1.944364\n",
      "epoch 289 loss = 1.979336\n",
      "epoch 290 loss = 2.060077\n",
      "epoch 291 loss = 2.029224\n",
      "epoch 292 loss = 2.222740\n",
      "epoch 293 loss = 1.910446\n",
      "epoch 294 loss = 2.161550\n",
      "epoch 295 loss = 2.125809\n",
      "epoch 296 loss = 1.867710\n",
      "epoch 297 loss = 2.070486\n",
      "epoch 298 loss = 2.087710\n",
      "epoch 299 loss = 2.117387\n",
      "epoch 300 loss = 1.997574\n",
      "epoch 301 loss = 2.097351\n",
      "epoch 302 loss = 2.021143\n",
      "epoch 303 loss = 2.096522\n",
      "epoch 304 loss = 1.933461\n",
      "epoch 305 loss = 2.049357\n",
      "epoch 306 loss = 2.054714\n",
      "epoch 307 loss = 1.997229\n",
      "epoch 308 loss = 2.145283\n",
      "epoch 309 loss = 1.886610\n",
      "epoch 310 loss = 2.235087\n",
      "epoch 311 loss = 2.150230\n",
      "epoch 312 loss = 2.014289\n",
      "epoch 313 loss = 2.171709\n",
      "epoch 314 loss = 2.174189\n",
      "epoch 315 loss = 2.190275\n",
      "epoch 316 loss = 2.119442\n",
      "epoch 317 loss = 2.197658\n",
      "epoch 318 loss = 2.013476\n",
      "epoch 319 loss = 2.087739\n",
      "epoch 320 loss = 2.139568\n",
      "epoch 321 loss = 2.081634\n",
      "epoch 322 loss = 1.998713\n",
      "epoch 323 loss = 2.033978\n",
      "epoch 324 loss = 2.075967\n",
      "epoch 325 loss = 2.083934\n",
      "epoch 326 loss = 1.985007\n",
      "epoch 327 loss = 2.096539\n",
      "epoch 328 loss = 1.974222\n",
      "epoch 329 loss = 2.308823\n",
      "epoch 330 loss = 2.036498\n",
      "epoch 331 loss = 1.979712\n",
      "epoch 332 loss = 2.228258\n",
      "epoch 333 loss = 2.046317\n",
      "epoch 334 loss = 1.932603\n",
      "epoch 335 loss = 2.118634\n",
      "epoch 336 loss = 1.965612\n",
      "epoch 337 loss = 2.162482\n",
      "epoch 338 loss = 2.007453\n",
      "epoch 339 loss = 2.086069\n",
      "epoch 340 loss = 2.058752\n",
      "epoch 341 loss = 2.084305\n",
      "epoch 342 loss = 2.038869\n",
      "epoch 343 loss = 2.137705\n",
      "epoch 344 loss = 1.949175\n",
      "epoch 345 loss = 2.038394\n",
      "epoch 346 loss = 1.969339\n",
      "epoch 347 loss = 2.101352\n",
      "epoch 348 loss = 2.001467\n",
      "epoch 349 loss = 2.079775\n",
      "epoch 350 loss = 1.977502\n",
      "epoch 351 loss = 1.961234\n",
      "epoch 352 loss = 2.073180\n",
      "epoch 353 loss = 2.077706\n",
      "epoch 354 loss = 2.133015\n",
      "epoch 355 loss = 2.044477\n",
      "epoch 356 loss = 1.968529\n",
      "epoch 357 loss = 2.015386\n",
      "epoch 358 loss = 2.145762\n",
      "epoch 359 loss = 2.055763\n",
      "epoch 360 loss = 1.885895\n",
      "epoch 361 loss = 2.033200\n",
      "epoch 362 loss = 1.792642\n",
      "epoch 363 loss = 1.936861\n",
      "epoch 364 loss = 1.983465\n",
      "epoch 365 loss = 1.967116\n",
      "epoch 366 loss = 2.046690\n",
      "epoch 367 loss = 2.069067\n",
      "epoch 368 loss = 2.142458\n",
      "epoch 369 loss = 2.082225\n",
      "epoch 370 loss = 2.096670\n",
      "epoch 371 loss = 1.922082\n",
      "epoch 372 loss = 2.060555\n",
      "epoch 373 loss = 2.081814\n",
      "epoch 374 loss = 2.109818\n",
      "epoch 375 loss = 1.928452\n",
      "epoch 376 loss = 1.942439\n",
      "epoch 377 loss = 2.054228\n",
      "epoch 378 loss = 2.084146\n",
      "epoch 379 loss = 2.066523\n",
      "epoch 380 loss = 2.099879\n",
      "epoch 381 loss = 2.183590\n",
      "epoch 382 loss = 1.956056\n",
      "epoch 383 loss = 2.027787\n",
      "epoch 384 loss = 1.997937\n",
      "epoch 385 loss = 2.047934\n",
      "epoch 386 loss = 2.102628\n",
      "epoch 387 loss = 2.117661\n",
      "epoch 388 loss = 2.034956\n",
      "epoch 389 loss = 2.227332\n",
      "epoch 390 loss = 2.246423\n",
      "epoch 391 loss = 2.074734\n",
      "epoch 392 loss = 2.126151\n",
      "epoch 393 loss = 2.190672\n",
      "epoch 394 loss = 2.024219\n",
      "epoch 395 loss = 1.973343\n",
      "epoch 396 loss = 2.216807\n",
      "epoch 397 loss = 2.207751\n",
      "epoch 398 loss = 2.118155\n",
      "epoch 399 loss = 2.161419\n",
      "epoch 400 loss = 1.878540\n",
      "epoch 401 loss = 2.076610\n",
      "epoch 402 loss = 2.112102\n",
      "epoch 403 loss = 2.032553\n",
      "epoch 404 loss = 2.107694\n",
      "epoch 405 loss = 2.046346\n",
      "epoch 406 loss = 2.085140\n",
      "epoch 407 loss = 2.134421\n",
      "epoch 408 loss = 2.037363\n",
      "epoch 409 loss = 1.951848\n",
      "epoch 410 loss = 2.126513\n",
      "epoch 411 loss = 2.017520\n",
      "epoch 412 loss = 2.048567\n",
      "epoch 413 loss = 2.107433\n",
      "epoch 414 loss = 2.068518\n",
      "epoch 415 loss = 2.186786\n",
      "epoch 416 loss = 2.110982\n",
      "epoch 417 loss = 1.932108\n",
      "epoch 418 loss = 2.059701\n",
      "epoch 419 loss = 2.019195\n",
      "epoch 420 loss = 2.126360\n",
      "epoch 421 loss = 1.892556\n",
      "epoch 422 loss = 2.113954\n",
      "epoch 423 loss = 2.139207\n",
      "epoch 424 loss = 1.977652\n",
      "epoch 425 loss = 2.126963\n",
      "epoch 426 loss = 2.161301\n",
      "epoch 427 loss = 1.966660\n",
      "epoch 428 loss = 2.131844\n",
      "epoch 429 loss = 1.968477\n",
      "epoch 430 loss = 2.011229\n",
      "epoch 431 loss = 1.982259\n",
      "epoch 432 loss = 2.042405\n",
      "epoch 433 loss = 2.171727\n",
      "epoch 434 loss = 2.092815\n",
      "epoch 435 loss = 2.076407\n",
      "epoch 436 loss = 2.169554\n",
      "epoch 437 loss = 2.043147\n",
      "epoch 438 loss = 1.970993\n",
      "epoch 439 loss = 2.070669\n",
      "epoch 440 loss = 2.119423\n",
      "epoch 441 loss = 2.120653\n",
      "epoch 442 loss = 2.154362\n",
      "epoch 443 loss = 2.040365\n",
      "epoch 444 loss = 2.133415\n",
      "epoch 445 loss = 1.822497\n",
      "epoch 446 loss = 2.130835\n",
      "epoch 447 loss = 2.202657\n",
      "epoch 448 loss = 2.070564\n",
      "epoch 449 loss = 2.207975\n",
      "epoch 450 loss = 2.016539\n",
      "epoch 451 loss = 2.094353\n",
      "epoch 452 loss = 2.204277\n",
      "epoch 453 loss = 2.033406\n",
      "epoch 454 loss = 2.087159\n",
      "epoch 455 loss = 1.997275\n",
      "epoch 456 loss = 1.975475\n",
      "epoch 457 loss = 1.968872\n",
      "epoch 458 loss = 2.091505\n",
      "epoch 459 loss = 2.152088\n",
      "epoch 460 loss = 2.009829\n",
      "epoch 461 loss = 2.068172\n",
      "epoch 462 loss = 1.882063\n",
      "epoch 463 loss = 2.188577\n",
      "epoch 464 loss = 1.963162\n",
      "epoch 465 loss = 2.201281\n",
      "epoch 466 loss = 2.158653\n",
      "epoch 467 loss = 2.064860\n",
      "epoch 468 loss = 2.113664\n",
      "epoch 469 loss = 2.265002\n",
      "epoch 470 loss = 2.044268\n",
      "epoch 471 loss = 2.252146\n",
      "epoch 472 loss = 1.916075\n",
      "epoch 473 loss = 2.125016\n",
      "epoch 474 loss = 2.139938\n",
      "epoch 475 loss = 2.151308\n",
      "epoch 476 loss = 2.040162\n",
      "epoch 477 loss = 2.064942\n",
      "epoch 478 loss = 2.128619\n",
      "epoch 479 loss = 1.967045\n",
      "epoch 480 loss = 2.052819\n",
      "epoch 481 loss = 2.191015\n",
      "epoch 482 loss = 2.157290\n",
      "epoch 483 loss = 2.228837\n",
      "epoch 484 loss = 2.104166\n",
      "epoch 485 loss = 2.050989\n",
      "epoch 486 loss = 2.057144\n",
      "epoch 487 loss = 2.127815\n",
      "epoch 488 loss = 2.081737\n",
      "epoch 489 loss = 2.071689\n",
      "epoch 490 loss = 2.112938\n",
      "epoch 491 loss = 2.040968\n",
      "epoch 492 loss = 2.257142\n",
      "epoch 493 loss = 1.973657\n",
      "epoch 494 loss = 1.973700\n",
      "epoch 495 loss = 2.046231\n",
      "epoch 496 loss = 2.203136\n",
      "epoch 497 loss = 1.846140\n",
      "epoch 498 loss = 1.947500\n",
      "epoch 499 loss = 2.038020\n",
      "final loss = 2.038020\n",
      "accuracy_mc = tensor(0.1649, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.1563, device='cuda:0')\n",
      "test_ll_mc = tensor(-2.0356, device='cuda:0')\n",
      "training time = 305.7182824611664 seconds\n",
      "testing time = 3.197150945663452 seconds\n",
      "\n",
      "Training with split 3\n",
      "epoch 0 loss = 2.326594\n",
      "epoch 1 loss = 2.260580\n",
      "epoch 2 loss = 2.037309\n",
      "epoch 3 loss = 2.160431\n",
      "epoch 4 loss = 2.227123\n",
      "epoch 5 loss = 2.215326\n",
      "epoch 6 loss = 2.192101\n",
      "epoch 7 loss = 2.187385\n",
      "epoch 8 loss = 2.118922\n",
      "epoch 9 loss = 2.060287\n",
      "epoch 10 loss = 2.014549\n",
      "epoch 11 loss = 2.076350\n",
      "epoch 12 loss = 2.113509\n",
      "epoch 13 loss = 2.033889\n",
      "epoch 14 loss = 2.110314\n",
      "epoch 15 loss = 1.963478\n",
      "epoch 16 loss = 1.947616\n",
      "epoch 17 loss = 2.068317\n",
      "epoch 18 loss = 1.939806\n",
      "epoch 19 loss = 2.107100\n",
      "epoch 20 loss = 1.982681\n",
      "epoch 21 loss = 2.068473\n",
      "epoch 22 loss = 1.870517\n",
      "epoch 23 loss = 1.954327\n",
      "epoch 24 loss = 2.259597\n",
      "epoch 25 loss = 1.989651\n",
      "epoch 26 loss = 1.970432\n",
      "epoch 27 loss = 1.960090\n",
      "epoch 28 loss = 1.990028\n",
      "epoch 29 loss = 2.026741\n",
      "epoch 30 loss = 2.183498\n",
      "epoch 31 loss = 2.061380\n",
      "epoch 32 loss = 1.965384\n",
      "epoch 33 loss = 2.000669\n",
      "epoch 34 loss = 2.110441\n",
      "epoch 35 loss = 2.008395\n",
      "epoch 36 loss = 1.929405\n",
      "epoch 37 loss = 1.987246\n",
      "epoch 38 loss = 2.013003\n",
      "epoch 39 loss = 1.966215\n",
      "epoch 40 loss = 1.972935\n",
      "epoch 41 loss = 2.038393\n",
      "epoch 42 loss = 1.902850\n",
      "epoch 43 loss = 2.056661\n",
      "epoch 44 loss = 2.091416\n",
      "epoch 45 loss = 1.994076\n",
      "epoch 46 loss = 2.091822\n",
      "epoch 47 loss = 1.941416\n",
      "epoch 48 loss = 2.123193\n",
      "epoch 49 loss = 2.100938\n",
      "epoch 50 loss = 2.077794\n",
      "epoch 51 loss = 2.083739\n",
      "epoch 52 loss = 2.133534\n",
      "epoch 53 loss = 2.162904\n",
      "epoch 54 loss = 1.994350\n",
      "epoch 55 loss = 2.028772\n",
      "epoch 56 loss = 1.984143\n",
      "epoch 57 loss = 2.098417\n",
      "epoch 58 loss = 1.946095\n",
      "epoch 59 loss = 2.034147\n",
      "epoch 60 loss = 2.003450\n",
      "epoch 61 loss = 1.946317\n",
      "epoch 62 loss = 1.873607\n",
      "epoch 63 loss = 1.973933\n",
      "epoch 64 loss = 1.881904\n",
      "epoch 65 loss = 2.008279\n",
      "epoch 66 loss = 2.037640\n",
      "epoch 67 loss = 2.136234\n",
      "epoch 68 loss = 1.921356\n",
      "epoch 69 loss = 2.089452\n",
      "epoch 70 loss = 2.259380\n",
      "epoch 71 loss = 2.119723\n",
      "epoch 72 loss = 2.031914\n",
      "epoch 73 loss = 2.206014\n",
      "epoch 74 loss = 2.073882\n",
      "epoch 75 loss = 1.754179\n",
      "epoch 76 loss = 2.089246\n",
      "epoch 77 loss = 2.106237\n",
      "epoch 78 loss = 1.889198\n",
      "epoch 79 loss = 2.043481\n",
      "epoch 80 loss = 1.951438\n",
      "epoch 81 loss = 2.127382\n",
      "epoch 82 loss = 2.047930\n",
      "epoch 83 loss = 1.793186\n",
      "epoch 84 loss = 2.004048\n",
      "epoch 85 loss = 2.020612\n",
      "epoch 86 loss = 2.023848\n",
      "epoch 87 loss = 1.929893\n",
      "epoch 88 loss = 1.955776\n",
      "epoch 89 loss = 1.805090\n",
      "epoch 90 loss = 1.924819\n",
      "epoch 91 loss = 2.058284\n",
      "epoch 92 loss = 2.123335\n",
      "epoch 93 loss = 1.944854\n",
      "epoch 94 loss = 2.170231\n",
      "epoch 95 loss = 1.994233\n",
      "epoch 96 loss = 2.054173\n",
      "epoch 97 loss = 1.927462\n",
      "epoch 98 loss = 2.072601\n",
      "epoch 99 loss = 1.974910\n",
      "epoch 100 loss = 2.051333\n",
      "epoch 101 loss = 1.777454\n",
      "epoch 102 loss = 2.092496\n",
      "epoch 103 loss = 2.039670\n",
      "epoch 104 loss = 1.910308\n",
      "epoch 105 loss = 1.945926\n",
      "epoch 106 loss = 1.990360\n",
      "epoch 107 loss = 1.992947\n",
      "epoch 108 loss = 2.038854\n",
      "epoch 109 loss = 1.898597\n",
      "epoch 110 loss = 2.129295\n",
      "epoch 111 loss = 2.072062\n",
      "epoch 112 loss = 1.922922\n",
      "epoch 113 loss = 1.917314\n",
      "epoch 114 loss = 1.820703\n",
      "epoch 115 loss = 2.163211\n",
      "epoch 116 loss = 2.041449\n",
      "epoch 117 loss = 2.024158\n",
      "epoch 118 loss = 1.962341\n",
      "epoch 119 loss = 1.971586\n",
      "epoch 120 loss = 1.906802\n",
      "epoch 121 loss = 2.036996\n",
      "epoch 122 loss = 2.035786\n",
      "epoch 123 loss = 1.979697\n",
      "epoch 124 loss = 2.074691\n",
      "epoch 125 loss = 2.038338\n",
      "epoch 126 loss = 1.928369\n",
      "epoch 127 loss = 1.994048\n",
      "epoch 128 loss = 1.999125\n",
      "epoch 129 loss = 2.005723\n",
      "epoch 130 loss = 1.886616\n",
      "epoch 131 loss = 2.126415\n",
      "epoch 132 loss = 1.879036\n",
      "epoch 133 loss = 2.136821\n",
      "epoch 134 loss = 1.909079\n",
      "epoch 135 loss = 2.121870\n",
      "epoch 136 loss = 1.961244\n",
      "epoch 137 loss = 2.170292\n",
      "epoch 138 loss = 1.879490\n",
      "epoch 139 loss = 1.966791\n",
      "epoch 140 loss = 1.997857\n",
      "epoch 141 loss = 1.857427\n",
      "epoch 142 loss = 1.952464\n",
      "epoch 143 loss = 2.059624\n",
      "epoch 144 loss = 1.836773\n",
      "epoch 145 loss = 1.952127\n",
      "epoch 146 loss = 1.912481\n",
      "epoch 147 loss = 1.892617\n",
      "epoch 148 loss = 2.090580\n",
      "epoch 149 loss = 2.035506\n",
      "epoch 150 loss = 2.086822\n",
      "epoch 151 loss = 2.186437\n",
      "epoch 152 loss = 1.883876\n",
      "epoch 153 loss = 1.939056\n",
      "epoch 154 loss = 2.071877\n",
      "epoch 155 loss = 1.922620\n",
      "epoch 156 loss = 1.944317\n",
      "epoch 157 loss = 1.984476\n",
      "epoch 158 loss = 2.118881\n",
      "epoch 159 loss = 1.999961\n",
      "epoch 160 loss = 1.857135\n",
      "epoch 161 loss = 1.902922\n",
      "epoch 162 loss = 2.032361\n",
      "epoch 163 loss = 2.058450\n",
      "epoch 164 loss = 2.013460\n",
      "epoch 165 loss = 1.991443\n",
      "epoch 166 loss = 2.059762\n",
      "epoch 167 loss = 2.044943\n",
      "epoch 168 loss = 2.087884\n",
      "epoch 169 loss = 1.907602\n",
      "epoch 170 loss = 2.132145\n",
      "epoch 171 loss = 2.065671\n",
      "epoch 172 loss = 2.023857\n",
      "epoch 173 loss = 2.066034\n",
      "epoch 174 loss = 2.004074\n",
      "epoch 175 loss = 2.016497\n",
      "epoch 176 loss = 2.105991\n",
      "epoch 177 loss = 2.157419\n",
      "epoch 178 loss = 1.996626\n",
      "epoch 179 loss = 1.829246\n",
      "epoch 180 loss = 2.162861\n",
      "epoch 181 loss = 1.911586\n",
      "epoch 182 loss = 1.871848\n",
      "epoch 183 loss = 2.039192\n",
      "epoch 184 loss = 1.935742\n",
      "epoch 185 loss = 2.005547\n",
      "epoch 186 loss = 2.107181\n",
      "epoch 187 loss = 2.060835\n",
      "epoch 188 loss = 1.968782\n",
      "epoch 189 loss = 2.073875\n",
      "epoch 190 loss = 1.963082\n",
      "epoch 191 loss = 1.918846\n",
      "epoch 192 loss = 1.955336\n",
      "epoch 193 loss = 2.056023\n",
      "epoch 194 loss = 1.997571\n",
      "epoch 195 loss = 2.061698\n",
      "epoch 196 loss = 2.102121\n",
      "epoch 197 loss = 1.992001\n",
      "epoch 198 loss = 1.986859\n",
      "epoch 199 loss = 1.920308\n",
      "epoch 200 loss = 1.893525\n",
      "epoch 201 loss = 2.006444\n",
      "epoch 202 loss = 2.163283\n",
      "epoch 203 loss = 1.948202\n",
      "epoch 204 loss = 1.996271\n",
      "epoch 205 loss = 2.035648\n",
      "epoch 206 loss = 1.967801\n",
      "epoch 207 loss = 2.130642\n",
      "epoch 208 loss = 2.096322\n",
      "epoch 209 loss = 1.984801\n",
      "epoch 210 loss = 2.090259\n",
      "epoch 211 loss = 1.978536\n",
      "epoch 212 loss = 2.123143\n",
      "epoch 213 loss = 1.864465\n",
      "epoch 214 loss = 1.932076\n",
      "epoch 215 loss = 1.978267\n",
      "epoch 216 loss = 1.995173\n",
      "epoch 217 loss = 1.894215\n",
      "epoch 218 loss = 1.936094\n",
      "epoch 219 loss = 1.939994\n",
      "epoch 220 loss = 2.042296\n",
      "epoch 221 loss = 1.927457\n",
      "epoch 222 loss = 1.897149\n",
      "epoch 223 loss = 2.100836\n",
      "epoch 224 loss = 1.982566\n",
      "epoch 225 loss = 1.818249\n",
      "epoch 226 loss = 2.050306\n",
      "epoch 227 loss = 2.012468\n",
      "epoch 228 loss = 2.020399\n",
      "epoch 229 loss = 2.012422\n",
      "epoch 230 loss = 2.118144\n",
      "epoch 231 loss = 2.045604\n",
      "epoch 232 loss = 2.121914\n",
      "epoch 233 loss = 1.972422\n",
      "epoch 234 loss = 2.076007\n",
      "epoch 235 loss = 2.115264\n",
      "epoch 236 loss = 1.963486\n",
      "epoch 237 loss = 1.994305\n",
      "epoch 238 loss = 1.991965\n",
      "epoch 239 loss = 1.973390\n",
      "epoch 240 loss = 1.981201\n",
      "epoch 241 loss = 1.961293\n",
      "epoch 242 loss = 2.150817\n",
      "epoch 243 loss = 2.026577\n",
      "epoch 244 loss = 2.125108\n",
      "epoch 245 loss = 2.105836\n",
      "epoch 246 loss = 1.939583\n",
      "epoch 247 loss = 2.004011\n",
      "epoch 248 loss = 1.924114\n",
      "epoch 249 loss = 1.838346\n",
      "epoch 250 loss = 1.903908\n",
      "epoch 251 loss = 1.925994\n",
      "epoch 252 loss = 1.995451\n",
      "epoch 253 loss = 2.034865\n",
      "epoch 254 loss = 2.111326\n",
      "epoch 255 loss = 2.087209\n",
      "epoch 256 loss = 2.067838\n",
      "epoch 257 loss = 2.113593\n",
      "epoch 258 loss = 1.981048\n",
      "epoch 259 loss = 1.883141\n",
      "epoch 260 loss = 1.954591\n",
      "epoch 261 loss = 1.913888\n",
      "epoch 262 loss = 2.024805\n",
      "epoch 263 loss = 2.198698\n",
      "epoch 264 loss = 2.050815\n",
      "epoch 265 loss = 2.028615\n",
      "epoch 266 loss = 2.142646\n",
      "epoch 267 loss = 1.921823\n",
      "epoch 268 loss = 2.078876\n",
      "epoch 269 loss = 2.038213\n",
      "epoch 270 loss = 1.773399\n",
      "epoch 271 loss = 2.049434\n",
      "epoch 272 loss = 1.951080\n",
      "epoch 273 loss = 2.049374\n",
      "epoch 274 loss = 2.068099\n",
      "epoch 275 loss = 1.903505\n",
      "epoch 276 loss = 1.985380\n",
      "epoch 277 loss = 2.017448\n",
      "epoch 278 loss = 2.124661\n",
      "epoch 279 loss = 1.933470\n",
      "epoch 280 loss = 2.106877\n",
      "epoch 281 loss = 2.033120\n",
      "epoch 282 loss = 2.023939\n",
      "epoch 283 loss = 2.032781\n",
      "epoch 284 loss = 2.233192\n",
      "epoch 285 loss = 2.017736\n",
      "epoch 286 loss = 1.869097\n",
      "epoch 287 loss = 1.962717\n",
      "epoch 288 loss = 1.982843\n",
      "epoch 289 loss = 2.034224\n",
      "epoch 290 loss = 2.035920\n",
      "epoch 291 loss = 1.911909\n",
      "epoch 292 loss = 1.895164\n",
      "epoch 293 loss = 2.003006\n",
      "epoch 294 loss = 2.028611\n",
      "epoch 295 loss = 1.985634\n",
      "epoch 296 loss = 1.929758\n",
      "epoch 297 loss = 2.132476\n",
      "epoch 298 loss = 1.967611\n",
      "epoch 299 loss = 1.915932\n",
      "epoch 300 loss = 1.895535\n",
      "epoch 301 loss = 2.016495\n",
      "epoch 302 loss = 1.968337\n",
      "epoch 303 loss = 1.920172\n",
      "epoch 304 loss = 1.917058\n",
      "epoch 305 loss = 2.037899\n",
      "epoch 306 loss = 1.974950\n",
      "epoch 307 loss = 1.946555\n",
      "epoch 308 loss = 2.081357\n",
      "epoch 309 loss = 1.910420\n",
      "epoch 310 loss = 2.163947\n",
      "epoch 311 loss = 2.122139\n",
      "epoch 312 loss = 1.782338\n",
      "epoch 313 loss = 2.011105\n",
      "epoch 314 loss = 1.930194\n",
      "epoch 315 loss = 1.984307\n",
      "epoch 316 loss = 2.018366\n",
      "epoch 317 loss = 1.920450\n",
      "epoch 318 loss = 1.962848\n",
      "epoch 319 loss = 2.036163\n",
      "epoch 320 loss = 1.984244\n",
      "epoch 321 loss = 2.019006\n",
      "epoch 322 loss = 1.762405\n",
      "epoch 323 loss = 2.091765\n",
      "epoch 324 loss = 1.992568\n",
      "epoch 325 loss = 1.972210\n",
      "epoch 326 loss = 1.978176\n",
      "epoch 327 loss = 2.079667\n",
      "epoch 328 loss = 2.007133\n",
      "epoch 329 loss = 2.030632\n",
      "epoch 330 loss = 2.203424\n",
      "epoch 331 loss = 1.858695\n",
      "epoch 332 loss = 2.044284\n",
      "epoch 333 loss = 1.914692\n",
      "epoch 334 loss = 1.973126\n",
      "epoch 335 loss = 2.124722\n",
      "epoch 336 loss = 2.242036\n",
      "epoch 337 loss = 1.885620\n",
      "epoch 338 loss = 1.976124\n",
      "epoch 339 loss = 2.147807\n",
      "epoch 340 loss = 2.073223\n",
      "epoch 341 loss = 1.963881\n",
      "epoch 342 loss = 2.032976\n",
      "epoch 343 loss = 2.096493\n",
      "epoch 344 loss = 2.272650\n",
      "epoch 345 loss = 2.074143\n",
      "epoch 346 loss = 2.047466\n",
      "epoch 347 loss = 1.958287\n",
      "epoch 348 loss = 2.024116\n",
      "epoch 349 loss = 2.146749\n",
      "epoch 350 loss = 1.986444\n",
      "epoch 351 loss = 1.928971\n",
      "epoch 352 loss = 2.001614\n",
      "epoch 353 loss = 2.054268\n",
      "epoch 354 loss = 1.936880\n",
      "epoch 355 loss = 2.024411\n",
      "epoch 356 loss = 1.961999\n",
      "epoch 357 loss = 1.767488\n",
      "epoch 358 loss = 2.099760\n",
      "epoch 359 loss = 2.074043\n",
      "epoch 360 loss = 1.874189\n",
      "epoch 361 loss = 2.113611\n",
      "epoch 362 loss = 2.113424\n",
      "epoch 363 loss = 2.072718\n",
      "epoch 364 loss = 1.900205\n",
      "epoch 365 loss = 1.999200\n",
      "epoch 366 loss = 1.944304\n",
      "epoch 367 loss = 1.988868\n",
      "epoch 368 loss = 1.982361\n",
      "epoch 369 loss = 2.023013\n",
      "epoch 370 loss = 2.081939\n",
      "epoch 371 loss = 1.780502\n",
      "epoch 372 loss = 2.063576\n",
      "epoch 373 loss = 1.846411\n",
      "epoch 374 loss = 1.869722\n",
      "epoch 375 loss = 2.074638\n",
      "epoch 376 loss = 2.144310\n",
      "epoch 377 loss = 2.075004\n",
      "epoch 378 loss = 2.122210\n",
      "epoch 379 loss = 1.997723\n",
      "epoch 380 loss = 2.183385\n",
      "epoch 381 loss = 1.840845\n",
      "epoch 382 loss = 1.927248\n",
      "epoch 383 loss = 1.970040\n",
      "epoch 384 loss = 1.921911\n",
      "epoch 385 loss = 2.047419\n",
      "epoch 386 loss = 1.961661\n",
      "epoch 387 loss = 2.182190\n",
      "epoch 388 loss = 1.965404\n",
      "epoch 389 loss = 1.920108\n",
      "epoch 390 loss = 1.921202\n",
      "epoch 391 loss = 2.036298\n",
      "epoch 392 loss = 2.088259\n",
      "epoch 393 loss = 1.792458\n",
      "epoch 394 loss = 2.144367\n",
      "epoch 395 loss = 2.124860\n",
      "epoch 396 loss = 2.050327\n",
      "epoch 397 loss = 1.898355\n",
      "epoch 398 loss = 2.033360\n",
      "epoch 399 loss = 1.927326\n",
      "epoch 400 loss = 1.924461\n",
      "epoch 401 loss = 2.053640\n",
      "epoch 402 loss = 1.792927\n",
      "epoch 403 loss = 2.167189\n",
      "epoch 404 loss = 1.951563\n",
      "epoch 405 loss = 2.010785\n",
      "epoch 406 loss = 1.950438\n",
      "epoch 407 loss = 1.882519\n",
      "epoch 408 loss = 2.077215\n",
      "epoch 409 loss = 1.997874\n",
      "epoch 410 loss = 1.827147\n",
      "epoch 411 loss = 2.018247\n",
      "epoch 412 loss = 2.140393\n",
      "epoch 413 loss = 2.127594\n",
      "epoch 414 loss = 2.040068\n",
      "epoch 415 loss = 1.908189\n",
      "epoch 416 loss = 1.939660\n",
      "epoch 417 loss = 2.264290\n",
      "epoch 418 loss = 1.844630\n",
      "epoch 419 loss = 2.094846\n",
      "epoch 420 loss = 2.082050\n",
      "epoch 421 loss = 2.118237\n",
      "epoch 422 loss = 1.941597\n",
      "epoch 423 loss = 2.062241\n",
      "epoch 424 loss = 1.991490\n",
      "epoch 425 loss = 2.058073\n",
      "epoch 426 loss = 1.780709\n",
      "epoch 427 loss = 2.053396\n",
      "epoch 428 loss = 1.809894\n",
      "epoch 429 loss = 1.877137\n",
      "epoch 430 loss = 2.035115\n",
      "epoch 431 loss = 1.898213\n",
      "epoch 432 loss = 2.119486\n",
      "epoch 433 loss = 1.986363\n",
      "epoch 434 loss = 1.955031\n",
      "epoch 435 loss = 2.124376\n",
      "epoch 436 loss = 2.025379\n",
      "epoch 437 loss = 2.034186\n",
      "epoch 438 loss = 2.018028\n",
      "epoch 439 loss = 1.867517\n",
      "epoch 440 loss = 1.980703\n",
      "epoch 441 loss = 2.015249\n",
      "epoch 442 loss = 1.929880\n",
      "epoch 443 loss = 2.048552\n",
      "epoch 444 loss = 2.086874\n",
      "epoch 445 loss = 1.914953\n",
      "epoch 446 loss = 2.071229\n",
      "epoch 447 loss = 1.917152\n",
      "epoch 448 loss = 1.927176\n",
      "epoch 449 loss = 2.007207\n",
      "epoch 450 loss = 2.180380\n",
      "epoch 451 loss = 1.980496\n",
      "epoch 452 loss = 2.052195\n",
      "epoch 453 loss = 1.908679\n",
      "epoch 454 loss = 2.120333\n",
      "epoch 455 loss = 2.011014\n",
      "epoch 456 loss = 1.996152\n",
      "epoch 457 loss = 1.832527\n",
      "epoch 458 loss = 1.969090\n",
      "epoch 459 loss = 1.927304\n",
      "epoch 460 loss = 2.034784\n",
      "epoch 461 loss = 1.990893\n",
      "epoch 462 loss = 1.996880\n",
      "epoch 463 loss = 2.074218\n",
      "epoch 464 loss = 1.864104\n",
      "epoch 465 loss = 1.842651\n",
      "epoch 466 loss = 2.074959\n",
      "epoch 467 loss = 1.843581\n",
      "epoch 468 loss = 2.115609\n",
      "epoch 469 loss = 2.019697\n",
      "epoch 470 loss = 2.036562\n",
      "epoch 471 loss = 2.065576\n",
      "epoch 472 loss = 1.988260\n",
      "epoch 473 loss = 1.991632\n",
      "epoch 474 loss = 2.065520\n",
      "epoch 475 loss = 2.165203\n",
      "epoch 476 loss = 2.028981\n",
      "epoch 477 loss = 2.012833\n",
      "epoch 478 loss = 2.089988\n",
      "epoch 479 loss = 1.907122\n",
      "epoch 480 loss = 1.819678\n",
      "epoch 481 loss = 2.079624\n",
      "epoch 482 loss = 2.010301\n",
      "epoch 483 loss = 1.889330\n",
      "epoch 484 loss = 2.018914\n",
      "epoch 485 loss = 1.938627\n",
      "epoch 486 loss = 2.042257\n",
      "epoch 487 loss = 2.042913\n",
      "epoch 488 loss = 1.983544\n",
      "epoch 489 loss = 1.981436\n",
      "epoch 490 loss = 1.787549\n",
      "epoch 491 loss = 2.148583\n",
      "epoch 492 loss = 1.951788\n",
      "epoch 493 loss = 1.931605\n",
      "epoch 494 loss = 1.919300\n",
      "epoch 495 loss = 1.970782\n",
      "epoch 496 loss = 1.954293\n",
      "epoch 497 loss = 1.966090\n",
      "epoch 498 loss = 1.933938\n",
      "epoch 499 loss = 1.858132\n",
      "final loss = 1.858132\n",
      "accuracy_mc = tensor(0.1764, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.1534, device='cuda:0')\n",
      "test_ll_mc = tensor(-2.0578, device='cuda:0')\n",
      "training time = 305.8031084537506 seconds\n",
      "testing time = 3.2128350734710693 seconds\n",
      "\n",
      "Training with split 4\n",
      "epoch 0 loss = 2.285092\n",
      "epoch 1 loss = 2.180470\n",
      "epoch 2 loss = 2.215306\n",
      "epoch 3 loss = 2.048764\n",
      "epoch 4 loss = 2.172017\n",
      "epoch 5 loss = 2.043543\n",
      "epoch 6 loss = 2.074965\n",
      "epoch 7 loss = 2.235101\n",
      "epoch 8 loss = 2.178505\n",
      "epoch 9 loss = 2.043800\n",
      "epoch 10 loss = 2.067887\n",
      "epoch 11 loss = 2.213075\n",
      "epoch 12 loss = 2.080415\n",
      "epoch 13 loss = 1.903559\n",
      "epoch 14 loss = 2.120764\n",
      "epoch 15 loss = 1.988974\n",
      "epoch 16 loss = 2.088674\n",
      "epoch 17 loss = 2.123015\n",
      "epoch 18 loss = 2.106524\n",
      "epoch 19 loss = 1.977539\n",
      "epoch 20 loss = 2.046742\n",
      "epoch 21 loss = 2.148511\n",
      "epoch 22 loss = 2.083433\n",
      "epoch 23 loss = 1.909349\n",
      "epoch 24 loss = 2.036512\n",
      "epoch 25 loss = 2.006444\n",
      "epoch 26 loss = 2.118320\n",
      "epoch 27 loss = 2.237134\n",
      "epoch 28 loss = 1.979400\n",
      "epoch 29 loss = 2.121332\n",
      "epoch 30 loss = 2.091019\n",
      "epoch 31 loss = 1.995166\n",
      "epoch 32 loss = 2.157280\n",
      "epoch 33 loss = 2.137611\n",
      "epoch 34 loss = 2.195543\n",
      "epoch 35 loss = 2.128897\n",
      "epoch 36 loss = 2.201245\n",
      "epoch 37 loss = 2.269824\n",
      "epoch 38 loss = 2.045152\n",
      "epoch 39 loss = 2.060848\n",
      "epoch 40 loss = 1.973715\n",
      "epoch 41 loss = 1.991349\n",
      "epoch 42 loss = 2.193502\n",
      "epoch 43 loss = 2.140058\n",
      "epoch 44 loss = 2.161031\n",
      "epoch 45 loss = 1.912324\n",
      "epoch 46 loss = 2.088660\n",
      "epoch 47 loss = 2.222299\n",
      "epoch 48 loss = 2.073290\n",
      "epoch 49 loss = 1.944359\n",
      "epoch 50 loss = 2.227649\n",
      "epoch 51 loss = 2.096192\n",
      "epoch 52 loss = 2.029697\n",
      "epoch 53 loss = 2.189116\n",
      "epoch 54 loss = 2.240357\n",
      "epoch 55 loss = 2.058988\n",
      "epoch 56 loss = 1.978670\n",
      "epoch 57 loss = 2.061515\n",
      "epoch 58 loss = 2.114088\n",
      "epoch 59 loss = 2.075526\n",
      "epoch 60 loss = 2.159892\n",
      "epoch 61 loss = 1.910438\n",
      "epoch 62 loss = 2.132300\n",
      "epoch 63 loss = 2.059448\n",
      "epoch 64 loss = 2.042818\n",
      "epoch 65 loss = 2.075837\n",
      "epoch 66 loss = 1.926633\n",
      "epoch 67 loss = 2.128716\n",
      "epoch 68 loss = 2.244177\n",
      "epoch 69 loss = 2.254147\n",
      "epoch 70 loss = 1.911292\n",
      "epoch 71 loss = 2.175933\n",
      "epoch 72 loss = 2.109439\n",
      "epoch 73 loss = 2.090626\n",
      "epoch 74 loss = 2.031003\n",
      "epoch 75 loss = 2.019680\n",
      "epoch 76 loss = 2.018793\n",
      "epoch 77 loss = 2.000476\n",
      "epoch 78 loss = 2.038552\n",
      "epoch 79 loss = 2.224576\n",
      "epoch 80 loss = 1.975059\n",
      "epoch 81 loss = 2.213407\n",
      "epoch 82 loss = 2.200856\n",
      "epoch 83 loss = 1.941115\n",
      "epoch 84 loss = 1.932977\n",
      "epoch 85 loss = 1.939129\n",
      "epoch 86 loss = 1.933366\n",
      "epoch 87 loss = 2.117677\n",
      "epoch 88 loss = 2.061641\n",
      "epoch 89 loss = 2.082981\n",
      "epoch 90 loss = 2.123842\n",
      "epoch 91 loss = 2.217065\n",
      "epoch 92 loss = 2.146537\n",
      "epoch 93 loss = 2.106618\n",
      "epoch 94 loss = 2.037427\n",
      "epoch 95 loss = 2.172271\n",
      "epoch 96 loss = 2.073786\n",
      "epoch 97 loss = 2.084175\n",
      "epoch 98 loss = 2.073527\n",
      "epoch 99 loss = 1.999775\n",
      "epoch 100 loss = 2.051481\n",
      "epoch 101 loss = 2.122633\n",
      "epoch 102 loss = 1.796829\n",
      "epoch 103 loss = 2.114207\n",
      "epoch 104 loss = 1.916013\n",
      "epoch 105 loss = 1.981338\n",
      "epoch 106 loss = 2.184062\n",
      "epoch 107 loss = 1.905459\n",
      "epoch 108 loss = 1.949736\n",
      "epoch 109 loss = 2.265306\n",
      "epoch 110 loss = 1.934658\n",
      "epoch 111 loss = 2.005572\n",
      "epoch 112 loss = 2.125570\n",
      "epoch 113 loss = 1.954594\n",
      "epoch 114 loss = 2.202315\n",
      "epoch 115 loss = 1.948805\n",
      "epoch 116 loss = 1.960947\n",
      "epoch 117 loss = 2.083064\n",
      "epoch 118 loss = 1.827208\n",
      "epoch 119 loss = 1.876920\n",
      "epoch 120 loss = 1.992578\n",
      "epoch 121 loss = 2.146233\n",
      "epoch 122 loss = 2.160550\n",
      "epoch 123 loss = 1.965392\n",
      "epoch 124 loss = 2.132197\n",
      "epoch 125 loss = 2.030583\n",
      "epoch 126 loss = 2.149070\n",
      "epoch 127 loss = 1.989218\n",
      "epoch 128 loss = 1.968931\n",
      "epoch 129 loss = 1.880216\n",
      "epoch 130 loss = 2.175319\n",
      "epoch 131 loss = 1.914926\n",
      "epoch 132 loss = 1.985432\n",
      "epoch 133 loss = 1.920438\n",
      "epoch 134 loss = 2.159352\n",
      "epoch 135 loss = 2.143705\n",
      "epoch 136 loss = 1.965449\n",
      "epoch 137 loss = 1.936502\n",
      "epoch 138 loss = 2.236723\n",
      "epoch 139 loss = 2.013129\n",
      "epoch 140 loss = 1.885324\n",
      "epoch 141 loss = 1.795026\n",
      "epoch 142 loss = 2.148637\n",
      "epoch 143 loss = 1.961238\n",
      "epoch 144 loss = 2.096660\n",
      "epoch 145 loss = 1.998053\n",
      "epoch 146 loss = 2.106720\n",
      "epoch 147 loss = 2.042939\n",
      "epoch 148 loss = 1.971618\n",
      "epoch 149 loss = 2.200138\n",
      "epoch 150 loss = 1.836488\n",
      "epoch 151 loss = 2.045446\n",
      "epoch 152 loss = 1.892494\n",
      "epoch 153 loss = 1.902092\n",
      "epoch 154 loss = 2.120812\n",
      "epoch 155 loss = 2.052211\n",
      "epoch 156 loss = 2.098236\n",
      "epoch 157 loss = 1.957200\n",
      "epoch 158 loss = 2.015906\n",
      "epoch 159 loss = 1.923149\n",
      "epoch 160 loss = 2.133882\n",
      "epoch 161 loss = 2.048834\n",
      "epoch 162 loss = 1.924229\n",
      "epoch 163 loss = 2.012480\n",
      "epoch 164 loss = 2.197866\n",
      "epoch 165 loss = 1.978920\n",
      "epoch 166 loss = 1.986034\n",
      "epoch 167 loss = 2.149344\n",
      "epoch 168 loss = 2.089048\n",
      "epoch 169 loss = 1.853125\n",
      "epoch 170 loss = 1.949397\n",
      "epoch 171 loss = 2.279450\n",
      "epoch 172 loss = 2.187735\n",
      "epoch 173 loss = 2.104126\n",
      "epoch 174 loss = 1.926982\n",
      "epoch 175 loss = 2.045888\n",
      "epoch 176 loss = 2.040086\n",
      "epoch 177 loss = 2.019511\n",
      "epoch 178 loss = 2.224575\n",
      "epoch 179 loss = 1.929720\n",
      "epoch 180 loss = 2.170382\n",
      "epoch 181 loss = 1.990402\n",
      "epoch 182 loss = 2.093560\n",
      "epoch 183 loss = 2.056627\n",
      "epoch 184 loss = 2.224276\n",
      "epoch 185 loss = 2.074350\n",
      "epoch 186 loss = 2.109249\n",
      "epoch 187 loss = 1.841894\n",
      "epoch 188 loss = 2.098609\n",
      "epoch 189 loss = 2.191772\n",
      "epoch 190 loss = 2.034580\n",
      "epoch 191 loss = 1.982063\n",
      "epoch 192 loss = 2.088149\n",
      "epoch 193 loss = 2.134392\n",
      "epoch 194 loss = 2.025939\n",
      "epoch 195 loss = 1.913976\n",
      "epoch 196 loss = 1.990543\n",
      "epoch 197 loss = 2.178123\n",
      "epoch 198 loss = 2.153243\n",
      "epoch 199 loss = 1.954602\n",
      "epoch 200 loss = 1.926500\n",
      "epoch 201 loss = 2.021119\n",
      "epoch 202 loss = 2.132926\n",
      "epoch 203 loss = 2.058847\n",
      "epoch 204 loss = 2.217390\n",
      "epoch 205 loss = 2.151274\n",
      "epoch 206 loss = 1.970112\n",
      "epoch 207 loss = 2.128802\n",
      "epoch 208 loss = 2.092054\n",
      "epoch 209 loss = 1.958032\n",
      "epoch 210 loss = 1.915480\n",
      "epoch 211 loss = 1.836919\n",
      "epoch 212 loss = 2.015885\n",
      "epoch 213 loss = 1.880414\n",
      "epoch 214 loss = 1.995510\n",
      "epoch 215 loss = 2.225821\n",
      "epoch 216 loss = 1.773912\n",
      "epoch 217 loss = 2.119439\n",
      "epoch 218 loss = 1.884361\n",
      "epoch 219 loss = 2.345683\n",
      "epoch 220 loss = 2.131040\n",
      "epoch 221 loss = 1.717108\n",
      "epoch 222 loss = 1.962422\n",
      "epoch 223 loss = 2.005059\n",
      "epoch 224 loss = 2.004501\n",
      "epoch 225 loss = 1.960094\n",
      "epoch 226 loss = 1.904393\n",
      "epoch 227 loss = 2.085534\n",
      "epoch 228 loss = 2.039895\n",
      "epoch 229 loss = 2.106569\n",
      "epoch 230 loss = 1.849223\n",
      "epoch 231 loss = 2.082701\n",
      "epoch 232 loss = 2.100235\n",
      "epoch 233 loss = 1.831224\n",
      "epoch 234 loss = 1.926543\n",
      "epoch 235 loss = 2.167603\n",
      "epoch 236 loss = 2.213687\n",
      "epoch 237 loss = 1.906625\n",
      "epoch 238 loss = 1.994948\n",
      "epoch 239 loss = 1.995048\n",
      "epoch 240 loss = 1.918035\n",
      "epoch 241 loss = 1.904777\n",
      "epoch 242 loss = 2.105517\n",
      "epoch 243 loss = 1.991067\n",
      "epoch 244 loss = 1.993512\n",
      "epoch 245 loss = 2.014735\n",
      "epoch 246 loss = 1.888080\n",
      "epoch 247 loss = 2.115186\n",
      "epoch 248 loss = 1.858121\n",
      "epoch 249 loss = 2.168943\n",
      "epoch 250 loss = 2.077923\n",
      "epoch 251 loss = 2.211895\n",
      "epoch 252 loss = 2.020129\n",
      "epoch 253 loss = 2.006992\n",
      "epoch 254 loss = 2.058326\n",
      "epoch 255 loss = 2.259313\n",
      "epoch 256 loss = 1.946774\n",
      "epoch 257 loss = 1.996833\n",
      "epoch 258 loss = 2.031584\n",
      "epoch 259 loss = 2.040254\n",
      "epoch 260 loss = 2.093211\n",
      "epoch 261 loss = 2.054445\n",
      "epoch 262 loss = 1.996922\n",
      "epoch 263 loss = 1.938877\n",
      "epoch 264 loss = 2.211346\n",
      "epoch 265 loss = 2.186803\n",
      "epoch 266 loss = 2.046438\n",
      "epoch 267 loss = 2.044916\n",
      "epoch 268 loss = 1.969036\n",
      "epoch 269 loss = 2.106633\n",
      "epoch 270 loss = 2.083009\n",
      "epoch 271 loss = 1.866493\n",
      "epoch 272 loss = 2.038113\n",
      "epoch 273 loss = 2.202884\n",
      "epoch 274 loss = 2.089227\n",
      "epoch 275 loss = 2.186281\n",
      "epoch 276 loss = 1.941996\n",
      "epoch 277 loss = 2.016436\n",
      "epoch 278 loss = 2.180641\n",
      "epoch 279 loss = 2.164819\n",
      "epoch 280 loss = 1.983181\n",
      "epoch 281 loss = 2.023148\n",
      "epoch 282 loss = 1.977192\n",
      "epoch 283 loss = 2.114784\n",
      "epoch 284 loss = 2.166592\n",
      "epoch 285 loss = 2.154333\n",
      "epoch 286 loss = 2.088802\n",
      "epoch 287 loss = 1.848695\n",
      "epoch 288 loss = 2.217299\n",
      "epoch 289 loss = 2.053234\n",
      "epoch 290 loss = 2.047895\n",
      "epoch 291 loss = 1.981552\n",
      "epoch 292 loss = 2.153054\n",
      "epoch 293 loss = 1.907029\n",
      "epoch 294 loss = 2.152921\n",
      "epoch 295 loss = 2.067051\n",
      "epoch 296 loss = 1.871869\n",
      "epoch 297 loss = 2.044256\n",
      "epoch 298 loss = 1.999222\n",
      "epoch 299 loss = 2.070424\n",
      "epoch 300 loss = 2.171142\n",
      "epoch 301 loss = 2.102841\n",
      "epoch 302 loss = 2.151114\n",
      "epoch 303 loss = 1.891548\n",
      "epoch 304 loss = 1.886050\n",
      "epoch 305 loss = 2.073096\n",
      "epoch 306 loss = 2.095767\n",
      "epoch 307 loss = 1.940818\n",
      "epoch 308 loss = 2.049943\n",
      "epoch 309 loss = 2.123147\n",
      "epoch 310 loss = 2.157157\n",
      "epoch 311 loss = 2.054823\n",
      "epoch 312 loss = 2.031948\n",
      "epoch 313 loss = 2.103744\n",
      "epoch 314 loss = 2.138982\n",
      "epoch 315 loss = 2.053768\n",
      "epoch 316 loss = 1.982751\n",
      "epoch 317 loss = 1.929293\n",
      "epoch 318 loss = 2.052768\n",
      "epoch 319 loss = 1.978812\n",
      "epoch 320 loss = 1.963653\n",
      "epoch 321 loss = 2.067358\n",
      "epoch 322 loss = 2.167611\n",
      "epoch 323 loss = 2.009641\n",
      "epoch 324 loss = 2.149867\n",
      "epoch 325 loss = 1.800508\n",
      "epoch 326 loss = 1.991624\n",
      "epoch 327 loss = 2.080495\n",
      "epoch 328 loss = 1.909860\n",
      "epoch 329 loss = 2.190179\n",
      "epoch 330 loss = 2.313675\n",
      "epoch 331 loss = 2.001342\n",
      "epoch 332 loss = 2.322840\n",
      "epoch 333 loss = 1.999397\n",
      "epoch 334 loss = 2.148391\n",
      "epoch 335 loss = 2.016871\n",
      "epoch 336 loss = 2.025339\n",
      "epoch 337 loss = 2.063072\n",
      "epoch 338 loss = 1.981049\n",
      "epoch 339 loss = 1.924116\n",
      "epoch 340 loss = 2.066385\n",
      "epoch 341 loss = 1.995282\n",
      "epoch 342 loss = 1.982576\n",
      "epoch 343 loss = 2.090957\n",
      "epoch 344 loss = 2.188891\n",
      "epoch 345 loss = 1.998806\n",
      "epoch 346 loss = 1.945267\n",
      "epoch 347 loss = 2.034709\n",
      "epoch 348 loss = 1.943502\n",
      "epoch 349 loss = 2.077981\n",
      "epoch 350 loss = 2.041599\n",
      "epoch 351 loss = 2.004080\n",
      "epoch 352 loss = 2.124408\n",
      "epoch 353 loss = 1.919137\n",
      "epoch 354 loss = 2.246735\n",
      "epoch 355 loss = 2.137779\n",
      "epoch 356 loss = 1.951483\n",
      "epoch 357 loss = 1.882939\n",
      "epoch 358 loss = 2.146009\n",
      "epoch 359 loss = 2.162385\n",
      "epoch 360 loss = 1.920009\n",
      "epoch 361 loss = 2.053580\n",
      "epoch 362 loss = 1.886204\n",
      "epoch 363 loss = 2.106138\n",
      "epoch 364 loss = 2.242482\n",
      "epoch 365 loss = 2.262169\n",
      "epoch 366 loss = 2.035836\n",
      "epoch 367 loss = 2.155065\n",
      "epoch 368 loss = 2.012338\n",
      "epoch 369 loss = 2.124713\n",
      "epoch 370 loss = 2.189072\n",
      "epoch 371 loss = 1.984317\n",
      "epoch 372 loss = 2.170343\n",
      "epoch 373 loss = 2.092431\n",
      "epoch 374 loss = 2.084635\n",
      "epoch 375 loss = 2.124451\n",
      "epoch 376 loss = 2.046593\n",
      "epoch 377 loss = 2.317435\n",
      "epoch 378 loss = 2.082111\n",
      "epoch 379 loss = 2.144493\n",
      "epoch 380 loss = 1.913797\n",
      "epoch 381 loss = 1.972738\n",
      "epoch 382 loss = 2.154894\n",
      "epoch 383 loss = 1.974943\n",
      "epoch 384 loss = 2.069869\n",
      "epoch 385 loss = 2.045520\n",
      "epoch 386 loss = 1.836676\n",
      "epoch 387 loss = 1.971059\n",
      "epoch 388 loss = 2.041372\n",
      "epoch 389 loss = 2.005281\n",
      "epoch 390 loss = 1.940547\n",
      "epoch 391 loss = 1.922456\n",
      "epoch 392 loss = 2.119967\n",
      "epoch 393 loss = 2.032643\n",
      "epoch 394 loss = 1.910313\n",
      "epoch 395 loss = 1.915628\n",
      "epoch 396 loss = 2.022295\n",
      "epoch 397 loss = 2.140385\n",
      "epoch 398 loss = 1.865609\n",
      "epoch 399 loss = 1.824354\n",
      "epoch 400 loss = 2.014806\n",
      "epoch 401 loss = 2.097173\n",
      "epoch 402 loss = 2.073080\n",
      "epoch 403 loss = 1.987099\n",
      "epoch 404 loss = 2.281838\n",
      "epoch 405 loss = 2.000971\n",
      "epoch 406 loss = 1.993495\n",
      "epoch 407 loss = 2.041918\n",
      "epoch 408 loss = 1.794210\n",
      "epoch 409 loss = 1.972147\n",
      "epoch 410 loss = 1.920196\n",
      "epoch 411 loss = 2.166185\n",
      "epoch 412 loss = 1.902463\n",
      "epoch 413 loss = 1.898372\n",
      "epoch 414 loss = 1.918280\n",
      "epoch 415 loss = 2.097576\n",
      "epoch 416 loss = 1.911831\n",
      "epoch 417 loss = 2.227203\n",
      "epoch 418 loss = 1.996523\n",
      "epoch 419 loss = 2.177045\n",
      "epoch 420 loss = 2.025507\n",
      "epoch 421 loss = 2.003372\n",
      "epoch 422 loss = 1.954309\n",
      "epoch 423 loss = 1.983308\n",
      "epoch 424 loss = 2.030677\n",
      "epoch 425 loss = 1.905995\n",
      "epoch 426 loss = 1.796954\n",
      "epoch 427 loss = 2.225832\n",
      "epoch 428 loss = 2.067158\n",
      "epoch 429 loss = 2.159276\n",
      "epoch 430 loss = 2.005613\n",
      "epoch 431 loss = 1.833804\n",
      "epoch 432 loss = 2.055273\n",
      "epoch 433 loss = 2.155285\n",
      "epoch 434 loss = 2.011699\n",
      "epoch 435 loss = 2.202505\n",
      "epoch 436 loss = 2.116085\n",
      "epoch 437 loss = 2.037081\n",
      "epoch 438 loss = 2.022202\n",
      "epoch 439 loss = 1.923027\n",
      "epoch 440 loss = 2.071255\n",
      "epoch 441 loss = 2.125919\n",
      "epoch 442 loss = 1.973624\n",
      "epoch 443 loss = 1.906285\n",
      "epoch 444 loss = 2.204905\n",
      "epoch 445 loss = 2.033641\n",
      "epoch 446 loss = 1.874829\n",
      "epoch 447 loss = 2.123348\n",
      "epoch 448 loss = 2.148513\n",
      "epoch 449 loss = 1.742200\n",
      "epoch 450 loss = 1.887454\n",
      "epoch 451 loss = 1.961645\n",
      "epoch 452 loss = 2.001567\n",
      "epoch 453 loss = 2.080002\n",
      "epoch 454 loss = 1.968826\n",
      "epoch 455 loss = 2.021122\n",
      "epoch 456 loss = 2.000144\n",
      "epoch 457 loss = 1.976971\n",
      "epoch 458 loss = 1.922601\n",
      "epoch 459 loss = 2.008562\n",
      "epoch 460 loss = 2.113282\n",
      "epoch 461 loss = 2.077731\n",
      "epoch 462 loss = 1.814938\n",
      "epoch 463 loss = 1.959819\n",
      "epoch 464 loss = 2.125263\n",
      "epoch 465 loss = 2.228273\n",
      "epoch 466 loss = 1.941183\n",
      "epoch 467 loss = 2.029804\n",
      "epoch 468 loss = 1.941476\n",
      "epoch 469 loss = 1.860806\n",
      "epoch 470 loss = 2.016798\n",
      "epoch 471 loss = 1.821405\n",
      "epoch 472 loss = 1.851878\n",
      "epoch 473 loss = 1.865285\n",
      "epoch 474 loss = 2.011642\n",
      "epoch 475 loss = 1.974623\n",
      "epoch 476 loss = 2.036669\n",
      "epoch 477 loss = 1.990953\n",
      "epoch 478 loss = 2.055090\n",
      "epoch 479 loss = 1.883229\n",
      "epoch 480 loss = 2.033118\n",
      "epoch 481 loss = 1.971598\n",
      "epoch 482 loss = 2.142233\n",
      "epoch 483 loss = 2.089336\n",
      "epoch 484 loss = 2.077327\n",
      "epoch 485 loss = 1.886706\n",
      "epoch 486 loss = 2.008662\n",
      "epoch 487 loss = 1.811352\n",
      "epoch 488 loss = 2.098368\n",
      "epoch 489 loss = 2.142942\n",
      "epoch 490 loss = 1.882837\n",
      "epoch 491 loss = 2.030064\n",
      "epoch 492 loss = 1.934538\n",
      "epoch 493 loss = 1.949117\n",
      "epoch 494 loss = 2.024607\n",
      "epoch 495 loss = 1.962038\n",
      "epoch 496 loss = 1.932761\n",
      "epoch 497 loss = 2.144394\n",
      "epoch 498 loss = 1.801327\n",
      "epoch 499 loss = 2.090900\n",
      "final loss = 2.090900\n",
      "accuracy_mc = tensor(0.2702, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2750, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.9713, device='cuda:0')\n",
      "training time = 304.814252614975 seconds\n",
      "testing time = 3.2510244846343994 seconds\n",
      "\n",
      "Training with split 5\n",
      "epoch 0 loss = 2.299954\n",
      "epoch 1 loss = 2.260417\n",
      "epoch 2 loss = 2.226501\n",
      "epoch 3 loss = 2.304123\n",
      "epoch 4 loss = 2.151318\n",
      "epoch 5 loss = 2.320581\n",
      "epoch 6 loss = 2.319239\n",
      "epoch 7 loss = 2.226741\n",
      "epoch 8 loss = 2.146188\n",
      "epoch 9 loss = 2.267866\n",
      "epoch 10 loss = 2.156364\n",
      "epoch 11 loss = 2.056939\n",
      "epoch 12 loss = 2.093282\n",
      "epoch 13 loss = 2.357142\n",
      "epoch 14 loss = 2.137142\n",
      "epoch 15 loss = 2.027100\n",
      "epoch 16 loss = 1.945880\n",
      "epoch 17 loss = 2.081905\n",
      "epoch 18 loss = 2.141800\n",
      "epoch 19 loss = 2.016395\n",
      "epoch 20 loss = 2.154028\n",
      "epoch 21 loss = 2.235674\n",
      "epoch 22 loss = 2.280022\n",
      "epoch 23 loss = 2.148077\n",
      "epoch 24 loss = 2.158103\n",
      "epoch 25 loss = 2.069916\n",
      "epoch 26 loss = 2.215153\n",
      "epoch 27 loss = 2.228290\n",
      "epoch 28 loss = 2.224144\n",
      "epoch 29 loss = 2.139571\n",
      "epoch 30 loss = 2.290106\n",
      "epoch 31 loss = 2.135544\n",
      "epoch 32 loss = 2.178516\n",
      "epoch 33 loss = 2.092549\n",
      "epoch 34 loss = 2.077600\n",
      "epoch 35 loss = 2.094825\n",
      "epoch 36 loss = 2.310401\n",
      "epoch 37 loss = 2.214914\n",
      "epoch 38 loss = 2.317659\n",
      "epoch 39 loss = 2.290439\n",
      "epoch 40 loss = 2.295521\n",
      "epoch 41 loss = 2.378350\n",
      "epoch 42 loss = 2.242589\n",
      "epoch 43 loss = 2.194151\n",
      "epoch 44 loss = 2.375899\n",
      "epoch 45 loss = 2.131380\n",
      "epoch 46 loss = 2.203594\n",
      "epoch 47 loss = 2.375789\n",
      "epoch 48 loss = 2.078754\n",
      "epoch 49 loss = 2.270721\n",
      "epoch 50 loss = 2.286277\n",
      "epoch 51 loss = 2.375185\n",
      "epoch 52 loss = 2.249152\n",
      "epoch 53 loss = 2.161564\n",
      "epoch 54 loss = 2.014809\n",
      "epoch 55 loss = 2.390457\n",
      "epoch 56 loss = 2.219973\n",
      "epoch 57 loss = 2.068943\n",
      "epoch 58 loss = 2.133416\n",
      "epoch 59 loss = 2.136828\n",
      "epoch 60 loss = 2.065989\n",
      "epoch 61 loss = 2.124852\n",
      "epoch 62 loss = 2.213520\n",
      "epoch 63 loss = 2.111978\n",
      "epoch 64 loss = 2.439269\n",
      "epoch 65 loss = 2.240395\n",
      "epoch 66 loss = 2.311045\n",
      "epoch 67 loss = 1.967760\n",
      "epoch 68 loss = 2.203221\n",
      "epoch 69 loss = 2.323722\n",
      "epoch 70 loss = 2.110890\n",
      "epoch 71 loss = 2.162524\n",
      "epoch 72 loss = 2.262173\n",
      "epoch 73 loss = 2.218402\n",
      "epoch 74 loss = 2.090683\n",
      "epoch 75 loss = 2.298702\n",
      "epoch 76 loss = 2.274056\n",
      "epoch 77 loss = 2.183687\n",
      "epoch 78 loss = 2.201113\n",
      "epoch 79 loss = 2.116355\n",
      "epoch 80 loss = 2.083570\n",
      "epoch 81 loss = 2.329293\n",
      "epoch 82 loss = 2.255042\n",
      "epoch 83 loss = 2.184723\n",
      "epoch 84 loss = 1.937225\n",
      "epoch 85 loss = 2.148046\n",
      "epoch 86 loss = 2.184611\n",
      "epoch 87 loss = 2.218314\n",
      "epoch 88 loss = 2.252858\n",
      "epoch 89 loss = 2.020835\n",
      "epoch 90 loss = 2.305129\n",
      "epoch 91 loss = 2.108231\n",
      "epoch 92 loss = 2.136061\n",
      "epoch 93 loss = 2.134419\n",
      "epoch 94 loss = 2.179282\n",
      "epoch 95 loss = 2.367169\n",
      "epoch 96 loss = 2.149184\n",
      "epoch 97 loss = 2.066662\n",
      "epoch 98 loss = 2.042670\n",
      "epoch 99 loss = 2.082667\n",
      "epoch 100 loss = 2.261753\n",
      "epoch 101 loss = 2.127117\n",
      "epoch 102 loss = 1.974720\n",
      "epoch 103 loss = 2.080963\n",
      "epoch 104 loss = 2.251689\n",
      "epoch 105 loss = 2.129164\n",
      "epoch 106 loss = 2.243805\n",
      "epoch 107 loss = 2.235091\n",
      "epoch 108 loss = 1.964167\n",
      "epoch 109 loss = 2.105181\n",
      "epoch 110 loss = 2.184445\n",
      "epoch 111 loss = 2.190943\n",
      "epoch 112 loss = 2.224097\n",
      "epoch 113 loss = 1.930107\n",
      "epoch 114 loss = 2.089609\n",
      "epoch 115 loss = 2.157606\n",
      "epoch 116 loss = 2.346256\n",
      "epoch 117 loss = 2.201449\n",
      "epoch 118 loss = 2.175464\n",
      "epoch 119 loss = 2.109256\n",
      "epoch 120 loss = 2.197881\n",
      "epoch 121 loss = 2.325603\n",
      "epoch 122 loss = 2.088794\n",
      "epoch 123 loss = 2.166235\n",
      "epoch 124 loss = 2.156259\n",
      "epoch 125 loss = 2.138281\n",
      "epoch 126 loss = 2.112315\n",
      "epoch 127 loss = 2.275213\n",
      "epoch 128 loss = 2.354768\n",
      "epoch 129 loss = 2.242920\n",
      "epoch 130 loss = 2.120161\n",
      "epoch 131 loss = 2.082688\n",
      "epoch 132 loss = 2.246500\n",
      "epoch 133 loss = 2.352034\n",
      "epoch 134 loss = 2.201856\n",
      "epoch 135 loss = 2.093774\n",
      "epoch 136 loss = 2.262336\n",
      "epoch 137 loss = 2.434182\n",
      "epoch 138 loss = 2.006333\n",
      "epoch 139 loss = 2.237839\n",
      "epoch 140 loss = 2.005305\n",
      "epoch 141 loss = 2.169654\n",
      "epoch 142 loss = 2.204467\n",
      "epoch 143 loss = 2.303836\n",
      "epoch 144 loss = 2.120048\n",
      "epoch 145 loss = 2.159453\n",
      "epoch 146 loss = 2.007879\n",
      "epoch 147 loss = 2.249477\n",
      "epoch 148 loss = 2.183134\n",
      "epoch 149 loss = 2.303530\n",
      "epoch 150 loss = 2.143665\n",
      "epoch 151 loss = 2.273570\n",
      "epoch 152 loss = 2.215560\n",
      "epoch 153 loss = 2.125630\n",
      "epoch 154 loss = 2.280309\n",
      "epoch 155 loss = 2.093857\n",
      "epoch 156 loss = 2.106154\n",
      "epoch 157 loss = 2.000931\n",
      "epoch 158 loss = 2.045851\n",
      "epoch 159 loss = 2.289810\n",
      "epoch 160 loss = 2.467064\n",
      "epoch 161 loss = 2.261072\n",
      "epoch 162 loss = 2.309383\n",
      "epoch 163 loss = 2.186357\n",
      "epoch 164 loss = 2.281891\n",
      "epoch 165 loss = 2.059786\n",
      "epoch 166 loss = 2.183824\n",
      "epoch 167 loss = 2.181979\n",
      "epoch 168 loss = 2.190765\n",
      "epoch 169 loss = 2.063098\n",
      "epoch 170 loss = 2.121929\n",
      "epoch 171 loss = 2.206431\n",
      "epoch 172 loss = 2.362050\n",
      "epoch 173 loss = 1.967401\n",
      "epoch 174 loss = 2.331782\n",
      "epoch 175 loss = 2.147941\n",
      "epoch 176 loss = 2.100507\n",
      "epoch 177 loss = 2.216267\n",
      "epoch 178 loss = 2.044085\n",
      "epoch 179 loss = 2.135293\n",
      "epoch 180 loss = 2.408157\n",
      "epoch 181 loss = 2.125385\n",
      "epoch 182 loss = 2.315157\n",
      "epoch 183 loss = 2.415428\n",
      "epoch 184 loss = 2.208689\n",
      "epoch 185 loss = 2.156726\n",
      "epoch 186 loss = 2.162981\n",
      "epoch 187 loss = 2.151411\n",
      "epoch 188 loss = 2.049751\n",
      "epoch 189 loss = 2.245177\n",
      "epoch 190 loss = 2.036658\n",
      "epoch 191 loss = 2.083851\n",
      "epoch 192 loss = 2.355597\n",
      "epoch 193 loss = 2.356916\n",
      "epoch 194 loss = 2.037816\n",
      "epoch 195 loss = 2.145744\n",
      "epoch 196 loss = 1.994678\n",
      "epoch 197 loss = 2.214150\n",
      "epoch 198 loss = 2.306529\n",
      "epoch 199 loss = 2.267678\n",
      "epoch 200 loss = 2.253116\n",
      "epoch 201 loss = 2.157831\n",
      "epoch 202 loss = 2.190933\n",
      "epoch 203 loss = 2.143398\n",
      "epoch 204 loss = 2.180139\n",
      "epoch 205 loss = 2.248882\n",
      "epoch 206 loss = 2.058672\n",
      "epoch 207 loss = 2.156472\n",
      "epoch 208 loss = 2.037194\n",
      "epoch 209 loss = 2.429972\n",
      "epoch 210 loss = 2.127489\n",
      "epoch 211 loss = 2.220043\n",
      "epoch 212 loss = 2.199549\n",
      "epoch 213 loss = 2.166944\n",
      "epoch 214 loss = 2.292290\n",
      "epoch 215 loss = 2.044869\n",
      "epoch 216 loss = 2.089249\n",
      "epoch 217 loss = 2.040309\n",
      "epoch 218 loss = 2.036070\n",
      "epoch 219 loss = 2.219135\n",
      "epoch 220 loss = 2.433741\n",
      "epoch 221 loss = 2.491751\n",
      "epoch 222 loss = 2.354235\n",
      "epoch 223 loss = 2.227217\n",
      "epoch 224 loss = 2.169022\n",
      "epoch 225 loss = 2.176419\n",
      "epoch 226 loss = 2.380137\n",
      "epoch 227 loss = 2.219188\n",
      "epoch 228 loss = 2.330896\n",
      "epoch 229 loss = 2.166167\n",
      "epoch 230 loss = 2.119488\n",
      "epoch 231 loss = 2.201312\n",
      "epoch 232 loss = 2.089058\n",
      "epoch 233 loss = 2.336107\n",
      "epoch 234 loss = 2.099276\n",
      "epoch 235 loss = 2.258456\n",
      "epoch 236 loss = 2.272738\n",
      "epoch 237 loss = 2.175947\n",
      "epoch 238 loss = 2.173131\n",
      "epoch 239 loss = 2.131386\n",
      "epoch 240 loss = 2.250572\n",
      "epoch 241 loss = 2.357118\n",
      "epoch 242 loss = 2.246635\n",
      "epoch 243 loss = 2.355488\n",
      "epoch 244 loss = 2.439246\n",
      "epoch 245 loss = 2.387550\n",
      "epoch 246 loss = 2.251986\n",
      "epoch 247 loss = 2.228127\n",
      "epoch 248 loss = 2.310882\n",
      "epoch 249 loss = 2.085418\n",
      "epoch 250 loss = 2.072389\n",
      "epoch 251 loss = 2.406441\n",
      "epoch 252 loss = 2.208417\n",
      "epoch 253 loss = 2.117281\n",
      "epoch 254 loss = 2.273287\n",
      "epoch 255 loss = 2.130862\n",
      "epoch 256 loss = 2.276007\n",
      "epoch 257 loss = 1.980243\n",
      "epoch 258 loss = 2.244854\n",
      "epoch 259 loss = 2.218771\n",
      "epoch 260 loss = 2.252463\n",
      "epoch 261 loss = 2.115045\n",
      "epoch 262 loss = 2.326499\n",
      "epoch 263 loss = 2.363651\n",
      "epoch 264 loss = 2.251355\n",
      "epoch 265 loss = 2.152814\n",
      "epoch 266 loss = 2.325475\n",
      "epoch 267 loss = 2.093418\n",
      "epoch 268 loss = 2.145961\n",
      "epoch 269 loss = 2.344171\n",
      "epoch 270 loss = 2.276673\n",
      "epoch 271 loss = 2.239145\n",
      "epoch 272 loss = 2.115291\n",
      "epoch 273 loss = 2.219567\n",
      "epoch 274 loss = 2.182492\n",
      "epoch 275 loss = 2.126574\n",
      "epoch 276 loss = 2.223259\n",
      "epoch 277 loss = 2.224262\n",
      "epoch 278 loss = 2.080806\n",
      "epoch 279 loss = 2.074249\n",
      "epoch 280 loss = 2.250387\n",
      "epoch 281 loss = 2.055562\n",
      "epoch 282 loss = 2.291499\n",
      "epoch 283 loss = 2.096414\n",
      "epoch 284 loss = 2.255851\n",
      "epoch 285 loss = 2.223849\n",
      "epoch 286 loss = 2.060301\n",
      "epoch 287 loss = 2.070702\n",
      "epoch 288 loss = 2.081900\n",
      "epoch 289 loss = 2.336820\n",
      "epoch 290 loss = 2.184019\n",
      "epoch 291 loss = 2.140162\n",
      "epoch 292 loss = 1.977538\n",
      "epoch 293 loss = 2.463144\n",
      "epoch 294 loss = 2.105452\n",
      "epoch 295 loss = 2.310662\n",
      "epoch 296 loss = 2.124636\n",
      "epoch 297 loss = 2.075182\n",
      "epoch 298 loss = 2.046622\n",
      "epoch 299 loss = 2.160856\n",
      "epoch 300 loss = 2.345729\n",
      "epoch 301 loss = 2.017289\n",
      "epoch 302 loss = 2.277295\n",
      "epoch 303 loss = 2.219572\n",
      "epoch 304 loss = 2.131509\n",
      "epoch 305 loss = 2.279909\n",
      "epoch 306 loss = 2.203554\n",
      "epoch 307 loss = 2.117878\n",
      "epoch 308 loss = 2.232252\n",
      "epoch 309 loss = 2.030955\n",
      "epoch 310 loss = 2.240125\n",
      "epoch 311 loss = 2.166132\n",
      "epoch 312 loss = 2.171994\n",
      "epoch 313 loss = 2.172264\n",
      "epoch 314 loss = 2.145423\n",
      "epoch 315 loss = 2.095397\n",
      "epoch 316 loss = 2.206334\n",
      "epoch 317 loss = 2.196176\n",
      "epoch 318 loss = 2.270859\n",
      "epoch 319 loss = 2.270167\n",
      "epoch 320 loss = 2.377769\n",
      "epoch 321 loss = 2.078616\n",
      "epoch 322 loss = 2.202588\n",
      "epoch 323 loss = 2.028860\n",
      "epoch 324 loss = 2.381905\n",
      "epoch 325 loss = 2.267951\n",
      "epoch 326 loss = 2.191810\n",
      "epoch 327 loss = 2.230314\n",
      "epoch 328 loss = 2.317651\n",
      "epoch 329 loss = 2.316910\n",
      "epoch 330 loss = 2.402267\n",
      "epoch 331 loss = 2.071797\n",
      "epoch 332 loss = 2.079983\n",
      "epoch 333 loss = 2.155105\n",
      "epoch 334 loss = 2.198120\n",
      "epoch 335 loss = 2.303210\n",
      "epoch 336 loss = 2.094013\n",
      "epoch 337 loss = 2.355803\n",
      "epoch 338 loss = 2.120034\n",
      "epoch 339 loss = 2.160784\n",
      "epoch 340 loss = 2.293432\n",
      "epoch 341 loss = 2.215834\n",
      "epoch 342 loss = 2.058724\n",
      "epoch 343 loss = 2.118802\n",
      "epoch 344 loss = 2.110373\n",
      "epoch 345 loss = 2.053848\n",
      "epoch 346 loss = 2.051842\n",
      "epoch 347 loss = 2.154942\n",
      "epoch 348 loss = 2.215980\n",
      "epoch 349 loss = 2.024001\n",
      "epoch 350 loss = 2.399878\n",
      "epoch 351 loss = 2.185466\n",
      "epoch 352 loss = 2.038376\n",
      "epoch 353 loss = 2.043655\n",
      "epoch 354 loss = 2.204521\n",
      "epoch 355 loss = 2.099631\n",
      "epoch 356 loss = 2.230628\n",
      "epoch 357 loss = 1.991749\n",
      "epoch 358 loss = 2.250067\n",
      "epoch 359 loss = 2.070750\n",
      "epoch 360 loss = 2.266969\n",
      "epoch 361 loss = 2.263190\n",
      "epoch 362 loss = 2.389589\n",
      "epoch 363 loss = 2.044630\n",
      "epoch 364 loss = 2.221284\n",
      "epoch 365 loss = 2.045296\n",
      "epoch 366 loss = 2.049999\n",
      "epoch 367 loss = 2.112816\n",
      "epoch 368 loss = 2.245299\n",
      "epoch 369 loss = 2.517954\n",
      "epoch 370 loss = 2.143641\n",
      "epoch 371 loss = 2.190791\n",
      "epoch 372 loss = 2.105633\n",
      "epoch 373 loss = 1.971120\n",
      "epoch 374 loss = 2.054253\n",
      "epoch 375 loss = 2.099393\n",
      "epoch 376 loss = 2.197951\n",
      "epoch 377 loss = 2.123929\n",
      "epoch 378 loss = 2.149659\n",
      "epoch 379 loss = 2.417895\n",
      "epoch 380 loss = 2.267946\n",
      "epoch 381 loss = 2.138300\n",
      "epoch 382 loss = 2.305459\n",
      "epoch 383 loss = 2.229731\n",
      "epoch 384 loss = 2.192934\n",
      "epoch 385 loss = 1.999854\n",
      "epoch 386 loss = 2.068609\n",
      "epoch 387 loss = 2.184688\n",
      "epoch 388 loss = 2.175822\n",
      "epoch 389 loss = 2.180538\n",
      "epoch 390 loss = 2.028752\n",
      "epoch 391 loss = 2.028151\n",
      "epoch 392 loss = 2.026708\n",
      "epoch 393 loss = 2.285178\n",
      "epoch 394 loss = 2.135996\n",
      "epoch 395 loss = 2.201327\n",
      "epoch 396 loss = 2.170047\n",
      "epoch 397 loss = 2.300184\n",
      "epoch 398 loss = 1.943849\n",
      "epoch 399 loss = 2.408870\n",
      "epoch 400 loss = 2.386173\n",
      "epoch 401 loss = 2.300053\n",
      "epoch 402 loss = 1.969307\n",
      "epoch 403 loss = 1.941566\n",
      "epoch 404 loss = 2.018138\n",
      "epoch 405 loss = 2.385694\n",
      "epoch 406 loss = 2.046728\n",
      "epoch 407 loss = 2.177702\n",
      "epoch 408 loss = 2.226163\n",
      "epoch 409 loss = 2.245564\n",
      "epoch 410 loss = 2.257266\n",
      "epoch 411 loss = 2.257421\n",
      "epoch 412 loss = 2.452724\n",
      "epoch 413 loss = 2.041678\n",
      "epoch 414 loss = 1.981323\n",
      "epoch 415 loss = 2.050150\n",
      "epoch 416 loss = 2.088671\n",
      "epoch 417 loss = 2.144882\n",
      "epoch 418 loss = 2.125998\n",
      "epoch 419 loss = 1.999113\n",
      "epoch 420 loss = 2.214302\n",
      "epoch 421 loss = 2.197590\n",
      "epoch 422 loss = 2.379675\n",
      "epoch 423 loss = 1.989051\n",
      "epoch 424 loss = 2.207485\n",
      "epoch 425 loss = 2.182590\n",
      "epoch 426 loss = 2.240283\n",
      "epoch 427 loss = 2.235080\n",
      "epoch 428 loss = 2.148640\n",
      "epoch 429 loss = 2.093919\n",
      "epoch 430 loss = 2.019583\n",
      "epoch 431 loss = 2.093799\n",
      "epoch 432 loss = 2.086260\n",
      "epoch 433 loss = 2.074339\n",
      "epoch 434 loss = 2.183610\n",
      "epoch 435 loss = 2.221487\n",
      "epoch 436 loss = 2.146779\n",
      "epoch 437 loss = 1.991930\n",
      "epoch 438 loss = 2.218486\n",
      "epoch 439 loss = 2.155857\n",
      "epoch 440 loss = 2.345124\n",
      "epoch 441 loss = 2.338711\n",
      "epoch 442 loss = 1.879606\n",
      "epoch 443 loss = 1.970839\n",
      "epoch 444 loss = 2.223686\n",
      "epoch 445 loss = 2.159865\n",
      "epoch 446 loss = 2.086867\n",
      "epoch 447 loss = 2.075667\n",
      "epoch 448 loss = 2.319446\n",
      "epoch 449 loss = 2.239145\n",
      "epoch 450 loss = 2.292761\n",
      "epoch 451 loss = 2.022296\n",
      "epoch 452 loss = 2.256743\n",
      "epoch 453 loss = 2.184386\n",
      "epoch 454 loss = 2.143395\n",
      "epoch 455 loss = 2.175802\n",
      "epoch 456 loss = 2.285859\n",
      "epoch 457 loss = 2.214673\n",
      "epoch 458 loss = 2.096042\n",
      "epoch 459 loss = 2.157989\n",
      "epoch 460 loss = 2.184248\n",
      "epoch 461 loss = 2.367280\n",
      "epoch 462 loss = 2.328854\n",
      "epoch 463 loss = 2.059309\n",
      "epoch 464 loss = 2.263395\n",
      "epoch 465 loss = 2.176234\n",
      "epoch 466 loss = 2.301383\n",
      "epoch 467 loss = 2.042505\n",
      "epoch 468 loss = 2.369828\n",
      "epoch 469 loss = 2.181290\n",
      "epoch 470 loss = 2.144196\n",
      "epoch 471 loss = 2.308972\n",
      "epoch 472 loss = 2.104779\n",
      "epoch 473 loss = 2.189198\n",
      "epoch 474 loss = 1.984982\n",
      "epoch 475 loss = 2.143008\n",
      "epoch 476 loss = 1.986657\n",
      "epoch 477 loss = 2.293344\n",
      "epoch 478 loss = 2.173818\n",
      "epoch 479 loss = 2.110521\n",
      "epoch 480 loss = 2.143844\n",
      "epoch 481 loss = 2.118948\n",
      "epoch 482 loss = 2.189820\n",
      "epoch 483 loss = 2.242585\n",
      "epoch 484 loss = 2.211954\n",
      "epoch 485 loss = 2.124661\n",
      "epoch 486 loss = 2.170410\n",
      "epoch 487 loss = 2.220236\n",
      "epoch 488 loss = 2.362341\n",
      "epoch 489 loss = 2.066894\n",
      "epoch 490 loss = 2.059295\n",
      "epoch 491 loss = 2.245710\n",
      "epoch 492 loss = 2.190629\n",
      "epoch 493 loss = 2.171084\n",
      "epoch 494 loss = 2.035771\n",
      "epoch 495 loss = 2.097207\n",
      "epoch 496 loss = 2.274309\n",
      "epoch 497 loss = 2.127368\n",
      "epoch 498 loss = 2.036974\n",
      "epoch 499 loss = 2.228753\n",
      "final loss = 2.228753\n",
      "accuracy_mc = tensor(0.2539, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2337, device='cuda:0')\n",
      "test_ll_mc = tensor(-2.0238, device='cuda:0')\n",
      "training time = 305.45570969581604 seconds\n",
      "testing time = 3.2864577770233154 seconds\n",
      "\n",
      "Training with split 6\n",
      "epoch 0 loss = 2.264802\n",
      "epoch 1 loss = 2.246777\n",
      "epoch 2 loss = 2.344478\n",
      "epoch 3 loss = 2.359929\n",
      "epoch 4 loss = 2.263917\n",
      "epoch 5 loss = 2.320744\n",
      "epoch 6 loss = 2.250128\n",
      "epoch 7 loss = 2.428173\n",
      "epoch 8 loss = 2.285175\n",
      "epoch 9 loss = 2.146845\n",
      "epoch 10 loss = 2.505821\n",
      "epoch 11 loss = 2.338848\n",
      "epoch 12 loss = 2.292657\n",
      "epoch 13 loss = 2.297626\n",
      "epoch 14 loss = 2.200902\n",
      "epoch 15 loss = 2.393281\n",
      "epoch 16 loss = 2.553744\n",
      "epoch 17 loss = 2.374899\n",
      "epoch 18 loss = 2.304614\n",
      "epoch 19 loss = 2.485765\n",
      "epoch 20 loss = 2.575534\n",
      "epoch 21 loss = 2.275147\n",
      "epoch 22 loss = 2.253113\n",
      "epoch 23 loss = 2.474309\n",
      "epoch 24 loss = 2.447294\n",
      "epoch 25 loss = 2.249058\n",
      "epoch 26 loss = 2.521632\n",
      "epoch 27 loss = 2.407878\n",
      "epoch 28 loss = 2.255065\n",
      "epoch 29 loss = 2.168511\n",
      "epoch 30 loss = 2.432704\n",
      "epoch 31 loss = 2.552941\n",
      "epoch 32 loss = 2.428035\n",
      "epoch 33 loss = 2.363151\n",
      "epoch 34 loss = 2.149999\n",
      "epoch 35 loss = 2.403716\n",
      "epoch 36 loss = 2.362109\n",
      "epoch 37 loss = 2.352307\n",
      "epoch 38 loss = 2.404518\n",
      "epoch 39 loss = 2.346224\n",
      "epoch 40 loss = 2.219698\n",
      "epoch 41 loss = 2.278084\n",
      "epoch 42 loss = 2.265134\n",
      "epoch 43 loss = 2.309211\n",
      "epoch 44 loss = 2.473486\n",
      "epoch 45 loss = 2.188395\n",
      "epoch 46 loss = 2.099326\n",
      "epoch 47 loss = 2.434906\n",
      "epoch 48 loss = 2.234529\n",
      "epoch 49 loss = 2.311204\n",
      "epoch 50 loss = 2.423935\n",
      "epoch 51 loss = 2.370579\n",
      "epoch 52 loss = 2.292450\n",
      "epoch 53 loss = 2.285330\n",
      "epoch 54 loss = 2.151880\n",
      "epoch 55 loss = 2.352336\n",
      "epoch 56 loss = 2.302004\n",
      "epoch 57 loss = 2.259965\n",
      "epoch 58 loss = 2.272435\n",
      "epoch 59 loss = 2.136338\n",
      "epoch 60 loss = 2.383762\n",
      "epoch 61 loss = 2.297395\n",
      "epoch 62 loss = 2.078122\n",
      "epoch 63 loss = 2.292072\n",
      "epoch 64 loss = 2.183708\n",
      "epoch 65 loss = 2.299092\n",
      "epoch 66 loss = 2.274114\n",
      "epoch 67 loss = 2.336939\n",
      "epoch 68 loss = 2.360213\n",
      "epoch 69 loss = 2.269230\n",
      "epoch 70 loss = 2.326389\n",
      "epoch 71 loss = 2.164615\n",
      "epoch 72 loss = 2.325957\n",
      "epoch 73 loss = 2.234522\n",
      "epoch 74 loss = 2.408741\n",
      "epoch 75 loss = 2.145794\n",
      "epoch 76 loss = 2.405254\n",
      "epoch 77 loss = 2.286757\n",
      "epoch 78 loss = 2.556345\n",
      "epoch 79 loss = 2.230247\n",
      "epoch 80 loss = 2.259884\n",
      "epoch 81 loss = 2.334052\n",
      "epoch 82 loss = 2.211624\n",
      "epoch 83 loss = 2.230075\n",
      "epoch 84 loss = 2.339992\n",
      "epoch 85 loss = 2.241237\n",
      "epoch 86 loss = 2.462363\n",
      "epoch 87 loss = 2.231224\n",
      "epoch 88 loss = 2.250163\n",
      "epoch 89 loss = 2.514316\n",
      "epoch 90 loss = 2.150350\n",
      "epoch 91 loss = 2.348715\n",
      "epoch 92 loss = 2.310550\n",
      "epoch 93 loss = 2.398554\n",
      "epoch 94 loss = 2.178700\n",
      "epoch 95 loss = 2.257900\n",
      "epoch 96 loss = 2.153178\n",
      "epoch 97 loss = 2.561006\n",
      "epoch 98 loss = 2.163634\n",
      "epoch 99 loss = 2.340500\n",
      "epoch 100 loss = 2.293741\n",
      "epoch 101 loss = 2.177141\n",
      "epoch 102 loss = 2.259634\n",
      "epoch 103 loss = 2.245362\n",
      "epoch 104 loss = 2.291575\n",
      "epoch 105 loss = 2.323268\n",
      "epoch 106 loss = 2.265568\n",
      "epoch 107 loss = 2.130926\n",
      "epoch 108 loss = 2.058090\n",
      "epoch 109 loss = 2.215213\n",
      "epoch 110 loss = 2.464436\n",
      "epoch 111 loss = 2.019805\n",
      "epoch 112 loss = 2.246158\n",
      "epoch 113 loss = 2.299759\n",
      "epoch 114 loss = 2.119683\n",
      "epoch 115 loss = 2.238903\n",
      "epoch 116 loss = 2.028315\n",
      "epoch 117 loss = 2.265987\n",
      "epoch 118 loss = 2.183186\n",
      "epoch 119 loss = 2.323689\n",
      "epoch 120 loss = 2.166071\n",
      "epoch 121 loss = 2.270757\n",
      "epoch 122 loss = 2.252444\n",
      "epoch 123 loss = 2.160977\n",
      "epoch 124 loss = 2.153164\n",
      "epoch 125 loss = 2.276474\n",
      "epoch 126 loss = 2.193710\n",
      "epoch 127 loss = 2.264533\n",
      "epoch 128 loss = 2.363084\n",
      "epoch 129 loss = 2.298300\n",
      "epoch 130 loss = 2.302944\n",
      "epoch 131 loss = 2.439822\n",
      "epoch 132 loss = 2.346177\n",
      "epoch 133 loss = 2.305417\n",
      "epoch 134 loss = 2.210062\n",
      "epoch 135 loss = 2.151702\n",
      "epoch 136 loss = 2.232614\n",
      "epoch 137 loss = 2.374900\n",
      "epoch 138 loss = 2.271663\n",
      "epoch 139 loss = 2.301225\n",
      "epoch 140 loss = 2.267307\n",
      "epoch 141 loss = 2.137985\n",
      "epoch 142 loss = 2.170670\n",
      "epoch 143 loss = 2.169130\n",
      "epoch 144 loss = 2.362339\n",
      "epoch 145 loss = 2.244927\n",
      "epoch 146 loss = 2.105010\n",
      "epoch 147 loss = 2.309275\n",
      "epoch 148 loss = 2.556328\n",
      "epoch 149 loss = 2.312787\n",
      "epoch 150 loss = 2.329833\n",
      "epoch 151 loss = 2.467067\n",
      "epoch 152 loss = 2.268002\n",
      "epoch 153 loss = 2.045379\n",
      "epoch 154 loss = 2.314171\n",
      "epoch 155 loss = 2.104282\n",
      "epoch 156 loss = 2.093556\n",
      "epoch 157 loss = 2.241125\n",
      "epoch 158 loss = 2.284039\n",
      "epoch 159 loss = 2.284159\n",
      "epoch 160 loss = 2.060596\n",
      "epoch 161 loss = 2.221961\n",
      "epoch 162 loss = 2.003476\n",
      "epoch 163 loss = 2.164013\n",
      "epoch 164 loss = 2.420342\n",
      "epoch 165 loss = 1.972203\n",
      "epoch 166 loss = 2.423471\n",
      "epoch 167 loss = 2.365078\n",
      "epoch 168 loss = 2.175324\n",
      "epoch 169 loss = 2.026051\n",
      "epoch 170 loss = 2.115308\n",
      "epoch 171 loss = 2.140821\n",
      "epoch 172 loss = 2.185294\n",
      "epoch 173 loss = 2.365205\n",
      "epoch 174 loss = 2.152855\n",
      "epoch 175 loss = 2.166400\n",
      "epoch 176 loss = 2.129044\n",
      "epoch 177 loss = 2.243508\n",
      "epoch 178 loss = 2.409637\n",
      "epoch 179 loss = 2.362060\n",
      "epoch 180 loss = 2.293943\n",
      "epoch 181 loss = 2.033158\n",
      "epoch 182 loss = 2.312769\n",
      "epoch 183 loss = 2.132041\n",
      "epoch 184 loss = 2.349505\n",
      "epoch 185 loss = 2.113899\n",
      "epoch 186 loss = 2.462451\n",
      "epoch 187 loss = 2.381308\n",
      "epoch 188 loss = 2.236884\n",
      "epoch 189 loss = 2.278354\n",
      "epoch 190 loss = 2.026897\n",
      "epoch 191 loss = 2.069164\n",
      "epoch 192 loss = 2.200113\n",
      "epoch 193 loss = 2.176634\n",
      "epoch 194 loss = 2.104288\n",
      "epoch 195 loss = 2.498635\n",
      "epoch 196 loss = 2.359457\n",
      "epoch 197 loss = 2.204676\n",
      "epoch 198 loss = 2.096258\n",
      "epoch 199 loss = 2.303773\n",
      "epoch 200 loss = 2.239557\n",
      "epoch 201 loss = 2.416900\n",
      "epoch 202 loss = 2.316247\n",
      "epoch 203 loss = 2.144463\n",
      "epoch 204 loss = 2.109203\n",
      "epoch 205 loss = 2.307641\n",
      "epoch 206 loss = 2.161735\n",
      "epoch 207 loss = 2.187104\n",
      "epoch 208 loss = 2.288642\n",
      "epoch 209 loss = 2.304696\n",
      "epoch 210 loss = 2.187705\n",
      "epoch 211 loss = 2.396075\n",
      "epoch 212 loss = 2.306166\n",
      "epoch 213 loss = 2.212380\n",
      "epoch 214 loss = 2.418426\n",
      "epoch 215 loss = 2.130696\n",
      "epoch 216 loss = 2.190892\n",
      "epoch 217 loss = 2.311906\n",
      "epoch 218 loss = 2.247946\n",
      "epoch 219 loss = 2.095906\n",
      "epoch 220 loss = 2.237984\n",
      "epoch 221 loss = 2.333820\n",
      "epoch 222 loss = 2.064917\n",
      "epoch 223 loss = 2.130725\n",
      "epoch 224 loss = 2.093938\n",
      "epoch 225 loss = 2.356169\n",
      "epoch 226 loss = 2.159931\n",
      "epoch 227 loss = 2.076817\n",
      "epoch 228 loss = 2.162926\n",
      "epoch 229 loss = 2.003505\n",
      "epoch 230 loss = 2.243429\n",
      "epoch 231 loss = 2.446329\n",
      "epoch 232 loss = 2.036376\n",
      "epoch 233 loss = 2.256108\n",
      "epoch 234 loss = 2.376776\n",
      "epoch 235 loss = 2.117632\n",
      "epoch 236 loss = 2.199988\n",
      "epoch 237 loss = 2.329808\n",
      "epoch 238 loss = 2.190588\n",
      "epoch 239 loss = 2.126325\n",
      "epoch 240 loss = 2.291945\n",
      "epoch 241 loss = 2.224556\n",
      "epoch 242 loss = 2.331928\n",
      "epoch 243 loss = 2.581485\n",
      "epoch 244 loss = 2.199411\n",
      "epoch 245 loss = 2.407386\n",
      "epoch 246 loss = 2.148601\n",
      "epoch 247 loss = 2.287369\n",
      "epoch 248 loss = 2.303081\n",
      "epoch 249 loss = 2.494642\n",
      "epoch 250 loss = 2.031479\n",
      "epoch 251 loss = 2.181901\n",
      "epoch 252 loss = 2.259784\n",
      "epoch 253 loss = 2.276057\n",
      "epoch 254 loss = 2.364517\n",
      "epoch 255 loss = 2.203924\n",
      "epoch 256 loss = 2.283674\n",
      "epoch 257 loss = 2.053464\n",
      "epoch 258 loss = 2.434150\n",
      "epoch 259 loss = 2.076491\n",
      "epoch 260 loss = 2.168580\n",
      "epoch 261 loss = 2.044819\n",
      "epoch 262 loss = 2.238758\n",
      "epoch 263 loss = 2.554244\n",
      "epoch 264 loss = 2.261111\n",
      "epoch 265 loss = 2.353809\n",
      "epoch 266 loss = 2.201277\n",
      "epoch 267 loss = 2.326932\n",
      "epoch 268 loss = 2.149458\n",
      "epoch 269 loss = 1.877480\n",
      "epoch 270 loss = 2.310426\n",
      "epoch 271 loss = 2.172805\n",
      "epoch 272 loss = 2.251904\n",
      "epoch 273 loss = 2.270198\n",
      "epoch 274 loss = 2.285332\n",
      "epoch 275 loss = 2.181026\n",
      "epoch 276 loss = 2.095555\n",
      "epoch 277 loss = 2.221364\n",
      "epoch 278 loss = 2.411011\n",
      "epoch 279 loss = 2.045475\n",
      "epoch 280 loss = 2.213345\n",
      "epoch 281 loss = 2.213908\n",
      "epoch 282 loss = 2.289779\n",
      "epoch 283 loss = 2.403296\n",
      "epoch 284 loss = 2.240004\n",
      "epoch 285 loss = 2.259338\n",
      "epoch 286 loss = 2.193692\n",
      "epoch 287 loss = 2.133163\n",
      "epoch 288 loss = 1.999612\n",
      "epoch 289 loss = 2.303554\n",
      "epoch 290 loss = 2.211365\n",
      "epoch 291 loss = 2.266793\n",
      "epoch 292 loss = 2.019868\n",
      "epoch 293 loss = 2.072364\n",
      "epoch 294 loss = 2.209774\n",
      "epoch 295 loss = 2.208296\n",
      "epoch 296 loss = 2.002074\n",
      "epoch 297 loss = 2.172886\n",
      "epoch 298 loss = 2.197356\n",
      "epoch 299 loss = 2.061385\n",
      "epoch 300 loss = 2.103108\n",
      "epoch 301 loss = 2.042380\n",
      "epoch 302 loss = 2.221655\n",
      "epoch 303 loss = 2.236635\n",
      "epoch 304 loss = 2.353446\n",
      "epoch 305 loss = 2.039966\n",
      "epoch 306 loss = 2.200603\n",
      "epoch 307 loss = 2.130146\n",
      "epoch 308 loss = 2.069168\n",
      "epoch 309 loss = 2.261274\n",
      "epoch 310 loss = 2.239722\n",
      "epoch 311 loss = 2.138223\n",
      "epoch 312 loss = 2.212404\n",
      "epoch 313 loss = 2.165473\n",
      "epoch 314 loss = 2.193919\n",
      "epoch 315 loss = 2.388082\n",
      "epoch 316 loss = 2.320290\n",
      "epoch 317 loss = 2.361965\n",
      "epoch 318 loss = 1.994119\n",
      "epoch 319 loss = 2.127964\n",
      "epoch 320 loss = 2.469776\n",
      "epoch 321 loss = 2.370180\n",
      "epoch 322 loss = 2.019310\n",
      "epoch 323 loss = 2.223177\n",
      "epoch 324 loss = 2.074961\n",
      "epoch 325 loss = 2.269401\n",
      "epoch 326 loss = 2.273409\n",
      "epoch 327 loss = 2.333280\n",
      "epoch 328 loss = 2.163836\n",
      "epoch 329 loss = 2.170316\n",
      "epoch 330 loss = 2.154500\n",
      "epoch 331 loss = 2.382281\n",
      "epoch 332 loss = 2.022722\n",
      "epoch 333 loss = 2.363710\n",
      "epoch 334 loss = 2.108170\n",
      "epoch 335 loss = 2.275656\n",
      "epoch 336 loss = 2.019448\n",
      "epoch 337 loss = 2.458639\n",
      "epoch 338 loss = 2.223870\n",
      "epoch 339 loss = 2.258518\n",
      "epoch 340 loss = 2.005174\n",
      "epoch 341 loss = 2.258544\n",
      "epoch 342 loss = 2.073973\n",
      "epoch 343 loss = 2.297838\n",
      "epoch 344 loss = 2.244815\n",
      "epoch 345 loss = 2.192134\n",
      "epoch 346 loss = 2.086209\n",
      "epoch 347 loss = 2.213406\n",
      "epoch 348 loss = 2.337255\n",
      "epoch 349 loss = 2.185991\n",
      "epoch 350 loss = 2.083047\n",
      "epoch 351 loss = 2.125845\n",
      "epoch 352 loss = 2.218594\n",
      "epoch 353 loss = 2.218098\n",
      "epoch 354 loss = 2.058926\n",
      "epoch 355 loss = 2.091446\n",
      "epoch 356 loss = 2.194263\n",
      "epoch 357 loss = 2.361283\n",
      "epoch 358 loss = 2.187052\n",
      "epoch 359 loss = 2.184229\n",
      "epoch 360 loss = 2.311640\n",
      "epoch 361 loss = 2.344098\n",
      "epoch 362 loss = 2.276370\n",
      "epoch 363 loss = 2.047273\n",
      "epoch 364 loss = 2.411032\n",
      "epoch 365 loss = 2.207332\n",
      "epoch 366 loss = 2.351158\n",
      "epoch 367 loss = 2.239576\n",
      "epoch 368 loss = 2.121204\n",
      "epoch 369 loss = 2.089432\n",
      "epoch 370 loss = 2.156243\n",
      "epoch 371 loss = 2.291529\n",
      "epoch 372 loss = 2.189958\n",
      "epoch 373 loss = 2.261992\n",
      "epoch 374 loss = 2.177541\n",
      "epoch 375 loss = 2.260642\n",
      "epoch 376 loss = 2.255529\n",
      "epoch 377 loss = 2.133792\n",
      "epoch 378 loss = 2.060934\n",
      "epoch 379 loss = 2.310523\n",
      "epoch 380 loss = 2.149071\n",
      "epoch 381 loss = 2.367918\n",
      "epoch 382 loss = 2.133753\n",
      "epoch 383 loss = 2.343989\n",
      "epoch 384 loss = 2.154951\n",
      "epoch 385 loss = 2.140209\n",
      "epoch 386 loss = 2.298025\n",
      "epoch 387 loss = 2.070912\n",
      "epoch 388 loss = 2.082777\n",
      "epoch 389 loss = 2.169862\n",
      "epoch 390 loss = 2.329375\n",
      "epoch 391 loss = 2.150523\n",
      "epoch 392 loss = 2.171319\n",
      "epoch 393 loss = 2.293310\n",
      "epoch 394 loss = 2.242094\n",
      "epoch 395 loss = 1.976231\n",
      "epoch 396 loss = 2.307700\n",
      "epoch 397 loss = 2.186105\n",
      "epoch 398 loss = 2.179533\n",
      "epoch 399 loss = 2.104768\n",
      "epoch 400 loss = 2.179051\n",
      "epoch 401 loss = 2.275115\n",
      "epoch 402 loss = 2.129016\n",
      "epoch 403 loss = 2.302194\n",
      "epoch 404 loss = 2.536195\n",
      "epoch 405 loss = 2.139245\n",
      "epoch 406 loss = 2.181561\n",
      "epoch 407 loss = 2.421674\n",
      "epoch 408 loss = 2.231090\n",
      "epoch 409 loss = 2.138508\n",
      "epoch 410 loss = 2.098083\n",
      "epoch 411 loss = 1.992291\n",
      "epoch 412 loss = 2.185445\n",
      "epoch 413 loss = 2.112741\n",
      "epoch 414 loss = 2.165561\n",
      "epoch 415 loss = 2.212800\n",
      "epoch 416 loss = 2.302700\n",
      "epoch 417 loss = 2.250091\n",
      "epoch 418 loss = 2.175717\n",
      "epoch 419 loss = 2.357786\n",
      "epoch 420 loss = 2.345699\n",
      "epoch 421 loss = 2.297346\n",
      "epoch 422 loss = 2.232218\n",
      "epoch 423 loss = 2.218485\n",
      "epoch 424 loss = 2.172525\n",
      "epoch 425 loss = 2.155037\n",
      "epoch 426 loss = 2.159607\n",
      "epoch 427 loss = 2.258255\n",
      "epoch 428 loss = 2.117311\n",
      "epoch 429 loss = 2.227161\n",
      "epoch 430 loss = 2.242320\n",
      "epoch 431 loss = 2.188133\n",
      "epoch 432 loss = 2.236212\n",
      "epoch 433 loss = 2.140198\n",
      "epoch 434 loss = 2.136619\n",
      "epoch 435 loss = 2.267710\n",
      "epoch 436 loss = 2.337398\n",
      "epoch 437 loss = 2.042333\n",
      "epoch 438 loss = 2.066377\n",
      "epoch 439 loss = 2.208788\n",
      "epoch 440 loss = 2.267733\n",
      "epoch 441 loss = 2.293232\n",
      "epoch 442 loss = 2.326657\n",
      "epoch 443 loss = 2.140096\n",
      "epoch 444 loss = 2.182826\n",
      "epoch 445 loss = 2.335099\n",
      "epoch 446 loss = 2.268363\n",
      "epoch 447 loss = 2.146024\n",
      "epoch 448 loss = 2.420511\n",
      "epoch 449 loss = 2.287396\n",
      "epoch 450 loss = 2.352514\n",
      "epoch 451 loss = 2.250997\n",
      "epoch 452 loss = 2.040599\n",
      "epoch 453 loss = 2.256975\n",
      "epoch 454 loss = 2.241102\n",
      "epoch 455 loss = 2.208354\n",
      "epoch 456 loss = 2.083388\n",
      "epoch 457 loss = 2.160822\n",
      "epoch 458 loss = 2.247221\n",
      "epoch 459 loss = 2.366226\n",
      "epoch 460 loss = 2.146307\n",
      "epoch 461 loss = 2.369513\n",
      "epoch 462 loss = 2.072988\n",
      "epoch 463 loss = 2.399217\n",
      "epoch 464 loss = 2.263274\n",
      "epoch 465 loss = 2.120523\n",
      "epoch 466 loss = 1.910604\n",
      "epoch 467 loss = 2.237652\n",
      "epoch 468 loss = 2.132646\n",
      "epoch 469 loss = 1.979511\n",
      "epoch 470 loss = 2.288248\n",
      "epoch 471 loss = 2.105448\n",
      "epoch 472 loss = 2.262974\n",
      "epoch 473 loss = 2.270446\n",
      "epoch 474 loss = 2.225159\n",
      "epoch 475 loss = 1.994407\n",
      "epoch 476 loss = 2.210406\n",
      "epoch 477 loss = 2.124108\n",
      "epoch 478 loss = 2.264386\n",
      "epoch 479 loss = 2.095216\n",
      "epoch 480 loss = 2.330074\n",
      "epoch 481 loss = 2.248603\n",
      "epoch 482 loss = 2.411338\n",
      "epoch 483 loss = 2.270461\n",
      "epoch 484 loss = 2.232422\n",
      "epoch 485 loss = 2.178520\n",
      "epoch 486 loss = 2.187284\n",
      "epoch 487 loss = 2.069098\n",
      "epoch 488 loss = 2.094742\n",
      "epoch 489 loss = 2.262678\n",
      "epoch 490 loss = 2.171639\n",
      "epoch 491 loss = 2.254616\n",
      "epoch 492 loss = 2.486662\n",
      "epoch 493 loss = 2.337602\n",
      "epoch 494 loss = 2.192295\n",
      "epoch 495 loss = 2.034757\n",
      "epoch 496 loss = 2.085267\n",
      "epoch 497 loss = 2.148607\n",
      "epoch 498 loss = 2.171276\n",
      "epoch 499 loss = 2.239187\n",
      "final loss = 2.239187\n",
      "accuracy_mc = tensor(0.1581, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.1677, device='cuda:0')\n",
      "test_ll_mc = tensor(-2.0217, device='cuda:0')\n",
      "training time = 305.1816146373749 seconds\n",
      "testing time = 3.2840235233306885 seconds\n",
      "\n",
      "Training with split 7\n",
      "epoch 0 loss = 2.280055\n",
      "epoch 1 loss = 2.252298\n",
      "epoch 2 loss = 2.301382\n",
      "epoch 3 loss = 2.251972\n",
      "epoch 4 loss = 2.191277\n",
      "epoch 5 loss = 2.209900\n",
      "epoch 6 loss = 2.130570\n",
      "epoch 7 loss = 2.140371\n",
      "epoch 8 loss = 2.169647\n",
      "epoch 9 loss = 2.177083\n",
      "epoch 10 loss = 2.072823\n",
      "epoch 11 loss = 2.170994\n",
      "epoch 12 loss = 2.135318\n",
      "epoch 13 loss = 2.272829\n",
      "epoch 14 loss = 2.192716\n",
      "epoch 15 loss = 2.124368\n",
      "epoch 16 loss = 2.140320\n",
      "epoch 17 loss = 2.031485\n",
      "epoch 18 loss = 2.194355\n",
      "epoch 19 loss = 2.132414\n",
      "epoch 20 loss = 2.135841\n",
      "epoch 21 loss = 1.987905\n",
      "epoch 22 loss = 2.219910\n",
      "epoch 23 loss = 2.125913\n",
      "epoch 24 loss = 2.130777\n",
      "epoch 25 loss = 2.229230\n",
      "epoch 26 loss = 2.111601\n",
      "epoch 27 loss = 2.208626\n",
      "epoch 28 loss = 2.200659\n",
      "epoch 29 loss = 2.128539\n",
      "epoch 30 loss = 2.034002\n",
      "epoch 31 loss = 2.179281\n",
      "epoch 32 loss = 2.100794\n",
      "epoch 33 loss = 2.115592\n",
      "epoch 34 loss = 2.089291\n",
      "epoch 35 loss = 2.166322\n",
      "epoch 36 loss = 2.124112\n",
      "epoch 37 loss = 2.265224\n",
      "epoch 38 loss = 2.088917\n",
      "epoch 39 loss = 2.215466\n",
      "epoch 40 loss = 2.102487\n",
      "epoch 41 loss = 2.101487\n",
      "epoch 42 loss = 2.082150\n",
      "epoch 43 loss = 2.085731\n",
      "epoch 44 loss = 2.259320\n",
      "epoch 45 loss = 2.071045\n",
      "epoch 46 loss = 2.133277\n",
      "epoch 47 loss = 2.151109\n",
      "epoch 48 loss = 2.145583\n",
      "epoch 49 loss = 1.962166\n",
      "epoch 50 loss = 2.078267\n",
      "epoch 51 loss = 2.118510\n",
      "epoch 52 loss = 2.192604\n",
      "epoch 53 loss = 2.079242\n",
      "epoch 54 loss = 2.197902\n",
      "epoch 55 loss = 2.073627\n",
      "epoch 56 loss = 2.103180\n",
      "epoch 57 loss = 2.169086\n",
      "epoch 58 loss = 2.073090\n",
      "epoch 59 loss = 2.138389\n",
      "epoch 60 loss = 2.258707\n",
      "epoch 61 loss = 2.170296\n",
      "epoch 62 loss = 2.050875\n",
      "epoch 63 loss = 2.092923\n",
      "epoch 64 loss = 2.200539\n",
      "epoch 65 loss = 2.058284\n",
      "epoch 66 loss = 2.145125\n",
      "epoch 67 loss = 2.057794\n",
      "epoch 68 loss = 2.176537\n",
      "epoch 69 loss = 2.070716\n",
      "epoch 70 loss = 2.040053\n",
      "epoch 71 loss = 2.061867\n",
      "epoch 72 loss = 2.005230\n",
      "epoch 73 loss = 2.053632\n",
      "epoch 74 loss = 2.185222\n",
      "epoch 75 loss = 1.993880\n",
      "epoch 76 loss = 2.048275\n",
      "epoch 77 loss = 2.112452\n",
      "epoch 78 loss = 2.088454\n",
      "epoch 79 loss = 2.148535\n",
      "epoch 80 loss = 2.149860\n",
      "epoch 81 loss = 2.033123\n",
      "epoch 82 loss = 2.127542\n",
      "epoch 83 loss = 2.116185\n",
      "epoch 84 loss = 2.003497\n",
      "epoch 85 loss = 1.946013\n",
      "epoch 86 loss = 2.011769\n",
      "epoch 87 loss = 2.096900\n",
      "epoch 88 loss = 2.116715\n",
      "epoch 89 loss = 2.094436\n",
      "epoch 90 loss = 2.080052\n",
      "epoch 91 loss = 1.984631\n",
      "epoch 92 loss = 2.068325\n",
      "epoch 93 loss = 1.984371\n",
      "epoch 94 loss = 2.014013\n",
      "epoch 95 loss = 2.111089\n",
      "epoch 96 loss = 2.092231\n",
      "epoch 97 loss = 2.198928\n",
      "epoch 98 loss = 2.067304\n",
      "epoch 99 loss = 2.184556\n",
      "epoch 100 loss = 2.080957\n",
      "epoch 101 loss = 2.099504\n",
      "epoch 102 loss = 1.945788\n",
      "epoch 103 loss = 2.038808\n",
      "epoch 104 loss = 1.984107\n",
      "epoch 105 loss = 2.080167\n",
      "epoch 106 loss = 2.190357\n",
      "epoch 107 loss = 2.055270\n",
      "epoch 108 loss = 2.061153\n",
      "epoch 109 loss = 2.162456\n",
      "epoch 110 loss = 2.118991\n",
      "epoch 111 loss = 1.880604\n",
      "epoch 112 loss = 2.101201\n",
      "epoch 113 loss = 2.012923\n",
      "epoch 114 loss = 2.046702\n",
      "epoch 115 loss = 1.872946\n",
      "epoch 116 loss = 1.960334\n",
      "epoch 117 loss = 2.057038\n",
      "epoch 118 loss = 1.960201\n",
      "epoch 119 loss = 2.025986\n",
      "epoch 120 loss = 2.057204\n",
      "epoch 121 loss = 2.077376\n",
      "epoch 122 loss = 2.219322\n",
      "epoch 123 loss = 2.116131\n",
      "epoch 124 loss = 2.112163\n",
      "epoch 125 loss = 2.061861\n",
      "epoch 126 loss = 2.149142\n",
      "epoch 127 loss = 2.032142\n",
      "epoch 128 loss = 2.054140\n",
      "epoch 129 loss = 2.075112\n",
      "epoch 130 loss = 2.044852\n",
      "epoch 131 loss = 2.072682\n",
      "epoch 132 loss = 2.173988\n",
      "epoch 133 loss = 2.090981\n",
      "epoch 134 loss = 2.134310\n",
      "epoch 135 loss = 2.107819\n",
      "epoch 136 loss = 2.094834\n",
      "epoch 137 loss = 2.193968\n",
      "epoch 138 loss = 2.033102\n",
      "epoch 139 loss = 2.164355\n",
      "epoch 140 loss = 2.089134\n",
      "epoch 141 loss = 2.153965\n",
      "epoch 142 loss = 2.145115\n",
      "epoch 143 loss = 2.009565\n",
      "epoch 144 loss = 2.040478\n",
      "epoch 145 loss = 2.067595\n",
      "epoch 146 loss = 2.100634\n",
      "epoch 147 loss = 2.050206\n",
      "epoch 148 loss = 2.096203\n",
      "epoch 149 loss = 2.088611\n",
      "epoch 150 loss = 2.127814\n",
      "epoch 151 loss = 2.060725\n",
      "epoch 152 loss = 2.154448\n",
      "epoch 153 loss = 2.147766\n",
      "epoch 154 loss = 1.924053\n",
      "epoch 155 loss = 1.985194\n",
      "epoch 156 loss = 2.070708\n",
      "epoch 157 loss = 1.943991\n",
      "epoch 158 loss = 2.084909\n",
      "epoch 159 loss = 2.106251\n",
      "epoch 160 loss = 2.074548\n",
      "epoch 161 loss = 2.112630\n",
      "epoch 162 loss = 2.138388\n",
      "epoch 163 loss = 2.209991\n",
      "epoch 164 loss = 2.165375\n",
      "epoch 165 loss = 2.110392\n",
      "epoch 166 loss = 2.063155\n",
      "epoch 167 loss = 2.068658\n",
      "epoch 168 loss = 1.917202\n",
      "epoch 169 loss = 2.052718\n",
      "epoch 170 loss = 2.084527\n",
      "epoch 171 loss = 1.950402\n",
      "epoch 172 loss = 2.077010\n",
      "epoch 173 loss = 1.973001\n",
      "epoch 174 loss = 2.088271\n",
      "epoch 175 loss = 2.050009\n",
      "epoch 176 loss = 2.045897\n",
      "epoch 177 loss = 2.083828\n",
      "epoch 178 loss = 2.176044\n",
      "epoch 179 loss = 2.186345\n",
      "epoch 180 loss = 2.030313\n",
      "epoch 181 loss = 2.037102\n",
      "epoch 182 loss = 2.212116\n",
      "epoch 183 loss = 2.152595\n",
      "epoch 184 loss = 2.155509\n",
      "epoch 185 loss = 2.102295\n",
      "epoch 186 loss = 1.985116\n",
      "epoch 187 loss = 2.061594\n",
      "epoch 188 loss = 2.156007\n",
      "epoch 189 loss = 2.167943\n",
      "epoch 190 loss = 1.889229\n",
      "epoch 191 loss = 1.938552\n",
      "epoch 192 loss = 2.073663\n",
      "epoch 193 loss = 1.993088\n",
      "epoch 194 loss = 2.071143\n",
      "epoch 195 loss = 2.085333\n",
      "epoch 196 loss = 2.120226\n",
      "epoch 197 loss = 2.074919\n",
      "epoch 198 loss = 2.127932\n",
      "epoch 199 loss = 1.928695\n",
      "epoch 200 loss = 1.972922\n",
      "epoch 201 loss = 1.946309\n",
      "epoch 202 loss = 2.139508\n",
      "epoch 203 loss = 2.088025\n",
      "epoch 204 loss = 2.238614\n",
      "epoch 205 loss = 2.062865\n",
      "epoch 206 loss = 1.964048\n",
      "epoch 207 loss = 2.036944\n",
      "epoch 208 loss = 1.931689\n",
      "epoch 209 loss = 2.132437\n",
      "epoch 210 loss = 2.023732\n",
      "epoch 211 loss = 2.005589\n",
      "epoch 212 loss = 2.094547\n",
      "epoch 213 loss = 2.007200\n",
      "epoch 214 loss = 2.088687\n",
      "epoch 215 loss = 2.207505\n",
      "epoch 216 loss = 2.007882\n",
      "epoch 217 loss = 2.015441\n",
      "epoch 218 loss = 1.980751\n",
      "epoch 219 loss = 2.065213\n",
      "epoch 220 loss = 1.880286\n",
      "epoch 221 loss = 2.068707\n",
      "epoch 222 loss = 1.973066\n",
      "epoch 223 loss = 2.133488\n",
      "epoch 224 loss = 2.086957\n",
      "epoch 225 loss = 2.011633\n",
      "epoch 226 loss = 2.044933\n",
      "epoch 227 loss = 2.126119\n",
      "epoch 228 loss = 2.043684\n",
      "epoch 229 loss = 2.035082\n",
      "epoch 230 loss = 2.238699\n",
      "epoch 231 loss = 2.073256\n",
      "epoch 232 loss = 1.993860\n",
      "epoch 233 loss = 1.997646\n",
      "epoch 234 loss = 1.906344\n",
      "epoch 235 loss = 2.176465\n",
      "epoch 236 loss = 2.074920\n",
      "epoch 237 loss = 2.016476\n",
      "epoch 238 loss = 2.078853\n",
      "epoch 239 loss = 2.011277\n",
      "epoch 240 loss = 2.040663\n",
      "epoch 241 loss = 2.132895\n",
      "epoch 242 loss = 2.109424\n",
      "epoch 243 loss = 2.079389\n",
      "epoch 244 loss = 2.008635\n",
      "epoch 245 loss = 2.238471\n",
      "epoch 246 loss = 2.247231\n",
      "epoch 247 loss = 2.119683\n",
      "epoch 248 loss = 2.080956\n",
      "epoch 249 loss = 2.064846\n",
      "epoch 250 loss = 2.050542\n",
      "epoch 251 loss = 1.967973\n",
      "epoch 252 loss = 2.022761\n",
      "epoch 253 loss = 2.101787\n",
      "epoch 254 loss = 2.058246\n",
      "epoch 255 loss = 1.925482\n",
      "epoch 256 loss = 2.061093\n",
      "epoch 257 loss = 1.797733\n",
      "epoch 258 loss = 1.908026\n",
      "epoch 259 loss = 1.945191\n",
      "epoch 260 loss = 2.048225\n",
      "epoch 261 loss = 2.047488\n",
      "epoch 262 loss = 2.002058\n",
      "epoch 263 loss = 2.036437\n",
      "epoch 264 loss = 2.091273\n",
      "epoch 265 loss = 1.911531\n",
      "epoch 266 loss = 2.040766\n",
      "epoch 267 loss = 2.118969\n",
      "epoch 268 loss = 2.056756\n",
      "epoch 269 loss = 2.127953\n",
      "epoch 270 loss = 2.132587\n",
      "epoch 271 loss = 1.950873\n",
      "epoch 272 loss = 1.930675\n",
      "epoch 273 loss = 2.056947\n",
      "epoch 274 loss = 2.117078\n",
      "epoch 275 loss = 1.998344\n",
      "epoch 276 loss = 2.054126\n",
      "epoch 277 loss = 2.112728\n",
      "epoch 278 loss = 1.993876\n",
      "epoch 279 loss = 2.132588\n",
      "epoch 280 loss = 2.184394\n",
      "epoch 281 loss = 1.933066\n",
      "epoch 282 loss = 2.133067\n",
      "epoch 283 loss = 2.000540\n",
      "epoch 284 loss = 2.087715\n",
      "epoch 285 loss = 1.972435\n",
      "epoch 286 loss = 2.048734\n",
      "epoch 287 loss = 2.118121\n",
      "epoch 288 loss = 1.996491\n",
      "epoch 289 loss = 2.160650\n",
      "epoch 290 loss = 1.958669\n",
      "epoch 291 loss = 2.022725\n",
      "epoch 292 loss = 2.154663\n",
      "epoch 293 loss = 2.088428\n",
      "epoch 294 loss = 2.110162\n",
      "epoch 295 loss = 2.145097\n",
      "epoch 296 loss = 2.093248\n",
      "epoch 297 loss = 2.041614\n",
      "epoch 298 loss = 1.964370\n",
      "epoch 299 loss = 2.062948\n",
      "epoch 300 loss = 1.781068\n",
      "epoch 301 loss = 2.061691\n",
      "epoch 302 loss = 2.137414\n",
      "epoch 303 loss = 1.961743\n",
      "epoch 304 loss = 1.926288\n",
      "epoch 305 loss = 2.025350\n",
      "epoch 306 loss = 2.061823\n",
      "epoch 307 loss = 1.922892\n",
      "epoch 308 loss = 2.043236\n",
      "epoch 309 loss = 1.976652\n",
      "epoch 310 loss = 1.955279\n",
      "epoch 311 loss = 2.158228\n",
      "epoch 312 loss = 2.151666\n",
      "epoch 313 loss = 2.063889\n",
      "epoch 314 loss = 2.146851\n",
      "epoch 315 loss = 1.977730\n",
      "epoch 316 loss = 1.825537\n",
      "epoch 317 loss = 1.912377\n",
      "epoch 318 loss = 2.038348\n",
      "epoch 319 loss = 2.157047\n",
      "epoch 320 loss = 1.919624\n",
      "epoch 321 loss = 2.033809\n",
      "epoch 322 loss = 1.947661\n",
      "epoch 323 loss = 2.076383\n",
      "epoch 324 loss = 2.028736\n",
      "epoch 325 loss = 2.067889\n",
      "epoch 326 loss = 1.966982\n",
      "epoch 327 loss = 2.041982\n",
      "epoch 328 loss = 1.987637\n",
      "epoch 329 loss = 2.094515\n",
      "epoch 330 loss = 2.092027\n",
      "epoch 331 loss = 2.112612\n",
      "epoch 332 loss = 2.150687\n",
      "epoch 333 loss = 2.096424\n",
      "epoch 334 loss = 1.819997\n",
      "epoch 335 loss = 1.948238\n",
      "epoch 336 loss = 2.025820\n",
      "epoch 337 loss = 2.154048\n",
      "epoch 338 loss = 2.093921\n",
      "epoch 339 loss = 1.798284\n",
      "epoch 340 loss = 2.131462\n",
      "epoch 341 loss = 2.137894\n",
      "epoch 342 loss = 1.999591\n",
      "epoch 343 loss = 1.966272\n",
      "epoch 344 loss = 1.978516\n",
      "epoch 345 loss = 2.017271\n",
      "epoch 346 loss = 2.089380\n",
      "epoch 347 loss = 1.920377\n",
      "epoch 348 loss = 1.937298\n",
      "epoch 349 loss = 2.184432\n",
      "epoch 350 loss = 2.163787\n",
      "epoch 351 loss = 2.068852\n",
      "epoch 352 loss = 2.193523\n",
      "epoch 353 loss = 2.121432\n",
      "epoch 354 loss = 2.176221\n",
      "epoch 355 loss = 2.022970\n",
      "epoch 356 loss = 2.214997\n",
      "epoch 357 loss = 2.039288\n",
      "epoch 358 loss = 2.032033\n",
      "epoch 359 loss = 1.975157\n",
      "epoch 360 loss = 2.067561\n",
      "epoch 361 loss = 2.027221\n",
      "epoch 362 loss = 2.048753\n",
      "epoch 363 loss = 1.911438\n",
      "epoch 364 loss = 2.064422\n",
      "epoch 365 loss = 1.944847\n",
      "epoch 366 loss = 2.058216\n",
      "epoch 367 loss = 2.023236\n",
      "epoch 368 loss = 2.098672\n",
      "epoch 369 loss = 2.117249\n",
      "epoch 370 loss = 2.112892\n",
      "epoch 371 loss = 2.130469\n",
      "epoch 372 loss = 2.201005\n",
      "epoch 373 loss = 2.076024\n",
      "epoch 374 loss = 1.974452\n",
      "epoch 375 loss = 1.959894\n",
      "epoch 376 loss = 1.989936\n",
      "epoch 377 loss = 2.135017\n",
      "epoch 378 loss = 2.213284\n",
      "epoch 379 loss = 1.978254\n",
      "epoch 380 loss = 2.086630\n",
      "epoch 381 loss = 2.070251\n",
      "epoch 382 loss = 2.032550\n",
      "epoch 383 loss = 2.023400\n",
      "epoch 384 loss = 2.004926\n",
      "epoch 385 loss = 2.175822\n",
      "epoch 386 loss = 2.053225\n",
      "epoch 387 loss = 2.014331\n",
      "epoch 388 loss = 2.073590\n",
      "epoch 389 loss = 2.072124\n",
      "epoch 390 loss = 2.051130\n",
      "epoch 391 loss = 2.190026\n",
      "epoch 392 loss = 2.109335\n",
      "epoch 393 loss = 1.997746\n",
      "epoch 394 loss = 2.009013\n",
      "epoch 395 loss = 2.148360\n",
      "epoch 396 loss = 1.927930\n",
      "epoch 397 loss = 1.844174\n",
      "epoch 398 loss = 2.056379\n",
      "epoch 399 loss = 1.809369\n",
      "epoch 400 loss = 2.002913\n",
      "epoch 401 loss = 2.001281\n",
      "epoch 402 loss = 1.920882\n",
      "epoch 403 loss = 1.982616\n",
      "epoch 404 loss = 2.080916\n",
      "epoch 405 loss = 2.017612\n",
      "epoch 406 loss = 1.974745\n",
      "epoch 407 loss = 1.857507\n",
      "epoch 408 loss = 2.005826\n",
      "epoch 409 loss = 1.933585\n",
      "epoch 410 loss = 1.992648\n",
      "epoch 411 loss = 1.979321\n",
      "epoch 412 loss = 2.125994\n",
      "epoch 413 loss = 1.981625\n",
      "epoch 414 loss = 2.173917\n",
      "epoch 415 loss = 2.066432\n",
      "epoch 416 loss = 2.020028\n",
      "epoch 417 loss = 2.038039\n",
      "epoch 418 loss = 1.923661\n",
      "epoch 419 loss = 2.112535\n",
      "epoch 420 loss = 1.811239\n",
      "epoch 421 loss = 2.155303\n",
      "epoch 422 loss = 2.016653\n",
      "epoch 423 loss = 1.886646\n",
      "epoch 424 loss = 2.137434\n",
      "epoch 425 loss = 2.034336\n",
      "epoch 426 loss = 2.035553\n",
      "epoch 427 loss = 2.007830\n",
      "epoch 428 loss = 2.062566\n",
      "epoch 429 loss = 2.055182\n",
      "epoch 430 loss = 1.926769\n",
      "epoch 431 loss = 2.202718\n",
      "epoch 432 loss = 1.863258\n",
      "epoch 433 loss = 1.882288\n",
      "epoch 434 loss = 2.061398\n",
      "epoch 435 loss = 1.879059\n",
      "epoch 436 loss = 1.955277\n",
      "epoch 437 loss = 2.056529\n",
      "epoch 438 loss = 1.914854\n",
      "epoch 439 loss = 2.060129\n",
      "epoch 440 loss = 1.953185\n",
      "epoch 441 loss = 2.114090\n",
      "epoch 442 loss = 2.094493\n",
      "epoch 443 loss = 1.932071\n",
      "epoch 444 loss = 2.030103\n",
      "epoch 445 loss = 1.914859\n",
      "epoch 446 loss = 2.039428\n",
      "epoch 447 loss = 1.978992\n",
      "epoch 448 loss = 2.046342\n",
      "epoch 449 loss = 2.076966\n",
      "epoch 450 loss = 2.004786\n",
      "epoch 451 loss = 2.003707\n",
      "epoch 452 loss = 1.969421\n",
      "epoch 453 loss = 2.053991\n",
      "epoch 454 loss = 1.977897\n",
      "epoch 455 loss = 1.951734\n",
      "epoch 456 loss = 1.996528\n",
      "epoch 457 loss = 2.305528\n",
      "epoch 458 loss = 2.101621\n",
      "epoch 459 loss = 1.794805\n",
      "epoch 460 loss = 1.988967\n",
      "epoch 461 loss = 1.958356\n",
      "epoch 462 loss = 1.967906\n",
      "epoch 463 loss = 1.940728\n",
      "epoch 464 loss = 2.154825\n",
      "epoch 465 loss = 1.941710\n",
      "epoch 466 loss = 2.166090\n",
      "epoch 467 loss = 1.961725\n",
      "epoch 468 loss = 1.920482\n",
      "epoch 469 loss = 2.040679\n",
      "epoch 470 loss = 2.066944\n",
      "epoch 471 loss = 2.019174\n",
      "epoch 472 loss = 2.014183\n",
      "epoch 473 loss = 1.946480\n",
      "epoch 474 loss = 2.059559\n",
      "epoch 475 loss = 2.005897\n",
      "epoch 476 loss = 2.047231\n",
      "epoch 477 loss = 1.955237\n",
      "epoch 478 loss = 2.063310\n",
      "epoch 479 loss = 2.104319\n",
      "epoch 480 loss = 2.108534\n",
      "epoch 481 loss = 2.044321\n",
      "epoch 482 loss = 2.104649\n",
      "epoch 483 loss = 1.875874\n",
      "epoch 484 loss = 1.987278\n",
      "epoch 485 loss = 1.975238\n",
      "epoch 486 loss = 2.151431\n",
      "epoch 487 loss = 2.094942\n",
      "epoch 488 loss = 1.878415\n",
      "epoch 489 loss = 2.054193\n",
      "epoch 490 loss = 2.054777\n",
      "epoch 491 loss = 2.020039\n",
      "epoch 492 loss = 2.123343\n",
      "epoch 493 loss = 2.041357\n",
      "epoch 494 loss = 2.025247\n",
      "epoch 495 loss = 1.920026\n",
      "epoch 496 loss = 2.058724\n",
      "epoch 497 loss = 2.072002\n",
      "epoch 498 loss = 2.106693\n",
      "epoch 499 loss = 2.052431\n",
      "final loss = 2.052431\n",
      "accuracy_mc = tensor(0.2280, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2987, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.9523, device='cuda:0')\n",
      "training time = 306.0254530906677 seconds\n",
      "testing time = 3.230353593826294 seconds\n",
      "\n",
      "Training with split 8\n",
      "epoch 0 loss = 2.272621\n",
      "epoch 1 loss = 2.202078\n",
      "epoch 2 loss = 2.402248\n",
      "epoch 3 loss = 2.208702\n",
      "epoch 4 loss = 2.215938\n",
      "epoch 5 loss = 2.176468\n",
      "epoch 6 loss = 2.143243\n",
      "epoch 7 loss = 2.144994\n",
      "epoch 8 loss = 2.267598\n",
      "epoch 9 loss = 2.144060\n",
      "epoch 10 loss = 2.273679\n",
      "epoch 11 loss = 2.165259\n",
      "epoch 12 loss = 2.135435\n",
      "epoch 13 loss = 2.131323\n",
      "epoch 14 loss = 2.245700\n",
      "epoch 15 loss = 2.150532\n",
      "epoch 16 loss = 2.019258\n",
      "epoch 17 loss = 2.109690\n",
      "epoch 18 loss = 2.177442\n",
      "epoch 19 loss = 2.102816\n",
      "epoch 20 loss = 2.098352\n",
      "epoch 21 loss = 2.023737\n",
      "epoch 22 loss = 1.983550\n",
      "epoch 23 loss = 2.161675\n",
      "epoch 24 loss = 1.938187\n",
      "epoch 25 loss = 2.127670\n",
      "epoch 26 loss = 2.201973\n",
      "epoch 27 loss = 2.069098\n",
      "epoch 28 loss = 2.301572\n",
      "epoch 29 loss = 2.097653\n",
      "epoch 30 loss = 2.156375\n",
      "epoch 31 loss = 1.961680\n",
      "epoch 32 loss = 2.084552\n",
      "epoch 33 loss = 2.157921\n",
      "epoch 34 loss = 1.997355\n",
      "epoch 35 loss = 2.205882\n",
      "epoch 36 loss = 2.110533\n",
      "epoch 37 loss = 2.204957\n",
      "epoch 38 loss = 2.022010\n",
      "epoch 39 loss = 2.063438\n",
      "epoch 40 loss = 2.001614\n",
      "epoch 41 loss = 2.021462\n",
      "epoch 42 loss = 2.120084\n",
      "epoch 43 loss = 2.210071\n",
      "epoch 44 loss = 2.042938\n",
      "epoch 45 loss = 2.155528\n",
      "epoch 46 loss = 2.060147\n",
      "epoch 47 loss = 2.057268\n",
      "epoch 48 loss = 2.028044\n",
      "epoch 49 loss = 2.081068\n",
      "epoch 50 loss = 2.224739\n",
      "epoch 51 loss = 2.125813\n",
      "epoch 52 loss = 1.980746\n",
      "epoch 53 loss = 1.977882\n",
      "epoch 54 loss = 1.977693\n",
      "epoch 55 loss = 1.905803\n",
      "epoch 56 loss = 1.990951\n",
      "epoch 57 loss = 2.175302\n",
      "epoch 58 loss = 2.043234\n",
      "epoch 59 loss = 2.072493\n",
      "epoch 60 loss = 1.961667\n",
      "epoch 61 loss = 2.152309\n",
      "epoch 62 loss = 2.049281\n",
      "epoch 63 loss = 2.018600\n",
      "epoch 64 loss = 1.889344\n",
      "epoch 65 loss = 2.090331\n",
      "epoch 66 loss = 2.180903\n",
      "epoch 67 loss = 2.011515\n",
      "epoch 68 loss = 2.108927\n",
      "epoch 69 loss = 2.008990\n",
      "epoch 70 loss = 1.996764\n",
      "epoch 71 loss = 2.141740\n",
      "epoch 72 loss = 2.154248\n",
      "epoch 73 loss = 1.992628\n",
      "epoch 74 loss = 2.107292\n",
      "epoch 75 loss = 2.241024\n",
      "epoch 76 loss = 2.023804\n",
      "epoch 77 loss = 2.056906\n",
      "epoch 78 loss = 2.119216\n",
      "epoch 79 loss = 1.958719\n",
      "epoch 80 loss = 2.207137\n",
      "epoch 81 loss = 2.103196\n",
      "epoch 82 loss = 2.056438\n",
      "epoch 83 loss = 2.002733\n",
      "epoch 84 loss = 2.050626\n",
      "epoch 85 loss = 2.053965\n",
      "epoch 86 loss = 2.074543\n",
      "epoch 87 loss = 2.228326\n",
      "epoch 88 loss = 2.238508\n",
      "epoch 89 loss = 2.128795\n",
      "epoch 90 loss = 2.302575\n",
      "epoch 91 loss = 2.035137\n",
      "epoch 92 loss = 2.066904\n",
      "epoch 93 loss = 2.119148\n",
      "epoch 94 loss = 2.087971\n",
      "epoch 95 loss = 2.052357\n",
      "epoch 96 loss = 2.210871\n",
      "epoch 97 loss = 2.134062\n",
      "epoch 98 loss = 2.030367\n",
      "epoch 99 loss = 2.048149\n",
      "epoch 100 loss = 2.062641\n",
      "epoch 101 loss = 1.878678\n",
      "epoch 102 loss = 2.120538\n",
      "epoch 103 loss = 2.107648\n",
      "epoch 104 loss = 2.188619\n",
      "epoch 105 loss = 2.090262\n",
      "epoch 106 loss = 2.089969\n",
      "epoch 107 loss = 2.115544\n",
      "epoch 108 loss = 2.010813\n",
      "epoch 109 loss = 2.087178\n",
      "epoch 110 loss = 2.094306\n",
      "epoch 111 loss = 2.165707\n",
      "epoch 112 loss = 2.001762\n",
      "epoch 113 loss = 2.000055\n",
      "epoch 114 loss = 1.946550\n",
      "epoch 115 loss = 2.102718\n",
      "epoch 116 loss = 1.813211\n",
      "epoch 117 loss = 1.991985\n",
      "epoch 118 loss = 2.031435\n",
      "epoch 119 loss = 2.057690\n",
      "epoch 120 loss = 2.052136\n",
      "epoch 121 loss = 2.115080\n",
      "epoch 122 loss = 2.088276\n",
      "epoch 123 loss = 2.011228\n",
      "epoch 124 loss = 2.111690\n",
      "epoch 125 loss = 2.064754\n",
      "epoch 126 loss = 2.087360\n",
      "epoch 127 loss = 2.205009\n",
      "epoch 128 loss = 2.064549\n",
      "epoch 129 loss = 2.097548\n",
      "epoch 130 loss = 2.132512\n",
      "epoch 131 loss = 2.080509\n",
      "epoch 132 loss = 1.987413\n",
      "epoch 133 loss = 2.016778\n",
      "epoch 134 loss = 2.071993\n",
      "epoch 135 loss = 2.139064\n",
      "epoch 136 loss = 2.207350\n",
      "epoch 137 loss = 1.918329\n",
      "epoch 138 loss = 2.156967\n",
      "epoch 139 loss = 2.144586\n",
      "epoch 140 loss = 2.124917\n",
      "epoch 141 loss = 2.011225\n",
      "epoch 142 loss = 1.985180\n",
      "epoch 143 loss = 2.180833\n",
      "epoch 144 loss = 2.052340\n",
      "epoch 145 loss = 2.075367\n",
      "epoch 146 loss = 2.134567\n",
      "epoch 147 loss = 2.332035\n",
      "epoch 148 loss = 2.049851\n",
      "epoch 149 loss = 2.039341\n",
      "epoch 150 loss = 2.010277\n",
      "epoch 151 loss = 2.039690\n",
      "epoch 152 loss = 2.167045\n",
      "epoch 153 loss = 1.947980\n",
      "epoch 154 loss = 2.061177\n",
      "epoch 155 loss = 2.079304\n",
      "epoch 156 loss = 2.024735\n",
      "epoch 157 loss = 2.104435\n",
      "epoch 158 loss = 2.098870\n",
      "epoch 159 loss = 2.189481\n",
      "epoch 160 loss = 2.071436\n",
      "epoch 161 loss = 2.118254\n",
      "epoch 162 loss = 1.880048\n",
      "epoch 163 loss = 1.986004\n",
      "epoch 164 loss = 1.971973\n",
      "epoch 165 loss = 1.972389\n",
      "epoch 166 loss = 1.933432\n",
      "epoch 167 loss = 2.120904\n",
      "epoch 168 loss = 2.019850\n",
      "epoch 169 loss = 2.197648\n",
      "epoch 170 loss = 2.047849\n",
      "epoch 171 loss = 2.050976\n",
      "epoch 172 loss = 2.068524\n",
      "epoch 173 loss = 1.965823\n",
      "epoch 174 loss = 2.098150\n",
      "epoch 175 loss = 2.144845\n",
      "epoch 176 loss = 2.227769\n",
      "epoch 177 loss = 1.994941\n",
      "epoch 178 loss = 1.924564\n",
      "epoch 179 loss = 1.938573\n",
      "epoch 180 loss = 2.138048\n",
      "epoch 181 loss = 2.102326\n",
      "epoch 182 loss = 2.057496\n",
      "epoch 183 loss = 2.077939\n",
      "epoch 184 loss = 2.039824\n",
      "epoch 185 loss = 2.198583\n",
      "epoch 186 loss = 2.068007\n",
      "epoch 187 loss = 1.986761\n",
      "epoch 188 loss = 2.146248\n",
      "epoch 189 loss = 2.066254\n",
      "epoch 190 loss = 1.965693\n",
      "epoch 191 loss = 2.106601\n",
      "epoch 192 loss = 2.108968\n",
      "epoch 193 loss = 2.176439\n",
      "epoch 194 loss = 2.132006\n",
      "epoch 195 loss = 2.068901\n",
      "epoch 196 loss = 2.074767\n",
      "epoch 197 loss = 2.129874\n",
      "epoch 198 loss = 2.217526\n",
      "epoch 199 loss = 2.154160\n",
      "epoch 200 loss = 2.282624\n",
      "epoch 201 loss = 2.083111\n",
      "epoch 202 loss = 2.049520\n",
      "epoch 203 loss = 2.196198\n",
      "epoch 204 loss = 2.155107\n",
      "epoch 205 loss = 2.027924\n",
      "epoch 206 loss = 2.015520\n",
      "epoch 207 loss = 2.157472\n",
      "epoch 208 loss = 2.053740\n",
      "epoch 209 loss = 2.212402\n",
      "epoch 210 loss = 1.897420\n",
      "epoch 211 loss = 2.119157\n",
      "epoch 212 loss = 2.026146\n",
      "epoch 213 loss = 2.061283\n",
      "epoch 214 loss = 2.124167\n",
      "epoch 215 loss = 2.095998\n",
      "epoch 216 loss = 2.191137\n",
      "epoch 217 loss = 2.114227\n",
      "epoch 218 loss = 2.077589\n",
      "epoch 219 loss = 2.065653\n",
      "epoch 220 loss = 2.001168\n",
      "epoch 221 loss = 2.227264\n",
      "epoch 222 loss = 2.050701\n",
      "epoch 223 loss = 2.070515\n",
      "epoch 224 loss = 1.956214\n",
      "epoch 225 loss = 2.078038\n",
      "epoch 226 loss = 2.105523\n",
      "epoch 227 loss = 1.912842\n",
      "epoch 228 loss = 2.205430\n",
      "epoch 229 loss = 2.020061\n",
      "epoch 230 loss = 1.995435\n",
      "epoch 231 loss = 2.138695\n",
      "epoch 232 loss = 2.278779\n",
      "epoch 233 loss = 2.025546\n",
      "epoch 234 loss = 1.866388\n",
      "epoch 235 loss = 2.006411\n",
      "epoch 236 loss = 2.098546\n",
      "epoch 237 loss = 1.917233\n",
      "epoch 238 loss = 2.271092\n",
      "epoch 239 loss = 1.886856\n",
      "epoch 240 loss = 2.110719\n",
      "epoch 241 loss = 1.958038\n",
      "epoch 242 loss = 2.209418\n",
      "epoch 243 loss = 2.122120\n",
      "epoch 244 loss = 2.005420\n",
      "epoch 245 loss = 2.074927\n",
      "epoch 246 loss = 2.164433\n",
      "epoch 247 loss = 1.923088\n",
      "epoch 248 loss = 2.201036\n",
      "epoch 249 loss = 2.200540\n",
      "epoch 250 loss = 2.136720\n",
      "epoch 251 loss = 2.103776\n",
      "epoch 252 loss = 2.054177\n",
      "epoch 253 loss = 1.932511\n",
      "epoch 254 loss = 1.995956\n",
      "epoch 255 loss = 2.172916\n",
      "epoch 256 loss = 2.001903\n",
      "epoch 257 loss = 2.099584\n",
      "epoch 258 loss = 2.008203\n",
      "epoch 259 loss = 2.006320\n",
      "epoch 260 loss = 1.974092\n",
      "epoch 261 loss = 1.907508\n",
      "epoch 262 loss = 2.112707\n",
      "epoch 263 loss = 2.177454\n",
      "epoch 264 loss = 2.085927\n",
      "epoch 265 loss = 2.034670\n",
      "epoch 266 loss = 2.089243\n",
      "epoch 267 loss = 1.994760\n",
      "epoch 268 loss = 2.105668\n",
      "epoch 269 loss = 1.949731\n",
      "epoch 270 loss = 1.920828\n",
      "epoch 271 loss = 2.016622\n",
      "epoch 272 loss = 2.104162\n",
      "epoch 273 loss = 2.288059\n",
      "epoch 274 loss = 1.992303\n",
      "epoch 275 loss = 1.813072\n",
      "epoch 276 loss = 1.958240\n",
      "epoch 277 loss = 1.992218\n",
      "epoch 278 loss = 1.991207\n",
      "epoch 279 loss = 2.009548\n",
      "epoch 280 loss = 2.114514\n",
      "epoch 281 loss = 1.990533\n",
      "epoch 282 loss = 2.001419\n",
      "epoch 283 loss = 1.975836\n",
      "epoch 284 loss = 2.029950\n",
      "epoch 285 loss = 2.129013\n",
      "epoch 286 loss = 2.095801\n",
      "epoch 287 loss = 1.982684\n",
      "epoch 288 loss = 1.963586\n",
      "epoch 289 loss = 2.200643\n",
      "epoch 290 loss = 2.117817\n",
      "epoch 291 loss = 2.131946\n",
      "epoch 292 loss = 2.037334\n",
      "epoch 293 loss = 2.032317\n",
      "epoch 294 loss = 2.081649\n",
      "epoch 295 loss = 2.008458\n",
      "epoch 296 loss = 2.071781\n",
      "epoch 297 loss = 1.804850\n",
      "epoch 298 loss = 1.983244\n",
      "epoch 299 loss = 2.132973\n",
      "epoch 300 loss = 2.108637\n",
      "epoch 301 loss = 2.191473\n",
      "epoch 302 loss = 2.043268\n",
      "epoch 303 loss = 2.147364\n",
      "epoch 304 loss = 2.068891\n",
      "epoch 305 loss = 2.206617\n",
      "epoch 306 loss = 1.983101\n",
      "epoch 307 loss = 2.049221\n",
      "epoch 308 loss = 2.200272\n",
      "epoch 309 loss = 1.997233\n",
      "epoch 310 loss = 1.906575\n",
      "epoch 311 loss = 1.876708\n",
      "epoch 312 loss = 2.248599\n",
      "epoch 313 loss = 1.957705\n",
      "epoch 314 loss = 2.069242\n",
      "epoch 315 loss = 2.088715\n",
      "epoch 316 loss = 2.135747\n",
      "epoch 317 loss = 2.024207\n",
      "epoch 318 loss = 2.115624\n",
      "epoch 319 loss = 2.006045\n",
      "epoch 320 loss = 2.057625\n",
      "epoch 321 loss = 2.037482\n",
      "epoch 322 loss = 2.164402\n",
      "epoch 323 loss = 2.082900\n",
      "epoch 324 loss = 2.046979\n",
      "epoch 325 loss = 2.120443\n",
      "epoch 326 loss = 2.054315\n",
      "epoch 327 loss = 2.063503\n",
      "epoch 328 loss = 2.005166\n",
      "epoch 329 loss = 2.001967\n",
      "epoch 330 loss = 2.116229\n",
      "epoch 331 loss = 1.996703\n",
      "epoch 332 loss = 2.169231\n",
      "epoch 333 loss = 2.053801\n",
      "epoch 334 loss = 2.284106\n",
      "epoch 335 loss = 2.155104\n",
      "epoch 336 loss = 2.103714\n",
      "epoch 337 loss = 2.115970\n",
      "epoch 338 loss = 1.948475\n",
      "epoch 339 loss = 2.223742\n",
      "epoch 340 loss = 2.082281\n",
      "epoch 341 loss = 2.080446\n",
      "epoch 342 loss = 2.141889\n",
      "epoch 343 loss = 2.065849\n",
      "epoch 344 loss = 2.036224\n",
      "epoch 345 loss = 2.073411\n",
      "epoch 346 loss = 1.904658\n",
      "epoch 347 loss = 1.976701\n",
      "epoch 348 loss = 1.879706\n",
      "epoch 349 loss = 2.222157\n",
      "epoch 350 loss = 2.098003\n",
      "epoch 351 loss = 2.115873\n",
      "epoch 352 loss = 1.937575\n",
      "epoch 353 loss = 1.940424\n",
      "epoch 354 loss = 1.940062\n",
      "epoch 355 loss = 2.053997\n",
      "epoch 356 loss = 2.109837\n",
      "epoch 357 loss = 2.312367\n",
      "epoch 358 loss = 2.104935\n",
      "epoch 359 loss = 1.952837\n",
      "epoch 360 loss = 2.103759\n",
      "epoch 361 loss = 2.125528\n",
      "epoch 362 loss = 2.164988\n",
      "epoch 363 loss = 2.254624\n",
      "epoch 364 loss = 2.162456\n",
      "epoch 365 loss = 2.132385\n",
      "epoch 366 loss = 1.996239\n",
      "epoch 367 loss = 2.180996\n",
      "epoch 368 loss = 2.070553\n",
      "epoch 369 loss = 1.919574\n",
      "epoch 370 loss = 1.933110\n",
      "epoch 371 loss = 2.029460\n",
      "epoch 372 loss = 2.073632\n",
      "epoch 373 loss = 2.161571\n",
      "epoch 374 loss = 2.000637\n",
      "epoch 375 loss = 1.860060\n",
      "epoch 376 loss = 2.066398\n",
      "epoch 377 loss = 2.091695\n",
      "epoch 378 loss = 1.992501\n",
      "epoch 379 loss = 2.016533\n",
      "epoch 380 loss = 2.062513\n",
      "epoch 381 loss = 1.934222\n",
      "epoch 382 loss = 2.124813\n",
      "epoch 383 loss = 2.195721\n",
      "epoch 384 loss = 2.184963\n",
      "epoch 385 loss = 1.960977\n",
      "epoch 386 loss = 2.183768\n",
      "epoch 387 loss = 2.028207\n",
      "epoch 388 loss = 2.072186\n",
      "epoch 389 loss = 2.058752\n",
      "epoch 390 loss = 2.007277\n",
      "epoch 391 loss = 2.105701\n",
      "epoch 392 loss = 2.203917\n",
      "epoch 393 loss = 2.087299\n",
      "epoch 394 loss = 1.892775\n",
      "epoch 395 loss = 1.965745\n",
      "epoch 396 loss = 2.104787\n",
      "epoch 397 loss = 2.137655\n",
      "epoch 398 loss = 2.034629\n",
      "epoch 399 loss = 2.095877\n",
      "epoch 400 loss = 2.277969\n",
      "epoch 401 loss = 2.071081\n",
      "epoch 402 loss = 1.995890\n",
      "epoch 403 loss = 2.048947\n",
      "epoch 404 loss = 2.093946\n",
      "epoch 405 loss = 1.953327\n",
      "epoch 406 loss = 2.189400\n",
      "epoch 407 loss = 2.122648\n",
      "epoch 408 loss = 2.244073\n",
      "epoch 409 loss = 1.988495\n",
      "epoch 410 loss = 1.988815\n",
      "epoch 411 loss = 2.151925\n",
      "epoch 412 loss = 2.036544\n",
      "epoch 413 loss = 2.255300\n",
      "epoch 414 loss = 2.162912\n",
      "epoch 415 loss = 2.122873\n",
      "epoch 416 loss = 2.201892\n",
      "epoch 417 loss = 2.094198\n",
      "epoch 418 loss = 2.008451\n",
      "epoch 419 loss = 2.271375\n",
      "epoch 420 loss = 1.949056\n",
      "epoch 421 loss = 1.960241\n",
      "epoch 422 loss = 2.110921\n",
      "epoch 423 loss = 2.007056\n",
      "epoch 424 loss = 2.067945\n",
      "epoch 425 loss = 2.047948\n",
      "epoch 426 loss = 2.190141\n",
      "epoch 427 loss = 2.072970\n",
      "epoch 428 loss = 2.115269\n",
      "epoch 429 loss = 2.111502\n",
      "epoch 430 loss = 1.819753\n",
      "epoch 431 loss = 2.013501\n",
      "epoch 432 loss = 2.085873\n",
      "epoch 433 loss = 2.075066\n",
      "epoch 434 loss = 1.965388\n",
      "epoch 435 loss = 1.977418\n",
      "epoch 436 loss = 2.193360\n",
      "epoch 437 loss = 2.063914\n",
      "epoch 438 loss = 2.156854\n",
      "epoch 439 loss = 2.015385\n",
      "epoch 440 loss = 2.175717\n",
      "epoch 441 loss = 2.070718\n",
      "epoch 442 loss = 1.994285\n",
      "epoch 443 loss = 2.191918\n",
      "epoch 444 loss = 2.044189\n",
      "epoch 445 loss = 2.246495\n",
      "epoch 446 loss = 2.025341\n",
      "epoch 447 loss = 2.089470\n",
      "epoch 448 loss = 2.065532\n",
      "epoch 449 loss = 2.017729\n",
      "epoch 450 loss = 2.169623\n",
      "epoch 451 loss = 2.154610\n",
      "epoch 452 loss = 2.182541\n",
      "epoch 453 loss = 2.034650\n",
      "epoch 454 loss = 2.092396\n",
      "epoch 455 loss = 2.068938\n",
      "epoch 456 loss = 2.233107\n",
      "epoch 457 loss = 2.170145\n",
      "epoch 458 loss = 2.037205\n",
      "epoch 459 loss = 1.839548\n",
      "epoch 460 loss = 1.944299\n",
      "epoch 461 loss = 2.072496\n",
      "epoch 462 loss = 2.016836\n",
      "epoch 463 loss = 2.023799\n",
      "epoch 464 loss = 2.008363\n",
      "epoch 465 loss = 2.077724\n",
      "epoch 466 loss = 2.178271\n",
      "epoch 467 loss = 1.967447\n",
      "epoch 468 loss = 1.817799\n",
      "epoch 469 loss = 2.090297\n",
      "epoch 470 loss = 2.011715\n",
      "epoch 471 loss = 2.029534\n",
      "epoch 472 loss = 2.113302\n",
      "epoch 473 loss = 2.057346\n",
      "epoch 474 loss = 2.168264\n",
      "epoch 475 loss = 2.064977\n",
      "epoch 476 loss = 2.210340\n",
      "epoch 477 loss = 2.128540\n",
      "epoch 478 loss = 2.066970\n",
      "epoch 479 loss = 2.036388\n",
      "epoch 480 loss = 2.034706\n",
      "epoch 481 loss = 2.079986\n",
      "epoch 482 loss = 2.104845\n",
      "epoch 483 loss = 1.981385\n",
      "epoch 484 loss = 2.111569\n",
      "epoch 485 loss = 2.064053\n",
      "epoch 486 loss = 2.153335\n",
      "epoch 487 loss = 1.970240\n",
      "epoch 488 loss = 2.143078\n",
      "epoch 489 loss = 2.031502\n",
      "epoch 490 loss = 2.159485\n",
      "epoch 491 loss = 2.143521\n",
      "epoch 492 loss = 2.159375\n",
      "epoch 493 loss = 2.039284\n",
      "epoch 494 loss = 2.133235\n",
      "epoch 495 loss = 2.165342\n",
      "epoch 496 loss = 2.110698\n",
      "epoch 497 loss = 1.948118\n",
      "epoch 498 loss = 2.165062\n",
      "epoch 499 loss = 2.140073\n",
      "final loss = 2.140073\n",
      "accuracy_mc = tensor(0.3083, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2842, device='cuda:0')\n",
      "test_ll_mc = tensor(-1.9884, device='cuda:0')\n",
      "training time = 307.724240064621 seconds\n",
      "testing time = 3.2695810794830322 seconds\n",
      "\n",
      "Training with split 9\n",
      "epoch 0 loss = 2.295151\n",
      "epoch 1 loss = 2.299922\n",
      "epoch 2 loss = 2.269918\n",
      "epoch 3 loss = 2.248308\n",
      "epoch 4 loss = 2.280675\n",
      "epoch 5 loss = 2.231398\n",
      "epoch 6 loss = 2.221474\n",
      "epoch 7 loss = 2.245364\n",
      "epoch 8 loss = 2.025112\n",
      "epoch 9 loss = 2.136258\n",
      "epoch 10 loss = 2.299427\n",
      "epoch 11 loss = 2.230747\n",
      "epoch 12 loss = 2.240287\n",
      "epoch 13 loss = 2.095808\n",
      "epoch 14 loss = 2.262973\n",
      "epoch 15 loss = 2.226658\n",
      "epoch 16 loss = 2.159524\n",
      "epoch 17 loss = 2.028324\n",
      "epoch 18 loss = 2.050060\n",
      "epoch 19 loss = 2.209562\n",
      "epoch 20 loss = 2.205715\n",
      "epoch 21 loss = 2.113595\n",
      "epoch 22 loss = 2.041393\n",
      "epoch 23 loss = 2.125643\n",
      "epoch 24 loss = 2.198638\n",
      "epoch 25 loss = 2.090147\n",
      "epoch 26 loss = 2.127333\n",
      "epoch 27 loss = 2.007738\n",
      "epoch 28 loss = 2.062886\n",
      "epoch 29 loss = 2.083809\n",
      "epoch 30 loss = 2.053779\n",
      "epoch 31 loss = 2.181618\n",
      "epoch 32 loss = 2.086002\n",
      "epoch 33 loss = 2.091046\n",
      "epoch 34 loss = 2.044890\n",
      "epoch 35 loss = 2.122342\n",
      "epoch 36 loss = 2.091419\n",
      "epoch 37 loss = 2.096010\n",
      "epoch 38 loss = 2.102519\n",
      "epoch 39 loss = 2.059864\n",
      "epoch 40 loss = 2.106073\n",
      "epoch 41 loss = 2.051008\n",
      "epoch 42 loss = 2.195090\n",
      "epoch 43 loss = 2.169267\n",
      "epoch 44 loss = 1.981657\n",
      "epoch 45 loss = 2.095026\n",
      "epoch 46 loss = 2.070956\n",
      "epoch 47 loss = 2.075040\n",
      "epoch 48 loss = 2.029833\n",
      "epoch 49 loss = 2.033003\n",
      "epoch 50 loss = 2.241759\n",
      "epoch 51 loss = 2.196727\n",
      "epoch 52 loss = 2.121063\n",
      "epoch 53 loss = 2.096331\n",
      "epoch 54 loss = 2.193255\n",
      "epoch 55 loss = 2.130682\n",
      "epoch 56 loss = 2.174223\n",
      "epoch 57 loss = 2.106058\n",
      "epoch 58 loss = 2.090666\n",
      "epoch 59 loss = 2.151642\n",
      "epoch 60 loss = 2.201339\n",
      "epoch 61 loss = 2.126707\n",
      "epoch 62 loss = 2.255956\n",
      "epoch 63 loss = 2.161170\n",
      "epoch 64 loss = 2.030679\n",
      "epoch 65 loss = 2.193949\n",
      "epoch 66 loss = 2.176173\n",
      "epoch 67 loss = 2.190322\n",
      "epoch 68 loss = 2.034989\n",
      "epoch 69 loss = 2.125898\n",
      "epoch 70 loss = 2.143543\n",
      "epoch 71 loss = 2.105992\n",
      "epoch 72 loss = 2.064119\n",
      "epoch 73 loss = 2.103271\n",
      "epoch 74 loss = 2.084233\n",
      "epoch 75 loss = 2.074367\n",
      "epoch 76 loss = 2.009143\n",
      "epoch 77 loss = 2.121875\n",
      "epoch 78 loss = 2.111476\n",
      "epoch 79 loss = 1.944589\n",
      "epoch 80 loss = 2.057052\n",
      "epoch 81 loss = 2.121600\n",
      "epoch 82 loss = 2.063311\n",
      "epoch 83 loss = 1.966225\n",
      "epoch 84 loss = 2.054223\n",
      "epoch 85 loss = 2.105711\n",
      "epoch 86 loss = 2.175798\n",
      "epoch 87 loss = 2.163203\n",
      "epoch 88 loss = 1.998018\n",
      "epoch 89 loss = 2.073963\n",
      "epoch 90 loss = 2.096379\n",
      "epoch 91 loss = 2.019610\n",
      "epoch 92 loss = 2.165451\n",
      "epoch 93 loss = 2.212635\n",
      "epoch 94 loss = 2.067707\n",
      "epoch 95 loss = 2.086103\n",
      "epoch 96 loss = 2.043151\n",
      "epoch 97 loss = 2.154415\n",
      "epoch 98 loss = 2.095574\n",
      "epoch 99 loss = 1.906733\n",
      "epoch 100 loss = 2.013180\n",
      "epoch 101 loss = 2.149306\n",
      "epoch 102 loss = 2.066425\n",
      "epoch 103 loss = 2.132447\n",
      "epoch 104 loss = 2.060054\n",
      "epoch 105 loss = 2.054071\n",
      "epoch 106 loss = 2.178791\n",
      "epoch 107 loss = 2.073807\n",
      "epoch 108 loss = 2.086127\n",
      "epoch 109 loss = 2.089652\n",
      "epoch 110 loss = 2.165537\n",
      "epoch 111 loss = 2.095585\n",
      "epoch 112 loss = 2.102092\n",
      "epoch 113 loss = 2.101818\n",
      "epoch 114 loss = 2.147716\n",
      "epoch 115 loss = 2.086147\n",
      "epoch 116 loss = 2.103279\n",
      "epoch 117 loss = 2.139662\n",
      "epoch 118 loss = 2.077023\n",
      "epoch 119 loss = 2.002892\n",
      "epoch 120 loss = 2.149860\n",
      "epoch 121 loss = 2.000794\n",
      "epoch 122 loss = 1.983296\n",
      "epoch 123 loss = 2.060310\n",
      "epoch 124 loss = 2.063295\n",
      "epoch 125 loss = 2.057819\n",
      "epoch 126 loss = 1.934460\n",
      "epoch 127 loss = 2.099728\n",
      "epoch 128 loss = 2.143695\n",
      "epoch 129 loss = 2.144159\n",
      "epoch 130 loss = 2.087141\n",
      "epoch 131 loss = 2.059822\n",
      "epoch 132 loss = 2.277594\n",
      "epoch 133 loss = 1.994044\n",
      "epoch 134 loss = 2.113430\n",
      "epoch 135 loss = 2.100061\n",
      "epoch 136 loss = 2.039488\n",
      "epoch 137 loss = 2.192588\n",
      "epoch 138 loss = 2.127198\n",
      "epoch 139 loss = 2.125058\n",
      "epoch 140 loss = 2.100258\n",
      "epoch 141 loss = 2.131250\n",
      "epoch 142 loss = 2.117399\n",
      "epoch 143 loss = 2.128664\n",
      "epoch 144 loss = 2.131277\n",
      "epoch 145 loss = 1.992374\n",
      "epoch 146 loss = 2.150657\n",
      "epoch 147 loss = 2.074762\n",
      "epoch 148 loss = 2.086223\n",
      "epoch 149 loss = 2.169284\n",
      "epoch 150 loss = 2.244008\n",
      "epoch 151 loss = 2.076520\n",
      "epoch 152 loss = 2.152472\n",
      "epoch 153 loss = 2.141397\n",
      "epoch 154 loss = 1.974525\n",
      "epoch 155 loss = 2.163354\n",
      "epoch 156 loss = 2.112073\n",
      "epoch 157 loss = 2.149212\n",
      "epoch 158 loss = 2.190853\n",
      "epoch 159 loss = 2.160780\n",
      "epoch 160 loss = 2.131659\n",
      "epoch 161 loss = 2.062065\n",
      "epoch 162 loss = 2.115329\n",
      "epoch 163 loss = 2.158377\n",
      "epoch 164 loss = 2.156153\n",
      "epoch 165 loss = 2.111150\n",
      "epoch 166 loss = 1.988166\n",
      "epoch 167 loss = 2.249832\n",
      "epoch 168 loss = 2.065498\n",
      "epoch 169 loss = 2.137639\n",
      "epoch 170 loss = 2.034014\n",
      "epoch 171 loss = 2.099832\n",
      "epoch 172 loss = 2.093279\n",
      "epoch 173 loss = 2.054899\n",
      "epoch 174 loss = 2.216175\n",
      "epoch 175 loss = 2.096858\n",
      "epoch 176 loss = 2.046540\n",
      "epoch 177 loss = 1.970074\n",
      "epoch 178 loss = 2.094921\n",
      "epoch 179 loss = 1.933817\n",
      "epoch 180 loss = 2.123086\n",
      "epoch 181 loss = 1.969369\n",
      "epoch 182 loss = 2.210441\n",
      "epoch 183 loss = 2.084645\n",
      "epoch 184 loss = 2.063007\n",
      "epoch 185 loss = 1.996233\n",
      "epoch 186 loss = 2.014050\n",
      "epoch 187 loss = 2.001337\n",
      "epoch 188 loss = 2.311356\n",
      "epoch 189 loss = 2.030046\n",
      "epoch 190 loss = 2.190458\n",
      "epoch 191 loss = 2.111779\n",
      "epoch 192 loss = 2.022839\n",
      "epoch 193 loss = 2.097702\n",
      "epoch 194 loss = 2.116088\n",
      "epoch 195 loss = 2.108085\n",
      "epoch 196 loss = 2.187193\n",
      "epoch 197 loss = 2.049745\n",
      "epoch 198 loss = 2.228432\n",
      "epoch 199 loss = 2.101017\n",
      "epoch 200 loss = 2.042906\n",
      "epoch 201 loss = 2.101137\n",
      "epoch 202 loss = 2.076521\n",
      "epoch 203 loss = 2.142342\n",
      "epoch 204 loss = 2.189142\n",
      "epoch 205 loss = 2.107685\n",
      "epoch 206 loss = 2.016731\n",
      "epoch 207 loss = 2.163998\n",
      "epoch 208 loss = 1.937713\n",
      "epoch 209 loss = 2.104372\n",
      "epoch 210 loss = 2.080503\n",
      "epoch 211 loss = 2.050677\n",
      "epoch 212 loss = 2.069213\n",
      "epoch 213 loss = 2.065801\n",
      "epoch 214 loss = 2.126010\n",
      "epoch 215 loss = 2.006447\n",
      "epoch 216 loss = 2.205802\n",
      "epoch 217 loss = 2.216353\n",
      "epoch 218 loss = 2.090607\n",
      "epoch 219 loss = 2.181181\n",
      "epoch 220 loss = 2.087559\n",
      "epoch 221 loss = 2.116911\n",
      "epoch 222 loss = 2.209991\n",
      "epoch 223 loss = 2.132547\n",
      "epoch 224 loss = 1.990096\n",
      "epoch 225 loss = 2.075074\n",
      "epoch 226 loss = 2.057972\n",
      "epoch 227 loss = 2.111310\n",
      "epoch 228 loss = 2.233258\n",
      "epoch 229 loss = 2.231015\n",
      "epoch 230 loss = 2.064936\n",
      "epoch 231 loss = 2.030707\n",
      "epoch 232 loss = 2.015342\n",
      "epoch 233 loss = 2.069820\n",
      "epoch 234 loss = 2.081238\n",
      "epoch 235 loss = 2.153363\n",
      "epoch 236 loss = 2.200246\n",
      "epoch 237 loss = 2.098327\n",
      "epoch 238 loss = 2.088570\n",
      "epoch 239 loss = 2.069013\n",
      "epoch 240 loss = 2.002126\n",
      "epoch 241 loss = 2.023820\n",
      "epoch 242 loss = 2.100267\n",
      "epoch 243 loss = 2.098819\n",
      "epoch 244 loss = 2.111815\n",
      "epoch 245 loss = 2.064265\n",
      "epoch 246 loss = 1.980799\n",
      "epoch 247 loss = 2.084571\n",
      "epoch 248 loss = 2.016331\n",
      "epoch 249 loss = 2.003406\n",
      "epoch 250 loss = 2.068875\n",
      "epoch 251 loss = 2.122406\n",
      "epoch 252 loss = 2.137207\n",
      "epoch 253 loss = 1.995114\n",
      "epoch 254 loss = 2.125685\n",
      "epoch 255 loss = 2.105686\n",
      "epoch 256 loss = 2.050805\n",
      "epoch 257 loss = 2.194371\n",
      "epoch 258 loss = 2.099320\n",
      "epoch 259 loss = 2.047121\n",
      "epoch 260 loss = 2.068310\n",
      "epoch 261 loss = 2.120233\n",
      "epoch 262 loss = 1.928752\n",
      "epoch 263 loss = 2.139677\n",
      "epoch 264 loss = 2.227237\n",
      "epoch 265 loss = 2.057160\n",
      "epoch 266 loss = 2.223349\n",
      "epoch 267 loss = 2.252934\n",
      "epoch 268 loss = 2.153909\n",
      "epoch 269 loss = 1.930734\n",
      "epoch 270 loss = 2.123341\n",
      "epoch 271 loss = 2.116073\n",
      "epoch 272 loss = 2.254462\n",
      "epoch 273 loss = 2.091277\n",
      "epoch 274 loss = 1.972406\n",
      "epoch 275 loss = 2.106306\n",
      "epoch 276 loss = 2.156674\n",
      "epoch 277 loss = 2.155075\n",
      "epoch 278 loss = 2.065330\n",
      "epoch 279 loss = 2.056445\n",
      "epoch 280 loss = 2.133004\n",
      "epoch 281 loss = 2.156060\n",
      "epoch 282 loss = 2.205727\n",
      "epoch 283 loss = 2.072432\n",
      "epoch 284 loss = 2.093381\n",
      "epoch 285 loss = 2.177992\n",
      "epoch 286 loss = 2.018710\n",
      "epoch 287 loss = 2.064138\n",
      "epoch 288 loss = 2.004346\n",
      "epoch 289 loss = 1.904614\n",
      "epoch 290 loss = 2.232704\n",
      "epoch 291 loss = 2.049858\n",
      "epoch 292 loss = 2.058819\n",
      "epoch 293 loss = 1.958432\n",
      "epoch 294 loss = 2.191692\n",
      "epoch 295 loss = 2.180898\n",
      "epoch 296 loss = 2.013354\n",
      "epoch 297 loss = 2.034121\n",
      "epoch 298 loss = 2.188578\n",
      "epoch 299 loss = 1.972989\n",
      "epoch 300 loss = 2.093367\n",
      "epoch 301 loss = 2.229055\n",
      "epoch 302 loss = 2.074930\n",
      "epoch 303 loss = 2.094767\n",
      "epoch 304 loss = 2.067050\n",
      "epoch 305 loss = 2.268758\n",
      "epoch 306 loss = 2.062631\n",
      "epoch 307 loss = 2.070012\n",
      "epoch 308 loss = 2.053989\n",
      "epoch 309 loss = 2.072961\n",
      "epoch 310 loss = 2.229830\n",
      "epoch 311 loss = 2.217138\n",
      "epoch 312 loss = 2.025123\n",
      "epoch 313 loss = 2.068278\n",
      "epoch 314 loss = 2.145195\n",
      "epoch 315 loss = 2.070503\n",
      "epoch 316 loss = 2.113997\n",
      "epoch 317 loss = 2.004771\n",
      "epoch 318 loss = 2.179337\n",
      "epoch 319 loss = 2.052635\n",
      "epoch 320 loss = 1.986232\n",
      "epoch 321 loss = 1.842902\n",
      "epoch 322 loss = 1.918584\n",
      "epoch 323 loss = 2.286496\n",
      "epoch 324 loss = 2.025119\n",
      "epoch 325 loss = 2.127185\n",
      "epoch 326 loss = 2.132560\n",
      "epoch 327 loss = 2.198970\n",
      "epoch 328 loss = 2.080304\n",
      "epoch 329 loss = 2.081300\n",
      "epoch 330 loss = 2.142565\n",
      "epoch 331 loss = 2.140634\n",
      "epoch 332 loss = 2.170383\n",
      "epoch 333 loss = 2.088838\n",
      "epoch 334 loss = 1.994381\n",
      "epoch 335 loss = 1.993471\n",
      "epoch 336 loss = 2.063169\n",
      "epoch 337 loss = 2.160089\n",
      "epoch 338 loss = 2.176009\n",
      "epoch 339 loss = 2.083819\n",
      "epoch 340 loss = 2.083919\n",
      "epoch 341 loss = 1.997035\n",
      "epoch 342 loss = 2.043132\n",
      "epoch 343 loss = 2.019138\n",
      "epoch 344 loss = 2.145180\n",
      "epoch 345 loss = 2.132309\n",
      "epoch 346 loss = 2.243810\n",
      "epoch 347 loss = 2.015299\n",
      "epoch 348 loss = 1.961162\n",
      "epoch 349 loss = 2.133373\n",
      "epoch 350 loss = 2.060110\n",
      "epoch 351 loss = 2.043091\n",
      "epoch 352 loss = 2.214439\n",
      "epoch 353 loss = 2.137308\n",
      "epoch 354 loss = 2.142179\n",
      "epoch 355 loss = 2.068788\n",
      "epoch 356 loss = 2.124483\n",
      "epoch 357 loss = 2.032065\n",
      "epoch 358 loss = 2.257134\n",
      "epoch 359 loss = 2.019560\n",
      "epoch 360 loss = 2.040655\n",
      "epoch 361 loss = 2.099420\n",
      "epoch 362 loss = 1.926858\n",
      "epoch 363 loss = 2.087750\n",
      "epoch 364 loss = 2.061097\n",
      "epoch 365 loss = 1.987753\n",
      "epoch 366 loss = 2.066999\n",
      "epoch 367 loss = 2.083759\n",
      "epoch 368 loss = 2.030928\n",
      "epoch 369 loss = 2.192781\n",
      "epoch 370 loss = 2.134060\n",
      "epoch 371 loss = 2.165444\n",
      "epoch 372 loss = 2.094731\n",
      "epoch 373 loss = 2.083202\n",
      "epoch 374 loss = 2.063715\n",
      "epoch 375 loss = 2.042573\n",
      "epoch 376 loss = 2.074022\n",
      "epoch 377 loss = 2.174633\n",
      "epoch 378 loss = 2.092761\n",
      "epoch 379 loss = 2.018603\n",
      "epoch 380 loss = 2.109722\n",
      "epoch 381 loss = 2.153955\n",
      "epoch 382 loss = 2.121076\n",
      "epoch 383 loss = 2.108568\n",
      "epoch 384 loss = 2.128942\n",
      "epoch 385 loss = 2.054291\n",
      "epoch 386 loss = 2.113404\n",
      "epoch 387 loss = 2.054681\n",
      "epoch 388 loss = 1.948049\n",
      "epoch 389 loss = 2.077329\n",
      "epoch 390 loss = 2.176640\n",
      "epoch 391 loss = 2.108812\n",
      "epoch 392 loss = 2.189895\n",
      "epoch 393 loss = 2.109357\n",
      "epoch 394 loss = 2.094236\n",
      "epoch 395 loss = 2.182456\n",
      "epoch 396 loss = 2.079747\n",
      "epoch 397 loss = 1.948924\n",
      "epoch 398 loss = 2.125893\n",
      "epoch 399 loss = 2.104371\n",
      "epoch 400 loss = 2.062884\n",
      "epoch 401 loss = 2.143919\n",
      "epoch 402 loss = 2.046210\n",
      "epoch 403 loss = 1.899162\n",
      "epoch 404 loss = 2.128797\n",
      "epoch 405 loss = 2.301305\n",
      "epoch 406 loss = 2.017980\n",
      "epoch 407 loss = 2.266429\n",
      "epoch 408 loss = 2.106707\n",
      "epoch 409 loss = 2.053032\n",
      "epoch 410 loss = 2.250008\n",
      "epoch 411 loss = 2.003450\n",
      "epoch 412 loss = 2.146501\n",
      "epoch 413 loss = 2.094308\n",
      "epoch 414 loss = 2.169843\n",
      "epoch 415 loss = 2.102345\n",
      "epoch 416 loss = 2.138754\n",
      "epoch 417 loss = 2.059824\n",
      "epoch 418 loss = 2.050341\n",
      "epoch 419 loss = 2.190757\n",
      "epoch 420 loss = 2.045689\n",
      "epoch 421 loss = 2.004628\n",
      "epoch 422 loss = 2.125523\n",
      "epoch 423 loss = 2.128168\n",
      "epoch 424 loss = 2.226044\n",
      "epoch 425 loss = 2.113775\n",
      "epoch 426 loss = 2.174075\n",
      "epoch 427 loss = 2.019770\n",
      "epoch 428 loss = 2.157747\n",
      "epoch 429 loss = 2.030893\n",
      "epoch 430 loss = 2.125341\n",
      "epoch 431 loss = 2.068073\n",
      "epoch 432 loss = 2.053729\n",
      "epoch 433 loss = 2.197807\n",
      "epoch 434 loss = 2.029421\n",
      "epoch 435 loss = 2.123084\n",
      "epoch 436 loss = 2.124866\n",
      "epoch 437 loss = 2.145621\n",
      "epoch 438 loss = 2.082978\n",
      "epoch 439 loss = 2.195432\n",
      "epoch 440 loss = 2.128590\n",
      "epoch 441 loss = 2.117052\n",
      "epoch 442 loss = 2.077674\n",
      "epoch 443 loss = 2.074285\n",
      "epoch 444 loss = 2.123869\n",
      "epoch 445 loss = 2.103275\n",
      "epoch 446 loss = 2.027540\n",
      "epoch 447 loss = 2.009789\n",
      "epoch 448 loss = 2.243762\n",
      "epoch 449 loss = 2.164962\n",
      "epoch 450 loss = 2.089477\n",
      "epoch 451 loss = 2.084909\n",
      "epoch 452 loss = 2.061815\n",
      "epoch 453 loss = 2.106234\n",
      "epoch 454 loss = 2.108055\n",
      "epoch 455 loss = 2.207706\n",
      "epoch 456 loss = 2.224938\n",
      "epoch 457 loss = 2.225562\n",
      "epoch 458 loss = 2.113404\n",
      "epoch 459 loss = 2.131453\n",
      "epoch 460 loss = 2.129515\n",
      "epoch 461 loss = 2.102576\n",
      "epoch 462 loss = 2.071812\n",
      "epoch 463 loss = 2.162885\n",
      "epoch 464 loss = 2.089628\n",
      "epoch 465 loss = 2.297031\n",
      "epoch 466 loss = 2.257158\n",
      "epoch 467 loss = 1.980285\n",
      "epoch 468 loss = 2.134419\n",
      "epoch 469 loss = 2.085069\n",
      "epoch 470 loss = 1.980301\n",
      "epoch 471 loss = 2.162423\n",
      "epoch 472 loss = 1.975911\n",
      "epoch 473 loss = 2.133110\n",
      "epoch 474 loss = 1.993891\n",
      "epoch 475 loss = 2.264210\n",
      "epoch 476 loss = 2.033717\n",
      "epoch 477 loss = 2.075758\n",
      "epoch 478 loss = 2.045097\n",
      "epoch 479 loss = 2.116232\n",
      "epoch 480 loss = 2.184896\n",
      "epoch 481 loss = 2.202313\n",
      "epoch 482 loss = 1.981502\n",
      "epoch 483 loss = 1.984889\n",
      "epoch 484 loss = 2.088099\n",
      "epoch 485 loss = 2.150199\n",
      "epoch 486 loss = 2.052484\n",
      "epoch 487 loss = 2.114811\n",
      "epoch 488 loss = 2.006524\n",
      "epoch 489 loss = 2.001012\n",
      "epoch 490 loss = 2.153807\n",
      "epoch 491 loss = 2.081808\n",
      "epoch 492 loss = 2.046667\n",
      "epoch 493 loss = 2.090879\n",
      "epoch 494 loss = 2.176105\n",
      "epoch 495 loss = 2.084032\n",
      "epoch 496 loss = 2.086610\n",
      "epoch 497 loss = 2.101085\n",
      "epoch 498 loss = 1.973249\n",
      "epoch 499 loss = 2.117281\n",
      "final loss = 2.117281\n",
      "accuracy_mc = tensor(0.2367, device='cuda:0')\n",
      "accuracy_non_mc = tensor(0.2064, device='cuda:0')\n",
      "test_ll_mc = tensor(-2.0182, device='cuda:0')\n",
      "training time = 307.1037321090698 seconds\n",
      "testing time = 3.174907922744751 seconds\n",
      "\n",
      "subset 0.050000, dropout_rate 0.700000, reg_strength 0.050000\n",
      "n_epoch 10\n",
      "\n",
      "Files already downloaded and verified\n",
      "subset size = (2500, 32, 32, 3)\n",
      "training set size = 2000\n",
      "test set size = 500\n",
      "\n",
      "Training with split 0\n",
      "epoch 0 loss = 2.356115\n",
      "epoch 1 loss = 2.343103\n",
      "epoch 2 loss = 2.334352\n",
      "epoch 3 loss = 2.296577\n",
      "epoch 4 loss = 2.243265\n",
      "epoch 5 loss = 2.268781\n",
      "epoch 6 loss = 2.279317\n",
      "epoch 7 loss = 2.295470\n",
      "epoch 8 loss = 2.315459\n",
      "epoch 9 loss = 2.264330\n",
      "final loss = 2.264330\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-20d1e85720d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mtic_testing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;31m# Record testing end time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/My Drive/Colab Notebooks/bayesian-dl-experiments/ronald_bdl/models/simple_cifar10_mc_dropout.py\u001b[0m in \u001b[0;36mpredict_dist\u001b[0;34m(self, test_loader, n_prediction, torch_device)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0;31m# Temporaily disable eval mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mwas_eval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \"\"\"\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;31m# put it from HWC to CHW format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# yikes, this transpose takes 80% of the loading time/CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for subset_prop, dropout_rate, reg_strength, n_epoch in itertools.product(\n",
    "    subset_proportions,\n",
    "    dropout_rates, reg_strengths, \n",
    "    n_epochs,\n",
    "):  \n",
    "    # Reset the random number generator for each method (to produce identical results)\n",
    "    torch.manual_seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    pyro.set_rng_seed(random_seed)\n",
    "\n",
    "    # Print parameter combinations being tested\n",
    "    print(\n",
    "        \"subset %f, dropout_rate %f, reg_strength %f\"\n",
    "        % (subset_prop, dropout_rate, reg_strength))\n",
    "\n",
    "    print(\"n_epoch %d\" % n_epoch)\n",
    "    print()\n",
    "\n",
    "    \"\"\"\n",
    "    Results file storage\n",
    "    \"\"\"\n",
    "\n",
    "    # Create directory to store results for the current test configuration\n",
    "    test_results_path = os.path.join(\n",
    "        './test_results',\n",
    "        'error_convergence_2',\n",
    "        'CIFAR-10',\n",
    "        test_start_time,\n",
    "        (\n",
    "            str(subset_prop)\n",
    "            + '_' + str(dropout_rate) \n",
    "            + '_' + str(reg_strength)\n",
    "            + '_' + str(n_epoch)),\n",
    "    )\n",
    "\n",
    "    os.makedirs(test_results_path, exist_ok=True)\n",
    "\n",
    "    test_results_accuracy_mc_path = os.path.join(\n",
    "        test_results_path,\n",
    "        \"accuracy_mc.txt\"\n",
    "    )\n",
    "\n",
    "    test_results_accuracy_non_mc_path = os.path.join(\n",
    "        test_results_path,\n",
    "        \"accuracy_non_mc.txt\"\n",
    "    )\n",
    "\n",
    "    test_results_lls_mc_path = os.path.join(\n",
    "        test_results_path,\n",
    "        \"lls_mc.txt\"\n",
    "    )\n",
    "\n",
    "    \"\"\"\n",
    "    Dataset multiple splits prep\n",
    "    \"\"\"\n",
    "    # Prepare new subset of the original dataset\n",
    "    subset = datasets.CIFAR10(\n",
    "        root='./datasets_files', limit_size=subset_prop, transform=transform, download=True)\n",
    "\n",
    "    # Determine sizes of training and testing set\n",
    "    train_size = int(dataset_train_size * len(subset))\n",
    "    test_size = len(subset) - train_size\n",
    "\n",
    "    # Print the size of the subset\n",
    "    print(\"subset size = \" + str(subset.data.shape))\n",
    "    print(\"training set size = %d\" % train_size)\n",
    "    print(\"test set size = %d\" % test_size)\n",
    "    print()\n",
    "\n",
    "    # Prepare multiple sets of random train-test splits \n",
    "    # to test the parameter combination\n",
    "    subset_splits = []\n",
    "\n",
    "    for _ in range(n_splits):\n",
    "        train, test = random_split(subset, lengths=[train_size, test_size])\n",
    "        subset_splits.append((train, test))\n",
    "\n",
    "    \"\"\"\n",
    "    Training & testing\n",
    "    \"\"\"\n",
    "\n",
    "    # Try learning with different splits\n",
    "    for s, (train, test) in enumerate(subset_splits):\n",
    "\n",
    "        \"\"\"\n",
    "        Training\n",
    "        \"\"\"\n",
    "\n",
    "        print('Training with split %d' % s)\n",
    "\n",
    "        train_loader = DataLoader(train, batch_size=n_training_batch, pin_memory=use_pin_memory)\n",
    "\n",
    "        # Prepare network\n",
    "        network = models.SimpleCIFAR10MCDropout(\n",
    "        #network = models.SqueezeNetDropout(\n",
    "        #    num_classes=10,\n",
    "            dropout_rate=dropout_rate,\n",
    "            dropout_type='bernoulli',\n",
    "        )\n",
    "\n",
    "        # Send the whole model to the selected torch.device\n",
    "        network.to(torch_device)\n",
    "\n",
    "        # Model to train mode\n",
    "        network.train()\n",
    "\n",
    "        # Adam optimizer\n",
    "        # https://pytorch.org/docs/stable/optim.html?highlight=adam#torch.optim.Adam\n",
    "        # NOTE: Need to set L2 regularization from here\n",
    "        optimizer = optim.Adam(\n",
    "            network.parameters(),\n",
    "            lr=optimizer_learning_rate,\n",
    "            #momentum=optimizer_momentum,\n",
    "            weight_decay=reg_strength, # L2 regularization\n",
    "        )\n",
    "\n",
    "        # Record training start time (for this split)\n",
    "        tic = time.time()\n",
    "\n",
    "        for epoch in range(n_epoch): # loop over the dataset multiple times\n",
    "            # Mini-batches\n",
    "            for data in train_loader:\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs, targets = data\n",
    "\n",
    "                # Store the batch to torch_device's memory\n",
    "                inputs = inputs.to(torch_device)\n",
    "                targets = targets.to(torch_device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = network(inputs)\n",
    "\n",
    "                loss = objective(outputs, targets)\n",
    "                loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "            print(\"epoch %d loss = %f\" % (epoch, loss.item()))\n",
    "\n",
    "        # Record training end time\n",
    "        toc = time.time()\n",
    "\n",
    "        # Report the final loss\n",
    "        print(\"final loss = %f\" % (loss.item()))\n",
    "\n",
    "        \"\"\"\n",
    "        Testing\n",
    "        \"\"\"\n",
    "\n",
    "        # Model to eval mode\n",
    "        network.eval()\n",
    "\n",
    "        # Store the batch to torch_device's memory\n",
    "        test_loader = DataLoader(test, batch_size=n_training_batch, pin_memory=use_pin_memory)\n",
    "\n",
    "        # Record testing start time\n",
    "        tic_testing = time.time()\n",
    "\n",
    "        _, mean, metrics = network.predict_dist(test_loader, n_prediction, torch_device)\n",
    "\n",
    "        # Record testing end time\n",
    "        toc_testing = time.time()\n",
    "\n",
    "        # Record all the scores to the score files\n",
    "        if len(metrics) > 0:\n",
    "            for key, value in metrics.items():\n",
    "                print(str(key) + \" = \" + str(value))\n",
    "\n",
    "                if key == 'accuracy_mc':\n",
    "                    with open(test_results_accuracy_mc_path, 'a+') as accuracy_mc_file:\n",
    "                        accuracy_mc_file.write('%d %f \\n' % (s, value))\n",
    "\n",
    "                elif key == 'accuracy_non_mc':\n",
    "                    with open(test_results_accuracy_non_mc_path, 'a+') as accuracy_non_mc_file:\n",
    "                        accuracy_non_mc_file.write('%d %f \\n' % (s, value))\n",
    "\n",
    "                elif key == 'test_ll_mc':\n",
    "                    with open(test_results_lls_mc_path, 'a+') as lls_mc_file:\n",
    "                        lls_mc_file.write('%d %f \\n' % (s, value))\n",
    "\n",
    "        # Report the total training time\n",
    "        print(\"training time = \" + str(toc - tic) + \" seconds\")\n",
    "\n",
    "        # Report the total testing time\n",
    "        print(\"testing time = \" + str(toc_testing - tic_testing) + \" seconds\")\n",
    "\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "whZbn3VTTUFa"
   },
   "source": [
    "## Results visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pDxkRM5aVrdf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "experiment_error_convergence_2_cifar10_simplecnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
