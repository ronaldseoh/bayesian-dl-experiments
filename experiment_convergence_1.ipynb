{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bka_bK83VFHh"
   },
   "source": [
    "## Experiment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8D5NSPs_cJZe"
   },
   "source": [
    "### Random seed / PyTorch / CUDA related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29359,
     "status": "ok",
     "timestamp": 1574907620301,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "pHbfpytEVFHu",
    "outputId": "3a49ecf4-bc3a-4be9-d656-d751811d42b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n",
      "Collecting pyro-ppl\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/9b/a8aa400ebb22a74ac00717ee897b9f179461d4f9052b348644aee36d1b87/pyro_ppl-1.0.0-py3-none-any.whl (404kB)\n",
      "\u001b[K     |████████████████████████████████| 409kB 9.6MB/s \n",
      "\u001b[?25hCollecting tqdm>=4.36\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/62/6f823501b3bf2bac242bd3c320b592ad1516b3081d82c77c1d813f076856/tqdm-4.39.0-py2.py3-none-any.whl (53kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 9.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (1.17.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (3.1.0)\n",
      "Requirement already satisfied: graphviz>=0.8 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (0.10.1)\n",
      "Collecting pyro-api>=0.1.1\n",
      "  Downloading https://files.pythonhosted.org/packages/c2/bc/6cdbd1929e32fff62a33592633c2cc0393c7f7739131ccc9c9c4e28ac8dd/pyro_api-0.1.1-py3-none-any.whl\n",
      "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (1.3.1)\n",
      "Installing collected packages: tqdm, pyro-api, pyro-ppl\n",
      "  Found existing installation: tqdm 4.28.1\n",
      "    Uninstalling tqdm-4.28.1:\n",
      "      Successfully uninstalled tqdm-4.28.1\n",
      "Successfully installed pyro-api-0.1.1 pyro-ppl-1.0.0 tqdm-4.39.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "tqdm"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks/bayesian-dl-experiments\n",
      "datasets_files\t\t\t experiment_nn_capacity_1.ipynb  ronald_bdl\n",
      "experiment_comparison_toy.ipynb  LICENSE\t\t\t test_results\n",
      "experiment_convergence_1.ipynb\t README.md\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "\n",
    "# Use Google Colab\n",
    "use_colab = True\n",
    "\n",
    "# Is this notebook running on Colab?\n",
    "# If so, then google.colab package (github.com/googlecolab/colabtools)\n",
    "# should be available in this environment\n",
    "\n",
    "# Previous version used importlib, but we could do the same thing with\n",
    "# just attempting to import google.colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    colab_available = True\n",
    "except:\n",
    "    colab_available = False\n",
    "\n",
    "if use_colab and colab_available:\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # If there's a package I need to install separately, do it here\n",
    "    !pip install pyro-ppl\n",
    "\n",
    "    # cd to the appropriate working directory under my Google Drive\n",
    "    %cd 'drive/My Drive/Colab Notebooks/bayesian-dl-experiments'\n",
    "    \n",
    "    # List the directory contents\n",
    "    !ls\n",
    "\n",
    "# IPython reloading magic\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Random seeds\n",
    "# Based on https://pytorch.org/docs/stable/notes/randomness.html\n",
    "random_seed = 682"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tqlpuws9Y-8U"
   },
   "source": [
    "### Third party libraries (NumPy, PyTorch, Pyro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32816,
     "status": "ok",
     "timestamp": 1574907623776,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "2zNVvKmZY-8X",
    "outputId": "267dbd7f-1192-4359-d1fc-42cffe692a12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.6.8 (default, Oct  7 2019, 12:59:55) \n",
      "[GCC 8.3.0]\n",
      "NumPy Version: 1.17.4\n",
      "PyTorch Version: 1.3.1\n",
      "Pyro Version: 1.0.0\n"
     ]
    }
   ],
   "source": [
    "# Third party libraries import\n",
    "import numpy as np\n",
    "import torch\n",
    "import pyro\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Print version information\n",
    "print(\"Python Version: \" + sys.version)\n",
    "print(\"NumPy Version: \" + np.__version__)\n",
    "print(\"PyTorch Version: \" + torch.__version__)\n",
    "print(\"Pyro Version: \" + pyro.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40394,
     "status": "ok",
     "timestamp": 1574907631370,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "uyRIfCC5Y-8g",
    "outputId": "90738a89-26ec-411e-d415-f627084379b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Version: 10.1.243\n",
      "cuDNN Version: 7603\n",
      "CUDA Device Name: Tesla P100-PCIE-16GB\n",
      "CUDA Capabilities: (6, 0)\n"
     ]
    }
   ],
   "source": [
    "# More imports...\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import random_split, DataLoader, RandomSampler\n",
    "\n",
    "# Import model and dataset classes from ronald_bdl\n",
    "from ronald_bdl import models, datasets\n",
    "\n",
    "# pyplot setting\n",
    "%matplotlib inline\n",
    "\n",
    "# torch.device / CUDA Setup\n",
    "use_cuda = True\n",
    "\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    torch_device = torch.device('cuda')\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    # Disable 'benchmark' mode\n",
    "    # Note: https://discuss.pytorch.org/t/what-does-torch-backends-cudnn-benchmark-do/5936\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    use_pin_memory = True # Faster Host to GPU copies with page-locked memory\n",
    "\n",
    "    # CUDA libraries version information\n",
    "    print(\"CUDA Version: \" + str(torch.version.cuda))\n",
    "    print(\"cuDNN Version: \" + str(torch.backends.cudnn.version()))\n",
    "    print(\"CUDA Device Name: \" + str(torch.cuda.get_device_name()))\n",
    "    print(\"CUDA Capabilities: \"+ str(torch.cuda.get_device_capability()))\n",
    "else:\n",
    "    torch_device = torch.device('cpu')\n",
    "    use_pin_memory = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XIFRoH3AcJZn"
   },
   "source": [
    "### Variable settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g_pzGq1_cJZp"
   },
   "outputs": [],
   "source": [
    "# Dataset to use\n",
    "dataset_name = 'yacht'\n",
    "\n",
    "# Training set size\n",
    "dataset_train_size = 0.8\n",
    "\n",
    "# Number of dataset splits\n",
    "n_splits = 10\n",
    "\n",
    "# Epochs\n",
    "n_epochs = [40, 400, 4000, 40000]\n",
    "\n",
    "# Data batch sizes\n",
    "n_training_batch = 128\n",
    "\n",
    "# Set the proportion of the dataset to be available as a whole\n",
    "subset_proportions = [1.0]\n",
    "\n",
    "# NN hyperparameters\n",
    "network_hidden_dims = [25, 50, 100]\n",
    "network_hidden_layers = [1, 3, 5]\n",
    "\n",
    "# Dropout\n",
    "network_dropout_rates = [0.01]\n",
    "\n",
    "# Regularization strengths\n",
    "regularization_strengths = [0.05]\n",
    "\n",
    "# Number of test predictions (for each data point)\n",
    "prediction_runs = [300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DuTnXABzVFKI"
   },
   "source": [
    "\n",
    "### Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p19qFgSAVFKS"
   },
   "outputs": [],
   "source": [
    "# Mean Squared Error for loss function to minimize\n",
    "objective = nn.MSELoss()\n",
    "\n",
    "# Test start time\n",
    "test_start_time = datetime.datetime.today().strftime('%Y%m%d%H%M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1PpzPMI8VFKE"
   },
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "m4kavCiTVFKf",
    "outputId": "4e4155ba-a965-406d-e8c2-e92a0e75f898",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subset 1.000000, n_hidden 1, hidden_dim 25, dropout_rate 0.010000, reg_strength 0.050000\n",
      "n_epoch 40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://archive.ics.uci.edu/ml/machine-learning-databases/00243/yacht_hydrodynamics.data to ./datasets_files/yacht/yacht_hydrodynamics.data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16384it [00:00, 35135.24it/s]            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subset size = (308, 6)\n",
      "training set size = 246\n",
      "test set size = 62\n",
      "\n",
      "Training with split 0\n",
      "final loss = 252.278519\n",
      "rmse_mc = tensor(14.8029, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(14.8018, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-7.8493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 0.6883201599121094 seconds\n",
      "testing time = 0.12498617172241211 seconds\n",
      "\n",
      "Training with split 1\n",
      "final loss = 245.172470\n",
      "rmse_mc = tensor(13.6397, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(13.6373, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-7.0218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 0.5279178619384766 seconds\n",
      "testing time = 0.0707998275756836 seconds\n",
      "\n",
      "Training with split 2\n",
      "final loss = 203.990540\n",
      "rmse_mc = tensor(14.4400, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(14.4368, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-7.5749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 0.5383021831512451 seconds\n",
      "testing time = 0.05926227569580078 seconds\n",
      "\n",
      "Training with split 3\n",
      "final loss = 254.195770\n",
      "rmse_mc = tensor(15.6353, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(15.6339, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-8.4879, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 0.5241246223449707 seconds\n",
      "testing time = 0.06628751754760742 seconds\n",
      "\n",
      "Training with split 4\n",
      "final loss = 169.495453\n",
      "rmse_mc = tensor(16.4897, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(16.4831, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-9.1543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 0.5219345092773438 seconds\n",
      "testing time = 0.05833315849304199 seconds\n",
      "\n",
      "Training with split 5\n",
      "final loss = 284.646759\n",
      "rmse_mc = tensor(13.5190, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(13.5177, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-6.9470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 0.544492244720459 seconds\n",
      "testing time = 0.06876778602600098 seconds\n",
      "\n",
      "Training with split 6\n",
      "final loss = 170.392380\n",
      "rmse_mc = tensor(15.4872, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(15.4875, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-8.2515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 0.5257573127746582 seconds\n",
      "testing time = 0.06078791618347168 seconds\n",
      "\n",
      "Training with split 7\n",
      "final loss = 212.669510\n",
      "rmse_mc = tensor(13.4897, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(13.4908, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-6.7170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 0.5205514430999756 seconds\n",
      "testing time = 0.05866527557373047 seconds\n",
      "\n",
      "Training with split 8\n",
      "final loss = 173.783752\n",
      "rmse_mc = tensor(13.5512, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(13.5509, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-6.9606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 0.5059607028961182 seconds\n",
      "testing time = 0.060196876525878906 seconds\n",
      "\n",
      "Training with split 9\n",
      "final loss = 210.904266\n",
      "rmse_mc = tensor(14.7950, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(14.7954, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-7.7445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 0.5209124088287354 seconds\n",
      "testing time = 0.058974266052246094 seconds\n",
      "\n",
      "subset 1.000000, n_hidden 1, hidden_dim 25, dropout_rate 0.010000, reg_strength 0.050000\n",
      "n_epoch 400\n",
      "\n",
      "Using downloaded and verified file: ./datasets_files/yacht/yacht_hydrodynamics.data\n",
      "subset size = (308, 6)\n",
      "training set size = 246\n",
      "test set size = 62\n",
      "\n",
      "Training with split 0\n",
      "final loss = 3.983265\n",
      "rmse_mc = tensor(2.8544, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(2.8571, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-2.6361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 5.145526885986328 seconds\n",
      "testing time = 0.056771039962768555 seconds\n",
      "\n",
      "Training with split 1\n",
      "final loss = 3.949060\n",
      "rmse_mc = tensor(1.5051, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(1.5021, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-2.4829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 5.188775300979614 seconds\n",
      "testing time = 0.05897879600524902 seconds\n",
      "\n",
      "Training with split 2\n",
      "final loss = 4.374402\n",
      "rmse_mc = tensor(1.6585, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(1.6373, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-2.5020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 5.11129903793335 seconds\n",
      "testing time = 0.057831764221191406 seconds\n",
      "\n",
      "Training with split 3\n",
      "final loss = 4.516055\n",
      "rmse_mc = tensor(2.3746, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(2.3605, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-2.5636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 5.14579176902771 seconds\n",
      "testing time = 0.06138014793395996 seconds\n",
      "\n",
      "Training with split 4\n",
      "final loss = 4.007836\n",
      "rmse_mc = tensor(1.8455, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(1.8214, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-2.5106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 5.127844333648682 seconds\n",
      "testing time = 0.05842995643615723 seconds\n",
      "\n",
      "Training with split 5\n",
      "final loss = 5.174178\n",
      "rmse_mc = tensor(1.8446, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(1.8501, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-2.5045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 5.148667573928833 seconds\n",
      "testing time = 0.058515310287475586 seconds\n",
      "\n",
      "Training with split 6\n",
      "final loss = 4.281913\n",
      "rmse_mc = tensor(1.6858, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(1.6810, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-2.4973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 5.144224643707275 seconds\n",
      "testing time = 0.060328006744384766 seconds\n",
      "\n",
      "Training with split 7\n",
      "final loss = 2.424831\n",
      "rmse_mc = tensor(1.3208, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(1.3359, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-2.4847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 5.10765266418457 seconds\n",
      "testing time = 0.058412790298461914 seconds\n",
      "\n",
      "Training with split 8\n",
      "final loss = 4.463462\n",
      "rmse_mc = tensor(1.3215, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(1.3021, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-2.4768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 5.051752328872681 seconds\n",
      "testing time = 0.05804896354675293 seconds\n",
      "\n",
      "Training with split 9\n",
      "final loss = 5.540998\n",
      "rmse_mc = tensor(2.1662, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(2.1972, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-2.5377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 5.102286338806152 seconds\n",
      "testing time = 0.059340715408325195 seconds\n",
      "\n",
      "subset 1.000000, n_hidden 1, hidden_dim 25, dropout_rate 0.010000, reg_strength 0.050000\n",
      "n_epoch 4000\n",
      "\n",
      "Using downloaded and verified file: ./datasets_files/yacht/yacht_hydrodynamics.data\n",
      "subset size = (308, 6)\n",
      "training set size = 246\n",
      "test set size = 62\n",
      "\n",
      "Training with split 0\n",
      "final loss = 1.556299\n",
      "rmse_mc = tensor(1.0675, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(1.0526, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-2.4584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 50.86602067947388 seconds\n",
      "testing time = 0.05597710609436035 seconds\n",
      "\n",
      "Training with split 1\n",
      "final loss = 5.029969\n",
      "rmse_mc = tensor(1.4938, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(1.4719, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-2.4758, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 50.53028178215027 seconds\n",
      "testing time = 0.056900739669799805 seconds\n",
      "\n",
      "Training with split 2\n",
      "final loss = 1.204911\n",
      "rmse_mc = tensor(0.8356, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(0.8257, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-2.4451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 49.63155794143677 seconds\n",
      "testing time = 0.05603480339050293 seconds\n",
      "\n",
      "Training with split 3\n",
      "final loss = 0.625482\n",
      "rmse_mc = tensor(3.0913, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(3.0875, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-2.6408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 49.32025909423828 seconds\n",
      "testing time = 0.060410261154174805 seconds\n",
      "\n",
      "Training with split 4\n",
      "final loss = 3.589242\n",
      "rmse_mc = tensor(1.1716, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(1.1710, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-2.4561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 48.66451144218445 seconds\n",
      "testing time = 0.05634880065917969 seconds\n",
      "\n",
      "Training with split 5\n",
      "final loss = 1.403115\n",
      "rmse_mc = tensor(1.9227, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(1.9453, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-2.5141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 48.60721755027771 seconds\n",
      "testing time = 0.05654144287109375 seconds\n",
      "\n",
      "Training with split 6\n",
      "final loss = 1.071114\n",
      "rmse_mc = tensor(1.7693, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(1.7904, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-2.5099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 48.527184009552 seconds\n",
      "testing time = 0.05904197692871094 seconds\n",
      "\n",
      "Training with split 7\n",
      "final loss = 1.279899\n",
      "rmse_mc = tensor(1.6121, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(1.6044, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-2.4828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 48.57888960838318 seconds\n",
      "testing time = 0.05570626258850098 seconds\n",
      "\n",
      "Training with split 8\n",
      "final loss = 1.215404\n",
      "rmse_mc = tensor(0.9338, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(0.9327, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-2.4463, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 48.27940225601196 seconds\n",
      "testing time = 0.05489611625671387 seconds\n",
      "\n",
      "Training with split 9\n",
      "final loss = 0.866820\n",
      "rmse_mc = tensor(0.7907, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(0.7756, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-2.4408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 47.945223331451416 seconds\n",
      "testing time = 0.05487370491027832 seconds\n",
      "\n",
      "subset 1.000000, n_hidden 1, hidden_dim 25, dropout_rate 0.010000, reg_strength 0.050000\n",
      "n_epoch 40000\n",
      "\n",
      "Using downloaded and verified file: ./datasets_files/yacht/yacht_hydrodynamics.data\n",
      "subset size = (308, 6)\n",
      "training set size = 246\n",
      "test set size = 62\n",
      "\n",
      "Training with split 0\n",
      "final loss = 1.866462\n",
      "rmse_mc = tensor(1.0216, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(1.0164, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-2.4532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 477.44726753234863 seconds\n",
      "testing time = 0.05399322509765625 seconds\n",
      "\n",
      "Training with split 1\n",
      "final loss = 3.517863\n",
      "rmse_mc = tensor(0.9138, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(0.9197, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-2.4456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 473.71129322052 seconds\n",
      "testing time = 0.05398821830749512 seconds\n",
      "\n",
      "Training with split 2\n",
      "final loss = 1.332877\n",
      "rmse_mc = tensor(0.8602, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(0.8618, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-2.4470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 472.3047709465027 seconds\n",
      "testing time = 0.0572199821472168 seconds\n",
      "\n",
      "Training with split 3\n",
      "final loss = 2.912461\n",
      "rmse_mc = tensor(1.7061, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(1.7018, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-2.4919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 474.5999827384949 seconds\n",
      "testing time = 0.056066274642944336 seconds\n",
      "\n",
      "Training with split 4\n",
      "final loss = 1.017509\n",
      "rmse_mc = tensor(1.2094, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(1.2019, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-2.4613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 474.48068141937256 seconds\n",
      "testing time = 0.05627751350402832 seconds\n",
      "\n",
      "Training with split 5\n",
      "final loss = 1.570419\n",
      "rmse_mc = tensor(1.0544, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "rmse_non_mc = tensor(1.0570, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "test_ll_mc = tensor(-2.4503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "training time = 480.18169689178467 seconds\n",
      "testing time = 0.053783416748046875 seconds\n",
      "\n",
      "Training with split 6\n"
     ]
    }
   ],
   "source": [
    "for subset_prop, hidden_dim, n_hidden, dropout_rate, reg_strength, n_predictions, n_epoch in itertools.product(\n",
    "    subset_proportions,\n",
    "    network_hidden_dims, network_hidden_layers,\n",
    "    network_dropout_rates, regularization_strengths,\n",
    "    prediction_runs, n_epochs,\n",
    "):\n",
    "    print(\n",
    "    \"subset %f, n_hidden %d, hidden_dim %d, dropout_rate %f, reg_strength %f\"\n",
    "    % (subset_prop, n_hidden, hidden_dim, dropout_rate, reg_strength))\n",
    "    \n",
    "    print(\"n_epoch %d\" % n_epoch)\n",
    "    print()\n",
    "\n",
    "    # Create directory to store results for the current test configuration\n",
    "    test_results_path = os.path.join(\n",
    "        './test_results',\n",
    "        'convergence_1',\n",
    "        dataset_name,\n",
    "        test_start_time,\n",
    "        (\n",
    "            str(subset_prop) \n",
    "            + '_' + str(hidden_dim) \n",
    "            + '_' + str(n_hidden) \n",
    "            + '_' + str(dropout_rate) \n",
    "            + '_' + str(reg_strength)\n",
    "            + '_' + str(n_epoch)),\n",
    "    )\n",
    "    \n",
    "    os.makedirs(test_results_path, exist_ok=True)\n",
    "    \n",
    "    test_results_rmse_mc_path = os.path.join(\n",
    "        test_results_path,\n",
    "        \"rmse_mc.txt\"\n",
    "    )\n",
    "    \n",
    "    test_results_lls_mc_path = os.path.join(\n",
    "        test_results_path,\n",
    "        \"lls_mc.txt\"\n",
    "    )\n",
    "\n",
    "    # Prepare new subset of the original dataset\n",
    "    subset = datasets.UCIDatasets(\n",
    "        dataset_name, root_dir='./datasets_files', \n",
    "        limit_size=subset_prop, transform=None, download=True)\n",
    "\n",
    "    # Determine sizes of training and testing set\n",
    "    train_size = int(dataset_train_size * len(subset))\n",
    "    test_size = len(subset) - train_size\n",
    "    \n",
    "    # Print the size of the subset\n",
    "    print(\"subset size = \" + str((len(subset), subset.n_features)))\n",
    "    print(\"training set size = %d\" % train_size)\n",
    "    print(\"test set size = %d\" % test_size)\n",
    "    print()\n",
    "    \n",
    "    # Prepare multiple sets of random train-test splits \n",
    "    # to test the parameter combination\n",
    "    subset_splits = []\n",
    "\n",
    "    for _ in range(n_splits):\n",
    "        train, test = random_split(subset, lengths=[train_size, test_size])\n",
    "        subset_splits.append((train, test))\n",
    "\n",
    "    # Try learning with different splits\n",
    "    for s, (train, test) in enumerate(subset_splits):\n",
    "        print('Training with split %d' % s)\n",
    "\n",
    "        train_loader = DataLoader(train, batch_size=n_training_batch, pin_memory=use_pin_memory)\n",
    "\n",
    "        # Prepare network\n",
    "        network = models.FCNetMCDropout(\n",
    "          input_dim=subset.n_features, \n",
    "          output_dim=subset.n_targets,\n",
    "          hidden_dim=hidden_dim,\n",
    "          n_hidden=n_hidden,\n",
    "          dropout_rate=dropout_rate,\n",
    "          dropout_type='bernoulli',\n",
    "        )\n",
    "\n",
    "        # Send the whole model to the selected torch.device\n",
    "        network.to(torch_device)\n",
    "\n",
    "        # Model to train mode\n",
    "        network.train()\n",
    "\n",
    "        # Adam optimizer\n",
    "        # https://pytorch.org/docs/stable/optim.html?highlight=adam#torch.optim.Adam\n",
    "        # NOTE: Need to set L2 regularization from here\n",
    "        optimizer = optim.Adam(\n",
    "            network.parameters(),\n",
    "            lr=0.01,\n",
    "            weight_decay=reg_strength, # L2 regularization\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "        Training\n",
    "        \"\"\"\n",
    "\n",
    "        # Record training start time (for this split)\n",
    "        tic = time.time()\n",
    "\n",
    "        for epoch in range(n_epoch): # loop over the dataset multiple times\n",
    "            # Mini-batches\n",
    "            for data in train_loader:\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs, targets = data\n",
    "\n",
    "                # Store the batch to torch_device's memory\n",
    "                inputs = inputs.to(torch_device)\n",
    "                targets = targets.to(torch_device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = network(inputs)\n",
    "\n",
    "                loss = objective(outputs, targets)\n",
    "                loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "        # Record training end time\n",
    "        toc = time.time()\n",
    "\n",
    "        # Report the final loss\n",
    "        print(\"final loss = %f\" % (loss.item()))\n",
    "\n",
    "        \"\"\"\n",
    "        Testing\n",
    "        \"\"\"\n",
    "\n",
    "        # Model to eval mode\n",
    "        network.eval()\n",
    "\n",
    "        # Get the test data\n",
    "        inputs, targets = test.dataset[test.indices]\n",
    "\n",
    "        # Store the batch to torch_device's memory\n",
    "        inputs = inputs.to(torch_device)\n",
    "        targets = targets.to(torch_device)\n",
    "\n",
    "        # Record testing start time\n",
    "        tic_testing = time.time()\n",
    "\n",
    "        _, mean, var, metrics = network.predict_dist(\n",
    "            inputs, n_predictions, y_test=targets, reg_strength=reg_strength)\n",
    "        \n",
    "        # Record testing end time\n",
    "        toc_testing = time.time()\n",
    "\n",
    "        # store additional metrics\n",
    "        if len(metrics) > 0:\n",
    "            for key, value in metrics.items():\n",
    "                print(str(key) + \" = \" + str(value))\n",
    "\n",
    "                if key == 'rmse_mc':\n",
    "                    with open(test_results_rmse_mc_path, 'a+') as rmse_mc_file:\n",
    "                        rmse_mc_file.write('%d %f \\n' % (s, value))\n",
    "\n",
    "                elif key == 'test_ll_mc':\n",
    "                    with open(test_results_lls_mc_path, 'a+') as lls_mc_file:\n",
    "                        lls_mc_file.write('%d %f \\n' % (s, value))\n",
    "                        \n",
    "        # Report the total training time\n",
    "        print(\"training time = \" + str(toc - tic) + \" seconds\")\n",
    "\n",
    "        # Report the total testing time\n",
    "        print(\"testing time = \" + str(toc_testing - tic_testing) + \" seconds\")\n",
    "\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pDxkRM5aVrdf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "experiment_convergence_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
